{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to David's Personal information repository! These were created with mkdocs For full documentation visit mkdocs.org . I'm also using mkdocs-material pip install mkdocs mkdocs-material Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to David's Personal information repository!"},{"location":"#welcome-to-davids-personal-information-repository","text":"","title":"Welcome to David's Personal information repository!"},{"location":"#these-were-created-with-mkdocs","text":"For full documentation visit mkdocs.org . I'm also using mkdocs-material pip install mkdocs mkdocs-material","title":"These were created with mkdocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"Motion_Graphs_2002/","text":"Motion Graphs Introduction Motion Graph is a structure that encodes how the captured clips may be re-assembled in different ways. It is a directed graph wherein edges contain either pieces of original motion data or automatically generated transitions. Each node is a choice point where small bits of motion join seamlessly. A motion graph is a direct graph where all edges correspond to clips of motion. Graph Walks are the issue of selecting sequences of nodes. Algorithms in graph theory create graph walks that satisfy certain criteria. Motion Graph Construction Because it's unlikely that two pieces of data are similar (houdini transition graph), we need to create cilps for that purpose. Transitions are clips desigened such that they can seamlessly connect two segments of original data. This is hard, so we look for similar portions of the clips where linear blending can provide a good result. (lol just like sidefx after all) Detecting Candidate transitions Why to not simply locate transition points by computing some vector norm to measure the difference between poses at each pair of frames: Meaning of Parameters. (A finger joint dose not has as much influence as the hips do) Neet to compare in the space of the agent You need to analyze multiple frames. Transitions must account not only for pose but also for velocity, accelleration, and maybe more. They use a point cloud similarity driven by the skeleton to measure similarity. This will be very similar to how the skinned geometry will deform, as that's the final ground truth of wether the transition will be effective. Ideally this is a downsampling of the skinned mesh of the agent To be cont!","title":"Motion Graphs"},{"location":"Motion_Graphs_2002/#motion-graphs","text":"","title":"Motion Graphs"},{"location":"Motion_Graphs_2002/#introduction","text":"Motion Graph is a structure that encodes how the captured clips may be re-assembled in different ways. It is a directed graph wherein edges contain either pieces of original motion data or automatically generated transitions. Each node is a choice point where small bits of motion join seamlessly. A motion graph is a direct graph where all edges correspond to clips of motion. Graph Walks are the issue of selecting sequences of nodes. Algorithms in graph theory create graph walks that satisfy certain criteria.","title":"Introduction"},{"location":"Motion_Graphs_2002/#motion-graph-construction","text":"Because it's unlikely that two pieces of data are similar (houdini transition graph), we need to create cilps for that purpose. Transitions are clips desigened such that they can seamlessly connect two segments of original data. This is hard, so we look for similar portions of the clips where linear blending can provide a good result. (lol just like sidefx after all)","title":"Motion Graph Construction"},{"location":"Motion_Graphs_2002/#detecting-candidate-transitions","text":"Why to not simply locate transition points by computing some vector norm to measure the difference between poses at each pair of frames: Meaning of Parameters. (A finger joint dose not has as much influence as the hips do) Neet to compare in the space of the agent You need to analyze multiple frames. Transitions must account not only for pose but also for velocity, accelleration, and maybe more. They use a point cloud similarity driven by the skeleton to measure similarity. This will be very similar to how the skinned geometry will deform, as that's the final ground truth of wether the transition will be effective. Ideally this is a downsampling of the skinned mesh of the agent","title":"Detecting Candidate transitions"},{"location":"Motion_Graphs_2002/#to-be-cont","text":"","title":"To be cont!"},{"location":"Game%20Engine/Cherno_Game_Engine/002_Designing_our_GAME_ENGINE/","text":"We need to start by building the minimal groundwork we need first so that we can then start iterating. Need to focus on what's achievable by us. Basic overview of what the engine will need in a bare bones way: Entry Point Launch the application and what happens? What gets executed with the main function? What controls what happens? Application Layer A section of our ode that deals with application lifestyle and events. What keeps time going forward? Timeline? Intput events? Window layer Technically this only exists on desktop platforms. It's different than mobile platforms where the \"app\" handles everything. This deals with input & events. This also handles recirving and sending events. It should also allow querying the state of an intput device. Renderer This is obviously a huge part of game engine development. Render API abstraction For me this will probably be and stay opengl, but it would be worth abstracting for a potential vulkan implementation. By far this is one of the most interesting and complicated pars of a game engine. Debugging support What does it mean to add debugging support to an application? We need good ways to figure out what's going on. Something like a logging system. Get a profiling system, so you can get logistics on any platform. Something that times every function. Scripting Basic scripting language build in. That way we can write scripts and make things easy for artists Memory Systems Memory is a huge deal with performance, and it's something that we want to be able to inspect. Entitiy-component System (ECS) A way to include components and systems with game entity objects. Objects, Actors, Constraints etc. How to attach entities to each other. Pysics Solution At first I balked at this, but it would be really useful to have ragdolls. Not a first level priority, but something to add ad some point. Build System Pre-optimize scenes/background caching something simlar. There are many things vfx can learn from game engine techniques. Reload assets in realtime. Collaborative editing? How do things interact with the filesystem? Next up... get started!","title":"002 Designing our GAME ENGINE"},{"location":"Game%20Engine/Cherno_Game_Engine/008_Planning_the_Event_System/","text":"Planning the Event System This is another planning session. Here we think about how we will deal with window events that we might receive. This is being done before the window system is added. Right now we have an Application Class. This needs to be able to receive events and dispatch them to something we're going to call \"layers\". More on that in a future vid. Just know that this is what evens will be propagated to. So we also have a Window class. This is a representation of our actual application window. Stuff comes in through the window class. But we don't want to tie our application to our window class. The Application creates and maintains the window class, but this should be through an api layer. So our window class will receive an event, and this then needs to get translated into a Choreo event. So we need an Event class which has all the details about an event that has occurred. And we need Application to provide window a callback that it can tie to these events. This could be just a function pointer, or something more abstract. This is so that ever time the window gets and event, it can call the callback. Window gets notified about which function to use, which will be called from within application. Through all of this window never stores a direct reference to application. Then we can expand to something like a buffered event system etc etc. But that's something to explore in the future. So we need classes for all the events, event dispatcher, listener etc.","title":"Planning the Event System"},{"location":"Game%20Engine/Cherno_Game_Engine/008_Planning_the_Event_System/#planning-the-event-system","text":"This is another planning session. Here we think about how we will deal with window events that we might receive. This is being done before the window system is added. Right now we have an Application Class. This needs to be able to receive events and dispatch them to something we're going to call \"layers\". More on that in a future vid. Just know that this is what evens will be propagated to. So we also have a Window class. This is a representation of our actual application window. Stuff comes in through the window class. But we don't want to tie our application to our window class. The Application creates and maintains the window class, but this should be through an api layer. So our window class will receive an event, and this then needs to get translated into a Choreo event. So we need an Event class which has all the details about an event that has occurred. And we need Application to provide window a callback that it can tie to these events. This could be just a function pointer, or something more abstract. This is so that ever time the window gets and event, it can call the callback. Window gets notified about which function to use, which will be called from within application. Through all of this window never stores a direct reference to application. Then we can expand to something like a buffered event system etc etc. But that's something to explore in the future. So we need classes for all the events, event dispatcher, listener etc.","title":"Planning the Event System"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/","text":"[Nucl.ai 2015] Motion Matching - The Road to Next Gen Animation What can MotionFields do? The well known video. Uses about 20 min of mocap data. How do traditional animation systems work? Usually yo uhave a bunch of clips you want to use and blend together smartly using Blend Trees and State Machines. There you manually decide which animatino go together. For locomotion we usually parametrerize on direction and speed Then we retime the animations to match the speeds, mark-up animations, and make sure their sync-tracks have the same \"starting\" event. Manually set the foot steps in order to synchronize the feet speeds. This is a lot of manual work and very error prone. Alternatively you have Parametric Blending (\"blend space\") which arranges a family of animations based on their parametrization The problem with this is that it does not properly account for weight shifting Then you put these blend spaces into state machines... which quickly end up in a spiderweb of transitions and edge cases. Then you add Strafing , slopes, uneven terrain, plants, turns and it's all a very long, tedious manual process. This is like a fruit-fly-counting-robot. And with all these edits we lost a lot of fidelity from the original mocap data. You lose the complex weight shifts needed for directional changes. Human Movement != Loops How can we Reduce the complexity and Improve the quality? Lets's have a closer lookat the ground truth -> Raw MoCap. It's great to start with a moveset that includes the largest possible combinations of how homans move around. How are MotionFields implemented So now you have an animation rig which we refer to as an Animated Hierarchy . Everything is in local space except for the hips. Then we have a mesh rig bound to this, and then a dynamics rig bround to that. Examining the simple case Let's simplify the problem before solving the general case by only looking at 3 individual \"clips\" and ignoring the problem of finding a matching pose. With traditional naimation clips, we control trajectory movement indirectly, by modifying a blend-weight. We know where we want our character to move to, and then blend the animations based off that blend weight. Now we do it the other way around, we have to select the right animation by selecting based on a desired path trajectory. So how do we match trajectory curves? To calculate the similarity we calculate the different in trajectories at a sample interval, take the differnce, and sum them up. For this we can directly use the raw mocap data, but we just have a large number of possible trajectories. We will now redefine what we amean when we refer to a pose: A pose is defined as the joint transforms including a trjectory section. i.e. a trajectory section is always associated with a pose. This does not require a different storage mechanism, it's jsut a different mental model. The length of the trajectory section is our \"planning horizon\". Given some MoCap keyframe, we can transform eac hsubsequent keyframe by the inverse of the virst keyframe. (Transform the target trajectory to compare to the origin). Gameplay in video games, create a desired trajectory which is what we are using. // Get the desired trajetory to compare against Transform currentTransform ( GetTransform ()); const Vector3 linearVelocity ( GetLinearVelocity ()); float elapsedTime ( 0.0f ); // how far ahead you want the character to \"plan\" it's trajectory const float timeHorizon ( 1.0f ); const float deltaTime ( 1.0f / 30.0f ); // you can use any other smoothing function // to smooth the current velocity of the character // into the desired velocity of the character // to generate the desired trajectory sample positions float ExponentialDecay ( const float target , const float current , const float lambda ){ return target + ( current - target ) / ( w .0f , + lambda + 0.5f * lambda * lambda ); } while ( elapsedTime < timeHorizon ){ currentTransform += linearVelocity * deltatime ; linarVelocity = ExponentialDecay ( linaryVelocity , targetLinearVelocity , deltaTime / ( timeHorizon - elapsedTime ) ); } We can change the velocity at every integration step. Gameplay code dictates how this desired movement is generated based on the desired set of actions. AI characters generate a pathfinder path to generate a predicted trajectory. How to actually select the animations? Loop over all available poses and find the best match based on the above comparison? uint32_t FindBestMatch ( const MotionField & motionField ){ uint32_t bestFrame ( static_cast < uint32_t > ( -1 )); float minCost ( FLT_MAX ); const uint32_t numFrames ( motionField . getNumFrames ()); for ( uint32_t i { 0 }; i < numFrames ; ++ i ){ const float cost ( EvaluateCose ( i , motionField )); if ( cost < minCose ){ minCose = cost ; bestFrame = i ; } } return bestFrame ; } If this would ever run fast enough, transitions would be handled automatically. Looping animations would just be special cases. The problem with this approach, is that it tends to only play the same pose for every location - not really advancing in the animation. The good thing is that there are no dramatic pops and you can control the velocity and trajectory really well. The problem is that we are not matching poses, and there is no incentive for the character to \"play through\" an animation. Ideally the amount of trajectory matching and the amount of pose matching are controlled by inputs to the FindBestMatch. This way we can control how well a \"candicdate pose\" matches as well as an associated trajectory matches. Because all our animations are in local space, and our trajectories are in glbal space. To compare the positions, we will need the joint positions in global space. One of the most common mistakes is to use all the joings of the skeleton when comparing poses. We're only really interested in where our foot positions are. Hands aren't that important. Only use the joints of the particular movement that we are interested in. The joints used depend on the type of movement. We are only interested in a subset of the available data. This subset is stored in a separate memory location in a cache-friendly compressed format. We refer to this subset as **\"MetaData\". We only use this for pose and trajectory comparison. MetaData is always stored in character space. This leads to much better results, but it's still not very smooth, because we are not respecting the Velocity . Velocity matching is much better than just trajectory matching - we need to match against the rate of change of position (velocity). The error margine is simply the difference in the velocities. This still leaves the problem of the weight shifting. For this we use Past Matching + Position and Velocity for trajectories. We use the history of previous position and velocity to match against a forward and backward tie horizon. This allows to distinguish between monotonic and non-monotonic curves. So the cost function can be written like this \\[ C\\downarrow p(x) + C\\downarrow f(x) + C \\downarrow h(x) \\] The Cost of the position, the future trajectory, and the past (history) of the trajectory. float CurrentCost ( const uint32_t frame ){ float cost = 0.0f ; // Add the right and left foot velocities and positions cost += 3 * RF . Current . Pos - RF . Candidate . Pos ; cost += 6 * RF . Current . Vel - RF . Candidate . Vel ; cost += 3 * LF . Current . Pos - LF . Candidate . Pos ; cost += 6 * LF . Current . Vel - LF . Candidate . Vel ; return cost } // run this twice with the future and past trajectories float Trajectory Cost ( const uint32_t frame ){ float cost = 0.0f ; cost += 3 * R . Predicted . Pos - R . Candidate . Pos ; cost += 2 * R . Predicted . Vel - R . Candidate . Vel ; return cost ; } Every frame we compare these for all the avaliable animations, and then if there is a better animation than the one currently playing we switch to that. This is a Simple Hill Climbing algorithm. The lambda values control quality vs responsiveness. Because we don't want to define these objective functions directly in the code, we need to abstract these constraints and parameters as impose. One thing that's interesting though is that the \"Current\" and lambdas are constant, and there is a stream of \"Candidates\". All of this operates on the same metadata, which starts sounding a lot like Vertex and Pixel shaders. These cost functions can be thought of as \"shaders\" that get executed 30,000+ times a frame with the same input data. Motion Shaders struct Metadata { Vector3 rightFootPosition ; Vector3 rightFootVelocity ; } Create a node graph that looks like this and at compiletime generate a struct that only includes the data that is needed The interesting part is that we can now access our data directly from the struct, and compile into superfast sses. Using Motion shaders brought this down to 400 cycles about. Essentially this is a bounded unconstrained optimization problem \\[ min \\vdash x C \\downarrow p (x) + C \\downarrow f(x) + C \\downarrow h (x) : \\natnums \\rightarrow \\reals \\] You can use online learning to remember the winning candidate for every stick input. This requires traning step every time animation set changes. We have a worst case for a steepest descent algorithm, but there is not guarantee on the upper bounds. We could find the minima for each objective function and then compare all of those, and evaluate the full objective fucntion for all arguments. But this still doesn't change the fact that the objective function depends on the prediction model - it changes every frame . The objective function depends on the preduction model, removing the predeiction model from the function turns into a Nearest neighbor search (NNS) *. kNN is a classification algorithm. Given some varying point in a high dimensional space return the best matches. Buildign connectivity graphs does not work (too explicit). Instead we store how clsoe objects are (expressed in terms of a dissimilarity functino) Given a set s of points in a space M and a query point q find the closest opint in s to q Which Term should we use? We could use the pose term, or the trajectory term, and then simply find the closest point to the end of the trajectory. So with that you can get the 500 closest trajectories, and then evaluate the poses on those to find the global minimum. Alternatively you could find the 500 most matching poses, and then get the global minimum of those, but it's much better to find the closest trajectory neighbors. To do this we take x number of subsamples per trajectory, and then compare against those. Each has it's own velocity and position attribute, and we minimize for those two. This is 18 scalar values, which can be visualized as an 18 dimensional minimization. Multi-Dimensional Scaling Try to find a solution that yields a visual result. MDS aims to place each object in N-dimensional space such that the betwee-object distances are preserved as well as possible. const float d ( 1.0f ); float dissimilarity ( 0.0f ); for ( float t = 0.0f ; t <= 1.0f ; t += d ){ dissimilarity += f ( t ) - g ( t ); } So you can caluclate the distance here in 18 dimensional spece by calculating the difference of each corresponding vector. This essentially generates a point cloud from which you can sample the cloests point to the desired point. Another attempt at optimizing this was using Kd-Trees, which perform exponentially worse in higher dimensions (int terms of number cells to visit) but yeild near perfect results. They are great for caching and using splits. The final algorithm now looks like this: uint32_t FindBestMatch ( const MotionField & motionField , const PredictionModel & predictionModel , const uint32_t numNeighbors ){ uint32_t bestFrame ( static_cast < uint32_t > ( -1 )); float minCost ( FLT_MAX ); STACK_ARRAY ( uint32_t , nearestNeighbors , numNeighbors ); motionField . getNearestNeighbors ( nearestNeighbors , numNeighbors ); const MotionShader & motionShader = motionField . getMotionShader (); for ( uint32_t i { 0 }, i < numNeighbors ; ++ i ){ const float cost ( motionShader . Run ( i , predictionModel )); if ( cost < minCose ){ minCost = cost ; bestFrame = i ; } } return bestFrame ; } Performance Metadata fits int ~2 cache lines Data oriented design is key. The time it takes to read the data out of memory is the bottleneck. Memory wise we only use 20% of the actual poses, so you could optimze this with dynamic proning potentially. Inside Traditional Systems It is a drop-in replacement for entire movement systems. Able to replace blend trees pretty well. This of it as an animation source node. It's a little difficult to synchronize layers, because you don't have tracks really. For the runtime side of the system, we have the dunamics rig on top of the animation rig. It's really powerful to add new motion / replace motion. No lengthy setup and taggin. This allows animators focus on making movements instead of tweaking parameters. Drawbacks are the lack of control, and difficulty to change style.","title":"[Nucl.ai 2015] Motion Matching - The Road to Next Gen Animation"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#nuclai-2015-motion-matching-the-road-to-next-gen-animation","text":"","title":"[Nucl.ai 2015] Motion Matching - The Road to Next Gen Animation"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#what-can-motionfields-do","text":"The well known video. Uses about 20 min of mocap data.","title":"What can MotionFields do?"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#how-do-traditional-animation-systems-work","text":"Usually yo uhave a bunch of clips you want to use and blend together smartly using Blend Trees and State Machines. There you manually decide which animatino go together. For locomotion we usually parametrerize on direction and speed Then we retime the animations to match the speeds, mark-up animations, and make sure their sync-tracks have the same \"starting\" event. Manually set the foot steps in order to synchronize the feet speeds. This is a lot of manual work and very error prone. Alternatively you have Parametric Blending (\"blend space\") which arranges a family of animations based on their parametrization The problem with this is that it does not properly account for weight shifting Then you put these blend spaces into state machines... which quickly end up in a spiderweb of transitions and edge cases. Then you add Strafing , slopes, uneven terrain, plants, turns and it's all a very long, tedious manual process. This is like a fruit-fly-counting-robot. And with all these edits we lost a lot of fidelity from the original mocap data. You lose the complex weight shifts needed for directional changes. Human Movement != Loops How can we Reduce the complexity and Improve the quality? Lets's have a closer lookat the ground truth -> Raw MoCap. It's great to start with a moveset that includes the largest possible combinations of how homans move around.","title":"How do traditional animation systems work?"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#how-are-motionfields-implemented","text":"So now you have an animation rig which we refer to as an Animated Hierarchy . Everything is in local space except for the hips. Then we have a mesh rig bound to this, and then a dynamics rig bround to that.","title":"How are MotionFields implemented"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#examining-the-simple-case","text":"Let's simplify the problem before solving the general case by only looking at 3 individual \"clips\" and ignoring the problem of finding a matching pose. With traditional naimation clips, we control trajectory movement indirectly, by modifying a blend-weight. We know where we want our character to move to, and then blend the animations based off that blend weight. Now we do it the other way around, we have to select the right animation by selecting based on a desired path trajectory. So how do we match trajectory curves? To calculate the similarity we calculate the different in trajectories at a sample interval, take the differnce, and sum them up. For this we can directly use the raw mocap data, but we just have a large number of possible trajectories. We will now redefine what we amean when we refer to a pose: A pose is defined as the joint transforms including a trjectory section. i.e. a trajectory section is always associated with a pose. This does not require a different storage mechanism, it's jsut a different mental model. The length of the trajectory section is our \"planning horizon\". Given some MoCap keyframe, we can transform eac hsubsequent keyframe by the inverse of the virst keyframe. (Transform the target trajectory to compare to the origin). Gameplay in video games, create a desired trajectory which is what we are using. // Get the desired trajetory to compare against Transform currentTransform ( GetTransform ()); const Vector3 linearVelocity ( GetLinearVelocity ()); float elapsedTime ( 0.0f ); // how far ahead you want the character to \"plan\" it's trajectory const float timeHorizon ( 1.0f ); const float deltaTime ( 1.0f / 30.0f ); // you can use any other smoothing function // to smooth the current velocity of the character // into the desired velocity of the character // to generate the desired trajectory sample positions float ExponentialDecay ( const float target , const float current , const float lambda ){ return target + ( current - target ) / ( w .0f , + lambda + 0.5f * lambda * lambda ); } while ( elapsedTime < timeHorizon ){ currentTransform += linearVelocity * deltatime ; linarVelocity = ExponentialDecay ( linaryVelocity , targetLinearVelocity , deltaTime / ( timeHorizon - elapsedTime ) ); } We can change the velocity at every integration step. Gameplay code dictates how this desired movement is generated based on the desired set of actions. AI characters generate a pathfinder path to generate a predicted trajectory.","title":"Examining the simple case"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#how-to-actually-select-the-animations","text":"Loop over all available poses and find the best match based on the above comparison? uint32_t FindBestMatch ( const MotionField & motionField ){ uint32_t bestFrame ( static_cast < uint32_t > ( -1 )); float minCost ( FLT_MAX ); const uint32_t numFrames ( motionField . getNumFrames ()); for ( uint32_t i { 0 }; i < numFrames ; ++ i ){ const float cost ( EvaluateCose ( i , motionField )); if ( cost < minCose ){ minCose = cost ; bestFrame = i ; } } return bestFrame ; } If this would ever run fast enough, transitions would be handled automatically. Looping animations would just be special cases. The problem with this approach, is that it tends to only play the same pose for every location - not really advancing in the animation. The good thing is that there are no dramatic pops and you can control the velocity and trajectory really well. The problem is that we are not matching poses, and there is no incentive for the character to \"play through\" an animation. Ideally the amount of trajectory matching and the amount of pose matching are controlled by inputs to the FindBestMatch. This way we can control how well a \"candicdate pose\" matches as well as an associated trajectory matches. Because all our animations are in local space, and our trajectories are in glbal space. To compare the positions, we will need the joint positions in global space. One of the most common mistakes is to use all the joings of the skeleton when comparing poses. We're only really interested in where our foot positions are. Hands aren't that important. Only use the joints of the particular movement that we are interested in. The joints used depend on the type of movement. We are only interested in a subset of the available data. This subset is stored in a separate memory location in a cache-friendly compressed format. We refer to this subset as **\"MetaData\". We only use this for pose and trajectory comparison. MetaData is always stored in character space. This leads to much better results, but it's still not very smooth, because we are not respecting the Velocity . Velocity matching is much better than just trajectory matching - we need to match against the rate of change of position (velocity). The error margine is simply the difference in the velocities. This still leaves the problem of the weight shifting. For this we use Past Matching + Position and Velocity for trajectories. We use the history of previous position and velocity to match against a forward and backward tie horizon. This allows to distinguish between monotonic and non-monotonic curves. So the cost function can be written like this \\[ C\\downarrow p(x) + C\\downarrow f(x) + C \\downarrow h(x) \\] The Cost of the position, the future trajectory, and the past (history) of the trajectory. float CurrentCost ( const uint32_t frame ){ float cost = 0.0f ; // Add the right and left foot velocities and positions cost += 3 * RF . Current . Pos - RF . Candidate . Pos ; cost += 6 * RF . Current . Vel - RF . Candidate . Vel ; cost += 3 * LF . Current . Pos - LF . Candidate . Pos ; cost += 6 * LF . Current . Vel - LF . Candidate . Vel ; return cost } // run this twice with the future and past trajectories float Trajectory Cost ( const uint32_t frame ){ float cost = 0.0f ; cost += 3 * R . Predicted . Pos - R . Candidate . Pos ; cost += 2 * R . Predicted . Vel - R . Candidate . Vel ; return cost ; } Every frame we compare these for all the avaliable animations, and then if there is a better animation than the one currently playing we switch to that. This is a Simple Hill Climbing algorithm. The lambda values control quality vs responsiveness. Because we don't want to define these objective functions directly in the code, we need to abstract these constraints and parameters as impose. One thing that's interesting though is that the \"Current\" and lambdas are constant, and there is a stream of \"Candidates\". All of this operates on the same metadata, which starts sounding a lot like Vertex and Pixel shaders. These cost functions can be thought of as \"shaders\" that get executed 30,000+ times a frame with the same input data.","title":"How to actually select the animations?"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#motion-shaders","text":"struct Metadata { Vector3 rightFootPosition ; Vector3 rightFootVelocity ; } Create a node graph that looks like this and at compiletime generate a struct that only includes the data that is needed The interesting part is that we can now access our data directly from the struct, and compile into superfast sses. Using Motion shaders brought this down to 400 cycles about. Essentially this is a bounded unconstrained optimization problem \\[ min \\vdash x C \\downarrow p (x) + C \\downarrow f(x) + C \\downarrow h (x) : \\natnums \\rightarrow \\reals \\] You can use online learning to remember the winning candidate for every stick input. This requires traning step every time animation set changes. We have a worst case for a steepest descent algorithm, but there is not guarantee on the upper bounds. We could find the minima for each objective function and then compare all of those, and evaluate the full objective fucntion for all arguments. But this still doesn't change the fact that the objective function depends on the prediction model - it changes every frame . The objective function depends on the preduction model, removing the predeiction model from the function turns into a Nearest neighbor search (NNS) *. kNN is a classification algorithm. Given some varying point in a high dimensional space return the best matches. Buildign connectivity graphs does not work (too explicit). Instead we store how clsoe objects are (expressed in terms of a dissimilarity functino) Given a set s of points in a space M and a query point q find the closest opint in s to q Which Term should we use? We could use the pose term, or the trajectory term, and then simply find the closest point to the end of the trajectory. So with that you can get the 500 closest trajectories, and then evaluate the poses on those to find the global minimum. Alternatively you could find the 500 most matching poses, and then get the global minimum of those, but it's much better to find the closest trajectory neighbors. To do this we take x number of subsamples per trajectory, and then compare against those. Each has it's own velocity and position attribute, and we minimize for those two. This is 18 scalar values, which can be visualized as an 18 dimensional minimization.","title":"Motion Shaders"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#multi-dimensional-scaling","text":"Try to find a solution that yields a visual result. MDS aims to place each object in N-dimensional space such that the betwee-object distances are preserved as well as possible. const float d ( 1.0f ); float dissimilarity ( 0.0f ); for ( float t = 0.0f ; t <= 1.0f ; t += d ){ dissimilarity += f ( t ) - g ( t ); } So you can caluclate the distance here in 18 dimensional spece by calculating the difference of each corresponding vector. This essentially generates a point cloud from which you can sample the cloests point to the desired point. Another attempt at optimizing this was using Kd-Trees, which perform exponentially worse in higher dimensions (int terms of number cells to visit) but yeild near perfect results. They are great for caching and using splits. The final algorithm now looks like this: uint32_t FindBestMatch ( const MotionField & motionField , const PredictionModel & predictionModel , const uint32_t numNeighbors ){ uint32_t bestFrame ( static_cast < uint32_t > ( -1 )); float minCost ( FLT_MAX ); STACK_ARRAY ( uint32_t , nearestNeighbors , numNeighbors ); motionField . getNearestNeighbors ( nearestNeighbors , numNeighbors ); const MotionShader & motionShader = motionField . getMotionShader (); for ( uint32_t i { 0 }, i < numNeighbors ; ++ i ){ const float cost ( motionShader . Run ( i , predictionModel )); if ( cost < minCose ){ minCost = cost ; bestFrame = i ; } } return bestFrame ; }","title":"Multi-Dimensional Scaling"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#performance","text":"Metadata fits int ~2 cache lines Data oriented design is key. The time it takes to read the data out of memory is the bottleneck. Memory wise we only use 20% of the actual poses, so you could optimze this with dynamic proning potentially.","title":"Performance"},{"location":"Motion%20Matching/Nucl.ai2015MotionMatching_TheRoadtoNextGenAnimation/#inside-traditional-systems","text":"It is a drop-in replacement for entire movement systems. Able to replace blend trees pretty well. This of it as an animation source node. It's a little difficult to synchronize layers, because you don't have tracks really. For the runtime side of the system, we have the dunamics rig on top of the animation rig. It's really powerful to add new motion / replace motion. No lengthy setup and taggin. This allows animators focus on making movements instead of tweaking parameters. Drawbacks are the lack of control, and difficulty to change style.","title":"Inside Traditional Systems"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/","text":"These are a dump from some google doc notes I was working on and I'm not sure if I will be formatting them, as I've decided to work through learncpp.com instead. Introduction C++ is a strongly typed language = each object has a predefined data type State = what the object stores Operations = it\u2019s behaviour Variable = Named object Declare variable with = int the_answer=42; Functions take in parameters or arguments Return output objects to their callers printf(\"Ten %du, Twenty %dv, Thirty %dw\", 10x, 20y, 30z); Must be defined before called by the compiler Signed: positive, negative, or zero Unsigned: non-negative Int = signed and int by default (watch the type in the format specifier for printf) Literal = hardcoded value in a program Floats Precision = how much memory it takes up and how detailed the value is. Float = single precision Double = double precision Long double = extended precision (generally just use a double) Floating point Literals Float a = 0.1F; Double b = 1.2; Long double c = 0.3L; You can use scientific notation in literals: Double plancks_constant = 6.62607004e-34 (no spaces) Character Types Character = a single keyboard input Char = 1 byte char16_t = utf-16 char32_2 = utf-32 Wchar_t = large enough to contain the largest character of the implementation locale Character literal = single, constant character. Boolean Only one type with 2 states Ints can be bools interchangeably. AND (&&) OR (||) are binary Std::byte = \u201cstood byte\u201d Sizeof returns a std:size_t object void = function doesn\u2019t return anything Arrays Define them like in vex sizeof(array) / sizeof(short) For loop for(init-statement; conditional; iteration-statement){} It understands how to iterate over each value of an array type for(element-type element-name : array-name){} String Literals Use quotes and supports unicode. User-Defined Types Enumeration Types The simplest of the user-defined types. The values that an enumeration can take are restricted to a set of possible values. Enumeration are excellent for modeling categorical concepts. Basically enums Switch statement: transfers control depending on the value of a condition. switch(condition){ case(case-a):{} case(case-b):{} default:{} } POD Classes Fully features types that give flexibility to pair data and functions. Classes that only contain data are data classes Simple containers. Struct Book{ Char name[256]; Int year; } Book neuromancer; Neuromancer.pages = 271 Union Types Dangerous and easy to misuse. Fully Featured C++ Classes Encapsulation = design pattern that binds data with the functions that manipulate it. Put related code in one place. Information hiding = Hide some of the code from the rest of your program Access controls = public and private. Only the class can access it\u2019s private members. Class invariant: a feature of a class that is always true (it never varies) Constructors Special methods with special declarations Basically make a method that is called the class name. Braced initialization=uniform initialization Always init with int = {} (always 0) Int array_1[]{1, 2, 3} You can have multiple constructors that react to different input types Destructor (optional) Call this when the object is destroyed Struct Earth { Earth() { // earths destructor printf(\u201cMaking way for hyperspace bypass\u201d) } } Reference Types These store the memory addresses of objects. Pointers = fundamental mechanism used to refer to memory addresses int my_ptr; Dereferency by my_ptr This will write to that address like so my_ptr = 34532 Otherwise it will reference the value of the address my_func( my_ptr) -> Member-of-Pointer Operator Dereferences (traverses) pointer Accesses member of that pointed-to-object Same as (*my_ptr).function(); Points and Arrays Creating a pointer pointing at an array will only point at the first value of that array You can access elements with brackets just like with arrays though Do not try to access out-of-bounds elements!! And NEVER assign to out of bounds memory!! You access and treat arrays and pointsers almost exactly the same. You can also dereference and array You can assign the fourth element like this as well *(array + 4) = val Note that adding to the array decays it into a pointer to that element Void pointers and std:byte Pointers They don\u2019t care about the type that they are pointing to. You cannot dereference a void* Void arithmetic is prohibited nullptr and Boolen Expressions Can use this to indicate that something failed Any value that is not nullptr = true, nullptr = false Function can return pointer to an object and nullptr if failed References& Safer and more convenient version of pointers They cannot be null, or researted (reassigned) If you try to assign them a new value the new value gets assigned to the ref value Forward-Linked Lists: Simple data structure made up of a series of elements. Each element holds a pointer to the next element. Last element holds nullptr Elements can be discontinuous in memory Basically lists that you can dynamically change the length of. this Pointers Access the current object Bit more verbose than just accessing the variables const Correctness Means this value will not be modified. Use to specify that a reference or pointer cannot be changed in a function. const methods are read only A const argument can only call const methods of itself Member Initializer Lists The only way to init const values class Thing{ Thing(const char* name) : name { name }{}} auto Type Deduction Instead of spelling out the class type of a variable auto year{2020} //int auto& year{2020} // int& (reference) auto year{2020} //int (pointer) Great for for loops that might have their type changed. Object Life Cycle Allocation = reserving space for objecting Deallocation = releasing that storage Automatic object = allocated at the beginning of a code block and deallocated at the end Function parameters, anything inside that function, all local variables Static object = global They are deallocated when the program stops. Extern = global outside the translation unit local static variable = local but doesn\u2019t get cleaned up. Variable keeps value after first initialization call of function Static members = members of a class that aren\u2019t associated with a particular instance of the class. Changing them changes them for all instances of the class that are active Refer to them using the scope resolution operator :: Must be initialized at global scope unless they are const Thread-Local Storage Duration Thread of execution = sequence of instructions that a thread executes Mutable global variables are the source of much non thread-safe code You can give each thread a copy of a variable by using thread_local keyword to the static or extern This will make a copy of the variable for each thread so that they cannot be writing to it at the same time Dynamic Storage Duration You create dynamic objects with the new expression (i.e. new int{42}) You need to deallocate them with the delete expression The object still exists for a bit after it has been deleted causing the program to appear to function correctly (pyside), but then when it\u2019s cleaned up crash randomly. Dynamic Arrays The size can\u2019t be changed but they have a dynamic storage duration New MyType[n_elements] {init-list} Returns a pointer to the first element of the array Exceptions Types that communicate an error condition Use throw keyword followed by throwable object like std::runtime_error Using try-catch Blocks These are exception handlers for a block of code Catch block specifies a handler for each exception type you can handle It\u2019s a way of anticipaoing that something might be thrown and logging it","title":"CCrashCourseAFastPacedIntroduction"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#introduction","text":"C++ is a strongly typed language = each object has a predefined data type State = what the object stores Operations = it\u2019s behaviour Variable = Named object Declare variable with = int the_answer=42;","title":"Introduction"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#functions","text":"take in parameters or arguments Return output objects to their callers printf(\"Ten %du, Twenty %dv, Thirty %dw\", 10x, 20y, 30z); Must be defined before called by the compiler Signed: positive, negative, or zero Unsigned: non-negative Int = signed and int by default (watch the type in the format specifier for printf) Literal = hardcoded value in a program","title":"Functions"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#floats","text":"Precision = how much memory it takes up and how detailed the value is. Float = single precision Double = double precision Long double = extended precision (generally just use a double)","title":"Floats"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#floating-point-literals","text":"Float a = 0.1F; Double b = 1.2; Long double c = 0.3L; You can use scientific notation in literals: Double plancks_constant = 6.62607004e-34 (no spaces)","title":"Floating point Literals"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#character-types","text":"Character = a single keyboard input Char = 1 byte char16_t = utf-16 char32_2 = utf-32 Wchar_t = large enough to contain the largest character of the implementation locale Character literal = single, constant character.","title":"Character Types"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#boolean","text":"Only one type with 2 states Ints can be bools interchangeably. AND (&&) OR (||) are binary Std::byte = \u201cstood byte\u201d Sizeof returns a std:size_t object void = function doesn\u2019t return anything","title":"Boolean"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#arrays","text":"Define them like in vex sizeof(array) / sizeof(short)","title":"Arrays"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#for-loop","text":"for(init-statement; conditional; iteration-statement){} It understands how to iterate over each value of an array type for(element-type element-name : array-name){}","title":"For loop"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#string-literals","text":"Use quotes and supports unicode.","title":"String Literals"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#user-defined-types","text":"","title":"User-Defined Types"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#enumeration-types","text":"The simplest of the user-defined types. The values that an enumeration can take are restricted to a set of possible values. Enumeration are excellent for modeling categorical concepts. Basically enums Switch statement: transfers control depending on the value of a condition. switch(condition){ case(case-a):{} case(case-b):{} default:{} }","title":"Enumeration Types"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#pod-classes","text":"Fully features types that give flexibility to pair data and functions. Classes that only contain data are data classes Simple containers. Struct Book{ Char name[256]; Int year; } Book neuromancer; Neuromancer.pages = 271","title":"POD Classes"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#union-types","text":"Dangerous and easy to misuse.","title":"Union Types"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#fully-featured-c-classes","text":"Encapsulation = design pattern that binds data with the functions that manipulate it. Put related code in one place. Information hiding = Hide some of the code from the rest of your program Access controls = public and private. Only the class can access it\u2019s private members. Class invariant: a feature of a class that is always true (it never varies)","title":"Fully Featured C++ Classes"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#constructors","text":"Special methods with special declarations Basically make a method that is called the class name. Braced initialization=uniform initialization Always init with int = {} (always 0) Int array_1[]{1, 2, 3} You can have multiple constructors that react to different input types","title":"Constructors"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#destructor-optional","text":"Call this when the object is destroyed Struct Earth { Earth() { // earths destructor printf(\u201cMaking way for hyperspace bypass\u201d) } }","title":"Destructor (optional)"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#reference-types","text":"These store the memory addresses of objects. Pointers = fundamental mechanism used to refer to memory addresses int my_ptr; Dereferency by my_ptr This will write to that address like so my_ptr = 34532 Otherwise it will reference the value of the address my_func( my_ptr)","title":"Reference Types"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#-member-of-pointer-operator","text":"Dereferences (traverses) pointer Accesses member of that pointed-to-object Same as (*my_ptr).function();","title":"-&gt; Member-of-Pointer Operator"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#points-and-arrays","text":"Creating a pointer pointing at an array will only point at the first value of that array You can access elements with brackets just like with arrays though Do not try to access out-of-bounds elements!! And NEVER assign to out of bounds memory!! You access and treat arrays and pointsers almost exactly the same. You can also dereference and array You can assign the fourth element like this as well *(array + 4) = val Note that adding to the array decays it into a pointer to that element","title":"Points and Arrays"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#void-pointers-and-stdbyte-pointers","text":"They don\u2019t care about the type that they are pointing to. You cannot dereference a void* Void arithmetic is prohibited","title":"Void pointers and std:byte Pointers"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#nullptr-and-boolen-expressions","text":"Can use this to indicate that something failed Any value that is not nullptr = true, nullptr = false Function can return pointer to an object and nullptr if failed","title":"nullptr and Boolen Expressions"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#references","text":"Safer and more convenient version of pointers They cannot be null, or researted (reassigned) If you try to assign them a new value the new value gets assigned to the ref value","title":"References&amp;"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#forward-linked-lists","text":"Simple data structure made up of a series of elements. Each element holds a pointer to the next element. Last element holds nullptr Elements can be discontinuous in memory Basically lists that you can dynamically change the length of.","title":"Forward-Linked Lists:"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#this-pointers","text":"Access the current object Bit more verbose than just accessing the variables","title":"this Pointers"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#const-correctness","text":"Means this value will not be modified. Use to specify that a reference or pointer cannot be changed in a function. const methods are read only A const argument can only call const methods of itself","title":"const Correctness"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#member-initializer-lists","text":"The only way to init const values class Thing{ Thing(const char* name) : name { name }{}}","title":"Member Initializer Lists"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#auto-type-deduction","text":"Instead of spelling out the class type of a variable auto year{2020} //int auto& year{2020} // int& (reference) auto year{2020} //int (pointer) Great for for loops that might have their type changed.","title":"auto Type Deduction"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#object-life-cycle","text":"Allocation = reserving space for objecting Deallocation = releasing that storage Automatic object = allocated at the beginning of a code block and deallocated at the end Function parameters, anything inside that function, all local variables Static object = global They are deallocated when the program stops. Extern = global outside the translation unit local static variable = local but doesn\u2019t get cleaned up. Variable keeps value after first initialization call of function","title":"Object Life Cycle"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#static-members","text":"= members of a class that aren\u2019t associated with a particular instance of the class. Changing them changes them for all instances of the class that are active Refer to them using the scope resolution operator :: Must be initialized at global scope unless they are const Thread-Local Storage Duration Thread of execution = sequence of instructions that a thread executes Mutable global variables are the source of much non thread-safe code You can give each thread a copy of a variable by using thread_local keyword to the static or extern This will make a copy of the variable for each thread so that they cannot be writing to it at the same time","title":"Static members"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#dynamic-storage-duration","text":"You create dynamic objects with the new expression (i.e. new int{42}) You need to deallocate them with the delete expression The object still exists for a bit after it has been deleted causing the program to appear to function correctly (pyside), but then when it\u2019s cleaned up crash randomly.","title":"Dynamic Storage Duration"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#dynamic-arrays","text":"The size can\u2019t be changed but they have a dynamic storage duration New MyType[n_elements] {init-list} Returns a pointer to the first element of the array","title":"Dynamic Arrays"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#exceptions","text":"Types that communicate an error condition Use throw keyword followed by throwable object like std::runtime_error","title":"Exceptions"},{"location":"cpp/CCrashCourseAFastPacedIntroduction/#using-try-catch-blocks","text":"These are exception handlers for a block of code Catch block specifies a handler for each exception type you can handle It\u2019s a way of anticipaoing that something might be thrown and logging it","title":"Using try-catch Blocks"},{"location":"cpp/cpp_reference_links/","text":"Useful Reference sites General cpp refernce. https://en.cppreference.com/w/cpp","title":"Useful Reference sites"},{"location":"cpp/cpp_reference_links/#useful-reference-sites","text":"","title":"Useful Reference sites"},{"location":"cpp/cpp_reference_links/#general-cpp-refernce","text":"https://en.cppreference.com/w/cpp","title":"General cpp refernce."},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/","text":"Bitwise AND (&), OR(|), XOR(^) and NOT (~) in C++ This continues from here AND ( & ) and OR ( | ) and XOR ( ^ ) These all operate on two inputs. AND (&) & works very similarly to logical AND (&&), but they are very different things. & is a bitwise operator. 0 & 0 = 0 ; 0 & 1 = 0 ; 1 & 0 = 0 ; 1 & 1 = 1 ; 0101 & 1101 -------- 0101 // this is how it works on bits Both sides need to be true for the result to be true. Very commonly this & is used as a bitwise mask. What the hell does that mean? If we have some random number in buts, we can use & to find the value of an index in a bit number // say we want the value of the following bit \u2193 10110010101 00010000000 &___________ 00010000000 // if it had been 0 the result would also have been zero. // now you can use that to test if a certain index is zero or not if(result) // result just needs to not be zero ( in this case it's 32 ) // You can also clear a bunch of bits this way 101100101 000001111 &_________ 000000101 OR (|) If either of them are true, the result is true. 0 | 0 = 0 ; 0 | 1 = 1 ; 1 | 0 = 1 ; 1 | 1 = 1 ; Just like Add can mask bits out, you can add bits back with OR. 000000101 101100000 // these have been bitshifted to the left by 4 |_________ 101100101 // back to the original value In Actual code int a = 0b101 ; int b = 0b10110 b <<= 4 ; int c = a | b ; // c = 10110101 NOT (~) This is not used very opften, but it's very useful for inverting a certain bit. // first you islate the bit you want say the 6th one and then not that ~000100000 // becomes 111011111 // then you & that to a byte &101100101 // becomes 101000101 XOR (^) This has mostly been used in hashing. This gives a 1 only if they are different 0 ^ 0 = 0 ; 0 ^ 1 = 1 ; 1 ^ 0 = 1 ; 1 ^ 1 = 0 ; If you XOR a value with itself it will always give you zero int a = 1101 ; int b = a ^ a ; // =0 This is really useful when checking for pairs in a vector int [] A = { 9 , 3 , 9 , 3 , 9 , 7 , 9 }; int result = 0 ; foreach ( var i in A ) result ^= i ; Console . WriteLine ( result ); // 7","title":"Bitwise AND (&), OR(|), XOR(^) and NOT (~) in C++"},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/#bitwise-and-or-xor-and-not-in-c","text":"This continues from here","title":"Bitwise AND (&amp;), OR(|), XOR(^) and NOT (~) in C++"},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/#and-and-or-and-xor","text":"These all operate on two inputs.","title":"AND ( &amp; ) and OR ( | ) and XOR ( ^ )"},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/#and","text":"& works very similarly to logical AND (&&), but they are very different things. & is a bitwise operator. 0 & 0 = 0 ; 0 & 1 = 0 ; 1 & 0 = 0 ; 1 & 1 = 1 ; 0101 & 1101 -------- 0101 // this is how it works on bits Both sides need to be true for the result to be true. Very commonly this & is used as a bitwise mask. What the hell does that mean? If we have some random number in buts, we can use & to find the value of an index in a bit number // say we want the value of the following bit \u2193 10110010101 00010000000 &___________ 00010000000 // if it had been 0 the result would also have been zero. // now you can use that to test if a certain index is zero or not if(result) // result just needs to not be zero ( in this case it's 32 ) // You can also clear a bunch of bits this way 101100101 000001111 &_________ 000000101","title":"AND (&amp;)"},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/#or","text":"If either of them are true, the result is true. 0 | 0 = 0 ; 0 | 1 = 1 ; 1 | 0 = 1 ; 1 | 1 = 1 ; Just like Add can mask bits out, you can add bits back with OR. 000000101 101100000 // these have been bitshifted to the left by 4 |_________ 101100101 // back to the original value In Actual code int a = 0b101 ; int b = 0b10110 b <<= 4 ; int c = a | b ; // c = 10110101","title":"OR (|)"},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/#not","text":"This is not used very opften, but it's very useful for inverting a certain bit. // first you islate the bit you want say the 6th one and then not that ~000100000 // becomes 111011111 // then you & that to a byte &101100101 // becomes 101000101","title":"NOT (~)"},{"location":"cpp/Cherno/BitwiseAndOrXorAndNotInCpp/#xor","text":"This has mostly been used in hashing. This gives a 1 only if they are different 0 ^ 0 = 0 ; 0 ^ 1 = 1 ; 1 ^ 0 = 1 ; 1 ^ 1 = 0 ; If you XOR a value with itself it will always give you zero int a = 1101 ; int b = a ^ a ; // =0 This is really useful when checking for pairs in a vector int [] A = { 9 , 3 , 9 , 3 , 9 , 7 , 9 }; int result = 0 ; foreach ( var i in A ) result ^= i ; Console . WriteLine ( result ); // 7","title":"XOR (^)"},{"location":"cpp/Cherno/IntroToBinaryAndBitwiseOperatorsInCpp/","text":"Intro to Binary and Bitwise Operators in C++ In addition to the mathematical operators that we learn about in school, computers have additional operators that operate directly on bits. What if you want mathematical operators that work on the bit level? That is what bit operators are all about. They apply to a base 2 number system instead of a base 10 number system like we are used to. There are 6 main operators: << Bit shift left >> Bit shift right & Bitwise AND | Bitwise OR ^ Btiwise XOR ~ Not operator (inverting all the bits) These operators can be overloaded and you can get them to work a lot like functions. E.g. std::cout Let's talk about bits and bytes int a = s ; // how does memory store this? We have a bunch of transistors and they are either 0 or 1 based on how much energy they have. Because we have only two states, we have to use a base 2 number system binary . This means that if we want to store a number larger than one we need an additional character. This is how you would count up to 5: : 0 : 1 : 10 : 11 : 100 : 101 etc... You can also fill up the left hand side with zeros, and they don't actually do anything, it's just easier to read. So based on your compiler when you create an int you are allocating X amount of bytes. When you look at the binary of an int in memory, you will see the 4 bytes (or 8 chars) as hexadecimal characters. Why do we use hexadecimal for this?? The problem is that base 10 doesn't line up with bytes very well. 16 is the maximum number that can be stored in half a byte which is 4 binary digits. Bitshift left and right These shift the bits to the left or the right by the amount of places specified. a = 5 ; a <<= 1 ; // this shifts 0101 to 1010 // the zero is inserted because there was nothing to the right a == 10 ; // true a >> 1 ; a == 5 ; //true // every time we shift we double the number So a bitshift right or left is esentially just doubling or halfing the number x amount of times What happens if you bitshift odd numbers? 5 >> 1 ; // 0101 = 0010 = 2 // effectively you've halfed it and lost the decimal place Basically it's integer division. How is this useful? You can be an asshold and use them instead of multiplication operators.... but the compiler will be doing this anyway. So instead you should be cool and just use readable operators. So you should still write code the way you used to... Next video can be found here","title":"Intro to Binary and Bitwise Operators in C++"},{"location":"cpp/Cherno/IntroToBinaryAndBitwiseOperatorsInCpp/#intro-to-binary-and-bitwise-operators-in-c","text":"In addition to the mathematical operators that we learn about in school, computers have additional operators that operate directly on bits. What if you want mathematical operators that work on the bit level? That is what bit operators are all about. They apply to a base 2 number system instead of a base 10 number system like we are used to. There are 6 main operators: << Bit shift left >> Bit shift right & Bitwise AND | Bitwise OR ^ Btiwise XOR ~ Not operator (inverting all the bits) These operators can be overloaded and you can get them to work a lot like functions. E.g. std::cout","title":"Intro to Binary and Bitwise Operators in C++"},{"location":"cpp/Cherno/IntroToBinaryAndBitwiseOperatorsInCpp/#lets-talk-about-bits-and-bytes","text":"int a = s ; // how does memory store this? We have a bunch of transistors and they are either 0 or 1 based on how much energy they have. Because we have only two states, we have to use a base 2 number system binary . This means that if we want to store a number larger than one we need an additional character. This is how you would count up to 5: : 0 : 1 : 10 : 11 : 100 : 101 etc... You can also fill up the left hand side with zeros, and they don't actually do anything, it's just easier to read. So based on your compiler when you create an int you are allocating X amount of bytes. When you look at the binary of an int in memory, you will see the 4 bytes (or 8 chars) as hexadecimal characters. Why do we use hexadecimal for this?? The problem is that base 10 doesn't line up with bytes very well. 16 is the maximum number that can be stored in half a byte which is 4 binary digits.","title":"Let's talk about bits and bytes"},{"location":"cpp/Cherno/IntroToBinaryAndBitwiseOperatorsInCpp/#bitshift-left-and-right","text":"These shift the bits to the left or the right by the amount of places specified. a = 5 ; a <<= 1 ; // this shifts 0101 to 1010 // the zero is inserted because there was nothing to the right a == 10 ; // true a >> 1 ; a == 5 ; //true // every time we shift we double the number So a bitshift right or left is esentially just doubling or halfing the number x amount of times","title":"Bitshift left and right"},{"location":"cpp/Cherno/IntroToBinaryAndBitwiseOperatorsInCpp/#what-happens-if-you-bitshift-odd-numbers","text":"5 >> 1 ; // 0101 = 0010 = 2 // effectively you've halfed it and lost the decimal place Basically it's integer division.","title":"What happens if you bitshift odd numbers?"},{"location":"cpp/Cherno/IntroToBinaryAndBitwiseOperatorsInCpp/#how-is-this-useful","text":"You can be an asshold and use them instead of multiplication operators.... but the compiler will be doing this anyway. So instead you should be cool and just use readable operators. So you should still write code the way you used to... Next video can be found here","title":"How is this useful?"},{"location":"cpp/Cherno/Precompiled_Headers_in_C%2B%2B/","text":"Precompied Headers in C++ Procompiled headers aren't really required to be used, but they are vital for larger projects. They give you an opportunity to take a bunch of headerfiles and put them into a format where the compiler doesn't need to read them over and over again. The Greatness of Pre-compiled headers Example: We use the std library a lot, strings, vectors etc. All these come from header files. Every time you include one of these, it needs to read the entire vector header file and compile it. This also goes for all the files that vector includes. Proabably about 1k lines of code. That whole mass of code has to be parsed and compiled every time. This isn't just for the main file - it's for every file that includes something. This means that compile times are a lot longer than they could be. Expcialy as you add more and more files. Enter pre-compiled headers. These parse each header file you want to include and then store it in a binary format that is much faster to parse. Every time we then include that header file, it already has everything you need. Basically this is many thousands of times faster especially as the projct size grows. What not to do with pre-compiled headers A pre-compiled header file is basically a heaer file which includes a bunch of other header files. The path of least resistance is therefore to put everything in your project into that PCH (pre-compiled header). Yes, that will speed up build times BUT BUT if you put stuff in there which changes as you are working.... everything will have to be re-built. And that could slow down your compilation. There's nothing wrong with putting your own stuff into there, but it shouldn't be stuff that changes a lot. It would make sense for something like a logging library, but not if you're currently working on it. What this is most useful for is external dependencies. STL or any head only stuff you are including. One Semantic thing to watch out for is that the PCH can potentially hide what is being used. For example if you use a windowing library in your PCH, you're not quite sure what parts a certain file needs. This can make it very difficult in terms of modularity when you want to move files between projects. Back to the example of the windowing library: if only one cpp file needs it, it's good practice to not put that file into your pre-compiled header. STL you definitly should be putting in there.","title":"Precompied Headers in C++"},{"location":"cpp/Cherno/Precompiled_Headers_in_C%2B%2B/#precompied-headers-in-c","text":"Procompiled headers aren't really required to be used, but they are vital for larger projects. They give you an opportunity to take a bunch of headerfiles and put them into a format where the compiler doesn't need to read them over and over again.","title":"Precompied Headers in C++"},{"location":"cpp/Cherno/Precompiled_Headers_in_C%2B%2B/#the-greatness-of-pre-compiled-headers","text":"","title":"The Greatness of Pre-compiled headers"},{"location":"cpp/Cherno/Precompiled_Headers_in_C%2B%2B/#example","text":"We use the std library a lot, strings, vectors etc. All these come from header files. Every time you include one of these, it needs to read the entire vector header file and compile it. This also goes for all the files that vector includes. Proabably about 1k lines of code. That whole mass of code has to be parsed and compiled every time. This isn't just for the main file - it's for every file that includes something. This means that compile times are a lot longer than they could be. Expcialy as you add more and more files. Enter pre-compiled headers. These parse each header file you want to include and then store it in a binary format that is much faster to parse. Every time we then include that header file, it already has everything you need. Basically this is many thousands of times faster especially as the projct size grows.","title":"Example:"},{"location":"cpp/Cherno/Precompiled_Headers_in_C%2B%2B/#what-not-to-do-with-pre-compiled-headers","text":"A pre-compiled header file is basically a heaer file which includes a bunch of other header files. The path of least resistance is therefore to put everything in your project into that PCH (pre-compiled header). Yes, that will speed up build times BUT BUT if you put stuff in there which changes as you are working.... everything will have to be re-built. And that could slow down your compilation. There's nothing wrong with putting your own stuff into there, but it shouldn't be stuff that changes a lot. It would make sense for something like a logging library, but not if you're currently working on it. What this is most useful for is external dependencies. STL or any head only stuff you are including. One Semantic thing to watch out for is that the PCH can potentially hide what is being used. For example if you use a windowing library in your PCH, you're not quite sure what parts a certain file needs. This can make it very difficult in terms of modularity when you want to move files between projects. Back to the example of the windowing library: if only one cpp file needs it, it's good practice to not put that file into your pre-compiled header. STL you definitly should be putting in there.","title":"What not to do with pre-compiled headers"},{"location":"cpp/Cherno/Using_Libraries_in_C%2B%2B/","text":"Using Libraries in C++ Ideally you should be able to just checkout a repository and compile and everything should just be able to run. People just want things to work. Because of this, usually we just copy code or binaries directly into the working directory of our solution. Should we compile them ourselves? Yes is it's a serious projet that you really want to work No if the libraries are platform specific No if it's just throwaway messing around For windows there are often pre-build binaries. Static linking means the libraries is in the executable, a dynamic library get linked at runtime. Dynamic libraries are loaded at application launch. It's the difference of if the library gets loaded into your exe at compile time or runtime. Static linking is technically faster, but is less flexible. So we have #include files (header files) and ones that we link to at compile time.","title":"Using Libraries in C++"},{"location":"cpp/Cherno/Using_Libraries_in_C%2B%2B/#using-libraries-in-c","text":"Ideally you should be able to just checkout a repository and compile and everything should just be able to run. People just want things to work. Because of this, usually we just copy code or binaries directly into the working directory of our solution.","title":"Using Libraries in C++"},{"location":"cpp/Cherno/Using_Libraries_in_C%2B%2B/#should-we-compile-them-ourselves","text":"Yes is it's a serious projet that you really want to work No if the libraries are platform specific No if it's just throwaway messing around For windows there are often pre-build binaries. Static linking means the libraries is in the executable, a dynamic library get linked at runtime. Dynamic libraries are loaded at application launch. It's the difference of if the library gets loaded into your exe at compile time or runtime. Static linking is technically faster, but is less flexible. So we have #include files (header files) and ones that we link to at compile time.","title":"Should we compile them ourselves?"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/","text":"CppCon 2014: Mike Acton \"Data-Oriented Design and C++\" What's important to game devs? Hard deadlines Soft realtime performance requirements (soft = 32 ms) Usability Performance Maintenance Debugability What languages do we use..? C C++ <- about 70% Asm <- most preferred Perl Javascript C# Pixel shaders, vertex shader, geometry shaders etc. How are games like the Mars rovers Exceptions (avoid at all costs) Templates (too long compile times) Iostream (not really used) Multiple inheriance (just dumb) Operator overloading (maybe if it's super obvious but don't be silly) RTTI (off the table) STL (it's not that we have a replacement for this it just don't solve the problems that we want to solve) Custom allocators ( we allocate all memory up front and divide things into their own heirarchies ) Custom Debugging Tools ... we have tools for everything Is data-oriented even a thing...? Philosophy The purpose of all programs, and all parts of those programs, is to transform data from one form to another. Philosophy If you don't understand the data you don't understand the problem at all. You understand a problem better by understanding the data better Philosophy Different problems require different solutions. If you have different data, you have different problem. I fyou don't understand the cost of sovling the problem, you don't understand the problem. If you don't understnad the hardware, you can't reason about the cost of solving the problem. Everything is a data problem. Including usability, maintenance, debug-ability, etc. Everything. Solving problems you probably don't have creates more problems you definitly do. Latency and throughput are only the same in sequential systems. Rule Where there is one, there are many. Try looking on the time axis. Rule The more context you have, the better you can make the solutino. Don't thow away data you need. Rule NUMA extends to i?O and pr-built data all the way back through time to original source creation. Software does not run in a magic fairy aether powered by the fevered dreams of CS PhDs. Ultimately reason must prevail. This is all what data-oriented means. This is a response to the broader culture of C++, and... The three big lies: 1. Software is a Platform Hardware is the platform - different hardware, different solutions. Different physical constraints apply. Reality is not a hack you're forced to deal with to sove your theoretical problem. Reality is the actual problem. 2. Code should be designed around model of the world This has trickled into cpp culture from Oop. Hiding data is implicit in this world modeling - even the point of it. It confuses the maintenance, and the properties of the data. The cost of slightly better maintinence can make it much more difficult to solve problems really well. In real life classes of things are actually the things, but in terms of data transformations, \"classes\" are really only superficially similar. How similar is a game static chair to a physical chair? There is nothing the same, but because they have a world modeling similarity they should be connected which is nonsensical. This leads to monolithic, unrelated data structures. It tries to idealize the problem away. But you can't make a problem simpler than it is. The reality is you have this actual set of hardware. World modeling is kind of like self-help books for programming, solving by analogy and storytelling instead of by hardware. 3. Code is more important than data. So much development time is spent talking about the code, while most of the time the code is a minor issue. The data we are dealing with and what we are doing with it is the actual problem. The only purpose of any code is to transform data . The programmer is fundamentally responsible for the data, not the code. The code is just the tool used for the transformations. Your job is to solve the transformation problems. Only write code that has direct provable value (i.e. transforms data in meaningful way) Understand the data to understand the ptorlbem. Tehre is no ideal, abstract solution to the problem. You can't \"Future proof\" you code against future data because you do not know future data. What problems do these lies cause? Poor performance, concurrency, optimizability, stability, testability. Solve for transfoming the data you have given the constraints of the platform (and nothing else). E.g. Dictionary lookup. You would expect key-value pair to be close to each other in memory. The reality is that they are not next to each other. The statistical chance that we will need value on any key is very low. Usually we will be iterating over the keys. That's what the data tells us that's what the problem is. This leads to doing unnecessary things because of a mental model. Principle Solve for the most common case first, not the most generic. Review of Ram Speeds L1 blazing fast basically instant L2 20 cpu cycles Main Ram 200+ cpu cycles The most significant part of our time will be spent waiting for L2 cache/misses. The incredibly slow process from loading something from main ram. Not even including shared memory modes between CPU and GPU and the different platforms associated with that. How to Data Orient A very simple example class GameObject { float m_pos [ 2 ]; float m_velocity [ 2 ]; char m_name [ 32 ]; model * m_model ; // etc float m_foo ; void UpdateFoo ( float f ){ float mag = sqrtf ( m_velocity [ 0 ] * m_velocity [ 0 ] + m_velocity [ 1 ] * m_velocity [ 1 ] ); m_foo += mag * f ; } }; We think looking at it that this sqrtf is the problem, but we know it's an order of magnitude less than access to ram. Breaking it down the majority of the work is in the initial read and the final read with the moves. The actual time is in the initial read and the final read-add. It's 10:1 for time spent during read : time spent with squrf. The vast majority of problems are ones the compiler can't reason about. Compiler is a tool, not a magic wand . It cannot solve the most significant problems that you have. So how do we use our capacity a little bit better? The best way is to make sure to fill that line with data we actually need. If we have multiple we might as well transform them together. Then we might as well pack them into the same cache line. By processing count of Foo we can be much more efficient per foo. // 12 bytes x count(32) = 384 = 64 x 6 struct FooUpdateIn { float m_Velocity [ 2 ]; float m_Foo ; }; // 4 bytes x count(32) = 128 = 64 x 2 struct FooUpdateOut { float m_Foo ; }; void updateFoos ( const FooUpdateIn * in , size_t count , FooUpdateOut * out , float f ){ for ( size_t i = 0 ; i < count ; ++ i ){ float mag = sqrtf ( in [ i ]. m_velocity [ 0 ] * in [ i ]. m_velocity [ 0 ] + in [ i ]. m_velocity [ 1 ] * in [ i ]. m_velocity [ 1 ]); // (6/32) = ~5.33 loop/cache line // Sqrt + math = ~40 x 5.33 = 213.33 cycles/cache line out [ i ]. m_Foo = in [ i ]. m_Foo + mag * f ; } } Using the whole capacity of the cache line is approximately a 10x speedup. Just using the whole line at all already makes a massive difference when iterating over this many operations. The previous example is much harder to reason about what to change. Here it's much easier. In additions to this: Code is maintainable Code is debugable Can REASON about cost of change Ignoring inconvenient facts is not engineering; It's dogma. We have to take the reality of what we're doing into account - it's only professional. Bools in Structs Let's reason a little bit about the cost of doing this. Let's assume the bools are at least packed. We can at least say it's got a very low information density because we are wasting a bool on a byte. We are pushin other objects out of cache lines because of that one extra bit needed for a bool. They are also common last minute problems in decision making. We can use more of this line. There are several approaches to this: A. Make same decision x512 B. Combine with other reads/xforms This is generally the simplest But things cannot exist in an abstract bubble - we need to know what other things are going on at the same time in order to merge them. The will require context C. Over-frames.. i.e. Only read when needed. If you process instructions over time, we can calculate when it will spawn and then push it into that instruction stream in the future. Not incrementing it every frame but calculating when it will pass the threshold once and then queing it for that. Ogre Engine example Lots of bools and last min decision making example. The node class is designed around a \"one at a time\" approach. In the most common places nodes are in a hierarchy and they will get looped over. The genericness of separating the node costs a lot because you are separating all of the data from that node as well. Complex constructors tend to imply that: Reads are unmanaged (one at a time...) Unnecessary reads/writes in destructors Unmanaged icache (i.e. virtuals) -> unmanaged reads/writes We have no idea what is getting loaded for all data because we don't know what's going on in the constructor which makes everything slower. We can also see unnecessarily complicated state machines. Ruleovthumb Store each state type separately. Store same states together. (No state value needed) Another thing to avoid is initializing default variables when they will most likely be overwritten somewhere else later. Zero initialization is important to prevent unnecessary reads and writes. This problem is compounded even more when you don't know exactly what will happen with a class. Fact Strings are generally BAD - especially filenames Ruleovthumb The best code is code that doesn't need to exists. Do it offline. Do it once. e.g. precompiled string hashes. We pay a heavy price for the mental model that a \"node\" exists alone in the world. This prevents us from aligning it's data more efficiently in memory and chaining operations together more efficiently. Separate the code into small functions instead of a switch statement. For example make 3 functions to translate a collection of nodes in local, world and parent space instead of using member functions to do the same thing. Then you make distinctions between use-cases like in-game vs. editor. They are two problems and they should be solved separately. Then reduce based on the most statistically common case. Organizing based on your data makes maintenance, debugging and concurrency much easier. The problem is that it's harder to program this way. #Truths Hardware is the Platform Design around the data, not an idealized world Your main responsibility is to transform data, solve that first, not the code design You main responsibility as a programmer is to transform data. Bad news is that there's a culture of hiding things. Quote Design patterns are spoonfeed material for brainless programmers incapable of independant thought, who will be resolved to producing code as mediocre as the design patterns they use to create it. The end","title":"CppCon 2014: Mike Acton \"Data-Oriented Design and C++\""},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#cppcon-2014-mike-acton-data-oriented-design-and-c","text":"","title":"CppCon 2014: Mike Acton \"Data-Oriented Design and C++\""},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#whats-important-to-game-devs","text":"Hard deadlines Soft realtime performance requirements (soft = 32 ms) Usability Performance Maintenance Debugability","title":"What's important to game devs?"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#what-languages-do-we-use","text":"C C++ <- about 70% Asm <- most preferred Perl Javascript C# Pixel shaders, vertex shader, geometry shaders etc.","title":"What languages do we use..?"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#how-are-games-like-the-mars-rovers","text":"Exceptions (avoid at all costs) Templates (too long compile times) Iostream (not really used) Multiple inheriance (just dumb) Operator overloading (maybe if it's super obvious but don't be silly) RTTI (off the table) STL (it's not that we have a replacement for this it just don't solve the problems that we want to solve) Custom allocators ( we allocate all memory up front and divide things into their own heirarchies ) Custom Debugging Tools ... we have tools for everything","title":"How are games like the Mars rovers"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#is-data-oriented-even-a-thing","text":"Philosophy The purpose of all programs, and all parts of those programs, is to transform data from one form to another. Philosophy If you don't understand the data you don't understand the problem at all. You understand a problem better by understanding the data better Philosophy Different problems require different solutions. If you have different data, you have different problem. I fyou don't understand the cost of sovling the problem, you don't understand the problem. If you don't understnad the hardware, you can't reason about the cost of solving the problem. Everything is a data problem. Including usability, maintenance, debug-ability, etc. Everything. Solving problems you probably don't have creates more problems you definitly do. Latency and throughput are only the same in sequential systems. Rule Where there is one, there are many. Try looking on the time axis. Rule The more context you have, the better you can make the solutino. Don't thow away data you need. Rule NUMA extends to i?O and pr-built data all the way back through time to original source creation. Software does not run in a magic fairy aether powered by the fevered dreams of CS PhDs. Ultimately reason must prevail. This is all what data-oriented means. This is a response to the broader culture of C++, and...","title":"Is data-oriented even a thing...?"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#the-three-big-lies","text":"","title":"The three big lies:"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#1-software-is-a-platform","text":"Hardware is the platform - different hardware, different solutions. Different physical constraints apply. Reality is not a hack you're forced to deal with to sove your theoretical problem. Reality is the actual problem.","title":"1. Software is a Platform"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#2-code-should-be-designed-around-model-of-the-world","text":"This has trickled into cpp culture from Oop. Hiding data is implicit in this world modeling - even the point of it. It confuses the maintenance, and the properties of the data. The cost of slightly better maintinence can make it much more difficult to solve problems really well. In real life classes of things are actually the things, but in terms of data transformations, \"classes\" are really only superficially similar. How similar is a game static chair to a physical chair? There is nothing the same, but because they have a world modeling similarity they should be connected which is nonsensical. This leads to monolithic, unrelated data structures. It tries to idealize the problem away. But you can't make a problem simpler than it is. The reality is you have this actual set of hardware. World modeling is kind of like self-help books for programming, solving by analogy and storytelling instead of by hardware.","title":"2. Code should be designed around model of the world"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#3-code-is-more-important-than-data","text":"So much development time is spent talking about the code, while most of the time the code is a minor issue. The data we are dealing with and what we are doing with it is the actual problem. The only purpose of any code is to transform data . The programmer is fundamentally responsible for the data, not the code. The code is just the tool used for the transformations. Your job is to solve the transformation problems. Only write code that has direct provable value (i.e. transforms data in meaningful way) Understand the data to understand the ptorlbem. Tehre is no ideal, abstract solution to the problem. You can't \"Future proof\" you code against future data because you do not know future data.","title":"3. Code is more important than data."},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#what-problems-do-these-lies-cause","text":"Poor performance, concurrency, optimizability, stability, testability. Solve for transfoming the data you have given the constraints of the platform (and nothing else). E.g. Dictionary lookup. You would expect key-value pair to be close to each other in memory. The reality is that they are not next to each other. The statistical chance that we will need value on any key is very low. Usually we will be iterating over the keys. That's what the data tells us that's what the problem is. This leads to doing unnecessary things because of a mental model. Principle Solve for the most common case first, not the most generic.","title":"What problems do these lies cause?"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#review-of-ram-speeds","text":"L1 blazing fast basically instant L2 20 cpu cycles Main Ram 200+ cpu cycles The most significant part of our time will be spent waiting for L2 cache/misses. The incredibly slow process from loading something from main ram. Not even including shared memory modes between CPU and GPU and the different platforms associated with that.","title":"Review of Ram Speeds"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#how-to-data-orient","text":"A very simple example class GameObject { float m_pos [ 2 ]; float m_velocity [ 2 ]; char m_name [ 32 ]; model * m_model ; // etc float m_foo ; void UpdateFoo ( float f ){ float mag = sqrtf ( m_velocity [ 0 ] * m_velocity [ 0 ] + m_velocity [ 1 ] * m_velocity [ 1 ] ); m_foo += mag * f ; } }; We think looking at it that this sqrtf is the problem, but we know it's an order of magnitude less than access to ram. Breaking it down the majority of the work is in the initial read and the final read with the moves. The actual time is in the initial read and the final read-add. It's 10:1 for time spent during read : time spent with squrf. The vast majority of problems are ones the compiler can't reason about. Compiler is a tool, not a magic wand . It cannot solve the most significant problems that you have. So how do we use our capacity a little bit better? The best way is to make sure to fill that line with data we actually need. If we have multiple we might as well transform them together. Then we might as well pack them into the same cache line. By processing count of Foo we can be much more efficient per foo. // 12 bytes x count(32) = 384 = 64 x 6 struct FooUpdateIn { float m_Velocity [ 2 ]; float m_Foo ; }; // 4 bytes x count(32) = 128 = 64 x 2 struct FooUpdateOut { float m_Foo ; }; void updateFoos ( const FooUpdateIn * in , size_t count , FooUpdateOut * out , float f ){ for ( size_t i = 0 ; i < count ; ++ i ){ float mag = sqrtf ( in [ i ]. m_velocity [ 0 ] * in [ i ]. m_velocity [ 0 ] + in [ i ]. m_velocity [ 1 ] * in [ i ]. m_velocity [ 1 ]); // (6/32) = ~5.33 loop/cache line // Sqrt + math = ~40 x 5.33 = 213.33 cycles/cache line out [ i ]. m_Foo = in [ i ]. m_Foo + mag * f ; } } Using the whole capacity of the cache line is approximately a 10x speedup. Just using the whole line at all already makes a massive difference when iterating over this many operations. The previous example is much harder to reason about what to change. Here it's much easier. In additions to this: Code is maintainable Code is debugable Can REASON about cost of change Ignoring inconvenient facts is not engineering; It's dogma. We have to take the reality of what we're doing into account - it's only professional.","title":"How to Data Orient"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#bools-in-structs","text":"Let's reason a little bit about the cost of doing this. Let's assume the bools are at least packed. We can at least say it's got a very low information density because we are wasting a bool on a byte. We are pushin other objects out of cache lines because of that one extra bit needed for a bool. They are also common last minute problems in decision making. We can use more of this line. There are several approaches to this: A. Make same decision x512 B. Combine with other reads/xforms This is generally the simplest But things cannot exist in an abstract bubble - we need to know what other things are going on at the same time in order to merge them. The will require context C. Over-frames.. i.e. Only read when needed. If you process instructions over time, we can calculate when it will spawn and then push it into that instruction stream in the future. Not incrementing it every frame but calculating when it will pass the threshold once and then queing it for that.","title":"Bools in Structs"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#ogre-engine-example","text":"Lots of bools and last min decision making example. The node class is designed around a \"one at a time\" approach. In the most common places nodes are in a hierarchy and they will get looped over. The genericness of separating the node costs a lot because you are separating all of the data from that node as well. Complex constructors tend to imply that: Reads are unmanaged (one at a time...) Unnecessary reads/writes in destructors Unmanaged icache (i.e. virtuals) -> unmanaged reads/writes We have no idea what is getting loaded for all data because we don't know what's going on in the constructor which makes everything slower. We can also see unnecessarily complicated state machines. Ruleovthumb Store each state type separately. Store same states together. (No state value needed) Another thing to avoid is initializing default variables when they will most likely be overwritten somewhere else later. Zero initialization is important to prevent unnecessary reads and writes. This problem is compounded even more when you don't know exactly what will happen with a class. Fact Strings are generally BAD - especially filenames Ruleovthumb The best code is code that doesn't need to exists. Do it offline. Do it once. e.g. precompiled string hashes. We pay a heavy price for the mental model that a \"node\" exists alone in the world. This prevents us from aligning it's data more efficiently in memory and chaining operations together more efficiently. Separate the code into small functions instead of a switch statement. For example make 3 functions to translate a collection of nodes in local, world and parent space instead of using member functions to do the same thing. Then you make distinctions between use-cases like in-game vs. editor. They are two problems and they should be solved separately. Then reduce based on the most statistically common case. Organizing based on your data makes maintenance, debugging and concurrency much easier. The problem is that it's harder to program this way.","title":"Ogre Engine example"},{"location":"cpp/CppCon/CppCon2014MikeActon-DataOrientedDesignandC%2B%2B/#truths","text":"Hardware is the Platform Design around the data, not an idealized world Your main responsibility is to transform data, solve that first, not the code design You main responsibility as a programmer is to transform data. Bad news is that there's a culture of hiding things. Quote Design patterns are spoonfeed material for brainless programmers incapable of independant thought, who will be resolved to producing code as mediocre as the design patterns they use to create it. The end","title":"#Truths"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/","text":"CppCon 2017: John Lakos \"Local ('Arena') Memory Allocators (part 1 of 2)\" Memory allocators are not new. Video game programmers have known this for a long time, and it's absolutely essential for them to do their jobs.The only question is: Is it worth the effort? In C++ 20 and 2013 the effort of this will go to zero. Important recurring Questions Are memory allocators really worth the trouble? What situations merit their use? How are they applied effectively? What's the performance impact? Performance is one area where allocators make a big difference, but it's only one of these areas. We are talking about performance, but arguing the values of allocators there would be another 2 complete talks about why they are important. This talk is just performance. 1. Introduction and Background What are memory allocators, and why are they useful? We should be proud that we are looking at the hardware a little bit. But we really just need to get the gist of it. We will talk about a general architecture, but benchmarks will be run on a specific architecture. Why do we like the C++ language? It enables us to \"fine-tune\" at a low level when needed. It can deliver very high runtime performance. Otherwise we'd probably use something else. Why (should) we care about memory allocators? They enable us to \"find-tune\" at a low level when needed They can help to improve runtime performance. If we care about performance, we need to care about memory allocators. Not all memory is alike: there is fast, shared, protected, mapped... you can deal with this. You can do testing, debugging, measuring and profiling in a more controlled way. And of course it will enable enhanced runtime performance. Better locality, less contention. Common arguments against allocators Requires more up-front design effort. It's programming though, you should be good at this Complicates user interfaces.... depending on your design May actually degrade performance: if you choose the wrong allocator or there is none needed. These can be addressed with well supported facts and careful measurements. Review of Computer Memory We have the CPU and then we have main Memory. Every time the cpu turns memory can get added. Cache Memory A Cache sits between the CPU and Main Memory. This gives us a cache line with some memory in it. A cache line is a chunk of contiguous memory that gets pulled into the cache all at once. So the next time you want to access something on the cache line you already have it loaded. The cache can take something from anywhere in memory and put the line there. If you then add things to the same line in memory, it's instantly in the cache, since it was already loaded. Eventually we change something in the cache, and then we put that back into memory. There are many levels of cache but we don't need to care about that. Higher levels of cache include paging: Where you have x amount of pages in your real memory that you need to page in and out. There's many different levels of cache from registers on one hand to pages to virtual memory. What you need to know is that things that need to be quickly accessed a lot need to be close together in memory. This is what locality means. Not having locality is bad. Main Memory Segments We have the executable program which is loaded into memory along with all static variables, then we have stack memory growing from one direction and dynamic memory from the other. They grow through the use of memory allocators . It's just something that allows us to control memory. Memory Allocators A memory allocator organizes a region of computer memory, dispensing and reclaiming authorized access to suitable sub-regions on demand. possibly non-contiguous There are general purpose allocators and special-purpose allocators. General purpose allocators work for everybody and always do a good job. A Special purpose allocators works especially well for some use cases. They may not be save in a multi-threaded program, or they may not resuse individually freed memory. Using special purpose allocators requires specific knowledge of the context of use. There are also global allocators and local allocators. A global allocator operators on a single ubiquitous region of memory, exists throughout the lifetime of a program and is inherently accessible from all parts of a program. A local allocator operats on a local sub-region (\"arena\") of memory. It may exist for less than the lifetime of a program, and is (typcially) supplied for client use via a \"reference\". These can (typically) be used to free memory unilaterally. In C we have General-Purpose Global Allocator // malloc.h void * malloc ( size_t nBytes ); void free ( void * address ); In C++ we have new // <new> namespace std { void * operator new ( size_t nbytes ); void operator delete ( void * address ); } This allows us to free and alloc from dynamic memory. They aren't allocators per-say they are syntax to work with them. Special-Purpose Local Allocator // alloca.h void * alloca ( size_t nBytes ); This give you memory from the \"hot\" program stack. That's really good if you know what you're doing but if not your program will crash and burn. Global Local General malloc/free , new/delete , tcmalloc, jemalloc multipool_allocator , Any general algorithm applied to a physically (and temporally) local region of memory Special An unsynchronized tmalloc allocator \"plugged into\" malloc/free alloca , monotonic_allocator , Unsynchronized version of a multipool_allocator If you can access something in quick succession and you can do it in a boxed region, local allocators are your friend. Otherwise, use global. A memory allocator is a stateful utility or mechanism that organizes a region of computer memory, dispensing and reclaiming authorized access to suitable sub-regions on demand possibly non-contiguous The allocator itself has some logic in it, but local allocators are tied to a very specific region in memory. !!! No You can't copy an allocator. It's a region in memory and therefore singular. Every allocator you ever deal with is a pointer to some region in memory. The logic lives in the allocator object, but the memory lives in the region of memory it points to. Local Allocator Mechanism class LocalAllocator { // internal data structure public : // you can't copy an allocator LocalAllocator ( const LocalAllocator & ) = delete ; LocalAllocator & operator = ( const LocalAllocator & ) = delete ; // CREATORS LocalAllocator ( void * begin , void * end ); // MANIPULATORS void * allocate ( std :: size_t nBytes ); void deallocate ( void * address ); // in this real you have to know what you're doing void release (); // LOCAL ALLOCATORS ONLY } A memory allcoator is (the client-facing interface for) a stateful utility or mechanism that organizes a region of coputer memory, dispensing and reclaiming authorized access to suitable sub-regions on demand possibly non-contiguous Memory Allocator Interfaces Allocators can be supplied for use in mutliple ways: As (stateful) utility functions. Now I can freeee! Doesn't support allocator objects As a \"reference wrapper\" template parameter. passed in as a template parameter Concrete allocator type is available for use by client's compiler Forces a client to be a template in order to hold the allocator reference Allocator type affects the C++ type of the client object As the address of a pure abstract base class Alocator can be held via a base-class reference by a non-template class the choice of allocator does not affect the C++ type of the client object. Allocator must be accessed via virtual-function interface Object must somehow hold an extra address - even for the default case. Have we measured this? 2. Understanding the Problem What aspects of software affect allocation strategy? Should we supply a local allocator? Which one? If No use Default Global Allocator. If yes should it be done via the base class or bake it into the type C++ 11 style. This is a syntax issue. Which allocator should we use? Do we want to bother destroying each individual object and sub-object or just make them go away? Use Optimal Local-Allocation Strategy Our Tool Chest of Allocation Strategies Global Allocator We have two primary options for how it's implemented: Type Parameter Abstract Base (Object that invokes new and delete) 2 Allocation Strategies Local Allocators To the block of memory created by the global allocator we now need to affix a pooling allocator. This can be Monotonic Multipool Multipool Then Type Parameter or Abstract Base Then Normal destruction or magically \"Winked out\". Winking out means it's just gone without saying anything 12 Allocation Strategies Label Allocator Type Allocator Binding Desruction of Allocated Objects AS1 Default Global Allocator Type Parameter Normal Destruction AS2 New/Delete Allocator Abstract Base Normal Destruction AS3 Monotonic Type Parameter Normal Destruction AS4 Monotonic Type Parameter (magically) \"Winked Out\" AS5 Monotonic Abstract Base Normal Destruction AS6 Monotonic Abstract Base (magically) \"Winked Out\" AS3 Multipool Type Parameter Normal Destruction AS4 Multipool Type Parameter (magically) \"Winked Out\" AS5 Multipool Abstract Base Normal Destruction AS6 Multipool Abstract Base (magically) \"Winked Out\" AS3 Multipool Type Parameter Normal Destruction AS4 Multipool Type Parameter (magically) \"Winked Out\" AS5 Multipool Abstract Base Normal Destruction AS6 Multipool Abstract Base (magically) \"Winked Out\" AS1 class allocator { // no data members public : // CREATORS allocator () {} allocator ( const allocator & ){} ~ allocator () {} // MANIPULATORS allocator & operator = () = delete ; void * allocate ( std :: size_t nBytes ){ return :: operator new ( nBytes ); } void deallocate ( void * address ){ :: operator delete ( address ); } }; FREE OPERATORS bool operator == ( const allocator & , const allocator & ){ return true ; } myFunction (){ std :: vector < int > v ; } myFunction (){ // allocator is the TYPE PARAMETER for std::vector here. // this is te same as myFunction above. std :: vector < int , allocator > v ; } Do a benchmark on the vector and destroy it like this: myBenchmark (){ const int N = 1000 ; std :: vector < std :: list < int >*> system ( N ); for ( int i { 0 }; i < N ; ++ i ){ system [ i ] = new std :: list < int > ; // build up list of elements } // Do benchmark (e.g. access links) for ( int i { 0 }; i < N ){ delete system [ i ]; } // system goes out of scope } AS2 Same thing but with a pure abstract base class. class NewDeleteAllocator : public Allocator { // no data members public : // CREATORS NewDeleteAllocator () = default ; ~ NewDeleteAllocator () = default ; NewDeleteAllocator ( const NewDeleteAllocator & ) = delete ; // MANIPULATORS void operator = ( cost NewDeleteAllocator & ) = delete ; inline void * allocate ( std :: size_t nBytes ) override { return :: operator new ( nBytes ); } inline void deallocate ( void * address ) override { :: operator delete ( address ); } } THESE ARE ACTUALLY INLINE AND HE IS NOT 3. Analyzing the Benchmark Data When and how do you use which allocator, and why? 4. Conclusions What must we remember about memory allocators?","title":"CppCon 2017: John Lakos \"Local ('Arena') Memory Allocators (part 1 of 2)\""},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#cppcon-2017-john-lakos-local-arena-memory-allocators-part-1-of-2","text":"Memory allocators are not new. Video game programmers have known this for a long time, and it's absolutely essential for them to do their jobs.The only question is: Is it worth the effort? In C++ 20 and 2013 the effort of this will go to zero.","title":"CppCon 2017: John Lakos \"Local ('Arena') Memory Allocators (part 1 of 2)\""},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#important-recurring-questions","text":"","title":"Important recurring Questions"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#are-memory-allocators-really-worth-the-trouble","text":"What situations merit their use? How are they applied effectively? What's the performance impact? Performance is one area where allocators make a big difference, but it's only one of these areas. We are talking about performance, but arguing the values of allocators there would be another 2 complete talks about why they are important. This talk is just performance.","title":"Are memory allocators really worth the trouble?"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#1-introduction-and-background","text":"What are memory allocators, and why are they useful? We should be proud that we are looking at the hardware a little bit. But we really just need to get the gist of it. We will talk about a general architecture, but benchmarks will be run on a specific architecture.","title":"1. Introduction and Background"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#why-do-we-like-the-c-language","text":"It enables us to \"fine-tune\" at a low level when needed. It can deliver very high runtime performance. Otherwise we'd probably use something else.","title":"Why do we like the C++ language?"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#why-should-we-care-about-memory-allocators","text":"They enable us to \"find-tune\" at a low level when needed They can help to improve runtime performance. If we care about performance, we need to care about memory allocators. Not all memory is alike: there is fast, shared, protected, mapped... you can deal with this. You can do testing, debugging, measuring and profiling in a more controlled way. And of course it will enable enhanced runtime performance. Better locality, less contention.","title":"Why (should) we care about memory allocators?"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#common-arguments-against-allocators","text":"Requires more up-front design effort. It's programming though, you should be good at this Complicates user interfaces.... depending on your design May actually degrade performance: if you choose the wrong allocator or there is none needed. These can be addressed with well supported facts and careful measurements.","title":"Common arguments against allocators"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#review-of-computer-memory","text":"We have the CPU and then we have main Memory. Every time the cpu turns memory can get added.","title":"Review of Computer Memory"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#cache-memory","text":"A Cache sits between the CPU and Main Memory. This gives us a cache line with some memory in it. A cache line is a chunk of contiguous memory that gets pulled into the cache all at once. So the next time you want to access something on the cache line you already have it loaded. The cache can take something from anywhere in memory and put the line there. If you then add things to the same line in memory, it's instantly in the cache, since it was already loaded. Eventually we change something in the cache, and then we put that back into memory. There are many levels of cache but we don't need to care about that. Higher levels of cache include paging: Where you have x amount of pages in your real memory that you need to page in and out. There's many different levels of cache from registers on one hand to pages to virtual memory. What you need to know is that things that need to be quickly accessed a lot need to be close together in memory. This is what locality means. Not having locality is bad.","title":"Cache Memory"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#main-memory-segments","text":"We have the executable program which is loaded into memory along with all static variables, then we have stack memory growing from one direction and dynamic memory from the other. They grow through the use of memory allocators . It's just something that allows us to control memory.","title":"Main Memory Segments"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#memory-allocators","text":"A memory allocator organizes a region of computer memory, dispensing and reclaiming authorized access to suitable sub-regions on demand. possibly non-contiguous There are general purpose allocators and special-purpose allocators. General purpose allocators work for everybody and always do a good job. A Special purpose allocators works especially well for some use cases. They may not be save in a multi-threaded program, or they may not resuse individually freed memory. Using special purpose allocators requires specific knowledge of the context of use. There are also global allocators and local allocators. A global allocator operators on a single ubiquitous region of memory, exists throughout the lifetime of a program and is inherently accessible from all parts of a program. A local allocator operats on a local sub-region (\"arena\") of memory. It may exist for less than the lifetime of a program, and is (typcially) supplied for client use via a \"reference\". These can (typically) be used to free memory unilaterally. In C we have General-Purpose Global Allocator // malloc.h void * malloc ( size_t nBytes ); void free ( void * address ); In C++ we have new // <new> namespace std { void * operator new ( size_t nbytes ); void operator delete ( void * address ); } This allows us to free and alloc from dynamic memory. They aren't allocators per-say they are syntax to work with them. Special-Purpose Local Allocator // alloca.h void * alloca ( size_t nBytes ); This give you memory from the \"hot\" program stack. That's really good if you know what you're doing but if not your program will crash and burn. Global Local General malloc/free , new/delete , tcmalloc, jemalloc multipool_allocator , Any general algorithm applied to a physically (and temporally) local region of memory Special An unsynchronized tmalloc allocator \"plugged into\" malloc/free alloca , monotonic_allocator , Unsynchronized version of a multipool_allocator If you can access something in quick succession and you can do it in a boxed region, local allocators are your friend. Otherwise, use global. A memory allocator is a stateful utility or mechanism that organizes a region of computer memory, dispensing and reclaiming authorized access to suitable sub-regions on demand possibly non-contiguous The allocator itself has some logic in it, but local allocators are tied to a very specific region in memory. !!! No You can't copy an allocator. It's a region in memory and therefore singular. Every allocator you ever deal with is a pointer to some region in memory. The logic lives in the allocator object, but the memory lives in the region of memory it points to.","title":"Memory Allocators"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#local-allocator-mechanism","text":"class LocalAllocator { // internal data structure public : // you can't copy an allocator LocalAllocator ( const LocalAllocator & ) = delete ; LocalAllocator & operator = ( const LocalAllocator & ) = delete ; // CREATORS LocalAllocator ( void * begin , void * end ); // MANIPULATORS void * allocate ( std :: size_t nBytes ); void deallocate ( void * address ); // in this real you have to know what you're doing void release (); // LOCAL ALLOCATORS ONLY } A memory allcoator is (the client-facing interface for) a stateful utility or mechanism that organizes a region of coputer memory, dispensing and reclaiming authorized access to suitable sub-regions on demand possibly non-contiguous","title":"Local Allocator Mechanism"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#memory-allocator-interfaces","text":"Allocators can be supplied for use in mutliple ways: As (stateful) utility functions. Now I can freeee! Doesn't support allocator objects As a \"reference wrapper\" template parameter. passed in as a template parameter Concrete allocator type is available for use by client's compiler Forces a client to be a template in order to hold the allocator reference Allocator type affects the C++ type of the client object As the address of a pure abstract base class Alocator can be held via a base-class reference by a non-template class the choice of allocator does not affect the C++ type of the client object. Allocator must be accessed via virtual-function interface Object must somehow hold an extra address - even for the default case. Have we measured this?","title":"Memory Allocator Interfaces"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#2-understanding-the-problem","text":"What aspects of software affect allocation strategy? Should we supply a local allocator? Which one? If No use Default Global Allocator. If yes should it be done via the base class or bake it into the type C++ 11 style. This is a syntax issue. Which allocator should we use? Do we want to bother destroying each individual object and sub-object or just make them go away? Use Optimal Local-Allocation Strategy","title":"2. Understanding the Problem"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#our-tool-chest-of-allocation-strategies","text":"","title":"Our Tool Chest of Allocation Strategies"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#global-allocator","text":"We have two primary options for how it's implemented: Type Parameter Abstract Base (Object that invokes new and delete) 2 Allocation Strategies","title":"Global Allocator"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#local-allocators","text":"To the block of memory created by the global allocator we now need to affix a pooling allocator. This can be Monotonic Multipool Multipool Then Type Parameter or Abstract Base Then Normal destruction or magically \"Winked out\". Winking out means it's just gone without saying anything","title":"Local Allocators"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#12-allocation-strategies","text":"Label Allocator Type Allocator Binding Desruction of Allocated Objects AS1 Default Global Allocator Type Parameter Normal Destruction AS2 New/Delete Allocator Abstract Base Normal Destruction AS3 Monotonic Type Parameter Normal Destruction AS4 Monotonic Type Parameter (magically) \"Winked Out\" AS5 Monotonic Abstract Base Normal Destruction AS6 Monotonic Abstract Base (magically) \"Winked Out\" AS3 Multipool Type Parameter Normal Destruction AS4 Multipool Type Parameter (magically) \"Winked Out\" AS5 Multipool Abstract Base Normal Destruction AS6 Multipool Abstract Base (magically) \"Winked Out\" AS3 Multipool Type Parameter Normal Destruction AS4 Multipool Type Parameter (magically) \"Winked Out\" AS5 Multipool Abstract Base Normal Destruction AS6 Multipool Abstract Base (magically) \"Winked Out\"","title":"12 Allocation Strategies"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#as1","text":"class allocator { // no data members public : // CREATORS allocator () {} allocator ( const allocator & ){} ~ allocator () {} // MANIPULATORS allocator & operator = () = delete ; void * allocate ( std :: size_t nBytes ){ return :: operator new ( nBytes ); } void deallocate ( void * address ){ :: operator delete ( address ); } }; FREE OPERATORS bool operator == ( const allocator & , const allocator & ){ return true ; } myFunction (){ std :: vector < int > v ; } myFunction (){ // allocator is the TYPE PARAMETER for std::vector here. // this is te same as myFunction above. std :: vector < int , allocator > v ; } Do a benchmark on the vector and destroy it like this: myBenchmark (){ const int N = 1000 ; std :: vector < std :: list < int >*> system ( N ); for ( int i { 0 }; i < N ; ++ i ){ system [ i ] = new std :: list < int > ; // build up list of elements } // Do benchmark (e.g. access links) for ( int i { 0 }; i < N ){ delete system [ i ]; } // system goes out of scope }","title":"AS1"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#as2","text":"Same thing but with a pure abstract base class. class NewDeleteAllocator : public Allocator { // no data members public : // CREATORS NewDeleteAllocator () = default ; ~ NewDeleteAllocator () = default ; NewDeleteAllocator ( const NewDeleteAllocator & ) = delete ; // MANIPULATORS void operator = ( cost NewDeleteAllocator & ) = delete ; inline void * allocate ( std :: size_t nBytes ) override { return :: operator new ( nBytes ); } inline void deallocate ( void * address ) override { :: operator delete ( address ); } } THESE ARE ACTUALLY INLINE AND HE IS NOT","title":"AS2"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#3-analyzing-the-benchmark-data","text":"When and how do you use which allocator, and why?","title":"3. Analyzing the Benchmark Data"},{"location":"cpp/CppCon/Cppcon2017_JohnLakos_LocalArenaMemoryAllocators_pt1/#4-conclusions","text":"What must we remember about memory allocators?","title":"4. Conclusions"},{"location":"cpp/CppCon/Nicolai_Josuttis_The_Nightmare_of_Move_Semantics_for_Trivial_Classes/","text":"The Nightmare of Move Semantics for Trivial Classes notes on a talk by Nicolai Josuttis This is about the problems that a naive programmer has when trying to implement a simple class with two strings. class cust { private : std :: string first ; std :: string last ; int id ; } What this class needs is a constructor. This entire talk is about that constructor. public : Cust ( const std :: string & f , const std :: string & 1 = \"\" , int i = 0 ) : first ( f ), last ( l ), id ( i ) { } The problem with this constructor isn't obvious at first. We do it how we learned it. We take a const string reference because we don't want to copy the string. So we take it by reference because copying is expensive. The first question for the morning is the following: How many expensive strnig calls are done here? Potential memory allocations mallocs if no SSO is used I.e., copy constructors or copy assignements for std::string Say we want to initialize like this Cust c { \"Joe\" , \"Fix\" , 42 }; The arguments expect a string, so we have to craete two strings. Assuming these strings can be over 15 characters so there is no short string optimization. This is our first malloc. Now when they enter the constructor, since they are const reference, they are copied again to creat our final object. Now the initial f and l will get destructed. This means we have 4 mallocs: 2 create + 2 copy. Before c++ 11 we would do this by overloading the constructor with const char* inputs. This allows us to avoid the 2 copy mallocs. But this breaks down when you try to mix std::strings with inlines. So we have to overload for all four functions class Cust { private : std :: string first ; std :: string last ; int id ; public : Cust ( const std :: string & f , const std :: string & l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } Cust ( const char * f , const char * l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } Cust ( const std :: string & f , const char * l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } Cust ( const char * f , const std :: string & l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } } This is what we need to do if we want to make it perfect before cpp 11. But now we have move semantics. This still has the same amount of copies as just inputting the string, because there's no support for std::move in the constructor. So let's overload the constructor for move semantics public : Cust ( std :: string && f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Now what happens when we initialize the string, is that we steal the heap memory of \"Joe\" and the heap memory of \"Fix\". This means two mallocs only. This is because we still need to create temps, but copying them got cheap since we are stealing the memory from the created temps. Again with this we need all the overloads for all the combinations. public : Cust ( std :: string & f , std :: string & l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string & l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string & f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } This is great and things work! But wait... what happens when you pass only one argument? Cust f { \"nico\" }; // Error: ambigious It doesn't compile. The problem is that we now have two matching constructors. So what you can do now is remove some default values. public : Cust ( std :: string & f , std :: string & l , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string & l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string & f , std :: string && l , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Now that previous error will compile. Let's try anothing this: copy intialization: cust g = \"nico\" ; //ERROR: two implicit user-defined onversions This hasn't worked all along. Also the following example has never compiled in c++ struct S { S ( std :: string s ); }; S x = \"hi\" ; // ERROR So this means we need to bring back our const * overloads. Technically we only need to overload three more because copy initiliazation is only possible with a single argument. But that would be too ambiguous so let's just do all of them. Cust ( const std :: string & f , const std :: string & l , int i = 0 ); Cust ( const std :: string & f , const std :: string && l = \"\" , int i = 0 ); Cust ( const std :: string & f , const char * l , int i = 0 ); Cust ( const std :: string && f , const std :: string & l , int i = 0 ); Cust ( const std :: string && f , const std :: string && l = \"\" , int i = 0 ); Cust ( const std :: string && f , const char * l , int i = 0 ); Cust ( const char * f , const std :: string & l , int i = 0 ); Cust ( const char * f , const std :: string && l = \"\" , int i = 0 ); Cust ( const char * f , const char * l , int i = 0 ); Now it works. We should at least talk about taking the arguments by value. Even though they are stings. This method creates 4 mallocs whith copying the temp strings. Now let's pass them by move. class Cust { private : std :: string first ; std :: string last ; int id ; public : Cust ( std :: string f , std :: string l = \"\" , int i = 0 ) : first { std :: move ( f )}, last { std :: move ( l )}, id ( i ) { } // for copy initialization Cust ( const char * f ) : first ( f ), last ( \"\" ), id ( 0 ) { } } This now only requires 2 mallocs, because we are stealing the memory with std::move. Now we can continue using templates, but I haven't learned about that yet, so I'm going to put this on hold to be continued after I have a deeper understanding of template metaprogramming.","title":"The Nightmare of Move Semantics for Trivial Classes"},{"location":"cpp/CppCon/Nicolai_Josuttis_The_Nightmare_of_Move_Semantics_for_Trivial_Classes/#the-nightmare-of-move-semantics-for-trivial-classes","text":"notes on a talk by Nicolai Josuttis This is about the problems that a naive programmer has when trying to implement a simple class with two strings. class cust { private : std :: string first ; std :: string last ; int id ; } What this class needs is a constructor. This entire talk is about that constructor. public : Cust ( const std :: string & f , const std :: string & 1 = \"\" , int i = 0 ) : first ( f ), last ( l ), id ( i ) { } The problem with this constructor isn't obvious at first. We do it how we learned it. We take a const string reference because we don't want to copy the string. So we take it by reference because copying is expensive. The first question for the morning is the following:","title":"The Nightmare of Move Semantics for Trivial Classes"},{"location":"cpp/CppCon/Nicolai_Josuttis_The_Nightmare_of_Move_Semantics_for_Trivial_Classes/#how-many-expensive-strnig-calls-are-done-here","text":"Potential memory allocations mallocs if no SSO is used I.e., copy constructors or copy assignements for std::string Say we want to initialize like this Cust c { \"Joe\" , \"Fix\" , 42 }; The arguments expect a string, so we have to craete two strings. Assuming these strings can be over 15 characters so there is no short string optimization. This is our first malloc. Now when they enter the constructor, since they are const reference, they are copied again to creat our final object. Now the initial f and l will get destructed. This means we have 4 mallocs: 2 create + 2 copy. Before c++ 11 we would do this by overloading the constructor with const char* inputs. This allows us to avoid the 2 copy mallocs. But this breaks down when you try to mix std::strings with inlines. So we have to overload for all four functions class Cust { private : std :: string first ; std :: string last ; int id ; public : Cust ( const std :: string & f , const std :: string & l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } Cust ( const char * f , const char * l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } Cust ( const std :: string & f , const char * l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } Cust ( const char * f , const std :: string & l = \"\" , int i = 0 ) : first { f }, last { l }, id { i } { } } This is what we need to do if we want to make it perfect before cpp 11. But now we have move semantics. This still has the same amount of copies as just inputting the string, because there's no support for std::move in the constructor. So let's overload the constructor for move semantics public : Cust ( std :: string && f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Now what happens when we initialize the string, is that we steal the heap memory of \"Joe\" and the heap memory of \"Fix\". This means two mallocs only. This is because we still need to create temps, but copying them got cheap since we are stealing the memory from the created temps. Again with this we need all the overloads for all the combinations. public : Cust ( std :: string & f , std :: string & l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string & l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string & f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } This is great and things work! But wait... what happens when you pass only one argument? Cust f { \"nico\" }; // Error: ambigious It doesn't compile. The problem is that we now have two matching constructors. So what you can do now is remove some default values. public : Cust ( std :: string & f , std :: string & l , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string && l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string && f , std :: string & l = \"\" , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Cust ( std :: string & f , std :: string && l , int i = 0 ) : first ( std :: move ( f )), last ( std :: move ( l )), id ( i ) { } Now that previous error will compile. Let's try anothing this: copy intialization: cust g = \"nico\" ; //ERROR: two implicit user-defined onversions This hasn't worked all along. Also the following example has never compiled in c++ struct S { S ( std :: string s ); }; S x = \"hi\" ; // ERROR So this means we need to bring back our const * overloads. Technically we only need to overload three more because copy initiliazation is only possible with a single argument. But that would be too ambiguous so let's just do all of them. Cust ( const std :: string & f , const std :: string & l , int i = 0 ); Cust ( const std :: string & f , const std :: string && l = \"\" , int i = 0 ); Cust ( const std :: string & f , const char * l , int i = 0 ); Cust ( const std :: string && f , const std :: string & l , int i = 0 ); Cust ( const std :: string && f , const std :: string && l = \"\" , int i = 0 ); Cust ( const std :: string && f , const char * l , int i = 0 ); Cust ( const char * f , const std :: string & l , int i = 0 ); Cust ( const char * f , const std :: string && l = \"\" , int i = 0 ); Cust ( const char * f , const char * l , int i = 0 ); Now it works. We should at least talk about taking the arguments by value. Even though they are stings. This method creates 4 mallocs whith copying the temp strings. Now let's pass them by move. class Cust { private : std :: string first ; std :: string last ; int id ; public : Cust ( std :: string f , std :: string l = \"\" , int i = 0 ) : first { std :: move ( f )}, last { std :: move ( l )}, id ( i ) { } // for copy initialization Cust ( const char * f ) : first ( f ), last ( \"\" ), id ( 0 ) { } } This now only requires 2 mallocs, because we are stealing the memory with std::move. Now we can continue using templates, but I haven't learned about that yet, so I'm going to put this on hold to be continued after I have a deeper understanding of template metaprogramming.","title":"How many expensive strnig calls are done here?"},{"location":"cpp/LearnCpp.com/000_Introduction/","text":"These are notes from going through the learning on this site They are not comprehensive, but purely based on what I found useful. Introduction to Programming languages Assembly translates machine code for the hardware. C++ is designed to be hardware agnostic - thus considered a high-level language. Assembly: mov al, 061h C++: a = 97 The process of translating high level code into runtime code is either compiling or interpreting. Compilers read source code and generate executables that can then be run. Interpreters directly execute instructions in the source code without requiring a compilation stage. They are generally less efficient. Introduction to C/C++ The C language was developed as a language to write operating systems with, a systems programming language . Most of the unix operating system is written in C. Philosophy The underlying design philosophy of C and C++ can be summed up as \"trust the programmer\" - which allows people to develop truly terrifying code. Knowing what not to do is almost as important as knowing what to do. Workflow Step 2 is very important. Too often you will have an idea and start programming immediately. Here's a list of requirements for good software: Structured well (not complicated or confusing) Documented well (especially what assumptions are being made) Modular design (interchangable parts) Robust and able to give meaningful error messages 20% of the time is spent writing the program, 80% is maintinence. Better to spend a bit more time up front. Warning Name code files .cpp This means that the file is a source file! Some people us .cc but it's not a standard. Compiling The compiler goes through each (.cpp) file and does two things: Checks that the code follows the rules of C++ Translates the code into machine language file called object file . The object file ends in .o Linking Object Files and Libraries After the compiler creates the appropriate code the linker brings in the correct libraries. This tutorial series does not cover a Makefile which is one of the things I was hoping to learn. It's considered \"advanced\". Writing your first program This is a simple helloworld example. Configuring your compiler: Build configurations A build configuration (aka a build target ) is a colelction of project settings that determine how things in the project will be built. Because I am using vim, I've folowed this guide to set up vim with cmake. I also used his previous guide to futher extend vim with some more savvy plugins. The guides also go over linking libraries with cmake, which was very useful. I now have a project root and buildsystem for following alowing with these tutorials. There are two types of build configuration usually: debug and release. Debug is great for prints and breaks, release is optimized and used for distrubution and benchmarking. Configuring your compiler: compiler extensions You generally want to disable all compilier extentions, because they will make it so that you can only compile with this compiler. I did this by adding -pedantic-errors to my gcc in my CMakeLists.txt Compilers issue warnings about things that are not great. It's good not to let warnings pile up. Sometimes you may need to tell the compiler not to generate a particular warning. Gcc supports this with #pragma directives. My gcc flags are as follows to enable maximum warnings set(gcc_flags \"-Wall;-Werror;-Wunused;-Wextra;-Wshadow;-Wshadow;-Wformat=2;-pedantic-errors\")","title":"000 Introduction"},{"location":"cpp/LearnCpp.com/000_Introduction/#introduction-to-programming-languages","text":"Assembly translates machine code for the hardware. C++ is designed to be hardware agnostic - thus considered a high-level language. Assembly: mov al, 061h C++: a = 97 The process of translating high level code into runtime code is either compiling or interpreting. Compilers read source code and generate executables that can then be run. Interpreters directly execute instructions in the source code without requiring a compilation stage. They are generally less efficient.","title":"Introduction to Programming languages"},{"location":"cpp/LearnCpp.com/000_Introduction/#introduction-to-cc","text":"The C language was developed as a language to write operating systems with, a systems programming language . Most of the unix operating system is written in C.","title":"Introduction to C/C++"},{"location":"cpp/LearnCpp.com/000_Introduction/#philosophy","text":"The underlying design philosophy of C and C++ can be summed up as \"trust the programmer\" - which allows people to develop truly terrifying code. Knowing what not to do is almost as important as knowing what to do.","title":"Philosophy"},{"location":"cpp/LearnCpp.com/000_Introduction/#workflow","text":"Step 2 is very important. Too often you will have an idea and start programming immediately. Here's a list of requirements for good software: Structured well (not complicated or confusing) Documented well (especially what assumptions are being made) Modular design (interchangable parts) Robust and able to give meaningful error messages 20% of the time is spent writing the program, 80% is maintinence. Better to spend a bit more time up front. Warning Name code files .cpp This means that the file is a source file! Some people us .cc but it's not a standard.","title":"Workflow"},{"location":"cpp/LearnCpp.com/000_Introduction/#compiling","text":"The compiler goes through each (.cpp) file and does two things: Checks that the code follows the rules of C++ Translates the code into machine language file called object file . The object file ends in .o","title":"Compiling"},{"location":"cpp/LearnCpp.com/000_Introduction/#linking-object-files-and-libraries","text":"After the compiler creates the appropriate code the linker brings in the correct libraries. This tutorial series does not cover a Makefile which is one of the things I was hoping to learn. It's considered \"advanced\".","title":"Linking Object Files and Libraries"},{"location":"cpp/LearnCpp.com/000_Introduction/#writing-your-first-program","text":"This is a simple helloworld example.","title":"Writing your first program"},{"location":"cpp/LearnCpp.com/000_Introduction/#configuring-your-compiler-build-configurations","text":"A build configuration (aka a build target ) is a colelction of project settings that determine how things in the project will be built. Because I am using vim, I've folowed this guide to set up vim with cmake. I also used his previous guide to futher extend vim with some more savvy plugins. The guides also go over linking libraries with cmake, which was very useful. I now have a project root and buildsystem for following alowing with these tutorials. There are two types of build configuration usually: debug and release. Debug is great for prints and breaks, release is optimized and used for distrubution and benchmarking.","title":"Configuring your compiler: Build configurations"},{"location":"cpp/LearnCpp.com/000_Introduction/#configuring-your-compiler-compiler-extensions","text":"You generally want to disable all compilier extentions, because they will make it so that you can only compile with this compiler. I did this by adding -pedantic-errors to my gcc in my CMakeLists.txt Compilers issue warnings about things that are not great. It's good not to let warnings pile up. Sometimes you may need to tell the compiler not to generate a particular warning. Gcc supports this with #pragma directives. My gcc flags are as follows to enable maximum warnings set(gcc_flags \"-Wall;-Werror;-Wunused;-Wextra;-Wshadow;-Wshadow;-Wformat=2;-pedantic-errors\")","title":"Configuring your compiler: compiler extensions"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/","text":"Statements and the structure of a program Yay we can finally start programming! At the end of this chapter we can write our own basic programs. A statement is a type of instruction for a program that causes the program to perform some action . Statements are like sentences. Most statements end in ; There are many different kinds of statments in C++: Declaration statements Jump Statements Expression statements Compount statements Selection statements (conditionals) Iteration statements (loops) Try blocks Statements are usually groupd into functions , which are collections of statements that execute sequentially. Every program must have a main function, which then starts all other functions. After the main function is finished the program usually terminates. Comments in C++ are started with // Multi-line comments are like this /* */ This is identical to vex. Proper use of comments For each library explain what the library does. For each program or function in a library explain how the code is going to accomplish the goal, and for statements what a statement is doing. Comments should be bringing the statement into the larger context, not re-writing what the statement is already saying. Describe why you made certain decisions. Don't ever assume people have any idea what your code is doing. In vim my hotkey for commentnig out code is <c-//> Intruduction to variables Data is any information that can be moved, processed, or stored by a computer. Programs are collections of instructions that manipulate data to produce a desired result. RAM (random access memory) can be though of as a series of mailboxes that can be used to hold data while the program is running. Each piece of data is called a value . In C++, direct memory access is not allowed. All values must be indirectly accessed through objects : regions of storage (usually memory) that have a value and properties. Objects that we use are usually named objects called variables , the name of which is called an identifier . In C++ objects are NOT functions. Variables are instantiated, by a statement called a definition . int x; // define a varible named x of type int At runtime (when the program is run), that variable will be instantiated (the variable object created and assigned to memory address). You cannot use uninstantiated variables! Instantiated objects are called an instance . Each variable must have a type which tells the compiler what object class that variable is. Types tell the program how to interpret a value in memory. In C++ the type of a varible must be known at compile-time - even if that type is auto. You can convert between types by casting the variables. You can also create your own types of course. Don't define variables of the same type on a single line. Just because you can doesn't mean you should. Variable assignment and initialization Assignment is when you give a varible a value. It is when you copy a value into a variable. = is the assignment operator . When you assigne a new value to a varriable it overwrites the previous value. Initialization is when you define and assign the variable in a single line. int width = 5; . Direct initialization is when you intialize from the value that a function/object returns. Generally you should initialize all your variables using list initialization . int width { 5 } This is one of the most general ways of initializing variables. You can leave the brackets empty to initialize to defaults, which is called value initialization . int width {}; The great thing about list initialization is that it will throw an error if you are initializing to an incorrect value. It might be worth int x { 0 } if you are explicity going to use that value and not immediately replace it. Generally you always want to initialize your variables upon creation to be more explicit unless there's a bespoke performance reason not to. Introduction to iostream: cout, cin, and endl std::cout throws things into the \"character output\" and is part of the std (standard) library. The insertion operator (<<) is used to send the text to the world. To print multiple lines you can use the << multiple times with std:endl . It's more efficient use use '\\n' though. Note that this is a backslash. std::cin >> x; prompts the user for an input and puts that value into x. Note that the >> arrows are pointing the other way in the direction the data is going. Note that this does not replace keyboard input as the user is required to hit enter to confirm their entry. Uninitialized variables and undefined behaviour C++ doesn't initialize most variables to a default. The default value is whatever garbage is already located at that address! This is called an uninitialized variable. Variables can have a value and be unintialized, so it's not a good idea to test for them having a value. Always initialize your variables ! Uninitialized variables is one example of undefined behaviour (UB) . This is the result of executing code whoe behaviour is not well defined by the c++ language. The following is a list of possible symptoms of undefined behaviour: Different results each time it's run (sys.argv!) Incorrect result Inconsisten behaviour Incorrect results come after a time Crashes Only works on some compilers Changing code in one place has very strange effects in other places Keywords and naming identifiers Keywords are words that have a predefined meaning in C++. Don't use these as variable names. There are also special identifiers that are not reserved, override, final import, module Identifier naming rules Cannot be keyword Can only have letter, numbers and _ Must begin with letter or underscore (cannot begin with number) Case sensitive Identidifer best practices lowercase unless user defined struct, class or enumeration snake_case or camelCase Always match the existing style of code don't begin with _ better to be too long than not descriptive enough trivial identifiers (like i in a quick for loop) are ok. avoid abbreviations Use comments to clarify more information if way too long. Whitespace and basic formatting Whitespace referrs to characters that are used for formatting purposes like spaces, tabs, and newlines. C++ compiilers generally ignore this, which means C++ is a whitespace-nidependent language. In quoted text they do matter though. You cannot have newline in quoted text. Also single line comments end with a newline character (duh) Tabs vs. Spaces. I use the Google C++ syle guide with the curly brace on the line becaus I want to see more code without scrolling. Like pep8 try to keep lines under 80 chars in length. When initializaing many varialbes you can tab them so that they are easier to read. Introduction to literals and operators A literal (aka literal constant) is a fixed values that is hardcoded into your program. An operation is a mathemetical calculation involving zero or more input values (called operands ). The symbol specifying the operation to be performed is called the operator . In addition to (+, -, *, /, ==, >, < etc.) in C++ we also have (=, <<, >>) There are three different arities of operators in C++ * Unary - act on one operand * Binary - act on left and right operand * Ternary - act on three operands (there is only one of these) You can chain operators together and the result will evaluate them in the order of operations like in maths. Introduction to expressions An expression is a combination of literals, variables, operators or explicit function calls that produce a signle output value. An expression is evaluated until only a single value, the result remains. Anywhere you use a single value in c++ you can use an expression instead. You can make expression statements which will compile and then be discarded unless being assigned to a variable.","title":"Statements and the structure of a program"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#statements-and-the-structure-of-a-program","text":"Yay we can finally start programming! At the end of this chapter we can write our own basic programs. A statement is a type of instruction for a program that causes the program to perform some action . Statements are like sentences. Most statements end in ; There are many different kinds of statments in C++: Declaration statements Jump Statements Expression statements Compount statements Selection statements (conditionals) Iteration statements (loops) Try blocks Statements are usually groupd into functions , which are collections of statements that execute sequentially. Every program must have a main function, which then starts all other functions. After the main function is finished the program usually terminates. Comments in C++ are started with // Multi-line comments are like this /* */ This is identical to vex.","title":"Statements and the structure of a program"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#proper-use-of-comments","text":"For each library explain what the library does. For each program or function in a library explain how the code is going to accomplish the goal, and for statements what a statement is doing. Comments should be bringing the statement into the larger context, not re-writing what the statement is already saying. Describe why you made certain decisions. Don't ever assume people have any idea what your code is doing. In vim my hotkey for commentnig out code is <c-//>","title":"Proper use of comments"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#intruduction-to-variables","text":"Data is any information that can be moved, processed, or stored by a computer. Programs are collections of instructions that manipulate data to produce a desired result. RAM (random access memory) can be though of as a series of mailboxes that can be used to hold data while the program is running. Each piece of data is called a value . In C++, direct memory access is not allowed. All values must be indirectly accessed through objects : regions of storage (usually memory) that have a value and properties. Objects that we use are usually named objects called variables , the name of which is called an identifier . In C++ objects are NOT functions. Variables are instantiated, by a statement called a definition . int x; // define a varible named x of type int At runtime (when the program is run), that variable will be instantiated (the variable object created and assigned to memory address). You cannot use uninstantiated variables! Instantiated objects are called an instance . Each variable must have a type which tells the compiler what object class that variable is. Types tell the program how to interpret a value in memory. In C++ the type of a varible must be known at compile-time - even if that type is auto. You can convert between types by casting the variables. You can also create your own types of course. Don't define variables of the same type on a single line. Just because you can doesn't mean you should.","title":"Intruduction to variables"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#variable-assignment-and-initialization","text":"Assignment is when you give a varible a value. It is when you copy a value into a variable. = is the assignment operator . When you assigne a new value to a varriable it overwrites the previous value. Initialization is when you define and assign the variable in a single line. int width = 5; . Direct initialization is when you intialize from the value that a function/object returns. Generally you should initialize all your variables using list initialization . int width { 5 } This is one of the most general ways of initializing variables. You can leave the brackets empty to initialize to defaults, which is called value initialization . int width {}; The great thing about list initialization is that it will throw an error if you are initializing to an incorrect value. It might be worth int x { 0 } if you are explicity going to use that value and not immediately replace it. Generally you always want to initialize your variables upon creation to be more explicit unless there's a bespoke performance reason not to.","title":"Variable assignment and initialization"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#introduction-to-iostream-cout-cin-and-endl","text":"std::cout throws things into the \"character output\" and is part of the std (standard) library. The insertion operator (<<) is used to send the text to the world. To print multiple lines you can use the << multiple times with std:endl . It's more efficient use use '\\n' though. Note that this is a backslash. std::cin >> x; prompts the user for an input and puts that value into x. Note that the >> arrows are pointing the other way in the direction the data is going. Note that this does not replace keyboard input as the user is required to hit enter to confirm their entry.","title":"Introduction to iostream: cout, cin, and endl"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#uninitialized-variables-and-undefined-behaviour","text":"C++ doesn't initialize most variables to a default. The default value is whatever garbage is already located at that address! This is called an uninitialized variable. Variables can have a value and be unintialized, so it's not a good idea to test for them having a value. Always initialize your variables ! Uninitialized variables is one example of undefined behaviour (UB) . This is the result of executing code whoe behaviour is not well defined by the c++ language. The following is a list of possible symptoms of undefined behaviour: Different results each time it's run (sys.argv!) Incorrect result Inconsisten behaviour Incorrect results come after a time Crashes Only works on some compilers Changing code in one place has very strange effects in other places","title":"Uninitialized variables and undefined behaviour"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#keywords-and-naming-identifiers","text":"Keywords are words that have a predefined meaning in C++. Don't use these as variable names. There are also special identifiers that are not reserved, override, final import, module","title":"Keywords and naming identifiers"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#identifier-naming-rules","text":"Cannot be keyword Can only have letter, numbers and _ Must begin with letter or underscore (cannot begin with number) Case sensitive","title":"Identifier naming rules"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#identidifer-best-practices","text":"lowercase unless user defined struct, class or enumeration snake_case or camelCase Always match the existing style of code don't begin with _ better to be too long than not descriptive enough trivial identifiers (like i in a quick for loop) are ok. avoid abbreviations Use comments to clarify more information if way too long.","title":"Identidifer best practices"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#whitespace-and-basic-formatting","text":"Whitespace referrs to characters that are used for formatting purposes like spaces, tabs, and newlines. C++ compiilers generally ignore this, which means C++ is a whitespace-nidependent language. In quoted text they do matter though. You cannot have newline in quoted text. Also single line comments end with a newline character (duh) Tabs vs. Spaces. I use the Google C++ syle guide with the curly brace on the line becaus I want to see more code without scrolling. Like pep8 try to keep lines under 80 chars in length. When initializaing many varialbes you can tab them so that they are easier to read.","title":"Whitespace and basic formatting"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#introduction-to-literals-and-operators","text":"A literal (aka literal constant) is a fixed values that is hardcoded into your program. An operation is a mathemetical calculation involving zero or more input values (called operands ). The symbol specifying the operation to be performed is called the operator . In addition to (+, -, *, /, ==, >, < etc.) in C++ we also have (=, <<, >>) There are three different arities of operators in C++ * Unary - act on one operand * Binary - act on left and right operand * Ternary - act on three operands (there is only one of these) You can chain operators together and the result will evaluate them in the order of operations like in maths.","title":"Introduction to literals and operators"},{"location":"cpp/LearnCpp.com/001_Cpp_Basics/#introduction-to-expressions","text":"An expression is a combination of literals, variables, operators or explicit function calls that produce a signle output value. An expression is evaluated until only a single value, the result remains. Anywhere you use a single value in c++ you can use an expression instead. You can make expression statements which will compile and then be discarded unless being assigned to a variable.","title":"Introduction to expressions"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/","text":"C++ Basics: Functions and Files As defiend in the previous section: A function is a reusable sequence of statements designed to do a particular job. Functions allow programs to be split into modular chunks that are bestter for organizing, testing and using. Functions users write are called user-defiend functions . The function body is the part between the curly braces. It's important to note that in C++ nested function are not supported. This is different than python. Functions can give a return value - the result of a function. When you defined a function, the first word is always the return type . The return statement inside the function indicates the specific return value . The process of copying the return value from the function back to the caller is called return by value . Functions can return a void value if there is no other sensible value they might want to reuturn. Only these functions do not require a return statement. The main function always returns an integer. This value returned frmo main is called status code , exit code or return code and is used to determin if the program ran successfully. You should return 0 if the program ran normally. If a function has a non-void return type, it must return a value of that type. Undefined behaviour ensues if you don't. DRY stands for daerdyoshi and also \"Do not Repeat Yourself\" - which basically means that you shouldn't have duplicate code. I'd like to argue and say that duplicate code can be valuable when you want your code to be more readable, as this concept can be taken too far. Introduction to function paraemters and arguments A function parameter is a variable that is is designed to have a function argment bound to it as an input to the function. Parameters are the variables used in the function, argments are the variables that are given outside the fucntion. The process of passing an argument to a parameter is called pass by value . You can use return values as arguments. Don't make function calls where argment order matters. Introduction to local scope Function parameters and variables defined in the function body are called local variables . They are accessible only within the function body. They are all automatically destroyed when the function ends. The time between an object's creation and destruction is considered it's lifetime . The scope of an identifier determines where the identifier can be accessed. When it can be accessed we say the identifier is in scope , and if not it is out of scope . Scop is checked at compile time, and the program won't compile if trying to access an identifier outside of it's scope. They say to defined local varialbes as close to their first use as possible, but I prefer to define them at the top of whatever scope they are used in with nice descriptive code. Functions should do only one task Foward declations and definitions You can't call a function before it is defined in C++. To work around this you can finess your functino order or use forward declaration . Forward declaration allows us to tell the compiler about the existence of an identifier before defining the identifier. The way to write a forward declaration for a function is using a declaration statement called a function prototype . It's the same as desclaring a functino but without the function body. int add(int x, int y) These are generally defined in the header files. Definition and declaration are often used interchangably. The key difference is that when you define a identifier you are actually implementing a value to it, but declaring it only creats the identifier. Definitions are needed to satisfy the linker. An identifier without definition will cause the linker to error. The one definition rule (ODR) states that things may only be defined once. When given file , a function, object, type, or template can only have one def When given a program , an object or normal function can have only one def. types, templates, inline functions and variables are allowed to have identical defs in different files. Note that it's possible to overload functions if you want to re-use them with differnt inputs. Programming with multiple code files If you just take your function into an external file it won't automatically work because it needs to get added to your project lol. I set up a new project and added the file manually in my CMakeLists.txt - though I'm sure this can be done in a much better way. Naming collisions and an introduction to namespaces If two functions are named the same you have a naming collision (or nameing conflict ). Luckily this will be detected by the linker. This can happen from two files in the same program or two or more functions added via an #include. You keep function names from conflicting through the magic of namespace Namespaces are regions that allow you to declare names inside them for the purpose of disambiguation. They provide a namespace scope to the names declared inside them. A name defined in a specific namespace won't be mistaken for an identical name declared in another scope. The default namespace is the global namespace or global scope . Originally in C++ everything in std:: was in the global scope, but this got changed. To tell the compiler to look for a function in a specific namespace you can either explicityly use the namespace qualifier std:: or using namespace std . The second method is called a using directive , which tells the compiler to checka spedified namespace when trying to resolve an identifier that has no namespace prefix. It's greatly preferred to write out the namespaces in order to be more explicit and because it's easier to run into conflicts otherwise. Introduction to the preprocessor Prior to compilations, code goes thruogh a translation phase and then becomes a translation unit . The most noteworthy translation phase is the preprocessor which is basically it's own program changing the text in each code file. When the preprocessor runs through a file, it is searching for preprocessor directives , which aer instructions that start with a # and end with a newline instead of a semicolon. The most common preprocessor directive is the #include . These directives are replaced by the entire code of that file in memory as the preprocessor. This is used almost excusively with header files. The #define directive can be used to create a macro : a rule that defines how input text is converted into replacement output text. There are two types of macros: object-like and function-like. Function like macros are generally consered dangerous, and anything they do can be done by a normal function. Object-like macros Object like macros have two forms: #define identifier #define identifier substitution_text When the preprocessor encounters the second one, the identifier is replaced with the substitution text. The convention for the identifier is ALL_CAPS. These provide a cheaper alternative to global constant variables, but those times are GONE so you only really see them in legacy code. Object like macros with no substitution text simply remove that word. If the word is part of another preprocessor directive it is not removed. Conditional compilation There are quite a few conditional compilation directives, the ones most used are #ifdev, #ifndev and #endif . These allow the preprocessor to check what has already been defined. So if a certain file has already been included you are not including it twice. #if 0 This basically works as a multi line comment paird with #endif Defines are not part of local/global scope, but part of the file scope. Header files These are files designed for the purpose of forward declaration. They usually have a .h extention, but sometimes have .hpp. They allow us to put declarations in one location and then impor them whereever we need them. The can save a lot of typing in multi-file programs. When you #include a header file, that files is added to your current file at compilation time. Then, later, the linker links those function to their definitions. Header files should generally not contain functions and variable definitions. An exception can be made for symbolic constants. Header files paired with code files shoul have the same name. Header files should be included in their corresponding src files. Use double quotes to include header files that you've written or are in the current directory, use angled brackets for others. For including the standard library, leave out the .h Do not include header files by relative pathing. It's better to tell the compiler which directories to add. Header files may include other headerfiles, but should do so explicitly and not rely on those header files including other headfiles. Order your #includes like this: Your own user-defined headers Third party headers Std headers More header best practices Always include header guards. Do not define variables and functions in header files except for global constants. Give the header files the same name as the source files Each header has one specific job and should be as independent as possible Try to include as little as possible and be mindful about it Each header should compile on it's own. Only #include what you need. Do not #include .cpp files. Header guards Header guards protect the ODR (One definition rule). header guards aka include guards are conditional compilation directives. #ifndev SOME_UNIQUE_NAME_HERE #define SOME_UNIQUE_NAME_HERE // your declarations #endif This prevents the same function from being compiled multiple times. You should be usinging more comlex names for your header guards than just the filename. This is a good template: <PROJECT>_<PATH>_<FILE>_H Note that if you're dumb and you write your functions into your header files they can be included multiple times. Example: main and geometry both include poly ops. If the head files only contains forward definitions, this is no problem, otherwise you will get a conflict.","title":"C++ Basics: Functions and Files"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#c-basics-functions-and-files","text":"As defiend in the previous section: A function is a reusable sequence of statements designed to do a particular job. Functions allow programs to be split into modular chunks that are bestter for organizing, testing and using. Functions users write are called user-defiend functions . The function body is the part between the curly braces. It's important to note that in C++ nested function are not supported. This is different than python. Functions can give a return value - the result of a function. When you defined a function, the first word is always the return type . The return statement inside the function indicates the specific return value . The process of copying the return value from the function back to the caller is called return by value . Functions can return a void value if there is no other sensible value they might want to reuturn. Only these functions do not require a return statement. The main function always returns an integer. This value returned frmo main is called status code , exit code or return code and is used to determin if the program ran successfully. You should return 0 if the program ran normally. If a function has a non-void return type, it must return a value of that type. Undefined behaviour ensues if you don't. DRY stands for daerdyoshi and also \"Do not Repeat Yourself\" - which basically means that you shouldn't have duplicate code. I'd like to argue and say that duplicate code can be valuable when you want your code to be more readable, as this concept can be taken too far.","title":"C++ Basics: Functions and Files"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#introduction-to-function-paraemters-and-arguments","text":"A function parameter is a variable that is is designed to have a function argment bound to it as an input to the function. Parameters are the variables used in the function, argments are the variables that are given outside the fucntion. The process of passing an argument to a parameter is called pass by value . You can use return values as arguments. Don't make function calls where argment order matters.","title":"Introduction to function paraemters and arguments"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#introduction-to-local-scope","text":"Function parameters and variables defined in the function body are called local variables . They are accessible only within the function body. They are all automatically destroyed when the function ends. The time between an object's creation and destruction is considered it's lifetime . The scope of an identifier determines where the identifier can be accessed. When it can be accessed we say the identifier is in scope , and if not it is out of scope . Scop is checked at compile time, and the program won't compile if trying to access an identifier outside of it's scope. They say to defined local varialbes as close to their first use as possible, but I prefer to define them at the top of whatever scope they are used in with nice descriptive code. Functions should do only one task","title":"Introduction to local scope"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#foward-declations-and-definitions","text":"You can't call a function before it is defined in C++. To work around this you can finess your functino order or use forward declaration . Forward declaration allows us to tell the compiler about the existence of an identifier before defining the identifier. The way to write a forward declaration for a function is using a declaration statement called a function prototype . It's the same as desclaring a functino but without the function body. int add(int x, int y) These are generally defined in the header files. Definition and declaration are often used interchangably. The key difference is that when you define a identifier you are actually implementing a value to it, but declaring it only creats the identifier. Definitions are needed to satisfy the linker. An identifier without definition will cause the linker to error. The one definition rule (ODR) states that things may only be defined once. When given file , a function, object, type, or template can only have one def When given a program , an object or normal function can have only one def. types, templates, inline functions and variables are allowed to have identical defs in different files. Note that it's possible to overload functions if you want to re-use them with differnt inputs.","title":"Foward declations and definitions"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#programming-with-multiple-code-files","text":"If you just take your function into an external file it won't automatically work because it needs to get added to your project lol. I set up a new project and added the file manually in my CMakeLists.txt - though I'm sure this can be done in a much better way.","title":"Programming with multiple code files"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#naming-collisions-and-an-introduction-to-namespaces","text":"If two functions are named the same you have a naming collision (or nameing conflict ). Luckily this will be detected by the linker. This can happen from two files in the same program or two or more functions added via an #include. You keep function names from conflicting through the magic of namespace Namespaces are regions that allow you to declare names inside them for the purpose of disambiguation. They provide a namespace scope to the names declared inside them. A name defined in a specific namespace won't be mistaken for an identical name declared in another scope. The default namespace is the global namespace or global scope . Originally in C++ everything in std:: was in the global scope, but this got changed. To tell the compiler to look for a function in a specific namespace you can either explicityly use the namespace qualifier std:: or using namespace std . The second method is called a using directive , which tells the compiler to checka spedified namespace when trying to resolve an identifier that has no namespace prefix. It's greatly preferred to write out the namespaces in order to be more explicit and because it's easier to run into conflicts otherwise.","title":"Naming collisions and an introduction to namespaces"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#introduction-to-the-preprocessor","text":"Prior to compilations, code goes thruogh a translation phase and then becomes a translation unit . The most noteworthy translation phase is the preprocessor which is basically it's own program changing the text in each code file. When the preprocessor runs through a file, it is searching for preprocessor directives , which aer instructions that start with a # and end with a newline instead of a semicolon. The most common preprocessor directive is the #include . These directives are replaced by the entire code of that file in memory as the preprocessor. This is used almost excusively with header files. The #define directive can be used to create a macro : a rule that defines how input text is converted into replacement output text. There are two types of macros: object-like and function-like. Function like macros are generally consered dangerous, and anything they do can be done by a normal function.","title":"Introduction to the preprocessor"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#object-like-macros","text":"Object like macros have two forms: #define identifier #define identifier substitution_text When the preprocessor encounters the second one, the identifier is replaced with the substitution text. The convention for the identifier is ALL_CAPS. These provide a cheaper alternative to global constant variables, but those times are GONE so you only really see them in legacy code. Object like macros with no substitution text simply remove that word. If the word is part of another preprocessor directive it is not removed.","title":"Object-like macros"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#conditional-compilation","text":"There are quite a few conditional compilation directives, the ones most used are #ifdev, #ifndev and #endif . These allow the preprocessor to check what has already been defined. So if a certain file has already been included you are not including it twice.","title":"Conditional compilation"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#if-0","text":"This basically works as a multi line comment paird with #endif Defines are not part of local/global scope, but part of the file scope.","title":"#if 0"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#header-files","text":"These are files designed for the purpose of forward declaration. They usually have a .h extention, but sometimes have .hpp. They allow us to put declarations in one location and then impor them whereever we need them. The can save a lot of typing in multi-file programs. When you #include a header file, that files is added to your current file at compilation time. Then, later, the linker links those function to their definitions. Header files should generally not contain functions and variable definitions. An exception can be made for symbolic constants. Header files paired with code files shoul have the same name. Header files should be included in their corresponding src files. Use double quotes to include header files that you've written or are in the current directory, use angled brackets for others. For including the standard library, leave out the .h Do not include header files by relative pathing. It's better to tell the compiler which directories to add. Header files may include other headerfiles, but should do so explicitly and not rely on those header files including other headfiles. Order your #includes like this: Your own user-defined headers Third party headers Std headers More header best practices Always include header guards. Do not define variables and functions in header files except for global constants. Give the header files the same name as the source files Each header has one specific job and should be as independent as possible Try to include as little as possible and be mindful about it Each header should compile on it's own. Only #include what you need. Do not #include .cpp files.","title":"Header files"},{"location":"cpp/LearnCpp.com/002_Cpp_Basics_Functions_and_Files/#header-guards","text":"Header guards protect the ODR (One definition rule). header guards aka include guards are conditional compilation directives. #ifndev SOME_UNIQUE_NAME_HERE #define SOME_UNIQUE_NAME_HERE // your declarations #endif This prevents the same function from being compiled multiple times. You should be usinging more comlex names for your header guards than just the filename. This is a good template: <PROJECT>_<PATH>_<FILE>_H Note that if you're dumb and you write your functions into your header files they can be included multiple times. Example: main and geometry both include poly ops. If the head files only contains forward definitions, this is no problem, otherwise you will get a conflict.","title":"Header guards"},{"location":"cpp/LearnCpp.com/003_Debugging_Cpp_Programs/","text":"Debugging C++ Programs Syntax and semantic errors A syntax error occurs when you write a statement that is not valid according to the grammar of C++. It's often missing semicolons, undeclared variables, mismatched braces etc. A semantic error occurs when the statement is syntactically valid, but does not do what you want it to. To find semantic errors you will need to debug your problem. There are generally five steps: Find the root cause of the problem Ensure you understand why the issue is occurring. Determin how you'll fix the problem Fix the problem Retest everything around the problem and write tests so it doesn't happen again The hardest part of all this is usualylly the first step. Reproduction steps are a series of steps needed to get the problem to repeat. In houdini I would create an empty scene with none of the garbage, and try to reproduce the problem without what the artist is doing and then one-by-one add the element the artist had in the scene until the problem comes. These steps are the reproduction steps. To find a problem in complex code if you have absoutely no idea where it is, you play the game of high-low. I did this when the vex compiler was broken and not giving me the correct errors. Just comment out half the code, see if it works, etc. Some common simple debugging tactics: Commenting out code Print function executions ( use std::cerr for this no std:cout!! ) Printing values These aren't very optimal though, because you are modifying your code and will have to undo all these changes again after you have found the problem which can lead to more errors! One thing you could consider for option 2 is to add preprocessing directives to clear all debug statements if a variable like ENABLE_DEBUG is not defined. This still makes your code harder to read than it should be, so I would preferr using a logger. A logger writes a log file to disk that records events that occur in software. This process is called logging . These don't clutter up your code, and you can easily get them from users of your software without asking them to copy their terminal output. I was very confused about how to add plog since the tutorial said I would need to add it to my IDE paths, but on linux building plog from AUR it automajikally just puts it into /usr/include which the linker knows about. Using a debugger I'll be learning using the gdb debugger. Vim 8.1 has a beautiful gdb integration. To start it run :packadd termdebug :Termdebug Note that you need to run the debug version of the build as the release version won't work! It's a visual debugger that allows stepping through code. You can set breakpoints visually in vim using :Break and :Clear to remove them. There's a tutorial on how to use it here At any point you can issue commands like print(var) to help figure out what is going on. Step executes the next statment in the normal execute path of the program and the npauses the execution of the program. It goes into all functions. It's equivalent to step into for visual studio. Next goes to the next line and pauses there. It's equivalent to step over in visual studio. Finish I think is like step out wher it finishes the current function and then gives you control again. Continue runs the program until the next breakpoint. There's not call stack in gdb but you can always call backtrace to see what has ben run so far.","title":"Debugging C++ Programs"},{"location":"cpp/LearnCpp.com/003_Debugging_Cpp_Programs/#debugging-c-programs","text":"","title":"Debugging C++ Programs"},{"location":"cpp/LearnCpp.com/003_Debugging_Cpp_Programs/#syntax-and-semantic-errors","text":"A syntax error occurs when you write a statement that is not valid according to the grammar of C++. It's often missing semicolons, undeclared variables, mismatched braces etc. A semantic error occurs when the statement is syntactically valid, but does not do what you want it to. To find semantic errors you will need to debug your problem. There are generally five steps: Find the root cause of the problem Ensure you understand why the issue is occurring. Determin how you'll fix the problem Fix the problem Retest everything around the problem and write tests so it doesn't happen again The hardest part of all this is usualylly the first step. Reproduction steps are a series of steps needed to get the problem to repeat. In houdini I would create an empty scene with none of the garbage, and try to reproduce the problem without what the artist is doing and then one-by-one add the element the artist had in the scene until the problem comes. These steps are the reproduction steps. To find a problem in complex code if you have absoutely no idea where it is, you play the game of high-low. I did this when the vex compiler was broken and not giving me the correct errors. Just comment out half the code, see if it works, etc. Some common simple debugging tactics: Commenting out code Print function executions ( use std::cerr for this no std:cout!! ) Printing values These aren't very optimal though, because you are modifying your code and will have to undo all these changes again after you have found the problem which can lead to more errors! One thing you could consider for option 2 is to add preprocessing directives to clear all debug statements if a variable like ENABLE_DEBUG is not defined. This still makes your code harder to read than it should be, so I would preferr using a logger. A logger writes a log file to disk that records events that occur in software. This process is called logging . These don't clutter up your code, and you can easily get them from users of your software without asking them to copy their terminal output. I was very confused about how to add plog since the tutorial said I would need to add it to my IDE paths, but on linux building plog from AUR it automajikally just puts it into /usr/include which the linker knows about.","title":"Syntax and semantic errors"},{"location":"cpp/LearnCpp.com/003_Debugging_Cpp_Programs/#using-a-debugger","text":"I'll be learning using the gdb debugger. Vim 8.1 has a beautiful gdb integration. To start it run :packadd termdebug :Termdebug Note that you need to run the debug version of the build as the release version won't work! It's a visual debugger that allows stepping through code. You can set breakpoints visually in vim using :Break and :Clear to remove them. There's a tutorial on how to use it here At any point you can issue commands like print(var) to help figure out what is going on. Step executes the next statment in the normal execute path of the program and the npauses the execution of the program. It goes into all functions. It's equivalent to step into for visual studio. Next goes to the next line and pauses there. It's equivalent to step over in visual studio. Finish I think is like step out wher it finishes the current function and then gives you control again. Continue runs the program until the next breakpoint. There's not call stack in gdb but you can always call backtrace to see what has ben run so far.","title":"Using a debugger"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/","text":"Fundamental Data Types In C++ we typically work in \"byte-sized\" chunks. The smallest unit of memory is a binary digit aka bit . All data types are represented by these. These are assigned to memory addresses so that we can find and reuse them. Bits are very small, so each bit doesn't get it's own address. Only for every byte of memory are addresses allocated. Each byte is 8 bits. Data types tell the compiler how to interpret the contents of a block of memory. Each object allocates memory, and then the compiler and cpu encode that and store it. The fundamental data types make up everything in C++ that gets stored. Types Category Meaning Example float, double, long double Floating Point fractional number 3.14159 bool Integral (Boolean) true or false true char, wchar_t char8_t (C++20), char16_t (C++11), char32_t (C++11) Integral (Character) a single character of text 'c' short, int, long, long long (C++11) Integral (Integer) positive and negative whole numbers including 0 64 std::nullptr_t (C++11) Null Pointer a null pointer nullptr void Void no type n/a Integral means \"like and integer\". They are stored in memory as integers. Newer types often have the _t suffix. Object sizes Depending on the object type, it might consist of more than one bit. Each bit can be either 1 or 0. The values that an object can hold goes up exponentially by the amount of bits it consists of. 3 bits can hold 8 possible values. You can find the size of variables using the sizeof operator Void Means \"no type\"! It's used for fucntions that don't need to return anything. It's also used for void pointers. Signed integers The sign of an integer determines if it is positive or negative. By default all ints are signed which means that the sign is preserved. short s ; int i ; long l ; long long l ; Signed integer ranges Size/Type Range 8 bit signed -128 to 127 16 bit signed -32,768 to 32,767 32 bit signed -2,147,483,648 to 2,147,483,647 64 bit signed -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 or an n-bit signed variable has a range of \\(-(2^{n-1})\\) to \\(2^{n-1} -1\\) If you try to assign an inter that is out of range you encounter integer overflow . This leads to undefined behavious. If you try to divide integers the fractional is always dropped! It's always rounded down. The best types for these are std::int_fast#_t if going for speed or std::int_least#_t if going for size. Unsigned integers Unisgned integers can only hold non-negative whole numbers. unsigned short us ; unsigned int ui ; unsigned long ul ; unsigned longlong ull ; Unisgned integer range Size/type Range 1 byte unsigned 0 to 255 2 byte unsigned 0 to 65,535 4 byte unsigned 0 to 4,294,967,295 8 byte unsigned 0 to 18,446,744,073,709,551,615 If you store a number that's too high or too low you get overflow. It stores the ramainder and essentially loops around. Same with the other direction. Ghandi from Civilization was suspected to be too peaceful and then wrap around to become very agrressive in the neuclear age. Generally it's reccomended not to use unsigned ints, because it becomes confusing to read the code. Especially if mixed with signed ints. Cases where it's alright to use unsigned ints: Bit manipulation Certain cases of array indexing Performance limitation on limited hardware Fixed-width integers and size_t Some systems allow for even larger variables. That is why we now have fixed-width integers in stdint.h that are guaranteed to have the same size on any architecture. You should generally not use these, because sometimes larger ints can have better performance. To compensate for this there are also now std::int_fast#_t (where # = 8, 16, 32,or 64) and std::int_least#_t. Favor these when you need an integer guaranteed a certain size. Even with these avoid the 8 bit ones as they are often treated as chars. best practices Use int wheever it's under 6k for sure. If you want a variable guaranteed a size use std::int_fast#_t Avoid: * Unsigned types * 8-bit fixed width integer types * compiler-specific fixed-width integers. Scientific Notation Scientific notation is a shorthand for writing lenghy number. 1.2 x \\(10^4\\) evaluates to 12,000. Start with 42030 Slide decimal left 4 spaces : 4.2030e4 No leading zeros to trim: 4.2030e4 Trim trailing zeros: 4.203e4 (4 significant digits) After applying Scientific notation you are left with significant digits, and these determine the number's precision. Floating point numbers Floating point is there to store very large numbers or numbers with a fractional components. Floating refers to the fact that the dcimal point can support a variable number of digits before and after the decimal points. The three different types of floating point data are float , double , and long double . When defined floating point literals, always include at least one decimal point for the compiler. int x { 5 } double y { 5.0 } // 5.0 is a floating point literal (no suffix means double float type by default) float z { 5.0f } // 5.0 is a floating point literal, f suffix means float typ Always make sure the type of your literals match the type of the variables they're being assigned to or used to initialize. Otherwise an unnecessary conversion will result, possibly with a loss of precision. Be wary of accidentally assinging integer literals where floating point literals should be used. The precision of a floating opint number defined how many significant digits it can represent. A float typically can represent 7 significant digits. This is why it's generally reccomended to use doubles unless there's a good performance reason to use floats. Because of the limited precision of float, you can often encounter rounding errors - even when working with doubles. This can make comparing floats difficult. The errors aren't the exception -- they're the rule. Be wary of using floatnig point number for financial or currency data. Two special categories for float numbers are Inf and NaN (Not a Number). they are only avaliable if the compiler uses a specific format. It can happen when dividing by zero. Boolean values A bool is a variables that can only have two possible values: true and false. bool b1 { true }; bool b2 { ! false }; // initialize to true b1 = false ; bool b3 {}; // default initialize to false Booleans get printed as 0 for false and 1 for true. Functions that return a boolean should start with is bool isEqual ( int x , int y ){ return ( x == y ) } If Statements Allows us to execute statements if some condition is true. if ( condition ) true_statement ; if ( condition ) true_statement ; if ( condition ){ statement_a ; statement_b ; } if ( condition ) statement_a ; else if ( condition ) statement_b ; else : statement_c ; Chars ASCII is American Standard Code for Informaion Interchange. char ch2 { 'a' }; // initialize with code point for 'a' (integer 97) char ch1 { 97 }; // initialize with integer 97 ('a')(not preferred) The fixed width integer int8_t is usually treated the same as a signed char. You can cast chars to ints. This is called a type cast char ch { 97 }; int i = static_cast < int > ( ch ); Always put stand-alone chars in single quotes 'a', 'b', and strings in double quotes \"The quick brown fox\" - this helps the compiler optimize better. Literals A constant is a fixed value that may not be changed. Literal constants or literals are values that are inserted directly into the code. You can change the default type of a literal by adding a suffix. Look up Literal suffixes if you ever need this. Don't use magic numbers in your code. Const variables Often you want to specify explicitly that a variable is immutable. This is done by defining that variable as const. constexpr double gravity { 9.8 }; iconst int myValue { x }; You can make function parameters const to assure the user that this variable will not be modified by the function. There are two types of constants in cpp * Runtime constants - their value can only be resolved at runtime. Things like userAge and myValue . These should be declared as const. * Compile-time constant are constants that are set during compile time. These are often hardcoded. These should be declared as constexp. Instead of using hard coded magic numbers, use constexpr variables. This makes refactoring much easier, and is more descriptive for what this value is representing. It's often useful to have something like a constants.h #ifndef CONSTANTS_H #define CONSTANTS_H // define your own namespace to hold constants namespace constants { constexpr double pi { 3.14159 }; constexpr double avogadro { 6.0221413e23 }; constexpr double my_gravity { 9.2 }; // m/s^2 -- gravity is light on this planet // ... other related constants } #endif","title":"Fundamental Data Types"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#fundamental-data-types","text":"In C++ we typically work in \"byte-sized\" chunks. The smallest unit of memory is a binary digit aka bit . All data types are represented by these. These are assigned to memory addresses so that we can find and reuse them. Bits are very small, so each bit doesn't get it's own address. Only for every byte of memory are addresses allocated. Each byte is 8 bits. Data types tell the compiler how to interpret the contents of a block of memory. Each object allocates memory, and then the compiler and cpu encode that and store it. The fundamental data types make up everything in C++ that gets stored. Types Category Meaning Example float, double, long double Floating Point fractional number 3.14159 bool Integral (Boolean) true or false true char, wchar_t char8_t (C++20), char16_t (C++11), char32_t (C++11) Integral (Character) a single character of text 'c' short, int, long, long long (C++11) Integral (Integer) positive and negative whole numbers including 0 64 std::nullptr_t (C++11) Null Pointer a null pointer nullptr void Void no type n/a Integral means \"like and integer\". They are stored in memory as integers. Newer types often have the _t suffix.","title":"Fundamental Data Types"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#object-sizes","text":"Depending on the object type, it might consist of more than one bit. Each bit can be either 1 or 0. The values that an object can hold goes up exponentially by the amount of bits it consists of. 3 bits can hold 8 possible values. You can find the size of variables using the sizeof operator","title":"Object sizes"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#void","text":"Means \"no type\"! It's used for fucntions that don't need to return anything. It's also used for void pointers.","title":"Void"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#signed-integers","text":"The sign of an integer determines if it is positive or negative. By default all ints are signed which means that the sign is preserved. short s ; int i ; long l ; long long l ;","title":"Signed integers"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#signed-integer-ranges","text":"Size/Type Range 8 bit signed -128 to 127 16 bit signed -32,768 to 32,767 32 bit signed -2,147,483,648 to 2,147,483,647 64 bit signed -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 or an n-bit signed variable has a range of \\(-(2^{n-1})\\) to \\(2^{n-1} -1\\) If you try to assign an inter that is out of range you encounter integer overflow . This leads to undefined behavious. If you try to divide integers the fractional is always dropped! It's always rounded down. The best types for these are std::int_fast#_t if going for speed or std::int_least#_t if going for size.","title":"Signed integer ranges"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#unsigned-integers","text":"Unisgned integers can only hold non-negative whole numbers. unsigned short us ; unsigned int ui ; unsigned long ul ; unsigned longlong ull ;","title":"Unsigned integers"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#unisgned-integer-range","text":"Size/type Range 1 byte unsigned 0 to 255 2 byte unsigned 0 to 65,535 4 byte unsigned 0 to 4,294,967,295 8 byte unsigned 0 to 18,446,744,073,709,551,615 If you store a number that's too high or too low you get overflow. It stores the ramainder and essentially loops around. Same with the other direction. Ghandi from Civilization was suspected to be too peaceful and then wrap around to become very agrressive in the neuclear age. Generally it's reccomended not to use unsigned ints, because it becomes confusing to read the code. Especially if mixed with signed ints. Cases where it's alright to use unsigned ints: Bit manipulation Certain cases of array indexing Performance limitation on limited hardware","title":"Unisgned integer range"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#fixed-width-integers-and-size_t","text":"Some systems allow for even larger variables. That is why we now have fixed-width integers in stdint.h that are guaranteed to have the same size on any architecture. You should generally not use these, because sometimes larger ints can have better performance. To compensate for this there are also now std::int_fast#_t (where # = 8, 16, 32,or 64) and std::int_least#_t. Favor these when you need an integer guaranteed a certain size. Even with these avoid the 8 bit ones as they are often treated as chars.","title":"Fixed-width integers and size_t"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#best-practices","text":"Use int wheever it's under 6k for sure. If you want a variable guaranteed a size use std::int_fast#_t Avoid: * Unsigned types * 8-bit fixed width integer types * compiler-specific fixed-width integers.","title":"best practices"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#scientific-notation","text":"Scientific notation is a shorthand for writing lenghy number. 1.2 x \\(10^4\\) evaluates to 12,000. Start with 42030 Slide decimal left 4 spaces : 4.2030e4 No leading zeros to trim: 4.2030e4 Trim trailing zeros: 4.203e4 (4 significant digits) After applying Scientific notation you are left with significant digits, and these determine the number's precision.","title":"Scientific Notation"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#floating-point-numbers","text":"Floating point is there to store very large numbers or numbers with a fractional components. Floating refers to the fact that the dcimal point can support a variable number of digits before and after the decimal points. The three different types of floating point data are float , double , and long double . When defined floating point literals, always include at least one decimal point for the compiler. int x { 5 } double y { 5.0 } // 5.0 is a floating point literal (no suffix means double float type by default) float z { 5.0f } // 5.0 is a floating point literal, f suffix means float typ Always make sure the type of your literals match the type of the variables they're being assigned to or used to initialize. Otherwise an unnecessary conversion will result, possibly with a loss of precision. Be wary of accidentally assinging integer literals where floating point literals should be used. The precision of a floating opint number defined how many significant digits it can represent. A float typically can represent 7 significant digits. This is why it's generally reccomended to use doubles unless there's a good performance reason to use floats. Because of the limited precision of float, you can often encounter rounding errors - even when working with doubles. This can make comparing floats difficult. The errors aren't the exception -- they're the rule. Be wary of using floatnig point number for financial or currency data. Two special categories for float numbers are Inf and NaN (Not a Number). they are only avaliable if the compiler uses a specific format. It can happen when dividing by zero.","title":"Floating point numbers"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#boolean-values","text":"A bool is a variables that can only have two possible values: true and false. bool b1 { true }; bool b2 { ! false }; // initialize to true b1 = false ; bool b3 {}; // default initialize to false Booleans get printed as 0 for false and 1 for true. Functions that return a boolean should start with is bool isEqual ( int x , int y ){ return ( x == y ) }","title":"Boolean values"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#if-statements","text":"Allows us to execute statements if some condition is true. if ( condition ) true_statement ; if ( condition ) true_statement ; if ( condition ){ statement_a ; statement_b ; } if ( condition ) statement_a ; else if ( condition ) statement_b ; else : statement_c ;","title":"If Statements"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#chars","text":"ASCII is American Standard Code for Informaion Interchange. char ch2 { 'a' }; // initialize with code point for 'a' (integer 97) char ch1 { 97 }; // initialize with integer 97 ('a')(not preferred) The fixed width integer int8_t is usually treated the same as a signed char. You can cast chars to ints. This is called a type cast char ch { 97 }; int i = static_cast < int > ( ch ); Always put stand-alone chars in single quotes 'a', 'b', and strings in double quotes \"The quick brown fox\" - this helps the compiler optimize better.","title":"Chars"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#literals","text":"A constant is a fixed value that may not be changed. Literal constants or literals are values that are inserted directly into the code. You can change the default type of a literal by adding a suffix. Look up Literal suffixes if you ever need this. Don't use magic numbers in your code.","title":"Literals"},{"location":"cpp/LearnCpp.com/004_Fundamental_Data_Types/#const-variables","text":"Often you want to specify explicitly that a variable is immutable. This is done by defining that variable as const. constexpr double gravity { 9.8 }; iconst int myValue { x }; You can make function parameters const to assure the user that this variable will not be modified by the function. There are two types of constants in cpp * Runtime constants - their value can only be resolved at runtime. Things like userAge and myValue . These should be declared as const. * Compile-time constant are constants that are set during compile time. These are often hardcoded. These should be declared as constexp. Instead of using hard coded magic numbers, use constexpr variables. This makes refactoring much easier, and is more descriptive for what this value is representing. It's often useful to have something like a constants.h #ifndef CONSTANTS_H #define CONSTANTS_H // define your own namespace to hold constants namespace constants { constexpr double pi { 3.14159 }; constexpr double avogadro { 6.0221413e23 }; constexpr double my_gravity { 9.2 }; // m/s^2 -- gravity is light on this planet // ... other related constants } #endif","title":"Const variables"},{"location":"cpp/LearnCpp.com/005_Operators/","text":"Operators You can find a reference chart for all cpp operators on this site An operation is a mathematical calculation invloving zero or more input values (called operands ) that produces a new value. The operation performed is denoted by an operator . 4 + 2 * 3 has 2 operators. The operator precedence determines which get resolves first. Cpp uses normal mathematial precedence rules. The table on the above site lists the operators in order of precedence. The associativity determinds wether to evaluate operators of the same precedence from left to right or right to left. Parenthesis have one of the highest precedence levels, so you can use them to determine which parts of your expressions you evaluate first. It's generally good practice to use () to be more explicit even if percedence would do it for you. Arithmetic operators Remember that unary operators determine the sign of the number. Unary minus returns the operand multiplied by -1, and unary plus returns the operator as is. + is really only there to provice symmetry with unary minus. Binary arithmetic operators + 0 * / % They take left and right operands. There are two version of the division operator depending on the operatnds: floating point devision and Integer division . As of C++11 integer division always drops the remainder no matter if above or below 0. Don't divide by zero - it will crash your program. Arithmetic assignment operators = += -= *= /= %= Just a nice little shorthand. Modulus is great for tesing if a number divided by another number has a remainder. You could test if two ints are divisible by static_cast<i> them in a %= and only cast them to double if they have a remainder. There is no exponent operator, but you can use std::pow(x, y) for that. Increment/decrementing + side effects ++x Increment and return --x Decrement and return x++ Copy, increment and return copy x-- Copy, decrement and return copy. Basically the first two modify the x variable, while the second two only return the inrementation. You sould use the first two unless there's a good reason to really need to copy it. Comma and conditional operators The comma operator allows you to evaluate multiple expressions where a single expression is allowed. Note that this operator has a really low precedence: z = ( a , b ) // evaluate (a, b) first to get result of b, then assign that value to z z = a , b // evaluates as (z = a), b so z get assigned tot he value of a, and be is evaluated and discarded Avoid using the comma operator except within for loops. Comma is often used as a seperator and this is not related to the operators. The conditional operator is kind of like a mini for loop. It's also referred to as the tenery operator. if ( condition ) statement_1 ; else statement_2 ; ( condition ) ? expression_1 : expression_2 ; It can help compact code without losing readability. larger = ( x > y ) ? x : y ; Always parenthesize the conditional part of the conditional operator, and consier parenthesizing the whole thing as well. Because it evaluates as expression the conditional operator can be used in some places where if/else can not. For example initializing const variables. Also note that both data types for the condition must be of the same type. Generally you should only use the conditional operator when you use the result adn where it enhances readability. Relational operators and floatnig point comparisons Relational operators let you compare two values. > < >= <= == != Each of these evaluates to a boolean. Also of course you should only use them if yo uneed to: if ( b1 == true ) // absolutely dumb if ( b1 ) Be careful using these operators with float values. They are not guaranteed to produce the correct results. Equality is especially troublesome. This is where an epsion function comes it. Use something like this if you really need to compare floats: #include <cmath> // std::abs #include <algorithm> // std::max // return true if the difference between a and b is within epsilon percent of the larger of a and b bool approximatelyEqual ( double a , double b , double epsilon ) { return ( std :: abs ( a - b ) <= ( std :: max ( std :: abs ( a ), std :: abs ( b )) * epsilon )); } Logical operators ! && || These allow us to check if multiple conditions are true simultaneously. If ! is indeded to work on multiple expressions use parentheses. When mixing && and || use parentheses.","title":"Operators"},{"location":"cpp/LearnCpp.com/005_Operators/#operators","text":"You can find a reference chart for all cpp operators on this site An operation is a mathematical calculation invloving zero or more input values (called operands ) that produces a new value. The operation performed is denoted by an operator . 4 + 2 * 3 has 2 operators. The operator precedence determines which get resolves first. Cpp uses normal mathematial precedence rules. The table on the above site lists the operators in order of precedence. The associativity determinds wether to evaluate operators of the same precedence from left to right or right to left. Parenthesis have one of the highest precedence levels, so you can use them to determine which parts of your expressions you evaluate first. It's generally good practice to use () to be more explicit even if percedence would do it for you.","title":"Operators"},{"location":"cpp/LearnCpp.com/005_Operators/#arithmetic-operators","text":"Remember that unary operators determine the sign of the number. Unary minus returns the operand multiplied by -1, and unary plus returns the operator as is. + is really only there to provice symmetry with unary minus.","title":"Arithmetic operators"},{"location":"cpp/LearnCpp.com/005_Operators/#binary-arithmetic-operators","text":"+ 0 * / % They take left and right operands. There are two version of the division operator depending on the operatnds: floating point devision and Integer division . As of C++11 integer division always drops the remainder no matter if above or below 0. Don't divide by zero - it will crash your program.","title":"Binary arithmetic operators"},{"location":"cpp/LearnCpp.com/005_Operators/#arithmetic-assignment-operators","text":"= += -= *= /= %= Just a nice little shorthand. Modulus is great for tesing if a number divided by another number has a remainder. You could test if two ints are divisible by static_cast<i> them in a %= and only cast them to double if they have a remainder. There is no exponent operator, but you can use std::pow(x, y) for that.","title":"Arithmetic assignment operators"},{"location":"cpp/LearnCpp.com/005_Operators/#incrementdecrementing-side-effects","text":"++x Increment and return --x Decrement and return x++ Copy, increment and return copy x-- Copy, decrement and return copy. Basically the first two modify the x variable, while the second two only return the inrementation. You sould use the first two unless there's a good reason to really need to copy it.","title":"Increment/decrementing + side effects"},{"location":"cpp/LearnCpp.com/005_Operators/#comma-and-conditional-operators","text":"The comma operator allows you to evaluate multiple expressions where a single expression is allowed. Note that this operator has a really low precedence: z = ( a , b ) // evaluate (a, b) first to get result of b, then assign that value to z z = a , b // evaluates as (z = a), b so z get assigned tot he value of a, and be is evaluated and discarded Avoid using the comma operator except within for loops. Comma is often used as a seperator and this is not related to the operators. The conditional operator is kind of like a mini for loop. It's also referred to as the tenery operator. if ( condition ) statement_1 ; else statement_2 ; ( condition ) ? expression_1 : expression_2 ; It can help compact code without losing readability. larger = ( x > y ) ? x : y ; Always parenthesize the conditional part of the conditional operator, and consier parenthesizing the whole thing as well. Because it evaluates as expression the conditional operator can be used in some places where if/else can not. For example initializing const variables. Also note that both data types for the condition must be of the same type. Generally you should only use the conditional operator when you use the result adn where it enhances readability.","title":"Comma and conditional operators"},{"location":"cpp/LearnCpp.com/005_Operators/#relational-operators-and-floatnig-point-comparisons","text":"Relational operators let you compare two values. > < >= <= == != Each of these evaluates to a boolean. Also of course you should only use them if yo uneed to: if ( b1 == true ) // absolutely dumb if ( b1 ) Be careful using these operators with float values. They are not guaranteed to produce the correct results. Equality is especially troublesome. This is where an epsion function comes it. Use something like this if you really need to compare floats: #include <cmath> // std::abs #include <algorithm> // std::max // return true if the difference between a and b is within epsilon percent of the larger of a and b bool approximatelyEqual ( double a , double b , double epsilon ) { return ( std :: abs ( a - b ) <= ( std :: max ( std :: abs ( a ), std :: abs ( b )) * epsilon )); }","title":"Relational operators and floatnig point comparisons"},{"location":"cpp/LearnCpp.com/005_Operators/#logical-operators","text":"! && || These allow us to check if multiple conditions are true simultaneously. If ! is indeded to work on multiple expressions use parentheses. When mixing && and || use parentheses.","title":"Logical operators"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/","text":"Object Scope and Conversions Code blocks work just like in vex. A compound statement is when you have multiple statements seperated by ; after an if statement. This is also called a block . You should keep the nesting level of your functions to 3 or less. If your function has a need for more, consider abstracting that to anther function. In cpp you manually defined user-defined namespaces - these allow you to have duplicate named functions that are still organized properly. It's very simple to set them up: namespace foo \\\\ defnie a namecpace named foo { int doSomething ( int x , int y ){ return x + y ; } } Now you call doSomething like this: int dosomething ( intx , int y ); //forward declaration int main (){ std :: cout << foo :: doSomething ( 4 , 3 ) << '\\n' ; return 0 } This example is incorrect and wouldn't compile, because you should define doSomething in it's own header file. Namespaces can be nested within other namespaces. You can create namespace aliases which allow you to temoprarily shorten long sequences of namespaces into something shorter. These can be useful for moving functionality between namespaces. namespace foo : goo { int add ( int x , int y ) { return x = y ; } } int main (){ namespace boo = foo :: goo ; // bo now refers to foo:goo std :: cout << boo :: add ( 1 , 2 ) << '\\n' ; return 0 ; } Use namespaces to seperate application-specific code from code that might be re-usable in a different setting. Math functions shouldn't be part of your core namespace for example. Local Variables Local variables have block scope - they are in scope from their point of definition to the end of the block they are defined in. The one exception is for exception handling in things like try blocks where they are avaliable after the block has errored. All variable names within a scope must be unique Local variables have automatic storage duration which means that they are automatically removed from memory after the function is complete. For this reason local variables are sometimes called automatic variables . Nested block are considered within scope of their outer blocks. Local variables have no linkage . Linkage determines whether other declarations of that name refer tothe same object or not. Each local variable declaration is a unique object. You should always defined variables in the most limited scope possible. Global Variables These are variables declared outside a function. Global varialbes are declared at the top of a file, below the inclues, but above any code. Considering using a \"g\" or \"g_\" prefix for all global variables to remind yourself of their scope. Global variables have file scope also known as global scope or global namespace scope . They have a static duration - this means they are created when the program starts and destroyed when the program ends. You can declare them as constant which can be very useful. Non-constant global variables can easily lead to unexpected results if you forget where you change them. Variable shadowing (name hiding) If you define a variable in an inner block that has the same name as a variable from the outer block it shadows the variable of the out block which means basically override it for the duration of the inner block's scope. You can do the same thing to global variables. In general you should avoid this always. But yea that's what happens. Internal linkage Global variables can have internal linkage or external linkage. an identifier with internal linkage can be seen and used within a single file, but not in other files. static int g_x ; // non-constant globals have external linkage by default, but can be given internal linkage via the static keyword const int g_y { 1 }; // const globals have internal linkage by default constexpr int g_z { 2 }; // constexpr globals have internal linkage by default The use of the static keyword is an example of a storage class specifier which sets both the name's linkage and its storage duration ( but not it's scope ). Linkage is a property of the identifier. An identifier's linkage determines whether other declarations of that name refer to the same object or not. External Linkage Through the power of forward declaration you can use a single variable in multiple files with external linkage . Functions have external linkage by default - they are also global varaibles. Global variables with external linkage are sometimes called external variables . int g_x { 2 } extern const int g - y { 3 }; // const globals can be defined as extern extern constexpr int g_z { 3 }; // constexp globals can be defined as extern Non const global variables are external by default. You have to place forward declaration in all files where you plan to use the external variable It makes no sense to declare constexpr as they can not be forward declared. If you want to defined an uninitialized non-const global variable, do not use the extern keyword, otherwise C++ will think you're trying to make a forward declaration for the variable. Initialization of globals happens as part of the program startup, before the main(). It has two phases Static Initialization. All the global variables with constexpr are evaluated, as well as all global variables without initializers are zero-initialized. Dynamic Initialization. All the other global variables are initialized. i Dynamic initialization of global variables causes a lot of problems. Avoid whenever possible. Global constants and inline variables Pre-C++17 this is how you would define all the constants for your project: constants.h #ifndn CONSTANTS_H #define CONSTANTS_h namespace constants { constexpr double pi { 3.14159 }; constexpr double avogadro { 6.020413e23 }; constexpr double my_gravity { 9.2 }; } #endif This is alright for smaller programs, but during compiletime this header will be added to every single file including it. This means that these variables will be initialized in every file as well. A way that scales better looks like this constants.cpp #include \"constants.h\" namespace constants { extern const double pi { 3.14159 }; extern const double avogadro { 6.0221413e23 }; exter const duoble my_gravity { 9.2 }; } constants.h #ifndev CONSTANTS_H #define CONSTANTS_H namespace constants { extern const double pi ; extern const double avogadro ; extern const my_gravity ; } #endif This forward declares them in the header file, so that they are only declared once at runtime and then linked. In C++17 you would define them as inline variables. Which would once again look like the first example. If your compilier is C++17 compatible this method is preferred. Why global variables are evil Many developers believe non-const global variables should be avoided completely! The danger is that their values can be changed by any function that is called. This can make changes to the program unpredictable if you don't know exactly what happens in each function. Use local variables instead of global variables whenever possible. Possible uses for globals: Log file. constants If you do decide to use globals protect yourself like this: prefix them with \"g_\" encapsulate the variable. (so that is can only be accessed from within the file it's decalred in) pass in the globas as variables in the functions to be more explicit. Static local variables Static has many meanings in cpp. Global variables have a static duration, and internal linkage if defined with the static keyword. You can create static local variables by using the static keyword on them. This means that their duration is changed from automatic to statuc. So now it won't be destroyed until the end of the program. This means it will retain it's value even after it goes out of scope! Static initializers are only executed the first time. A good practice is to use \"s_\" to prefix static local variables. They are commonly used for unique ID generators. int generateID (){ static int s_itemID { 0 }; return s_itemID ++ ; This will return a unique id for the duration of the programs' runtime. These are cool, but don't overuse them because they make code harder to follow. Avoid static local variables unless the variable never needs to be reset. A great review of these can be found here Typedefs and type aliases You can create an alias for a data type, and use that name instead of the actual type name while still referring to the same type definition . It's good to suffix type defs with \"_t\" typedef double distance_t ; // define distance_t as an alias for type double using distance_c = double ; //the following two statements are not equivalent doubld howFar ; distance_t howFar ; distance_c howFar ; The using keyword has no correlation to how using is incorporated for namespaces. This aliasing of types can help you make your code more explicit by adding more descriptive identifier type names. It can also help make our code easier to refactor. They also help for platform independent coding. Use aliases (using = type) over typedefs and use them liberally to help document your code. The auto keyword This has great potential for misuse! Avoid using type inference for function return types. Type inference tells the compiler to infer the variable's type from the initiliazer's type. auto d { 5.0 }; \\\\ will be type double auto i { 1 + 2 }; \\\\ evaluates to in so i will be type int Implicit type conversion (coercion) The process of converting a value from one data type to another is called type conversion . This is done automatically if the compilier knows how to for the given types ( Implicit/automatic type conversion ). Converting to a larger numeric data type is called numberic promotion or widening. Converting to a smaller numeric data type, or between data types is called numeric conversion . Narrowing conversions are when data is lost. Note that if you are converting a very large out of range number to a smaller type you are very likely to get overflow. Explicit type conversion (casting) and static_cast You should avoid c-style casts int i1 { 10 }; int i2 { 4 }; float f { ( float ) i1 / i2 }; In C++ there is an operator called static_cast which is the preferred method of converting types. int i1 { 10 }; int i2 { 4 }; // convert an int to a float so we can get floatnig point division rather than integer division float f { static_cast < float > ( i1 ) / i2 } Unnamed and inline namespaces An unnamed namespace is a namespace without a name. The functions in it are considered part of the parent namespsace. This is still useful because all of the identifiers inside an unnamed namespace are treated as if they had internal linkage. Using functions from an unnamed namespace is the same as static functions. An inline namespace is a namespace that is often used to version content. Everything in it is also considered part of the parent namespace, but the inline namespace does not give everything internal linkage. This can save a lot of refactoring time.","title":"Object Scope and Conversions"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#object-scope-and-conversions","text":"Code blocks work just like in vex. A compound statement is when you have multiple statements seperated by ; after an if statement. This is also called a block . You should keep the nesting level of your functions to 3 or less. If your function has a need for more, consider abstracting that to anther function. In cpp you manually defined user-defined namespaces - these allow you to have duplicate named functions that are still organized properly. It's very simple to set them up: namespace foo \\\\ defnie a namecpace named foo { int doSomething ( int x , int y ){ return x + y ; } } Now you call doSomething like this: int dosomething ( intx , int y ); //forward declaration int main (){ std :: cout << foo :: doSomething ( 4 , 3 ) << '\\n' ; return 0 } This example is incorrect and wouldn't compile, because you should define doSomething in it's own header file. Namespaces can be nested within other namespaces. You can create namespace aliases which allow you to temoprarily shorten long sequences of namespaces into something shorter. These can be useful for moving functionality between namespaces. namespace foo : goo { int add ( int x , int y ) { return x = y ; } } int main (){ namespace boo = foo :: goo ; // bo now refers to foo:goo std :: cout << boo :: add ( 1 , 2 ) << '\\n' ; return 0 ; } Use namespaces to seperate application-specific code from code that might be re-usable in a different setting. Math functions shouldn't be part of your core namespace for example.","title":"Object Scope and Conversions"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#local-variables","text":"Local variables have block scope - they are in scope from their point of definition to the end of the block they are defined in. The one exception is for exception handling in things like try blocks where they are avaliable after the block has errored. All variable names within a scope must be unique Local variables have automatic storage duration which means that they are automatically removed from memory after the function is complete. For this reason local variables are sometimes called automatic variables . Nested block are considered within scope of their outer blocks. Local variables have no linkage . Linkage determines whether other declarations of that name refer tothe same object or not. Each local variable declaration is a unique object. You should always defined variables in the most limited scope possible.","title":"Local Variables"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#global-variables","text":"These are variables declared outside a function. Global varialbes are declared at the top of a file, below the inclues, but above any code. Considering using a \"g\" or \"g_\" prefix for all global variables to remind yourself of their scope. Global variables have file scope also known as global scope or global namespace scope . They have a static duration - this means they are created when the program starts and destroyed when the program ends. You can declare them as constant which can be very useful. Non-constant global variables can easily lead to unexpected results if you forget where you change them.","title":"Global Variables"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#variable-shadowing-name-hiding","text":"If you define a variable in an inner block that has the same name as a variable from the outer block it shadows the variable of the out block which means basically override it for the duration of the inner block's scope. You can do the same thing to global variables. In general you should avoid this always. But yea that's what happens.","title":"Variable shadowing (name hiding)"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#internal-linkage","text":"Global variables can have internal linkage or external linkage. an identifier with internal linkage can be seen and used within a single file, but not in other files. static int g_x ; // non-constant globals have external linkage by default, but can be given internal linkage via the static keyword const int g_y { 1 }; // const globals have internal linkage by default constexpr int g_z { 2 }; // constexpr globals have internal linkage by default The use of the static keyword is an example of a storage class specifier which sets both the name's linkage and its storage duration ( but not it's scope ). Linkage is a property of the identifier. An identifier's linkage determines whether other declarations of that name refer to the same object or not.","title":"Internal linkage"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#external-linkage","text":"Through the power of forward declaration you can use a single variable in multiple files with external linkage . Functions have external linkage by default - they are also global varaibles. Global variables with external linkage are sometimes called external variables . int g_x { 2 } extern const int g - y { 3 }; // const globals can be defined as extern extern constexpr int g_z { 3 }; // constexp globals can be defined as extern Non const global variables are external by default. You have to place forward declaration in all files where you plan to use the external variable It makes no sense to declare constexpr as they can not be forward declared. If you want to defined an uninitialized non-const global variable, do not use the extern keyword, otherwise C++ will think you're trying to make a forward declaration for the variable. Initialization of globals happens as part of the program startup, before the main(). It has two phases Static Initialization. All the global variables with constexpr are evaluated, as well as all global variables without initializers are zero-initialized. Dynamic Initialization. All the other global variables are initialized. i Dynamic initialization of global variables causes a lot of problems. Avoid whenever possible.","title":"External Linkage"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#global-constants-and-inline-variables","text":"Pre-C++17 this is how you would define all the constants for your project: constants.h #ifndn CONSTANTS_H #define CONSTANTS_h namespace constants { constexpr double pi { 3.14159 }; constexpr double avogadro { 6.020413e23 }; constexpr double my_gravity { 9.2 }; } #endif This is alright for smaller programs, but during compiletime this header will be added to every single file including it. This means that these variables will be initialized in every file as well. A way that scales better looks like this constants.cpp #include \"constants.h\" namespace constants { extern const double pi { 3.14159 }; extern const double avogadro { 6.0221413e23 }; exter const duoble my_gravity { 9.2 }; } constants.h #ifndev CONSTANTS_H #define CONSTANTS_H namespace constants { extern const double pi ; extern const double avogadro ; extern const my_gravity ; } #endif This forward declares them in the header file, so that they are only declared once at runtime and then linked. In C++17 you would define them as inline variables. Which would once again look like the first example. If your compilier is C++17 compatible this method is preferred.","title":"Global constants and inline variables"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#why-global-variables-are-evil","text":"Many developers believe non-const global variables should be avoided completely! The danger is that their values can be changed by any function that is called. This can make changes to the program unpredictable if you don't know exactly what happens in each function. Use local variables instead of global variables whenever possible. Possible uses for globals: Log file. constants If you do decide to use globals protect yourself like this: prefix them with \"g_\" encapsulate the variable. (so that is can only be accessed from within the file it's decalred in) pass in the globas as variables in the functions to be more explicit.","title":"Why global variables are evil"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#static-local-variables","text":"Static has many meanings in cpp. Global variables have a static duration, and internal linkage if defined with the static keyword. You can create static local variables by using the static keyword on them. This means that their duration is changed from automatic to statuc. So now it won't be destroyed until the end of the program. This means it will retain it's value even after it goes out of scope! Static initializers are only executed the first time. A good practice is to use \"s_\" to prefix static local variables. They are commonly used for unique ID generators. int generateID (){ static int s_itemID { 0 }; return s_itemID ++ ; This will return a unique id for the duration of the programs' runtime. These are cool, but don't overuse them because they make code harder to follow. Avoid static local variables unless the variable never needs to be reset. A great review of these can be found here","title":"Static local variables"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#typedefs-and-type-aliases","text":"You can create an alias for a data type, and use that name instead of the actual type name while still referring to the same type definition . It's good to suffix type defs with \"_t\" typedef double distance_t ; // define distance_t as an alias for type double using distance_c = double ; //the following two statements are not equivalent doubld howFar ; distance_t howFar ; distance_c howFar ; The using keyword has no correlation to how using is incorporated for namespaces. This aliasing of types can help you make your code more explicit by adding more descriptive identifier type names. It can also help make our code easier to refactor. They also help for platform independent coding. Use aliases (using = type) over typedefs and use them liberally to help document your code.","title":"Typedefs and type aliases"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#the-auto-keyword","text":"This has great potential for misuse! Avoid using type inference for function return types. Type inference tells the compiler to infer the variable's type from the initiliazer's type. auto d { 5.0 }; \\\\ will be type double auto i { 1 + 2 }; \\\\ evaluates to in so i will be type int","title":"The auto keyword"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#implicit-type-conversion-coercion","text":"The process of converting a value from one data type to another is called type conversion . This is done automatically if the compilier knows how to for the given types ( Implicit/automatic type conversion ). Converting to a larger numeric data type is called numberic promotion or widening. Converting to a smaller numeric data type, or between data types is called numeric conversion . Narrowing conversions are when data is lost. Note that if you are converting a very large out of range number to a smaller type you are very likely to get overflow.","title":"Implicit type conversion (coercion)"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#explicit-type-conversion-casting-and-static_cast","text":"You should avoid c-style casts int i1 { 10 }; int i2 { 4 }; float f { ( float ) i1 / i2 }; In C++ there is an operator called static_cast which is the preferred method of converting types. int i1 { 10 }; int i2 { 4 }; // convert an int to a float so we can get floatnig point division rather than integer division float f { static_cast < float > ( i1 ) / i2 }","title":"Explicit type conversion (casting) and static_cast"},{"location":"cpp/LearnCpp.com/006_Object_Scope_and_Conversions/#unnamed-and-inline-namespaces","text":"An unnamed namespace is a namespace without a name. The functions in it are considered part of the parent namespsace. This is still useful because all of the identifiers inside an unnamed namespace are treated as if they had internal linkage. Using functions from an unnamed namespace is the same as static functions. An inline namespace is a namespace that is often used to version content. Everything in it is also considered part of the parent namespace, but the inline namespace does not give everything internal linkage. This can save a lot of refactoring time.","title":"Unnamed and inline namespaces"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/","text":"Control Flow and Error Handling A straig-line program is a program that takes the same path every time it is run. This is not practical when requesting input from a user. For this, C++ provides a number of control flow statements , which allow the programmer to change the normal path of execution. When a control flow statement causes the point of execution to change to a non-sequential statement this is called branching . If statements and blocks The most basic conditional statement. Else is optional. Generally you want to always block if statements, or keep them in one-liners for readability. Otherwise you might run into a dangling else problem where you're not quite sure which if an else belongs to. Also be careful not to terminate your if statements with semicolons because that will immediately end them. Switch statements Instead of chaining a bunch of if statements together, it can be more readable to use a switch statement. This is also more efficient because the conditional is evaluated only once. switch ( x ){ case 1 : std :: cout << \"One\" ; return ; case 2 : std :: cout << \"Two\" ; return ; case 3 : std :: cout << \"Three\" ; return ; default : std :: cout << \"Unknown\" ; return ; } These are preferred both computationally and visually. Each label in the switch statement is called a case label . The default label or default case is used when the switch statement is evaluated to a value that does not have a case label. This should be placed last in the switch block. Instead of returning the entire function, you can also use a break statement to continue running the function after executing the statement block. If you do not have a break or return statement, the switch will continue evaluating until it finds a matching case statement like the default case statement. This is called fallthrough and is usually not intended. If you do intend it, you should use the [[fallthrough]]; attribute to explicitly call the fallthrough. If you would like a single staement block to be used for several case statements this can be done very elegantly: bool isVowel ( charc ){ switch ( c ){ case 'a' : case 'e' : case 'i' : case 'o' : case 'u' : return true ; default : return false ; } } If you want to defined variables inside a case statement, do so in a block inside the case or before the switch. Goto statements The unconditional jump casus execution to jump to another spon in the code. This requires a goto statement and a statement label . Because this quickly leads to spaghetti code goto statements are to be avoided. Loops Each time a loop exectutes, it is called an iteration The simplest loops is the while statement : while ( condition ) statement ; They are dangerous because they can quicly lead to an infinite loop whter the condition is never met. If you intend for a while loop to go indefinitly use while(true). If you are counting your variables in a while loop, be sure to use signed ints. (otherwise they will overflow when they reach zero). A do while statement is a looping construct that is like a while loop, except the statement always executes at least once. Basically it checks the statement after the first iteration. do { selected = std :: cin >> selection ; } while ( selected != 1 && selection != 2 ) This is useful for things like selection where you want to get a selected number first, but you would favor while loops over do-while loops when given an equal choice for readability. The for loop is preferred when we have an obvious loop variable. There are two types of for loops, the classic for statement and the range-based for statement. The range based for statement uses iterators, and that is not covered at this point in the learning. for ( int count { 1 }; count <= 10 ; ++ count ){ std :: cout << count << ' ' ; } You can achieve the same result easily with a while loop, but the for loop is considered more readable. One cool thing you can also do is iterate over multiple variables with a for loop: for ( int x { 0 }, y { 9 }; x < 10 ; ++ x , -- y ) std :: cout << x << ' ' << y << '\\n' This is an acceptable way of working in a for loop. Break and continue The break statement causes a while loop, do-while loop, for loop, or switch statemetn to end, with execution continuing with the next statement after the loop. It's different than return, because it does not exit the function. The continue statement is similar, but continues iterating the loop. These statements can make the flow harder to follow, so they should be used primarily when they simplify the loop logic. There is also debate about using early returns which are not at the end of the function. It's similar to using continue and break, use it when they simplify the functions' logic. Halts A halt is a flow control statement that terminates the program. The std::exit() function is a halt that causes your program to terminate normally. Normal termination means that the program is exiting the expected way. Note that the std::exit() function does not clean up local variables in the current function or call stake. To help with this there is the std::atexit() function, which lets you specify functions to run whenever the program exits. The std::abort() function causes abnormal terminations which is a way of terminating due to an error. You should only use a halt if there is no safe way to return normally from the main function. If you haven't disabled exceptions, prefer using exceptions for handling errors safely? Testing your code Scope creep happens when you add new capabilities that were originally not planned for. Software verification/testing is the process of determining whether or not the software still works for all of the cases. It's important to test your programs in small pieces. Write your program in smalle, well defined units (functions or classes), compile often, and test your code as you go. As you get more advanced there are also many unit testing frameworks you can use in C++ that help with a testing framework. Once each of your units has been tested in isolatino they can be integrated into your program, and to make sure this happens correctly you can create integration tests . Code coverage Code coverage is a term used to describe how much of the source code of a program is executed while testing. Statement coverage refers to the percentage of statements in your code that have been exercised by your testign routines. While aiming for 100% statement coverage is fine, it's not enough to ensure correctness. Branch coverage refers to the percentage of branches that have been executed, each possible branch counted separately. (i.e. an if statement has 2 branches. ) You should aim for 100% branch coverage of your code. Loop coverage (0, 1, 2, test) is the concept that if you have a loop in your code you should ensure it works properly when it iterates 0 times, 1, time, and 2 times. Any value greater than 2 should then also work. You also need to consider what tests make sense for functions that take different categories of input. Detecting and handling errors Many new programmers write code and then only test the happy path : only the cases where there are no errors. Remember that defensive programming is the practice of trying to anticipate all of thee ways software can be misused, either by end-users, or by developers. Test for the edge cases. If one of your functions encounters and error there are two ways to respond: continue re-trying the function. This is useful for things outside of the error's control (like network connectivity) Throw an exception. A good example is a division function: what should the function do if presented with an input of 0? This could be solved like this void printDivision ( int x , int y ){ if ( y != 0 ){ std :: cout << static_cast < double > ( x ) / y ; } else { std :: cerr << \"Error: Could not divide by zero \\n \" } } ``` This also makes it much easier for future programmers to see where an error is coming up . For really terrible errors , you can use a halt statement . More on exceptions in a later chapter . #### Handling intput data A ** buffer ** is a piece of memory set aside for storing data temporarily while it ' s moved from one place to another . ** Input valication ** is the process of checking whether user input conforms to what the program is expecting . This can be done inline ( as the user types ), or post - entry ( after the user types ). There are 4 main areas where extraction from a buffer might fail * Input extractino succeeds but the input in meaningless to the program ( e . g . entering 'k' as your mathematical operators ) * Input extraction succeeds but the suer enters additional input which stays in the buffer * Input extraction fails ( trying to enter 'q' into a numeric input ) * Input extraction succeeds but the user overflows a numeric value . As you write programs , consider how they could fail . ## Asserts and static_assert A ** precondition ** is any condition that is assumed by the programmer and necessary for their code to run . An ** invariant ** is a condition that must be true while some component is executing , and a ** postconditio ** is something that must be true after the execution of some component of code . A shortcut method to using a conditional statement to detect an invalid paraemter is the ** assertion ** expression . It will be true unless there is a bug in the program . Asserts are implemented via the ** assert * preprocessor macro which lives in the < cassert > header . ``` cpp assert ( gravity > 0.0 && \"Gravity cannot be less than zero\" ) \" Many developers prefer that asserts are only in debug builds. This can be done by using the macro NDEBUG, which if defined disables the assert macro. Use asserts to document your assumtions and cases that should be logically impossible. There is also a static_assert which is checked at compile-time rather than at tuntime. The condition for a static asser muse be able to be evaluated at compiletime. It can even be placed in global space. static_assert ( gravity > 0.0 , \"Code in this file assumes gravity cannot be negative\" );","title":"Control Flow and Error Handling"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#control-flow-and-error-handling","text":"A straig-line program is a program that takes the same path every time it is run. This is not practical when requesting input from a user. For this, C++ provides a number of control flow statements , which allow the programmer to change the normal path of execution. When a control flow statement causes the point of execution to change to a non-sequential statement this is called branching .","title":"Control Flow and Error Handling"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#if-statements-and-blocks","text":"The most basic conditional statement. Else is optional. Generally you want to always block if statements, or keep them in one-liners for readability. Otherwise you might run into a dangling else problem where you're not quite sure which if an else belongs to. Also be careful not to terminate your if statements with semicolons because that will immediately end them.","title":"If statements and blocks"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#switch-statements","text":"Instead of chaining a bunch of if statements together, it can be more readable to use a switch statement. This is also more efficient because the conditional is evaluated only once. switch ( x ){ case 1 : std :: cout << \"One\" ; return ; case 2 : std :: cout << \"Two\" ; return ; case 3 : std :: cout << \"Three\" ; return ; default : std :: cout << \"Unknown\" ; return ; } These are preferred both computationally and visually. Each label in the switch statement is called a case label . The default label or default case is used when the switch statement is evaluated to a value that does not have a case label. This should be placed last in the switch block. Instead of returning the entire function, you can also use a break statement to continue running the function after executing the statement block. If you do not have a break or return statement, the switch will continue evaluating until it finds a matching case statement like the default case statement. This is called fallthrough and is usually not intended. If you do intend it, you should use the [[fallthrough]]; attribute to explicitly call the fallthrough. If you would like a single staement block to be used for several case statements this can be done very elegantly: bool isVowel ( charc ){ switch ( c ){ case 'a' : case 'e' : case 'i' : case 'o' : case 'u' : return true ; default : return false ; } } If you want to defined variables inside a case statement, do so in a block inside the case or before the switch.","title":"Switch statements"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#goto-statements","text":"The unconditional jump casus execution to jump to another spon in the code. This requires a goto statement and a statement label . Because this quickly leads to spaghetti code goto statements are to be avoided.","title":"Goto statements"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#loops","text":"Each time a loop exectutes, it is called an iteration The simplest loops is the while statement : while ( condition ) statement ; They are dangerous because they can quicly lead to an infinite loop whter the condition is never met. If you intend for a while loop to go indefinitly use while(true). If you are counting your variables in a while loop, be sure to use signed ints. (otherwise they will overflow when they reach zero). A do while statement is a looping construct that is like a while loop, except the statement always executes at least once. Basically it checks the statement after the first iteration. do { selected = std :: cin >> selection ; } while ( selected != 1 && selection != 2 ) This is useful for things like selection where you want to get a selected number first, but you would favor while loops over do-while loops when given an equal choice for readability. The for loop is preferred when we have an obvious loop variable. There are two types of for loops, the classic for statement and the range-based for statement. The range based for statement uses iterators, and that is not covered at this point in the learning. for ( int count { 1 }; count <= 10 ; ++ count ){ std :: cout << count << ' ' ; } You can achieve the same result easily with a while loop, but the for loop is considered more readable. One cool thing you can also do is iterate over multiple variables with a for loop: for ( int x { 0 }, y { 9 }; x < 10 ; ++ x , -- y ) std :: cout << x << ' ' << y << '\\n' This is an acceptable way of working in a for loop.","title":"Loops"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#break-and-continue","text":"The break statement causes a while loop, do-while loop, for loop, or switch statemetn to end, with execution continuing with the next statement after the loop. It's different than return, because it does not exit the function. The continue statement is similar, but continues iterating the loop. These statements can make the flow harder to follow, so they should be used primarily when they simplify the loop logic. There is also debate about using early returns which are not at the end of the function. It's similar to using continue and break, use it when they simplify the functions' logic.","title":"Break and continue"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#halts","text":"A halt is a flow control statement that terminates the program. The std::exit() function is a halt that causes your program to terminate normally. Normal termination means that the program is exiting the expected way. Note that the std::exit() function does not clean up local variables in the current function or call stake. To help with this there is the std::atexit() function, which lets you specify functions to run whenever the program exits. The std::abort() function causes abnormal terminations which is a way of terminating due to an error. You should only use a halt if there is no safe way to return normally from the main function. If you haven't disabled exceptions, prefer using exceptions for handling errors safely?","title":"Halts"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#testing-your-code","text":"Scope creep happens when you add new capabilities that were originally not planned for. Software verification/testing is the process of determining whether or not the software still works for all of the cases. It's important to test your programs in small pieces. Write your program in smalle, well defined units (functions or classes), compile often, and test your code as you go. As you get more advanced there are also many unit testing frameworks you can use in C++ that help with a testing framework. Once each of your units has been tested in isolatino they can be integrated into your program, and to make sure this happens correctly you can create integration tests .","title":"Testing your code"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#code-coverage","text":"Code coverage is a term used to describe how much of the source code of a program is executed while testing. Statement coverage refers to the percentage of statements in your code that have been exercised by your testign routines. While aiming for 100% statement coverage is fine, it's not enough to ensure correctness. Branch coverage refers to the percentage of branches that have been executed, each possible branch counted separately. (i.e. an if statement has 2 branches. ) You should aim for 100% branch coverage of your code. Loop coverage (0, 1, 2, test) is the concept that if you have a loop in your code you should ensure it works properly when it iterates 0 times, 1, time, and 2 times. Any value greater than 2 should then also work. You also need to consider what tests make sense for functions that take different categories of input.","title":"Code coverage"},{"location":"cpp/LearnCpp.com/007_Control_Flo_and_Error_Handling/#detecting-and-handling-errors","text":"Many new programmers write code and then only test the happy path : only the cases where there are no errors. Remember that defensive programming is the practice of trying to anticipate all of thee ways software can be misused, either by end-users, or by developers. Test for the edge cases. If one of your functions encounters and error there are two ways to respond: continue re-trying the function. This is useful for things outside of the error's control (like network connectivity) Throw an exception. A good example is a division function: what should the function do if presented with an input of 0? This could be solved like this void printDivision ( int x , int y ){ if ( y != 0 ){ std :: cout << static_cast < double > ( x ) / y ; } else { std :: cerr << \"Error: Could not divide by zero \\n \" } } ``` This also makes it much easier for future programmers to see where an error is coming up . For really terrible errors , you can use a halt statement . More on exceptions in a later chapter . #### Handling intput data A ** buffer ** is a piece of memory set aside for storing data temporarily while it ' s moved from one place to another . ** Input valication ** is the process of checking whether user input conforms to what the program is expecting . This can be done inline ( as the user types ), or post - entry ( after the user types ). There are 4 main areas where extraction from a buffer might fail * Input extractino succeeds but the input in meaningless to the program ( e . g . entering 'k' as your mathematical operators ) * Input extraction succeeds but the suer enters additional input which stays in the buffer * Input extraction fails ( trying to enter 'q' into a numeric input ) * Input extraction succeeds but the user overflows a numeric value . As you write programs , consider how they could fail . ## Asserts and static_assert A ** precondition ** is any condition that is assumed by the programmer and necessary for their code to run . An ** invariant ** is a condition that must be true while some component is executing , and a ** postconditio ** is something that must be true after the execution of some component of code . A shortcut method to using a conditional statement to detect an invalid paraemter is the ** assertion ** expression . It will be true unless there is a bug in the program . Asserts are implemented via the ** assert * preprocessor macro which lives in the < cassert > header . ``` cpp assert ( gravity > 0.0 && \"Gravity cannot be less than zero\" ) \" Many developers prefer that asserts are only in debug builds. This can be done by using the macro NDEBUG, which if defined disables the assert macro. Use asserts to document your assumtions and cases that should be logically impossible. There is also a static_assert which is checked at compile-time rather than at tuntime. The condition for a static asser muse be able to be evaluated at compiletime. It can even be placed in global space. static_assert ( gravity > 0.0 , \"Code in this file assumes gravity cannot be negative\" );","title":"Detecting and handling errors"},{"location":"cpp/LearnCpp.com/008_Compound_types/","text":"Compound Types Strings A string is a series of numbers. You can store it as a value using the std::string object from the string header. Strings will not automaticalyl convert to integer or floating point. One thing to note is that std::cin with strings does not work as expected because it breaks on whitespace. For that it's better to use std::getline() to input text. std : string name {}; std :: getline ( std :: cin , age ); //read a full line of text into age This will read the entire line of the buffer after the std::cin prompt. Note that compining this with std::cin might have unexpected results, because the previous buffer might still be in the line. Because there is already something in the buffer std:cin resolves prematurely. This happens even if the user correctly only entered a single number, because of the newline character that is left in the buffer. A good rule of thumb is that after reading a vlue with std::cin, remove the newline from the stream. std :: cin . ignore ( std :: numeric_limits < std :: streamsize >:: max (), '\\n' ); You can append string with the + operator or += to append a string to the end of an existing string. Enumerated types One of the simplest user-defined data types is the enumeration type aka enum . enum Color { color_red , color_green } This enum would guarantee that your program can only run in christmas colors. You can't have the same value in multiple enums of the same namespace. enum Color { red , blue , // blue is put into the global namespace green }; enum Feeling { happy , tired , blue // error, blue was already used in enum Color in the global namespace }; Each enumerator is automatically assigned an integer value based on it's index in the enumeration list. You can override this by assigning specific values to your enumerators, but you shouldn't because it can lead to confusion. You cannot input directly to an enum or cast an enum directly unless you use a static cast. (ugly). It's safe to use an unsigned int for enums. Enums are great for returning descriptive result of functions: enum ParseResult { // We don't need specific values for our enumerators. success , error_opening_file , error_reading_file , error_parsing_file }; ParseResult readFileContents () { if ( ! openFile ()) return error_opening_file ; if ( ! readFile ()) return error_reading_file ; if ( ! parsefile ()) return error_parsing_file ; return success ; } ``` One problem with default enumerators is that they are not ** type safe ** . Entry 2 of enum color will resolve as true when compared to entry 2 of enum fruit . For this , c ++ 11 defined a new concept , the ** enum class ** , which makes enumerations both strongly typed and strongly scoped . ``` cpp enum class Color // \"enum class\" defines this as a scoped enumeration instead of a standard enumeration { red , // red is inside the scope of Color blue }; enum class Fruit { banana , // banana is inside the scope of Fruit apple }; Color color { Color :: red }; // note: red is not directly accessible any more, we have to use Color::red Fruit fruit { Fruit :: banana }; // note: banana is not directly accessible any more, we have to use Fruit::banana if ( color == fruit ) // compile error here, as the compiler doesn't know how to compare different types Color and Fruit std :: cout << \"color and fruit are equal \\n \" ; else std :: cout << \"color and fruit are not equal \\n \" ; return 0 ; With enum classes you have to type out the scop of the enum. Generally it's better to use enum classes. Structs C++ allows us to creat our own user-defined aggregate data types which are types taht group multiple indifvidual variables together. The struct is one of the simples aggregate data types. struct Employee { short id ; int age ; double wage ; }; ``` Each variable in the struct is called a ** member ** . Generally aggregate data types start with capital letter to distinguish them from variable names . You can give each instance of a struct an identifier and set the values ``` cpp Employee joe ; joe . id = 14 ; joe . age = 32 ; joe . wage = 24.15 ; You can also initialize struct using an initializer list , which lets you set some or all members of the struct at declaration time. Employee joe{ 1, 32, 60000.0 }; joe = {2, 32, 50000.0 }; //paycuts Starting with C++11 you can give non-static (normal) struct members a default value struct Rectangle{ double length{ 1.0 }; double width{ 1.0 }; } Note that this will be incompatible with the initilization list. Because of that it's reccomended against using non-static member initilization. The useful thing about structs is that you can use them as a single argument in a function and pass a lot of date through with them. They can also contain other structs. To access structs in many files, it's common to put them into header files since they don't take up any memeory. These basic structs are what classes (future lesson) are built on. Random number generation a pseudo-random number generator (PRNG) is a program that takes a starting number seed and performs mathematical operations on it to transform it into some other number that appears unrealated to the seed. You should only seed your PRNG once, multiple times will cause the results to be less random or not random at all. std random number generator has std::srand() and std::rand(). The first is run at the top of your program, and std::rand() then keeps on generating new random numbers from that. Each time you give the same seed you get the same result back. The commonly accepted method for creating purely random seeds is the system clock. std::srand(static_cast<unsigned int>(std::time(nullptr))); std::cout << std::rand() << '\\t'; The number generated by std::rand() is alwasy between 0 and RAND_MAX, a constant in cstdlib that is usually 32767. To fit between two arbitrary values you ca ndo something like this: int getRandomNumber(int min, int max){ static constexpr double fraction { 1.0 / (RAND_MAX + 1.0) }; // static is more efficient, since we can cacluate this at compile time return min + static_cast<int>((max - min + 1) * (std::rand() * fraction)); } The length of the sequence before a PRNG begins to repeat itself is known as the preiod of the PRNG. std::rand() is a mediocre PRNG - the results differ across systems. The main drawback is that RAND_MAX is usually set to 32767 which means it cannot generate numbers larger than this. A good prng is Mersenne Twister . #include <iostream> #include <random> // for std::mt19937 #include <ctime> // for std::time int main () { // Initialize our mersenne twister with a random seed based on the clock std :: mt19937 mersenne { static_cast < std :: mt19937 :: result_type > ( std :: time ( nullptr )) }; // Create a reusable random number generator that generates uniform numbers between 1 and 6 std :: uniform_int_distribution die { 1 , 6 }; // If your compiler doesn't support C++17, use this instead // std::uniform_int_distribution<> die{ 1, 6 }; // Print a bunch of random numbers for ( int count { 1 }; count <= 48 ; ++ count ) { std :: cout << die ( mersenne ) << '\\t' ; // generate a roll of the die here // If we've printed 6 numbers, start a new row if ( count % 6 == 0 ) std :: cout << '\\n' ; } return 0 ; } If you want to use random number generators across multiple functions, it's reccomended to create a global random number generator (in it's own namespace!). Or you could use a third party library like Effolkronium's random library","title":"Compound Types"},{"location":"cpp/LearnCpp.com/008_Compound_types/#compound-types","text":"","title":"Compound Types"},{"location":"cpp/LearnCpp.com/008_Compound_types/#strings","text":"A string is a series of numbers. You can store it as a value using the std::string object from the string header. Strings will not automaticalyl convert to integer or floating point. One thing to note is that std::cin with strings does not work as expected because it breaks on whitespace. For that it's better to use std::getline() to input text. std : string name {}; std :: getline ( std :: cin , age ); //read a full line of text into age This will read the entire line of the buffer after the std::cin prompt. Note that compining this with std::cin might have unexpected results, because the previous buffer might still be in the line. Because there is already something in the buffer std:cin resolves prematurely. This happens even if the user correctly only entered a single number, because of the newline character that is left in the buffer. A good rule of thumb is that after reading a vlue with std::cin, remove the newline from the stream. std :: cin . ignore ( std :: numeric_limits < std :: streamsize >:: max (), '\\n' ); You can append string with the + operator or += to append a string to the end of an existing string.","title":"Strings"},{"location":"cpp/LearnCpp.com/008_Compound_types/#enumerated-types","text":"One of the simplest user-defined data types is the enumeration type aka enum . enum Color { color_red , color_green } This enum would guarantee that your program can only run in christmas colors. You can't have the same value in multiple enums of the same namespace. enum Color { red , blue , // blue is put into the global namespace green }; enum Feeling { happy , tired , blue // error, blue was already used in enum Color in the global namespace }; Each enumerator is automatically assigned an integer value based on it's index in the enumeration list. You can override this by assigning specific values to your enumerators, but you shouldn't because it can lead to confusion. You cannot input directly to an enum or cast an enum directly unless you use a static cast. (ugly). It's safe to use an unsigned int for enums. Enums are great for returning descriptive result of functions: enum ParseResult { // We don't need specific values for our enumerators. success , error_opening_file , error_reading_file , error_parsing_file }; ParseResult readFileContents () { if ( ! openFile ()) return error_opening_file ; if ( ! readFile ()) return error_reading_file ; if ( ! parsefile ()) return error_parsing_file ; return success ; } ``` One problem with default enumerators is that they are not ** type safe ** . Entry 2 of enum color will resolve as true when compared to entry 2 of enum fruit . For this , c ++ 11 defined a new concept , the ** enum class ** , which makes enumerations both strongly typed and strongly scoped . ``` cpp enum class Color // \"enum class\" defines this as a scoped enumeration instead of a standard enumeration { red , // red is inside the scope of Color blue }; enum class Fruit { banana , // banana is inside the scope of Fruit apple }; Color color { Color :: red }; // note: red is not directly accessible any more, we have to use Color::red Fruit fruit { Fruit :: banana }; // note: banana is not directly accessible any more, we have to use Fruit::banana if ( color == fruit ) // compile error here, as the compiler doesn't know how to compare different types Color and Fruit std :: cout << \"color and fruit are equal \\n \" ; else std :: cout << \"color and fruit are not equal \\n \" ; return 0 ; With enum classes you have to type out the scop of the enum. Generally it's better to use enum classes.","title":"Enumerated types"},{"location":"cpp/LearnCpp.com/008_Compound_types/#structs","text":"C++ allows us to creat our own user-defined aggregate data types which are types taht group multiple indifvidual variables together. The struct is one of the simples aggregate data types. struct Employee { short id ; int age ; double wage ; }; ``` Each variable in the struct is called a ** member ** . Generally aggregate data types start with capital letter to distinguish them from variable names . You can give each instance of a struct an identifier and set the values ``` cpp Employee joe ; joe . id = 14 ; joe . age = 32 ; joe . wage = 24.15 ; You can also initialize struct using an initializer list , which lets you set some or all members of the struct at declaration time. Employee joe{ 1, 32, 60000.0 }; joe = {2, 32, 50000.0 }; //paycuts Starting with C++11 you can give non-static (normal) struct members a default value struct Rectangle{ double length{ 1.0 }; double width{ 1.0 }; } Note that this will be incompatible with the initilization list. Because of that it's reccomended against using non-static member initilization. The useful thing about structs is that you can use them as a single argument in a function and pass a lot of date through with them. They can also contain other structs. To access structs in many files, it's common to put them into header files since they don't take up any memeory. These basic structs are what classes (future lesson) are built on.","title":"Structs"},{"location":"cpp/LearnCpp.com/008_Compound_types/#random-number-generation","text":"a pseudo-random number generator (PRNG) is a program that takes a starting number seed and performs mathematical operations on it to transform it into some other number that appears unrealated to the seed. You should only seed your PRNG once, multiple times will cause the results to be less random or not random at all. std random number generator has std::srand() and std::rand(). The first is run at the top of your program, and std::rand() then keeps on generating new random numbers from that. Each time you give the same seed you get the same result back. The commonly accepted method for creating purely random seeds is the system clock. std::srand(static_cast<unsigned int>(std::time(nullptr))); std::cout << std::rand() << '\\t'; The number generated by std::rand() is alwasy between 0 and RAND_MAX, a constant in cstdlib that is usually 32767. To fit between two arbitrary values you ca ndo something like this: int getRandomNumber(int min, int max){ static constexpr double fraction { 1.0 / (RAND_MAX + 1.0) }; // static is more efficient, since we can cacluate this at compile time return min + static_cast<int>((max - min + 1) * (std::rand() * fraction)); } The length of the sequence before a PRNG begins to repeat itself is known as the preiod of the PRNG. std::rand() is a mediocre PRNG - the results differ across systems. The main drawback is that RAND_MAX is usually set to 32767 which means it cannot generate numbers larger than this. A good prng is Mersenne Twister . #include <iostream> #include <random> // for std::mt19937 #include <ctime> // for std::time int main () { // Initialize our mersenne twister with a random seed based on the clock std :: mt19937 mersenne { static_cast < std :: mt19937 :: result_type > ( std :: time ( nullptr )) }; // Create a reusable random number generator that generates uniform numbers between 1 and 6 std :: uniform_int_distribution die { 1 , 6 }; // If your compiler doesn't support C++17, use this instead // std::uniform_int_distribution<> die{ 1, 6 }; // Print a bunch of random numbers for ( int count { 1 }; count <= 48 ; ++ count ) { std :: cout << die ( mersenne ) << '\\t' ; // generate a roll of the die here // If we've printed 6 numbers, start a new row if ( count % 6 == 0 ) std :: cout << '\\n' ; } return 0 ; } If you want to use random number generators across multiple functions, it's reccomended to create a global random number generator (in it's own namespace!). Or you could use a third party library like Effolkronium's random library","title":"Random number generation"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/","text":"Arrays, Strings, Pointers, and references An array is a aggregate datat types that lets us access many variables of the same type though a single identifier. They are declared like this: int testScore [ 30 ]{}; // allocate 30 integer variables in a fixed array The 30 in brackets tells the compiler both that this is an array variables as well as the array length - the amount of variables to allocate. A fixed array is an array where the length is known at compile time. It cannot chaneg length. Each of the variables in an array is called an element . They do not have unique identifiers, but are accessed using the subscript operator ([]) and a parameter called the subscript or index that tells the compilier which element we want. This is called subscripting or indexing the array. The range of an array is the numbering of the elements in the array. Arrays can be made from any data types, including structs. To access struct members: rects [ 0 ]. length = 24 Array subscripts must always be an integral type. These can be char, short, int, long, long long, enums, etc. For fixed array declarations you need the length to be a compile time const - it cannot be calculated dynamically at runtime. You can also initialize arrays with an initizlizer list : int prime [ 5 ]{ 2 , 3 , 5 , 7 , 11 }; If you are initializing with an initializer list you don't need to specify the length of the array. If there are less initilizer in the list than the array can hold, the remaining elements are initialized to 0 - caled zero initialization . Even if you are find with all the elements being initialized to 0, you should still initialize them with empty brackets std :: string array [ 5 ]{ }; For fixed arrays you can have better code documentation by using enums. enum StudentNames { kenny , // 0 kyle , // 1 stan , // 2 butters , // 3 cartman , // 4 max_students // 5 }; int testScores [ max_students ]{}; testScores [ stan ] = 76 ; When passing arrays to a function, the entire array is not copied. Only the actual array is copied, but not the elements. This means that all elements are passed by reference - they can be changed by the function!!To signify that a function will not change the elements of an array you can make the array const. Keep in mind that Cpp will not stop you from assigning out of range elements to arrays! That value will simply overwrite that next part of memory, which could be allocated to a different variable! The std::size can measure the size of an array. Note that due to how the arrays are passed into functions (as pointers) this will not work on arrays in functions! Also note that std::size returns an unsigned variable. For all cases where this is required, you can use a * dynamic array , whose length can be set at runtime. You can iterate over the values in an array using a loop to apply the same thing to every entry. int scores []{ 84 , 92 , 76 , 81 , 56 }; int numStudents { std :: size ( scores ) }; // const int numStudents{ sizeof(scores) / sizeof(scores[0]) }; // use this instead if not C++17 capable int totalScore { 0 }; // use a loop to calculate totalScore for ( int student { 0 }; student < numStudents ; ++ student ) totalScore += scores [ student ]; auto averageScore { static_cast < double > ( totalScore ) / numStudents }; Use std::swap to swap two elements of an array. This is useful when sorting arrays. For this lesson the assignment was to write a bubble sort program to sort an array. Arrays can also be arrays of arrays called multidimensional arrays . When thinking of these like a matrix, it's convenient o think of the first (left) subscript as being the row, and the second (right) subscript as being the column. Interpreting multi-dimensional arrays this way is considered row-major order. array [ 3 ][ 5 ]; You can initiliaze these arrays with nested braces: int array [ 3 ][ 5 ]{ { 1 , 2 , 3 , 4 , 5 }, { 6 , 7 , 8 , 9 , 10 }, { 11 , 12 , 13 , 14 , 15 } }; C-style strings You will never use these, but it's interesting to know that std::string are based on C-style strings which are null terminated strings. This means that a null terminator '\\0' is used to indicate the end of the string. These strings are essentially arrays of chars, and are defined that way: char myString []{ \"string\" }; If you conver the string chars to ints, the last will always be zero. Because these strings work exactly like arrays, you can't assigne values of them directly! It's fine if the array is larger than the string it contains, but if you replace the last element in it and print, the print will keep printing until it encounters a zero! You should use std::stirng or std::string_view instead of C-syle strings. String View This is an object which, like a pointer, views an existing string object. Prefer this over C-style strings and std::string for read-only strings. It includes function for reducing what parts of the string it referrs to. For this you use std::strnigview.remove_prefix and remove_suffix. It's also not null-terminated. If the string that std::string_view is viewing goes out of scope or becomes unavaliable, then it's uncertain what string_view is pointing to. You can convert it to a std::string by casting it to one. Pointers The address-of operator (&) allows us to see what memeory address is assigned to a variable, and the indirection (*) operator allows us to access that value. int x { 5 }; std :: cout << x << '\\n' ; // print the value of variable x std :: cout << & x << '\\n' ; // print the memory address of variable x std :: cout << * ( & x ) << '\\n' ; /// print the value at the memory address of variable x (parenthesis not required, but make it easier to read) A pointer is a variable that holds a memory address as its value. int * iPtr {}; The asteric is not an indiretion - it's just part of the pointer declaration syntax. When defining variables it's bettr to put the asterisk next to the variable name, but when returning a pointer from a function it's better to put the asterisk of a pointer return value next to the type. int * doSomething (); One of the most commoon things to do with pointers is to have them hold the address of a different variable. int v { 5 }; int * ptr { & v }; \\\\ inititialize ptr with address of variable v The type of the pointer has to match the type of the variable being pointed to. It's worth noting that the address of (&) doesn't return the addres of its operand as a literal, but returns a pointer containing the address of the operand. The other common thing to do with pointers is to get the values that they are pointing at. For this use the indirection (*) operator to evaluate the cnotents of the address it is pointing to. int value { 5 }; int * ptr { & value }; // ptr point to value std :: cout << * ptr ; // print the value that the ptr is pointing to This is why pointers need a type. Without a type, when indirecting throught a pointer, the pointer wouldn't know how to interpret the contents it was poitning to. You can reassign pointers to different values of the same type. If your program tries to access a location in memory that's not part of the program, the operating system might crash. Because of this all operating systems sandbox applications. What are pointers good for? Arrays are implemented using pointers They are the only way you can dynamically allocate memory in C++ They can be used to pass a function as a parameter to another function They can be used to achieve polymorphism when dealing with inheritance. They can be used to have one struct/class point to another struct/class to form a chain. What should you initialize a pointer to if you don't have the memory address yet? The answer is a null value , which is a spacial value that means the pointer is not pointing at anything. Pointers pointing at null values are called null pointers . They are assigned by initializing the pointer to 0 or (C++ 11) a special value called null ptr. float * ptr { nullptr }; Your pointers should always be initializaed even if it is to null value. Some compilers misinterpret the value of zero and try to initialize pointers to that as an integer, which is why nullptr was added. Pointers and arrays are intrinsicalyl related in C++. When you pass an array to a function, it decays (is implicitly converted) to a pointer that points to the first element of the array. Because both pointers and arrays can access elements in them with the subscript, it might be better to understand where the data types differ: sizeof() on arrays returns the entire array (array length * element size). On a pointer it returns the size of a memory address. Using the address-of operator (&) on a pointer yields the memory address of the opinter variables. Of an array it returns a pointer to the entire array. The resulting pointer points to the same address, but the data type is different. Arrays degrade to pointers because they have all of the same funcionality and a much smaller memory footprint. They do not decay if they are part of a class or struct. When scaling a pointer, you are telling it to point to the next object in memory of the pointer's type. This assumes that the next object is the same size as the pointer, and the same type. How is this useful? It's because arrays are laid out sequentially in memory. This is how you grab a specific element in an array. These are equal: array [ 1 ]; * ( array + 1 ); Dynamic Memory Allocation with new and delete C++ supports three basic types of memory allocation: Static memory allocation for static and global variables. This is avaliable for the entire runtime of the program. Automatic memory allocation for function parameters and local variables. Memory for these types is allocated when the relevant block is entered, and free when the block is exited. Dynamic memory allocation - which is user controlled. Why not just use static and automatic? Wasted Memory Hard to tell which bits of memory are actually being used. Most variables are allocated to a portion of memory called the stack , which is usually quite small. This is isually around 1MB, otherwise the operating system will close the program. It can lead to artificial limitation and array overflows. What if the user has a name longer than the allocated char[25] array? This is where dynamic memory allocation comes in. It is a way for running programs to request memory from the operating system when needed. It comes from a much larger pool memory managed by the operating system called the heap . On modern machines this is gigabytes in size. To allocate a single variable dynamically we use the scalar (non-array) form of the new operator. int * ptr { new int }; // dynamically allocate an integer (and discard the result) new int returns a pointer that we are storing in our automatically allocated ptr variable. We can then perform indirection through the pointer to access the memory * ptr = 7 ; //assign value of 7 to allocated memory When you dynamically allocate memory, you're asking the operating system to reserve some of thatmemory for your program's use. You can also directly initilize the variable you are directly allocating: int * ptr1 { new int { 6 }} To release the variables you use the delete operator. You should only delete ptrs that are not pointing to dynamically allocated memeory. A pointer that is pointing to deallocated memory is caleld a dangling pointer . After deleting a pointer you should assign it to a nullptr immediately afterward. int * ptr { new int {} }; // dynamically allocate an integer int * otherPtr { ptr }; // otherPtr is now pointed at that same memory location delete ptr ; // return the memory to the operating system. ptr and otherPtr are now dangling pointers. ptr = nullptr ; // ptr is now a nullptr // however, otherPtr is still a dangling pointer! return 0 ; Operator new can fail if the operating system has no more memory to grant the request with. If this happens, the program will simply terminate with an unhandled exception error. There is an alternate form of new that will return a null pointer if memory can't be allocated. int * value = new ( std :: nothrow ) int ; \\\\ the value will be a null pointer if the integer allocation fails . At that point you probably want to test if the pointer is null and throw an exception otherwise to elegantly exit the progam. Because a pointer can go out of scope without freeing the memory it was pointing to, there can be instances where it is impossible to delete the allocated memory. This is called a memory leak . This can also happen if the pointer is assigned to another value, in which case you should have deleted the memory the pointer was pointing towards before re-assigning it. Allocate memory for an array and return a pointer: int * array { new int [ length ]{} }; delete [] array ; array = nullptr ; You cannot have a non-const pointer to a const value. You can have const pointers to non-const values, but not non-const pointers to const values. You can have a const int *ptr to a value and the pointer will think the value is const even if it isn't. int value = 5 ; int * const ptr = & value ; A const pointer is a pointer whose value can not be changed after initialization. The value that this pointer points to cannot be changed. You can also have a const pointer pointing to const int type like this int value = 5 ; const int * const ptr = & value ; A non-const opinter can be redirected to point to other addresses A const pointer always oint to the same address, and this address can not be changed A pointer to a non-const value can change the value it is pointing to. These pointers can not point to a const value. A pointer to a const value treats the value as const (even it is not), and thus cannot change the value it is pointing to. Reference Variables Reference variables can be thought of like instances of a variable, it acts like an alias to another object or value. This is different that pointers that point to the memory address of an object or value, or normal variables, which hold values directly. int value { 5 }; int & ref1 { value }; int & ref2 { value }; The second initiliazation form is preferred for variables, and the first for function return types, just like with the address of and indirection operators. References must be initialized when created and won't compile otherwise. They cannot be re-assigned trying to do so will re-assign the value to the reference. They are most often used as function parameters. This is especially useful when the function is intended to modify the variable, and is what people means when they say \"pass by reference\" . All varialbes are a type of l-value (ell-value), which are values that have an address in memory. These are the only values that are on the left side of an assignment statement. The opposite of l-values are r-valuse - the are expressions that are not l-values. x = x + 1 In the above statement x is both used as an l-value and an r-value. The key takewaway is that the right side you have something that will be evaluated and then put into the variable's address in memory on the left side. You can have const references just like const pointers. Unlike pointers you can have const references to non-const values. This is great if you want to illustrate that this reference variable won't change. A great use of const references is as function parameters: void changeN ( const int & ref ){ ref = 6 ; //not allowed, ref is const. } When passing C-style arrays to a function, if they are passed as reference they do not decay. Their size needs to be defined in the parameter though. References are particularly useful when used as an alias for deeply nested objects. int & ref { other . somthing . value1 }; References are generally much safer than pointers, but have more limited functionality. Pointers should only be used in situations where references are not sufficient (such as dynamically allocating memory). For references the compilier automatically add the indirection, which we'd do manually on a pointer using an asterisk. Pass non-pointer, non-fundamental data type variables (such as structs) by (const) reference, unless you konw that passing it by value is faster. Structs are generally passed around by reference or pointer struct Person { int age {}; double weight {}; }; Person person {}; Person & ref { person }; Person * ptr { & person }; ptr -> age = 5 ; \\\\ remember that -> is the same as ( * ptr ). age = 5 ; Remember that the * does the same as indirection followed by the . member selection. When using a pointer to access teh value of a member, use the operator -> instead of the (.) For-each loops For most loops, it's simpler and safer to use a for-each loop instead of manual for loops. The syntax is as follows: for (element_declaration : array) statement; For each loops are a great place to use the auto keyword. This saves a lot of time when refactoring the contents of a list. Because the list is alerady strongly typed, the auto is not ambiguous. for(auto number : fibonacci){ \\\\ type is auto, so number has its type deducted from the fibonacci arary std::cout << number << ' '; } The above example copies the value into number from fibonacci. In most cases it's more efficient to do this by reference: for ( autch & number : array ){ std :: cout << number << ' ' ; } ``` In for - each loops element declarations , if your elements are non - fundamental types , use references or const references for performance reasons . As of cpp 20 , you can auto assigne a variable with the current index of the for loop : ``` cpp for ( int i { 0 }; auto score : scores ){ std :: cout << score << ' ' ; } Void Pointers Similar to the auto keyword, the void pointer can point at any datatype. This is great, but indirection will not work because the void pointer doesn't know how large the data type is. int value { 5 }; void * voidPtr { & value }; std :: cout << * voidPtr << '\\n' // this will not compile int * intPtr { static_case < int *> ( voidPtr ) }; // you need to cast to int first std :: cout << * intPtr << '\\n' ; The difficulty with void points is that you need to keep track of what their data type is. Xtra juice Interesting but rarely used knowlage: you can have pointers to pointers: int ** ptrptr ; \\\\ pointer to a pointer to an int , two asterisks The most common use for this is to dynamically allocate an array of pointers. This is like a standard dynamically allocated array, except the array elemeents are of type \"pointer to integer\" instead of integer. This is espcially useful for multidimensional arrays of pointers. int ** array = new int * [ 10 ]; \\\\ allocate an array of 10 int pointers - these are our rows for ( int count = 0 ; count < 10 ++ count ){ array [ cout ] = new int [ 5 ]; \\\\ these are our columns . } \\\\ deallocating the the array also requires a loop for ( int count = 0 ; count < 10 ; ++ count ) delete [] array [ count ]; delete [] array ; // this needs to be done last We need to deallocate the array elements first, then the array. Otherwise there would be no array left to access the elements that we are deleting. Instead of complex multidimensional arrays consider a flat array where you access the elements by the (row * numberOfColumnsInArray) + col; Generally avoid using pointers to pointers unless no other options are available. std::array This object provides fixed array functionality and does not decay into a pointer when passed to a function. std :: array < int , 5 > myArray { 9 , 6 , 7 , 2 , 4 , 5 , 2 , 1 }; One good thing about std::array is using the myArray.at(1) function to acces elements. This will throw an error if out of range unlike the [] operators. It will also clean up after itself when out of scope. Because it is not a fundamental data type you should alsoway pass std::array by reference or const reference. You can sort std::array using std::sort which lives in the header. std :: sort ( myArray . begin (), myArray . end ()); std::array also come with a .size() function which is really nice when looping over the elements. It's a bit weird through, because .size() return an unsigned integral data type defined inside of std::array so when looping over it you have to do it like this: std :: array myArray { 7 , 3 , 1 , 9 , 5 }; for ( std :: array < int , 5 >:: size_type i { 0 }; i < myArray . size (); ++ i ){ std :: cout << myArray [ i ] << ' ' ; } A better solution is to just avoid manual indexing of std::array and use a range-based for loop This still makes it a challenge to iterate over the array in reverse because size is an unsigned int. For this modify i each iteration and see if that it still above zero to prevent i from ever reaching zero and then looping back up to the maximum value. for ( auto i { myArray . size () }; i -- > 0 ; ){ std :: cout << myArray [ i ] << ' ' ; } When initializing an array of structs or nested array, it can be confusing with the braces. The first element in the initialization is the key argument, and arrays of arrays must be defined within in: Array houses { { { 13 , 4 , 30 }, { 14 , 3 , 10 }, { 15 , 3 , 40 } } } Those extra braces are imporant! std::array is a great replacement for the build build-in fixed array, but with a slightly awkward syntax. std::vector The true dynamic list obect! This is what you use to work with dynamic arrays. It's one of the most useful and versatile tools. With std::vector you can create arrays that have their length set at runtime without having to explicitly allocate and deallocate memory using new and delete. It lives in the <vector> headers. Declaring it is simple: std :: vector < int > myArray { 9 , 7 , 8 , 9 , 1 , 2 , 3 }; Note that you do not need to include the array length at compile time. std::vector will dynamically allocate. Because it cleans itself up when going out of scope you do not need to worry about memeory leaks. Vectors also remember their length. Resizing a std::vector is as simple as calling the resize() function. std :: vector array { 0 , 1 , 2 }; array . resize ( 5 ); This is still computationally expensive, so you should still try to minimize the cases where you resize vectors. You should use std::vector in most cases where dynamic arrays are needed. Iterators How do range-based for loops work? An iterator is an object designed to traverse through a container while providing access to each element while it's doing so. Pointers are the simplest kind of iterator. Because a pointer knows the size of memory to increment, you can use it to iterate over a block of memory. std :: array data { 0 , 1 , 2 , 3 , 4 , 5 , 6 }; auto begin { & data [ 0 ] }; \\\\ create a pointer that points to the first element auto end { begin + std :: size ( data ) }; \\\\ this points to one spot beyond the last element . The spot where in the for loop the ptr will stop iterating . for ( ato ptr { begin }; ptr != end ++ ptr ){ std :: cout << * ptr << ' ' ; } Because iterating is so common, the array objct has convenience function named begin and end auto begin { array . begin () }; auto end { array . end ()}; If it's not an array you can also use std::begin(array) and std::end(array). Any type that has a begin and end function or can be used with std::begin and std::end are usable directly in range-based-for loops (this is what they look for). for (int i: array) \\\\ array has array.begin() and array.end() Behind the scenes begin() and end() are called. Dynamic arrays won't work though, because there is no end() function. If the elements being iterated over change address or are destroyed iterator can be left dangling: then they are reffered to as invalidated . Accessing invalidated iterators produces undefined behaviour. Standard Library algorithms Don't type up your own complex for loops for things you can easily do with std. These are all found in the <algorithms> library . std::find searched for the first occurrence of a value. std::find{arr.begin(), arr.end(), search)} std::find_if bool containsNut(std::string_view str){ // std::string_view::find returns std::string_view::npos if it doesn't find the substring. Otherwise it returns the index where the sustring occurs in str. return (str.find(\"nut\") != std::string_view::npos); } int main(){ auto found{ std::find_if(arr.begin(), arr.end(), containsNut) }; } This return all elements of the array if they contain nut (I did abbreviate this for berevity). The string view object has a function find which returns a bool. That is used on each element in the array until one is found. std::count and std::count_if see how many occurances in an iterator match the comparison. std::sort for custom sorting. This takes in a function very similar to std::find_if. std::sort(arr.begin(), arr.end(), std::greater<int>{}) - greater is also part of std std::for_each with a function applies that to every element of the list: void doubleNumber ( int & i ){ i *= 2 ; } int main (){ std :: for_each ( arr . begin (), arr . end (), doubleNumber ); } The advantage here is that you easile set the beginning and end. std::reduce applies a function to all elements in a list (by default the + operator), which results in a single value. By default (+), this is the sum of all the elements of the list. std::accumulate - this does the same as std::reduce, but from left-toright std::shuffle takes a list and randomly re-orders its elements. Unless otherwise specified, do not assume that the standard ilbrary algorithms will execute in a particular sequence. This means they do not iterate over the for-loop in sequential order, but in parallel. Favor these functions over writing your own. A game I wrote with the concepts of this chapter can be found here","title":"Arrays, Strings, Pointers, and references"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#arrays-strings-pointers-and-references","text":"An array is a aggregate datat types that lets us access many variables of the same type though a single identifier. They are declared like this: int testScore [ 30 ]{}; // allocate 30 integer variables in a fixed array The 30 in brackets tells the compiler both that this is an array variables as well as the array length - the amount of variables to allocate. A fixed array is an array where the length is known at compile time. It cannot chaneg length. Each of the variables in an array is called an element . They do not have unique identifiers, but are accessed using the subscript operator ([]) and a parameter called the subscript or index that tells the compilier which element we want. This is called subscripting or indexing the array. The range of an array is the numbering of the elements in the array. Arrays can be made from any data types, including structs. To access struct members: rects [ 0 ]. length = 24 Array subscripts must always be an integral type. These can be char, short, int, long, long long, enums, etc. For fixed array declarations you need the length to be a compile time const - it cannot be calculated dynamically at runtime. You can also initialize arrays with an initizlizer list : int prime [ 5 ]{ 2 , 3 , 5 , 7 , 11 }; If you are initializing with an initializer list you don't need to specify the length of the array. If there are less initilizer in the list than the array can hold, the remaining elements are initialized to 0 - caled zero initialization . Even if you are find with all the elements being initialized to 0, you should still initialize them with empty brackets std :: string array [ 5 ]{ }; For fixed arrays you can have better code documentation by using enums. enum StudentNames { kenny , // 0 kyle , // 1 stan , // 2 butters , // 3 cartman , // 4 max_students // 5 }; int testScores [ max_students ]{}; testScores [ stan ] = 76 ; When passing arrays to a function, the entire array is not copied. Only the actual array is copied, but not the elements. This means that all elements are passed by reference - they can be changed by the function!!To signify that a function will not change the elements of an array you can make the array const. Keep in mind that Cpp will not stop you from assigning out of range elements to arrays! That value will simply overwrite that next part of memory, which could be allocated to a different variable! The std::size can measure the size of an array. Note that due to how the arrays are passed into functions (as pointers) this will not work on arrays in functions! Also note that std::size returns an unsigned variable. For all cases where this is required, you can use a * dynamic array , whose length can be set at runtime. You can iterate over the values in an array using a loop to apply the same thing to every entry. int scores []{ 84 , 92 , 76 , 81 , 56 }; int numStudents { std :: size ( scores ) }; // const int numStudents{ sizeof(scores) / sizeof(scores[0]) }; // use this instead if not C++17 capable int totalScore { 0 }; // use a loop to calculate totalScore for ( int student { 0 }; student < numStudents ; ++ student ) totalScore += scores [ student ]; auto averageScore { static_cast < double > ( totalScore ) / numStudents }; Use std::swap to swap two elements of an array. This is useful when sorting arrays. For this lesson the assignment was to write a bubble sort program to sort an array. Arrays can also be arrays of arrays called multidimensional arrays . When thinking of these like a matrix, it's convenient o think of the first (left) subscript as being the row, and the second (right) subscript as being the column. Interpreting multi-dimensional arrays this way is considered row-major order. array [ 3 ][ 5 ]; You can initiliaze these arrays with nested braces: int array [ 3 ][ 5 ]{ { 1 , 2 , 3 , 4 , 5 }, { 6 , 7 , 8 , 9 , 10 }, { 11 , 12 , 13 , 14 , 15 } };","title":"Arrays, Strings, Pointers, and references"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#c-style-strings","text":"You will never use these, but it's interesting to know that std::string are based on C-style strings which are null terminated strings. This means that a null terminator '\\0' is used to indicate the end of the string. These strings are essentially arrays of chars, and are defined that way: char myString []{ \"string\" }; If you conver the string chars to ints, the last will always be zero. Because these strings work exactly like arrays, you can't assigne values of them directly! It's fine if the array is larger than the string it contains, but if you replace the last element in it and print, the print will keep printing until it encounters a zero! You should use std::stirng or std::string_view instead of C-syle strings.","title":"C-style strings"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#string-view","text":"This is an object which, like a pointer, views an existing string object. Prefer this over C-style strings and std::string for read-only strings. It includes function for reducing what parts of the string it referrs to. For this you use std::strnigview.remove_prefix and remove_suffix. It's also not null-terminated. If the string that std::string_view is viewing goes out of scope or becomes unavaliable, then it's uncertain what string_view is pointing to. You can convert it to a std::string by casting it to one.","title":"String View"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#pointers","text":"The address-of operator (&) allows us to see what memeory address is assigned to a variable, and the indirection (*) operator allows us to access that value. int x { 5 }; std :: cout << x << '\\n' ; // print the value of variable x std :: cout << & x << '\\n' ; // print the memory address of variable x std :: cout << * ( & x ) << '\\n' ; /// print the value at the memory address of variable x (parenthesis not required, but make it easier to read) A pointer is a variable that holds a memory address as its value. int * iPtr {}; The asteric is not an indiretion - it's just part of the pointer declaration syntax. When defining variables it's bettr to put the asterisk next to the variable name, but when returning a pointer from a function it's better to put the asterisk of a pointer return value next to the type. int * doSomething (); One of the most commoon things to do with pointers is to have them hold the address of a different variable. int v { 5 }; int * ptr { & v }; \\\\ inititialize ptr with address of variable v The type of the pointer has to match the type of the variable being pointed to. It's worth noting that the address of (&) doesn't return the addres of its operand as a literal, but returns a pointer containing the address of the operand. The other common thing to do with pointers is to get the values that they are pointing at. For this use the indirection (*) operator to evaluate the cnotents of the address it is pointing to. int value { 5 }; int * ptr { & value }; // ptr point to value std :: cout << * ptr ; // print the value that the ptr is pointing to This is why pointers need a type. Without a type, when indirecting throught a pointer, the pointer wouldn't know how to interpret the contents it was poitning to. You can reassign pointers to different values of the same type. If your program tries to access a location in memory that's not part of the program, the operating system might crash. Because of this all operating systems sandbox applications. What are pointers good for? Arrays are implemented using pointers They are the only way you can dynamically allocate memory in C++ They can be used to pass a function as a parameter to another function They can be used to achieve polymorphism when dealing with inheritance. They can be used to have one struct/class point to another struct/class to form a chain. What should you initialize a pointer to if you don't have the memory address yet? The answer is a null value , which is a spacial value that means the pointer is not pointing at anything. Pointers pointing at null values are called null pointers . They are assigned by initializing the pointer to 0 or (C++ 11) a special value called null ptr. float * ptr { nullptr }; Your pointers should always be initializaed even if it is to null value. Some compilers misinterpret the value of zero and try to initialize pointers to that as an integer, which is why nullptr was added. Pointers and arrays are intrinsicalyl related in C++. When you pass an array to a function, it decays (is implicitly converted) to a pointer that points to the first element of the array. Because both pointers and arrays can access elements in them with the subscript, it might be better to understand where the data types differ: sizeof() on arrays returns the entire array (array length * element size). On a pointer it returns the size of a memory address. Using the address-of operator (&) on a pointer yields the memory address of the opinter variables. Of an array it returns a pointer to the entire array. The resulting pointer points to the same address, but the data type is different. Arrays degrade to pointers because they have all of the same funcionality and a much smaller memory footprint. They do not decay if they are part of a class or struct. When scaling a pointer, you are telling it to point to the next object in memory of the pointer's type. This assumes that the next object is the same size as the pointer, and the same type. How is this useful? It's because arrays are laid out sequentially in memory. This is how you grab a specific element in an array. These are equal: array [ 1 ]; * ( array + 1 );","title":"Pointers"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#dynamic-memory-allocation-with-new-and-delete","text":"C++ supports three basic types of memory allocation: Static memory allocation for static and global variables. This is avaliable for the entire runtime of the program. Automatic memory allocation for function parameters and local variables. Memory for these types is allocated when the relevant block is entered, and free when the block is exited. Dynamic memory allocation - which is user controlled. Why not just use static and automatic? Wasted Memory Hard to tell which bits of memory are actually being used. Most variables are allocated to a portion of memory called the stack , which is usually quite small. This is isually around 1MB, otherwise the operating system will close the program. It can lead to artificial limitation and array overflows. What if the user has a name longer than the allocated char[25] array? This is where dynamic memory allocation comes in. It is a way for running programs to request memory from the operating system when needed. It comes from a much larger pool memory managed by the operating system called the heap . On modern machines this is gigabytes in size. To allocate a single variable dynamically we use the scalar (non-array) form of the new operator. int * ptr { new int }; // dynamically allocate an integer (and discard the result) new int returns a pointer that we are storing in our automatically allocated ptr variable. We can then perform indirection through the pointer to access the memory * ptr = 7 ; //assign value of 7 to allocated memory When you dynamically allocate memory, you're asking the operating system to reserve some of thatmemory for your program's use. You can also directly initilize the variable you are directly allocating: int * ptr1 { new int { 6 }} To release the variables you use the delete operator. You should only delete ptrs that are not pointing to dynamically allocated memeory. A pointer that is pointing to deallocated memory is caleld a dangling pointer . After deleting a pointer you should assign it to a nullptr immediately afterward. int * ptr { new int {} }; // dynamically allocate an integer int * otherPtr { ptr }; // otherPtr is now pointed at that same memory location delete ptr ; // return the memory to the operating system. ptr and otherPtr are now dangling pointers. ptr = nullptr ; // ptr is now a nullptr // however, otherPtr is still a dangling pointer! return 0 ; Operator new can fail if the operating system has no more memory to grant the request with. If this happens, the program will simply terminate with an unhandled exception error. There is an alternate form of new that will return a null pointer if memory can't be allocated. int * value = new ( std :: nothrow ) int ; \\\\ the value will be a null pointer if the integer allocation fails . At that point you probably want to test if the pointer is null and throw an exception otherwise to elegantly exit the progam. Because a pointer can go out of scope without freeing the memory it was pointing to, there can be instances where it is impossible to delete the allocated memory. This is called a memory leak . This can also happen if the pointer is assigned to another value, in which case you should have deleted the memory the pointer was pointing towards before re-assigning it. Allocate memory for an array and return a pointer: int * array { new int [ length ]{} }; delete [] array ; array = nullptr ; You cannot have a non-const pointer to a const value. You can have const pointers to non-const values, but not non-const pointers to const values. You can have a const int *ptr to a value and the pointer will think the value is const even if it isn't. int value = 5 ; int * const ptr = & value ; A const pointer is a pointer whose value can not be changed after initialization. The value that this pointer points to cannot be changed. You can also have a const pointer pointing to const int type like this int value = 5 ; const int * const ptr = & value ; A non-const opinter can be redirected to point to other addresses A const pointer always oint to the same address, and this address can not be changed A pointer to a non-const value can change the value it is pointing to. These pointers can not point to a const value. A pointer to a const value treats the value as const (even it is not), and thus cannot change the value it is pointing to.","title":"Dynamic Memory Allocation with new and delete"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#reference-variables","text":"Reference variables can be thought of like instances of a variable, it acts like an alias to another object or value. This is different that pointers that point to the memory address of an object or value, or normal variables, which hold values directly. int value { 5 }; int & ref1 { value }; int & ref2 { value }; The second initiliazation form is preferred for variables, and the first for function return types, just like with the address of and indirection operators. References must be initialized when created and won't compile otherwise. They cannot be re-assigned trying to do so will re-assign the value to the reference. They are most often used as function parameters. This is especially useful when the function is intended to modify the variable, and is what people means when they say \"pass by reference\" . All varialbes are a type of l-value (ell-value), which are values that have an address in memory. These are the only values that are on the left side of an assignment statement. The opposite of l-values are r-valuse - the are expressions that are not l-values. x = x + 1 In the above statement x is both used as an l-value and an r-value. The key takewaway is that the right side you have something that will be evaluated and then put into the variable's address in memory on the left side. You can have const references just like const pointers. Unlike pointers you can have const references to non-const values. This is great if you want to illustrate that this reference variable won't change. A great use of const references is as function parameters: void changeN ( const int & ref ){ ref = 6 ; //not allowed, ref is const. } When passing C-style arrays to a function, if they are passed as reference they do not decay. Their size needs to be defined in the parameter though. References are particularly useful when used as an alias for deeply nested objects. int & ref { other . somthing . value1 }; References are generally much safer than pointers, but have more limited functionality. Pointers should only be used in situations where references are not sufficient (such as dynamically allocating memory). For references the compilier automatically add the indirection, which we'd do manually on a pointer using an asterisk. Pass non-pointer, non-fundamental data type variables (such as structs) by (const) reference, unless you konw that passing it by value is faster. Structs are generally passed around by reference or pointer struct Person { int age {}; double weight {}; }; Person person {}; Person & ref { person }; Person * ptr { & person }; ptr -> age = 5 ; \\\\ remember that -> is the same as ( * ptr ). age = 5 ; Remember that the * does the same as indirection followed by the . member selection. When using a pointer to access teh value of a member, use the operator -> instead of the (.)","title":"Reference Variables"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#for-each-loops","text":"For most loops, it's simpler and safer to use a for-each loop instead of manual for loops. The syntax is as follows: for (element_declaration : array) statement; For each loops are a great place to use the auto keyword. This saves a lot of time when refactoring the contents of a list. Because the list is alerady strongly typed, the auto is not ambiguous. for(auto number : fibonacci){ \\\\ type is auto, so number has its type deducted from the fibonacci arary std::cout << number << ' '; } The above example copies the value into number from fibonacci. In most cases it's more efficient to do this by reference: for ( autch & number : array ){ std :: cout << number << ' ' ; } ``` In for - each loops element declarations , if your elements are non - fundamental types , use references or const references for performance reasons . As of cpp 20 , you can auto assigne a variable with the current index of the for loop : ``` cpp for ( int i { 0 }; auto score : scores ){ std :: cout << score << ' ' ; }","title":"For-each loops"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#void-pointers","text":"Similar to the auto keyword, the void pointer can point at any datatype. This is great, but indirection will not work because the void pointer doesn't know how large the data type is. int value { 5 }; void * voidPtr { & value }; std :: cout << * voidPtr << '\\n' // this will not compile int * intPtr { static_case < int *> ( voidPtr ) }; // you need to cast to int first std :: cout << * intPtr << '\\n' ; The difficulty with void points is that you need to keep track of what their data type is.","title":"Void Pointers"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#xtra-juice","text":"Interesting but rarely used knowlage: you can have pointers to pointers: int ** ptrptr ; \\\\ pointer to a pointer to an int , two asterisks The most common use for this is to dynamically allocate an array of pointers. This is like a standard dynamically allocated array, except the array elemeents are of type \"pointer to integer\" instead of integer. This is espcially useful for multidimensional arrays of pointers. int ** array = new int * [ 10 ]; \\\\ allocate an array of 10 int pointers - these are our rows for ( int count = 0 ; count < 10 ++ count ){ array [ cout ] = new int [ 5 ]; \\\\ these are our columns . } \\\\ deallocating the the array also requires a loop for ( int count = 0 ; count < 10 ; ++ count ) delete [] array [ count ]; delete [] array ; // this needs to be done last We need to deallocate the array elements first, then the array. Otherwise there would be no array left to access the elements that we are deleting. Instead of complex multidimensional arrays consider a flat array where you access the elements by the (row * numberOfColumnsInArray) + col; Generally avoid using pointers to pointers unless no other options are available.","title":"Xtra juice"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#stdarray","text":"This object provides fixed array functionality and does not decay into a pointer when passed to a function. std :: array < int , 5 > myArray { 9 , 6 , 7 , 2 , 4 , 5 , 2 , 1 }; One good thing about std::array is using the myArray.at(1) function to acces elements. This will throw an error if out of range unlike the [] operators. It will also clean up after itself when out of scope. Because it is not a fundamental data type you should alsoway pass std::array by reference or const reference. You can sort std::array using std::sort which lives in the header. std :: sort ( myArray . begin (), myArray . end ()); std::array also come with a .size() function which is really nice when looping over the elements. It's a bit weird through, because .size() return an unsigned integral data type defined inside of std::array so when looping over it you have to do it like this: std :: array myArray { 7 , 3 , 1 , 9 , 5 }; for ( std :: array < int , 5 >:: size_type i { 0 }; i < myArray . size (); ++ i ){ std :: cout << myArray [ i ] << ' ' ; } A better solution is to just avoid manual indexing of std::array and use a range-based for loop This still makes it a challenge to iterate over the array in reverse because size is an unsigned int. For this modify i each iteration and see if that it still above zero to prevent i from ever reaching zero and then looping back up to the maximum value. for ( auto i { myArray . size () }; i -- > 0 ; ){ std :: cout << myArray [ i ] << ' ' ; } When initializing an array of structs or nested array, it can be confusing with the braces. The first element in the initialization is the key argument, and arrays of arrays must be defined within in: Array houses { { { 13 , 4 , 30 }, { 14 , 3 , 10 }, { 15 , 3 , 40 } } } Those extra braces are imporant! std::array is a great replacement for the build build-in fixed array, but with a slightly awkward syntax.","title":"std::array"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#stdvector","text":"The true dynamic list obect! This is what you use to work with dynamic arrays. It's one of the most useful and versatile tools. With std::vector you can create arrays that have their length set at runtime without having to explicitly allocate and deallocate memory using new and delete. It lives in the <vector> headers. Declaring it is simple: std :: vector < int > myArray { 9 , 7 , 8 , 9 , 1 , 2 , 3 }; Note that you do not need to include the array length at compile time. std::vector will dynamically allocate. Because it cleans itself up when going out of scope you do not need to worry about memeory leaks. Vectors also remember their length. Resizing a std::vector is as simple as calling the resize() function. std :: vector array { 0 , 1 , 2 }; array . resize ( 5 ); This is still computationally expensive, so you should still try to minimize the cases where you resize vectors. You should use std::vector in most cases where dynamic arrays are needed.","title":"std::vector"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#iterators","text":"How do range-based for loops work? An iterator is an object designed to traverse through a container while providing access to each element while it's doing so. Pointers are the simplest kind of iterator. Because a pointer knows the size of memory to increment, you can use it to iterate over a block of memory. std :: array data { 0 , 1 , 2 , 3 , 4 , 5 , 6 }; auto begin { & data [ 0 ] }; \\\\ create a pointer that points to the first element auto end { begin + std :: size ( data ) }; \\\\ this points to one spot beyond the last element . The spot where in the for loop the ptr will stop iterating . for ( ato ptr { begin }; ptr != end ++ ptr ){ std :: cout << * ptr << ' ' ; } Because iterating is so common, the array objct has convenience function named begin and end auto begin { array . begin () }; auto end { array . end ()}; If it's not an array you can also use std::begin(array) and std::end(array). Any type that has a begin and end function or can be used with std::begin and std::end are usable directly in range-based-for loops (this is what they look for). for (int i: array) \\\\ array has array.begin() and array.end() Behind the scenes begin() and end() are called. Dynamic arrays won't work though, because there is no end() function. If the elements being iterated over change address or are destroyed iterator can be left dangling: then they are reffered to as invalidated . Accessing invalidated iterators produces undefined behaviour.","title":"Iterators"},{"location":"cpp/LearnCpp.com/009_Arrays_Strings_Pointers_and_References/#standard-library-algorithms","text":"Don't type up your own complex for loops for things you can easily do with std. These are all found in the <algorithms> library . std::find searched for the first occurrence of a value. std::find{arr.begin(), arr.end(), search)} std::find_if bool containsNut(std::string_view str){ // std::string_view::find returns std::string_view::npos if it doesn't find the substring. Otherwise it returns the index where the sustring occurs in str. return (str.find(\"nut\") != std::string_view::npos); } int main(){ auto found{ std::find_if(arr.begin(), arr.end(), containsNut) }; } This return all elements of the array if they contain nut (I did abbreviate this for berevity). The string view object has a function find which returns a bool. That is used on each element in the array until one is found. std::count and std::count_if see how many occurances in an iterator match the comparison. std::sort for custom sorting. This takes in a function very similar to std::find_if. std::sort(arr.begin(), arr.end(), std::greater<int>{}) - greater is also part of std std::for_each with a function applies that to every element of the list: void doubleNumber ( int & i ){ i *= 2 ; } int main (){ std :: for_each ( arr . begin (), arr . end (), doubleNumber ); } The advantage here is that you easile set the beginning and end. std::reduce applies a function to all elements in a list (by default the + operator), which results in a single value. By default (+), this is the sum of all the elements of the list. std::accumulate - this does the same as std::reduce, but from left-toright std::shuffle takes a list and randomly re-orders its elements. Unless otherwise specified, do not assume that the standard ilbrary algorithms will execute in a particular sequence. This means they do not iterate over the for-loop in sequential order, but in parallel. Favor these functions over writing your own. A game I wrote with the concepts of this chapter can be found here","title":"Standard Library algorithms"},{"location":"cpp/LearnCpp.com/010_Functions/","text":"Functions By Value, Reference, Address and Return types This is going to serve as a thourough review of functions. There are three ways of passing variables into functions: by value, by reference and by address. Passing by value makes it impossible to modify the original argument. This is a simple and safe way. Passing by value copies the arguments, which can be problematic for very large data objects. Passing by reference does not copy the objects, which means they can be modified by the function. This can be circumvented by making the function parameters const. This can be also be useful if a function needs to return more than one argument. One convention for these is to suffix them with out, and put them at the end of the function's parameter list. These are often called out parameters . You should always use pass by const reference unless intentionally modifying the out parameters. Passing by address is passing the actual address into the function as a pointer. It's also a good practice to make this input pointer address a const as well if not modifying it. Theoretically these addresses are passed by value. So if you change what the pointer is pointing to in the function then afterwards the pointer will be unchanged. You can also pass addresses by reference though. Be careful about returning values by reference - if they are defiend in the fucntion they will go out of scope and you will be left with a dangling reference! This is only really used to return arguments passed by reference to the function back to the caller. Return by address is useful when returning large objects that have been dynamically allocated in the function (new). You can return multiple elements with out parameters or also by std::tuple<type, type, etc> . #include <tuple> #include <iostream> std :: tuple < int , double > returnTuple (){ return { 5 , 6.7 }; } int main (){ int a ; double b ; std :: tie ( a , b ) = returnTuple (); return 0 ; } Inline Functions One drawback of functions is that every time they are called, there is a very tiny amount of cpu overhead. this is because the CPU must store the adderss of the current instruction it is executing along with registers, copying the values, etc. In-place code is much faster. This isn't bad for really large functions, but for small ones that get called millions of times it can make a difference. C++ offers inline functions to make up for this. This bascially tells the compiler to expand all the functions inline, so that there is no longer a reference to an extra data object! Because of code bloat, inlining function is best suited to short functions. You can force inline a function with the following keyword inline int min ( int x , int y ){ return x > y ? y : x ; } Most modern compiliers automatically inline functions as appropriate. It's interesting though, because inline function can skirt the one-definition rule since they are not actually referenced by the linker. This will get interested when you get member functions in the next chapter. Function overloading Function overloading is a feature of C++ where you can have different amounts of arguments in functions of the same name, or different argument types. in add ( int x , int y ); double add ( doublex , double , y ); The compiler is able to tell which version of add() to call based on the arguments used in the function call. Not that function return types are not considerd for uniqueness. This will not compile: int getRandomInt (); double getRandomDouble (); In trying to match the correct function the inputs C++ will try to find a match through promotion if there is no immediate matching function. Char, unsigned char, and short is promoted to an int. Unsigned shrot can be promoted to into or unsigned int, depending on the size of an int Float is promoted to double Enum is promoted to int void print ( float value ); void print ( Employeed value ); print ( 'a' ); // a is converted to match print(float) Finally C++ tries to match through user-defined conversion. Classes can define conversions to other types that can be implicitly applied to objects of that class. Even with all this, it is still possible for an ambiguous match. These are considered a compile-time error. Just freaking cast your vars dude. Function overloadig can simplify you program, but it can be tricky to handle different return types. Default Arguments A default argument allows you to make function parameters optional. These parameters are then called optional parameters . This is useful for functions that are usually supposed to operate a certain way, but might want to operate a different way sometimes. Note that this does not allow you to change the order the arguments are input to the function. So you can't have printValues(,,3). Because of this if more than one default argument exists, the leftmost default argument should be the one most likely to be explicitly set by the user. You cannot re-declare default arguments if a function has been forward-declared. If it has, put the default argument into the forward declaration. in foo.h void printValues ( int x , int y = 10 ); in main.cpp void printValues ( int x , int y ){ // print the things. } You can use default arguments in combination with function overloading. It's important to note that these arguments do NOT count towards making the function unique. This doesn't compile void printValues(int x ); void printValues(int x, int y=20); This does: void print(std::string string); void print(char ch=' '); The secone one basically counts as \"no arguments\" from the perspective of the compilier. Function Pointers You can have pointers that point to functions!? This is what functions are when you use them with the (). int ( * fcnPtr )(){ & foo }; For a const function pointer you need to put the * before the const, otherwise it would get interpreted that the function would return a const int. int ( * const fcnPtr )(){ & foo }; Note that there's no () after foo. Otherwise we would be assigning the return value of foo to the pointer which could be valid if foo is returning a function. C++ will implicitly convert function to their address, so the & is only there to be extra explicit. Note that default parameters won't work for functions called through function pointers, since the default parameters are supplied at compile-time, and function pointers are resolved at run-time. One of the most common uses for this is to pass function points as arguments to other functions. Sorting algorithms are an example of this. You can re-write the selection sort from a previous lesson like this void selectionSort ( int * array , int size , bool ( * comparisonFcn )( int , int )){ ... if ( comparisonFcn ( array [ bestIdx ], array [ currentIndex ])){ ... } } int main (){ ... selectionSort ( array , 9 , descending ); ... } This prevents you from having to write multiple function for every single sort case! Often you will want to provide a default function: void selectionSort ( int * array , int size , bool ( * comparisonFcn )( int , int ) = ascending ); Consider making your function pointer parameters prettuing using using using ValidateFuntion = bool ( * )( int , int ); // bool validate(int x, int y, bool (*fcnPtr)(int, int)); // ugle bool validate ( int x , int y , ValidationFunction pfcn ) // clean You can also use std::function to store and define function pointers. #include <functional> bool validate ( int x , int y , std :: function < bool ( int , int ) > fcn ); You can also use auto to infer the type from a function. You should generally use std::function for all your function pointer needs because it's much cleaner. Stack and heap The memory that a program uses has several segments (areas): The code segment: readonly segment of the raw text of the code in memory. The bss segment: uninitialized data segment where zero-intialized global and static variables are stored the data segment: initialized data segment where initialized global and static variables are stored the heap - where dynamically allocated variables are allocated to the call stack, where function parameters, local variables and other in-brackets, limited-scope information is stored. The most interesting stuff happens in the heap and stack. We already talked about the heap in ch9 , and how you dynamically allocate memory to it with new and delete. There is no guarantee that this allocated memory is sequential - this is a process that \"just works\". The heap is comparatively slow to allocate manual allocation/cleanup memory must be accessed through pointer. Dereferencing this is slower than accessing memory directly. It's a huge pool, and so can store very large objects. The call stack is what keeps track of all the active functions, and all auto allocation of function parameters and local variables. What is a stack data structure? In order for data to be used efficiently, data structures are created to organize and sort it. Arrays and structs are data structuers, and they provide mechanism for storing data and accessing that data in an effiecient way. A stack is more limited than an array which can access any element at any time ( random access ). In the stack what you can do is Look at the top item on the stack: top() or peek() Take the top item off the stack pop() Put a new item on the top of the stack push() Stack is a last-in, first-out (LIFO) structure. The last item pushed onto the stack is the first one taken off. The call stack segment holds the memory used for the call stack. Whenever a function is encountered, the function is pushed on the call stack, and when it ends it is removed from the call stack. Every item pushed to the call stack is called a stack frame . You can imagine a marker on a giant stack of mailboxes. When you add new mail, you move it up to the last filled mailbox. Then when mail is \"delted\" you move it down, except you don't empty the redundant mailboxes. You just fill them again next time. The call stack The program encoutners a function call Stack frame is constructed and pushed on the stack. This frame consists of: The address of the instruction ( return address ) All the function arguments Memory for local variables copies of registers modified by the function that need to be restored when the function returns The Cpu jumps to the functions's start poitn The instructions inside of the function begin. After the function terminates Registers are restored from the call stack The stack frame is popped off the stack freeing all local variables and arguments. The return value is handles The CPU resumes execution from the return address. This is the basic rundown of the call stack. If a program tries to put too much information on the stack, stack overflow will result. It's generally the result of allocating too many variables on the stack and/or too many nested function calls. Allocating memory on the stack is fast Memory on the stack stays in scope as long as it is on the stack and popped off after All memory on the stack is known at compile time and can be accessed directly through a variable The stack can't handle large amounts of memory. std::vector is a great alternative for large arrays because it interally hanles all the allocation to the heap. Even better is that if you make a vector smaller, it keeps it's larger capacity. It doesn't do intensive resizeing unless necessary. If you know you will be pushing a lot onto the vector like with array.push_back() , it can be a good idea to array.reserve(5) memory given the case that you know you will be pushing 5 variables to the vector. Recursion A recursive function is a function that calls itself. If a recursive function goes on for infinity at some point the program will terminate because the stack is out of memory! You always want some sort of termination condition (like an if statement) to stop recursive function from going on for infinity. This is a pretty neat example int fibonacci ( int count ) { if ( count == 0 ) return 0 ; // base case (termination condition) if ( count == 1 ) return 1 ; // base case (termination condition) return fibonacci ( count -1 ) + fibonacci ( count -2 ); } // And a main program to display the first 13 Fibonacci numbers int main () { for ( int count = 0 ; count < 13 ; ++ count ) std :: cout << fibonacci ( count ) << \" \" ; return 0 ; } This isn't very efficient, because fibonacci is called twice for each step in recursion! It can be optimized with a technique called memoization caches the results of expensive function calls so the result can be returned when the same input occurs again. // h/t to potterman28wxcv for a variant of this code int fibonacci(int count) { // We'll use a static std::vector to cache calculated results static std::vector<int> results{ 0, 1 }; // If we've already seen this count, then use the cache'd result if (count < static_cast<int>(std::size(results))) return results[count]; else { // Otherwise calculate the new result and add it results.push_back(fibonacci(count - 1) + fibonacci(count - 2)); return results[count]; } } // And a main program to display the first 13 Fibonacci numbers int main() { for (int count = 0; count < 13; ++count) std::cout << fibonacci(count) << \" \"; return 0; } This caches all the results of the fibbonachi numbers that have already been calculated. Note that theoretically all recursion examples can also be solved iteratively ( for , and while ). This is also generally more efficient, since it doesn't include the overhead of a function call. Recursion is a good choice when The recursion code is simpler to implement The recursion depth < 100,000 levels at all times The iterative version of the algorithm requires managing a stack of data This isn't a performance-critical section of code. Command line arguments Command line arguments provide a way for other programs to input data into your program. To add command line arguments, you use them as an input to your main as follows: int main ( int argc , char argv {}) ``` * ** argc ** is an integer parameter containing a count of the number of arguments passed to the program . ( ** arg ** uments ** c ** ount ) * ** argv ** is where the values are stored ( ** arg ** ument ** v ** alues ). It ' s an array of C - style strings . Here is an example for getting an integer input ``` cpp // h/t to potterman28wxcv for a variant of this code int fibonacci ( int count ) { // We'll use a static std::vector to cache calculated results static std :: vector < int > results { 0 , 1 }; // If we've already seen this count, then use the cache'd result if ( count < static_cast < int > ( std :: size ( results ))) return results [ count ]; else { // Otherwise calculate the new result and add it results . push_back ( fibonacci ( count - 1 ) + fibonacci ( count - 2 )); return results [ count ]; } } // And a main program to display the first 13 Fibonacci numbers int main () { for ( int count = 0 ; count < 13 ; ++ count ) std :: cout << fibonacci ( count ) << \" \" ; return 0 ; } Ellipsis Don't use ellipsis. (...) captuer optional arguments. It can be thought of as an array that holds extra arguments. It allows functions to take a varialbe number of arguments without having to make an overloaded variation for each one. What makes them dangerous is that type checking is suspended. Lambdas A lambda expression is a function within a function, that is not part of any namespace. [captureClause] (parameters) -> returnType{ statements; } The return type is optional - if left out auto will be assumed. Check out the example from a previous section re-written with lambda constexpr std::array<std::string_view, 4> arr{\"apple\", \"banana\", \"walnut\", \"lemon\" }; const auto found{ std::find_if(arr.begin(), arr.end(), [](std::string_view str){ return (std.find(\"nut\") != std::string_view::npos); }) }; In this case we are using the lambda \"in line?\" without storing it in a variable first. This can quicly become quite difficult to read. Using it this way is called a function literal . When we store lambdas in variables it can be a bit confusing, because don't know their type. This is because a type is generated for each lambda. Because of this we need to use auto: auto isEven { []( int i ){ return (( i % 2 ) == 0 ); } }; return std :: all_of ( array . begin (), array . end (), isEven ); Technically lambdas aren't functions, but functors. These contain an overladed operator() that makes them callable like a function. Instead of using auto, std::function can also be used to capture all cases for lambdas. Note Use auto when initializating variables with lanbdas, and std::fucntion for function parameters. As of C++ 14 we can use auto for parameters in lambda (in C++ 20 we can use it for regular functions too). These sort of lambdas are called generic lambdas , becasuse they can work with a wide variety of types. What used in the context of a lambda, auto is just a shorthand for a template parameters. Auto isn't always the best choice, for example, you might not want to pass in C-style strings a in a function that measures their length. Note that when using auto with lambdas, a function is generated for each type. This means that if you are incrementing a static varialbe in each function, the count will be unique for each input value type. If you do not specify a return type, and have mutliple return statements with differnt types, you will get a compile error. Remember that lambda auto infers the return type if none is specified. In cases like this it's best to specify a return type and let the compiler to implicit conversions. Also try not to write lambdas for function that are already in ! Labdas can only access global identifiers, entities that are known at compile time, and entities with static storage duration. This makes it hard to pass in runtime variables, and that is what the capture clause is for. The captuer clause gives a lambda access to variables avaliable in the surrounding scope that it would normally not have access to. std :: string search {}; std :; cin >> search ; auto found { std :: find_if ( arr . begin (), arr . end (), [ search ]( std :: string_view std ){ return std . find ( search ) != std :: string_view :: npos ); }) }; If search was not in the capture clause, this function would not compile. It's important to know that this capture clause clones the variable in it. By default these are captured as const values, so you can't modify them. If you want to modify the variables you can use the mutable keyword: auto shoot { [ ammo ]() mutable { -- ammo ; \\\\ we can modify ammo no , and this will be across all calls of this function } std :: cout << ammo << \" shot(s) left \\n \" ; \\\\ this will not be modified by lambda because the lambda is copying the function } For cases like this it makes more sense to capture variables by reference. You should prefer this over capture by value auto shoot { [ & ammo ]() { -- ammo ; \\\\ this now modifies ammo inside and out of the lambda } }; If your fingers are too tired to update your lambda captures after updating your lambdas, you can use default capture to capture all varialbes. To captuer all used variables by value use = and by reference use & auto found { std :: find_if ( areas . begin (), areas . end (), [ = ]( int knownArea ){ return ( width * height == knownArea ); }) }; You can also mix and match captures: [ = , & enemies ](){}; You can also define new variables directly in the capture. [ userArea { width * height }]( int knownArea ) { return ( userArea == knownArea ); } Note Only initialize variables in the capture if their value is short and their type is obvious. Otherwise it's best to defined the variables outside of the lambda and captuer it. If you are defining varialbes in-line for the lambda do not pass them by reference! They will be left dangline after the scope of the lambda has finished. Also note than when copyinga lambda, you are copying it in it's current state with all the variables as they are. To avoid this you can wrap it in t a std::reference_wrapper which can be created by using the std::ref() function. This will ensure that all the lambdas are pointing to the same function object void invoke ( const std :: function < void ( void ) > & fn ){ fn (); } int main (){ int i { 0 }; auto count { [ i ]() mutable { std :: cout << ++ 1 << '\\n' ; }}; invoke ( std :: ref ( count )); // 1 invoke ( std :: ref ( count )); // 2 invoke ( std :: ref ( count )); // 3 return 0 ; } Standard library functinos my copy function objects. If you want to provide lambdas with mutable captured variables, pass them by reference usign std::ref Note Try to avoid lambdas with states altogether. They are easier to understand and don't suffer fro mthe above issues, as well as more dangerout issues that arise when you add parallel execution. As a review for this chapter we wrote a binary search algorithm. First we made it iterative, then recursive.","title":"Functions"},{"location":"cpp/LearnCpp.com/010_Functions/#functions","text":"","title":"Functions"},{"location":"cpp/LearnCpp.com/010_Functions/#by-value-reference-address-and-return-types","text":"This is going to serve as a thourough review of functions. There are three ways of passing variables into functions: by value, by reference and by address. Passing by value makes it impossible to modify the original argument. This is a simple and safe way. Passing by value copies the arguments, which can be problematic for very large data objects. Passing by reference does not copy the objects, which means they can be modified by the function. This can be circumvented by making the function parameters const. This can be also be useful if a function needs to return more than one argument. One convention for these is to suffix them with out, and put them at the end of the function's parameter list. These are often called out parameters . You should always use pass by const reference unless intentionally modifying the out parameters. Passing by address is passing the actual address into the function as a pointer. It's also a good practice to make this input pointer address a const as well if not modifying it. Theoretically these addresses are passed by value. So if you change what the pointer is pointing to in the function then afterwards the pointer will be unchanged. You can also pass addresses by reference though. Be careful about returning values by reference - if they are defiend in the fucntion they will go out of scope and you will be left with a dangling reference! This is only really used to return arguments passed by reference to the function back to the caller. Return by address is useful when returning large objects that have been dynamically allocated in the function (new). You can return multiple elements with out parameters or also by std::tuple<type, type, etc> . #include <tuple> #include <iostream> std :: tuple < int , double > returnTuple (){ return { 5 , 6.7 }; } int main (){ int a ; double b ; std :: tie ( a , b ) = returnTuple (); return 0 ; }","title":"By Value, Reference, Address and Return types"},{"location":"cpp/LearnCpp.com/010_Functions/#inline-functions","text":"One drawback of functions is that every time they are called, there is a very tiny amount of cpu overhead. this is because the CPU must store the adderss of the current instruction it is executing along with registers, copying the values, etc. In-place code is much faster. This isn't bad for really large functions, but for small ones that get called millions of times it can make a difference. C++ offers inline functions to make up for this. This bascially tells the compiler to expand all the functions inline, so that there is no longer a reference to an extra data object! Because of code bloat, inlining function is best suited to short functions. You can force inline a function with the following keyword inline int min ( int x , int y ){ return x > y ? y : x ; } Most modern compiliers automatically inline functions as appropriate. It's interesting though, because inline function can skirt the one-definition rule since they are not actually referenced by the linker. This will get interested when you get member functions in the next chapter.","title":"Inline Functions"},{"location":"cpp/LearnCpp.com/010_Functions/#function-overloading","text":"Function overloading is a feature of C++ where you can have different amounts of arguments in functions of the same name, or different argument types. in add ( int x , int y ); double add ( doublex , double , y ); The compiler is able to tell which version of add() to call based on the arguments used in the function call. Not that function return types are not considerd for uniqueness. This will not compile: int getRandomInt (); double getRandomDouble (); In trying to match the correct function the inputs C++ will try to find a match through promotion if there is no immediate matching function. Char, unsigned char, and short is promoted to an int. Unsigned shrot can be promoted to into or unsigned int, depending on the size of an int Float is promoted to double Enum is promoted to int void print ( float value ); void print ( Employeed value ); print ( 'a' ); // a is converted to match print(float) Finally C++ tries to match through user-defined conversion. Classes can define conversions to other types that can be implicitly applied to objects of that class. Even with all this, it is still possible for an ambiguous match. These are considered a compile-time error. Just freaking cast your vars dude. Function overloadig can simplify you program, but it can be tricky to handle different return types.","title":"Function overloading"},{"location":"cpp/LearnCpp.com/010_Functions/#default-arguments","text":"A default argument allows you to make function parameters optional. These parameters are then called optional parameters . This is useful for functions that are usually supposed to operate a certain way, but might want to operate a different way sometimes. Note that this does not allow you to change the order the arguments are input to the function. So you can't have printValues(,,3). Because of this if more than one default argument exists, the leftmost default argument should be the one most likely to be explicitly set by the user. You cannot re-declare default arguments if a function has been forward-declared. If it has, put the default argument into the forward declaration. in foo.h void printValues ( int x , int y = 10 ); in main.cpp void printValues ( int x , int y ){ // print the things. } You can use default arguments in combination with function overloading. It's important to note that these arguments do NOT count towards making the function unique. This doesn't compile void printValues(int x ); void printValues(int x, int y=20); This does: void print(std::string string); void print(char ch=' '); The secone one basically counts as \"no arguments\" from the perspective of the compilier.","title":"Default Arguments"},{"location":"cpp/LearnCpp.com/010_Functions/#function-pointers","text":"You can have pointers that point to functions!? This is what functions are when you use them with the (). int ( * fcnPtr )(){ & foo }; For a const function pointer you need to put the * before the const, otherwise it would get interpreted that the function would return a const int. int ( * const fcnPtr )(){ & foo }; Note that there's no () after foo. Otherwise we would be assigning the return value of foo to the pointer which could be valid if foo is returning a function. C++ will implicitly convert function to their address, so the & is only there to be extra explicit. Note that default parameters won't work for functions called through function pointers, since the default parameters are supplied at compile-time, and function pointers are resolved at run-time. One of the most common uses for this is to pass function points as arguments to other functions. Sorting algorithms are an example of this. You can re-write the selection sort from a previous lesson like this void selectionSort ( int * array , int size , bool ( * comparisonFcn )( int , int )){ ... if ( comparisonFcn ( array [ bestIdx ], array [ currentIndex ])){ ... } } int main (){ ... selectionSort ( array , 9 , descending ); ... } This prevents you from having to write multiple function for every single sort case! Often you will want to provide a default function: void selectionSort ( int * array , int size , bool ( * comparisonFcn )( int , int ) = ascending ); Consider making your function pointer parameters prettuing using using using ValidateFuntion = bool ( * )( int , int ); // bool validate(int x, int y, bool (*fcnPtr)(int, int)); // ugle bool validate ( int x , int y , ValidationFunction pfcn ) // clean You can also use std::function to store and define function pointers. #include <functional> bool validate ( int x , int y , std :: function < bool ( int , int ) > fcn ); You can also use auto to infer the type from a function. You should generally use std::function for all your function pointer needs because it's much cleaner.","title":"Function Pointers"},{"location":"cpp/LearnCpp.com/010_Functions/#stack-and-heap","text":"The memory that a program uses has several segments (areas): The code segment: readonly segment of the raw text of the code in memory. The bss segment: uninitialized data segment where zero-intialized global and static variables are stored the data segment: initialized data segment where initialized global and static variables are stored the heap - where dynamically allocated variables are allocated to the call stack, where function parameters, local variables and other in-brackets, limited-scope information is stored. The most interesting stuff happens in the heap and stack. We already talked about the heap in ch9 , and how you dynamically allocate memory to it with new and delete. There is no guarantee that this allocated memory is sequential - this is a process that \"just works\". The heap is comparatively slow to allocate manual allocation/cleanup memory must be accessed through pointer. Dereferencing this is slower than accessing memory directly. It's a huge pool, and so can store very large objects. The call stack is what keeps track of all the active functions, and all auto allocation of function parameters and local variables.","title":"Stack and heap"},{"location":"cpp/LearnCpp.com/010_Functions/#what-is-a-stack-data-structure","text":"In order for data to be used efficiently, data structures are created to organize and sort it. Arrays and structs are data structuers, and they provide mechanism for storing data and accessing that data in an effiecient way. A stack is more limited than an array which can access any element at any time ( random access ). In the stack what you can do is Look at the top item on the stack: top() or peek() Take the top item off the stack pop() Put a new item on the top of the stack push() Stack is a last-in, first-out (LIFO) structure. The last item pushed onto the stack is the first one taken off. The call stack segment holds the memory used for the call stack. Whenever a function is encountered, the function is pushed on the call stack, and when it ends it is removed from the call stack. Every item pushed to the call stack is called a stack frame . You can imagine a marker on a giant stack of mailboxes. When you add new mail, you move it up to the last filled mailbox. Then when mail is \"delted\" you move it down, except you don't empty the redundant mailboxes. You just fill them again next time. The call stack The program encoutners a function call Stack frame is constructed and pushed on the stack. This frame consists of: The address of the instruction ( return address ) All the function arguments Memory for local variables copies of registers modified by the function that need to be restored when the function returns The Cpu jumps to the functions's start poitn The instructions inside of the function begin. After the function terminates Registers are restored from the call stack The stack frame is popped off the stack freeing all local variables and arguments. The return value is handles The CPU resumes execution from the return address. This is the basic rundown of the call stack. If a program tries to put too much information on the stack, stack overflow will result. It's generally the result of allocating too many variables on the stack and/or too many nested function calls. Allocating memory on the stack is fast Memory on the stack stays in scope as long as it is on the stack and popped off after All memory on the stack is known at compile time and can be accessed directly through a variable The stack can't handle large amounts of memory. std::vector is a great alternative for large arrays because it interally hanles all the allocation to the heap. Even better is that if you make a vector smaller, it keeps it's larger capacity. It doesn't do intensive resizeing unless necessary. If you know you will be pushing a lot onto the vector like with array.push_back() , it can be a good idea to array.reserve(5) memory given the case that you know you will be pushing 5 variables to the vector.","title":"What is a stack data structure?"},{"location":"cpp/LearnCpp.com/010_Functions/#recursion","text":"A recursive function is a function that calls itself. If a recursive function goes on for infinity at some point the program will terminate because the stack is out of memory! You always want some sort of termination condition (like an if statement) to stop recursive function from going on for infinity. This is a pretty neat example int fibonacci ( int count ) { if ( count == 0 ) return 0 ; // base case (termination condition) if ( count == 1 ) return 1 ; // base case (termination condition) return fibonacci ( count -1 ) + fibonacci ( count -2 ); } // And a main program to display the first 13 Fibonacci numbers int main () { for ( int count = 0 ; count < 13 ; ++ count ) std :: cout << fibonacci ( count ) << \" \" ; return 0 ; } This isn't very efficient, because fibonacci is called twice for each step in recursion! It can be optimized with a technique called memoization caches the results of expensive function calls so the result can be returned when the same input occurs again. // h/t to potterman28wxcv for a variant of this code int fibonacci(int count) { // We'll use a static std::vector to cache calculated results static std::vector<int> results{ 0, 1 }; // If we've already seen this count, then use the cache'd result if (count < static_cast<int>(std::size(results))) return results[count]; else { // Otherwise calculate the new result and add it results.push_back(fibonacci(count - 1) + fibonacci(count - 2)); return results[count]; } } // And a main program to display the first 13 Fibonacci numbers int main() { for (int count = 0; count < 13; ++count) std::cout << fibonacci(count) << \" \"; return 0; } This caches all the results of the fibbonachi numbers that have already been calculated. Note that theoretically all recursion examples can also be solved iteratively ( for , and while ). This is also generally more efficient, since it doesn't include the overhead of a function call. Recursion is a good choice when The recursion code is simpler to implement The recursion depth < 100,000 levels at all times The iterative version of the algorithm requires managing a stack of data This isn't a performance-critical section of code.","title":"Recursion"},{"location":"cpp/LearnCpp.com/010_Functions/#command-line-arguments","text":"Command line arguments provide a way for other programs to input data into your program. To add command line arguments, you use them as an input to your main as follows: int main ( int argc , char argv {}) ``` * ** argc ** is an integer parameter containing a count of the number of arguments passed to the program . ( ** arg ** uments ** c ** ount ) * ** argv ** is where the values are stored ( ** arg ** ument ** v ** alues ). It ' s an array of C - style strings . Here is an example for getting an integer input ``` cpp // h/t to potterman28wxcv for a variant of this code int fibonacci ( int count ) { // We'll use a static std::vector to cache calculated results static std :: vector < int > results { 0 , 1 }; // If we've already seen this count, then use the cache'd result if ( count < static_cast < int > ( std :: size ( results ))) return results [ count ]; else { // Otherwise calculate the new result and add it results . push_back ( fibonacci ( count - 1 ) + fibonacci ( count - 2 )); return results [ count ]; } } // And a main program to display the first 13 Fibonacci numbers int main () { for ( int count = 0 ; count < 13 ; ++ count ) std :: cout << fibonacci ( count ) << \" \" ; return 0 ; }","title":"Command line arguments"},{"location":"cpp/LearnCpp.com/010_Functions/#ellipsis","text":"Don't use ellipsis. (...) captuer optional arguments. It can be thought of as an array that holds extra arguments. It allows functions to take a varialbe number of arguments without having to make an overloaded variation for each one. What makes them dangerous is that type checking is suspended.","title":"Ellipsis"},{"location":"cpp/LearnCpp.com/010_Functions/#lambdas","text":"A lambda expression is a function within a function, that is not part of any namespace. [captureClause] (parameters) -> returnType{ statements; } The return type is optional - if left out auto will be assumed. Check out the example from a previous section re-written with lambda constexpr std::array<std::string_view, 4> arr{\"apple\", \"banana\", \"walnut\", \"lemon\" }; const auto found{ std::find_if(arr.begin(), arr.end(), [](std::string_view str){ return (std.find(\"nut\") != std::string_view::npos); }) }; In this case we are using the lambda \"in line?\" without storing it in a variable first. This can quicly become quite difficult to read. Using it this way is called a function literal . When we store lambdas in variables it can be a bit confusing, because don't know their type. This is because a type is generated for each lambda. Because of this we need to use auto: auto isEven { []( int i ){ return (( i % 2 ) == 0 ); } }; return std :: all_of ( array . begin (), array . end (), isEven ); Technically lambdas aren't functions, but functors. These contain an overladed operator() that makes them callable like a function. Instead of using auto, std::function can also be used to capture all cases for lambdas. Note Use auto when initializating variables with lanbdas, and std::fucntion for function parameters. As of C++ 14 we can use auto for parameters in lambda (in C++ 20 we can use it for regular functions too). These sort of lambdas are called generic lambdas , becasuse they can work with a wide variety of types. What used in the context of a lambda, auto is just a shorthand for a template parameters. Auto isn't always the best choice, for example, you might not want to pass in C-style strings a in a function that measures their length. Note that when using auto with lambdas, a function is generated for each type. This means that if you are incrementing a static varialbe in each function, the count will be unique for each input value type. If you do not specify a return type, and have mutliple return statements with differnt types, you will get a compile error. Remember that lambda auto infers the return type if none is specified. In cases like this it's best to specify a return type and let the compiler to implicit conversions. Also try not to write lambdas for function that are already in ! Labdas can only access global identifiers, entities that are known at compile time, and entities with static storage duration. This makes it hard to pass in runtime variables, and that is what the capture clause is for. The captuer clause gives a lambda access to variables avaliable in the surrounding scope that it would normally not have access to. std :: string search {}; std :; cin >> search ; auto found { std :: find_if ( arr . begin (), arr . end (), [ search ]( std :: string_view std ){ return std . find ( search ) != std :: string_view :: npos ); }) }; If search was not in the capture clause, this function would not compile. It's important to know that this capture clause clones the variable in it. By default these are captured as const values, so you can't modify them. If you want to modify the variables you can use the mutable keyword: auto shoot { [ ammo ]() mutable { -- ammo ; \\\\ we can modify ammo no , and this will be across all calls of this function } std :: cout << ammo << \" shot(s) left \\n \" ; \\\\ this will not be modified by lambda because the lambda is copying the function } For cases like this it makes more sense to capture variables by reference. You should prefer this over capture by value auto shoot { [ & ammo ]() { -- ammo ; \\\\ this now modifies ammo inside and out of the lambda } }; If your fingers are too tired to update your lambda captures after updating your lambdas, you can use default capture to capture all varialbes. To captuer all used variables by value use = and by reference use & auto found { std :: find_if ( areas . begin (), areas . end (), [ = ]( int knownArea ){ return ( width * height == knownArea ); }) }; You can also mix and match captures: [ = , & enemies ](){}; You can also define new variables directly in the capture. [ userArea { width * height }]( int knownArea ) { return ( userArea == knownArea ); } Note Only initialize variables in the capture if their value is short and their type is obvious. Otherwise it's best to defined the variables outside of the lambda and captuer it. If you are defining varialbes in-line for the lambda do not pass them by reference! They will be left dangline after the scope of the lambda has finished. Also note than when copyinga lambda, you are copying it in it's current state with all the variables as they are. To avoid this you can wrap it in t a std::reference_wrapper which can be created by using the std::ref() function. This will ensure that all the lambdas are pointing to the same function object void invoke ( const std :: function < void ( void ) > & fn ){ fn (); } int main (){ int i { 0 }; auto count { [ i ]() mutable { std :: cout << ++ 1 << '\\n' ; }}; invoke ( std :: ref ( count )); // 1 invoke ( std :: ref ( count )); // 2 invoke ( std :: ref ( count )); // 3 return 0 ; } Standard library functinos my copy function objects. If you want to provide lambdas with mutable captured variables, pass them by reference usign std::ref Note Try to avoid lambdas with states altogether. They are easier to understand and don't suffer fro mthe above issues, as well as more dangerout issues that arise when you add parallel execution. As a review for this chapter we wrote a binary search algorithm. First we made it iterative, then recursive.","title":"Lambdas"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/","text":"Basic object-oriented programming Traditional programming, programs are basically a list of instructions with the semantics defined by the user: driveTo ( you , work ); Obects are the conceptual definitions we use to sort reality. Object have major components which defined them as different or similar to other objects. Objects also have behaviours that they can exhibit (being opened, making something hot, etc) you . driveTo ( work ) This reads more clearly and makes it clear what the subject of the instructions is (you). Classes Classes are similar to structs in that they hold data, but they can also hold a lot more, like functions. The class keyword defines a new user-defined class. struct DateStruct { int year {}; int month {}; int day {} }; class DateClass { public : int m_year {}; int m_month {}; int m_day {}; }; The only significan difference is the public keyword in the class. Just like struct declarations, class delcarations do not allocate any memory. Class and struct definitions are like blueprints, they describe what the resulting object will look like, but do not actually create the object. The big benefit of classes are that they can hold functions, called member functions or methods . class DateClass { public : int m_year {}; int m_month {}; int m_day {}; void print (){ std :: cout << m_year << '/' << m_month << '/' << m_day ; } }; int main (){ DateClass today { 2020 , 10 , 14 }; today . m_day = 16 ; today . print (); } Note that within the function you do not need to use it's namespace to access the member variables. These are called implicit objects . Note Name your classes starting with a capital letter. You can call your functions out of the order they are defined within the function. The following works class foo { public : void x () { y (); } void y () {}; }; Classes can have member types (including type aliases). You can also nest classes within other classes, though the cases for using this are rare. Structs can also have many of these associated member function in C++, but they do not clean up after themselves. Note Use the struct keyword for data-only structures. Use the class keyword for objects that have both data and functions. all of the elements of the standard library are also classes! Public vs. Private Public members are members of a struct or class that can e accessed from outisde of the struct or class. If they are not explicitely declared as public and you try to access the variables otuside of the class, the program will not compile. The variables not after the public: keyword are considered Private members . The public keyword with the : is called an access specifier - these dtermine who has access to the members that follow the specifier. There are three access specifier keywords: public private protected You can (and will) use multiple access specifiers to set the access levels of each member. The default member variable is private. Note Make member variables private, and member functions public, unless you have a good reason not to. The group of public member variables are commonly referred to as the public inteface . This interface determines how we interact with the class. One interesting nuance of C++ is that every object instance has the same rights to every instance of that project. This means that if a function inside a class of object A can access variable foo, it can also access variable foo of object B. The big difference between structs vs classes here it is: Note A struct default is members to public but a class to private Encapsulation Why have private member variables at all? This can seem strange at first, but having less ways to interact with an object allows it to be simplified in the context of large code. It's abstraction of a concept, so you don't need to remember or know the entire inner workings of objects. This concept is referred to as encapsulation in object oriented programming, or information hiding. This way users can use the object without understanding how it is working. Benefits of encapsulation Easier to use and reduction of program complexity. You can safley forget how a class is working internally, and just use the public interface. This dramatically reduces teh complexity of programs, and reduces mistakes. Protect your data and pervent misuse. This allows you a guarantee over your utility variables, and extends the assumptions that you can make about them. For example a variable m_length should maybe always be the length of a string. If a user sets this variable incorrectly, other parts of the class might not work. This can force users to use the public functions instead of the varialbes themselves, and allows implementation of a validation layer. This is very similar to the at() functions of std::array and std::vector! Encapsulated classes are easier to change. You can keep legacy functions by simply re-directing them to refactored and updated versions. Encapsulated classes are easier to debug. If there are less ways to use a class, it's much easier to find errors in it. Depending on the class, it may or may not be appropriate to set variables directly. Note that if you are setting them directly, it's a commitment to never change that variable name. Because of this, it is common to wrap your variables in access functions , which get/set the functionality of that variable instead. There are two types of access functions: getters and setters . Getters should always return by value or const reference as \"read-only\" access to data. Otherwise the getter would allow the user to change the variable effectively circumventing the setter function. Some general rulse which can help decide wether to implement getter/setter functions: If nobody outside the class needs access to the member, don't provide access functions If access is required for the memeber, think about whether you can expose a behaviour or action instead. Consider providing only a getter. Constructors If all members of a class are public, we can use aggregate initialization to initialize the class with a list or uniform initialization. This stops working as soon as some variables become private. Constructors are a special kind of class member function that are called when an object is instantiated. Typically they are used to initialize class variables. The default costructor is what is called when no arguments are used when creating the class. It is called the same as the class. class Fraction { private : int m_numerator ; int m_denominator ; public : Fraction (){ m_numerator = 1 ; m_denominator = 1 ; } }; Of course constructurs can also take inputs. These now allow the classes to be initialized with direct or list initialization: fraction fiveThirds { 5 , 3 }; Fraction threeQuaters ( 3 , 4 ); Consider how you might keep the number of constructors down through smart defaulting of variables when you implement your constructor. If there is no constructor provided, C++ will generate a default one. You can initialize member variables as you define them when you don't have a constructor or there is no special logic in setting them. If you don't need a construct use = default; class Date{ private: int m_year{ 1900 }; int m_month{ 1 }; int m_day{ 1 }; public: Date() = default; Date(int year, int month, int day){ m_year = year; m_month = month; m_day = day; } } This is better because it's more explicit, and it guarantees that there will be an empty constructor wether there are other constructors or not. If classes are nested, the constructors of the internal classes will be called first. Note Always initialize all member variables in your objects One problem with assigning all member variables in your constructor, is that it won't work with const vars. Because of this and style in general, it's reccomended to use a member initializer list - which is different than a regular initializer list. A member initializer list is almost identical to doing direct initialization or unitform initialization. class Something { private : int m_value1 ; double m_value2 ; char m_value3 ; public : Something ( int value1 , double value2 , char value3 = 'c' ) : m_value { value1 }, m_value2 { value2 }, m_value3 { value3 }{ // no need for assignment here } \\\\ Initialize our member variables } Note Use member initializer lists to initialize your class member values instead of assignment. Depending on how many arguments your member initializer list has you can put the whole thing on one line, two lines () and :{}, or one line for each value with commas at the end of each. Don't initialize member variables in such a way that they are dependent upon other member variables being initialized first. Initialize variables in the member initialization list in the same order that they are declared in your class. This isn't required but makes sense. In general for non-static member varialbes you should intialize them when they are defined, and possibly overwrite them with the constructor. Static members are pretty rare anyway, and if you run into them you're probably going to have some extra logic around that anyway. Note Favor use of non-static member initialization to give default values for your member variables. To avoid duplicate code we might try the following: class Foo { public : Foo (){ // code to do A } Foo ( int value ){ Foo (); // code to do B } } Surprisingly this will not work as you expect. What's happening is that the second constructor is creating a new Foo() object, which is immediately discareded. To combat this problem we use constructor chaining , the process of which is called delegating constructors . The above problem would be fixed like this: class Foo { public : Foo (){ // code to do A } Foo ( int value ) : Foo {}{ // code to do B } } Note If you have multiple constructors that have the same functionality, use delegating constructors to avoid duplicate code. This is how it's generally done: class Employee { private : int m_id {}; std :: string m_name {}; public : Employee ( int id = 0 , const std :: string & name = \"\" ) : m_id { id }, m_name { name }{ init ( name ); } Employee ( const std :: string & name ) : Employee { 0 , name } { } init ( const std :: string & name ){ std :: cout << \"Employee \" << m_name << \" created. \\n \" ; } }; The only caveaut with this is that anybody can re-init your object anytime. So you might consider makint init a private member function. Destructors Similar to how a constructor is called when creating objects, a destructor is called when the object is destroyed. This is espcially usefull when cleaning up any arrays created by the object. The destructor must have the same name as the class preceded by a ~ The destructor can not take arguments The destructor has no return type You can safely call member functions with the destructor, as it runs just before the object is removed. Interior classes are deconstructed first in the opposite order to how the constructors create them. RAII (Resource Acquisition Is Initialization) is a programming technique that has the constructor allocating \"new\" and then the destructor clearning it up. How do classes know to call their own member varialbes? simple . setId ( 2 ) Is converted by the compiler to setId ( & simple , 2 ); and setId likewise void setID ( intid ) { m_id = id ; } // converted to void setID ( Simple * const this , int id ) { this -> m_id = id ; } The this pointer is a hidden const pointer that holds the address of the object the member function was called on. The compiler add this-> to all class members inside of the classes. \"this\" always points to the object being operated on. Often people will explicitly reference \"this\", but I prefer the m_ prefix to member variables for better readability. If your member functions return a this, you can chain them together similar to std::cout, which does that as well by returning the this pointer. That way if you chain them together they will always resolve to themselves: class Calc { private : int m_value {}; public : Calc & add ( int value ) { m_value += value ; return * this ; } Calc & sub ( int value ) { m_value -= value ; return * this ; } Calc & mult ( int value ) { m_value *= value ; return * this ; } int getValue () { return m_value ; } } Calc calc {}; calc . add ( 5 ). sub ( 3 ). mult ( 3 ); std :: cout << calc . getvalue () << '\\n' ; This allows very readable compression into a single expression. Class code and header files As classes get longer and more complicated, it becomes distracting having the implementation code next to the defenitions. Because of this it's common to defined member functions outside of the class itself. class Date { private : int m_year ; int m_month ; int m_day ; public : Date ( int year , int month , int day ); void SetDate ( int year , int month , int day ); int getYear () { return m_year ; } int getMonth () { return m_month ; } int getDay () { return m_day ; } }; // Date constructor Date :: Date ( int year , int month , int day ) { SetDate ( year , month , day ); } // Date member function void Date :: SetDate ( int year , int month , int day ) { m_month = month ; m_day = day ; } This way of seperating the definitions of the member functions from the class makes it much easier to put the class for forward-declaration into a header file. This doesn't violoate the one-definition rule because if the header file has proper header guards, it shoulnd't be possible to include the class definition more than once in the same file. Defining member functions in the head does not violate the one-definition rule, because they are considered implicitly inline. This means it's no problem defining trivial member functions (such as getters/setters) inside the class definition itself. For classes used in only one file that aren't generally reusable, defien them directly in the single .cpp file they're used int. For classes used in multiple files, or intended for general reuse, define them in a .h file that has the same name as the class Trivial member functions (trivial cnostructors or destructors, acces functions, etc...) can be defined inside the class. Non-trivial member functions should be defined in a .cpp file that has the same name as the class. Default parameters for member function should be declared int he class definitions (.h) where they can be seen by whomever #includes the header. The examples in this course usually have the classes defined in the main .cpp file for ease of illustration, but larger code project should have everything structured into headers etc. A \"header only\" library is a library of .h files for your syntax comletion and illustration of the objects, and a pre-compiled binary. this makes it faster to link and recomiple, and it can be shared with many applications. It also makes it less likely that people will steal the code. Const class objects and member functions The guy who wrote doom says we should basically const all our functions and classes. What does this mean exactly? If you instantiate the class using the const keyword, any modification of the member variables of the object is disallowed. We're familiar with this behaviour and have already been using it. This isn't what mr. doom meant tho, he meant consting member functions. This is because consting a class makes so you can't call any of the class' non const member functions! A const member functions is a member function that guarantees it will not modify the object or call any non-const member functions. To make a function a const member function, just append the const keyword to the function prototype after the parameter list, but before the function body: class Something { public : int m_value ; Something () : m_value { 0 } {} void resetValue () { m_value = 0 ; } void setValue ( int value ) { m_value = value ; } int getValue () const { return m_value ;} }; Note Make any member function that does not modify the state of the class object const, so that it can be called by const objects. The const keyword must be used in both the function prototype in the class defintion and on the function definition. You can overload functions for different behaviour for const and non-const versions of the class. Static member variables When you instnatiate a class, each instance gets its own copy of all normal member variables. When you make a member variables static, it is the same reference across all instances of the object. Static members are not associated with class objects, they are create when the program starts and destroyed when the program ends. They can also be accessed directly without creating an instance of the class class something { public : static int s_value ; }; int Something :: s_value { 1 }; int main (){ Something :: s_value = 2 ; std :: cout << Something :: s_value << '\\n' ; return 0 ; }; This can be useful for something like a unique id counter for the duration of the program... When you declare the static member variable in the function, you are informing the complier of its existence, but you still need to define it outside of the class. If the static member is a const integral type, or const enum, you can initialize it inside the class definitions. constexpr can also be initialized directly inside the class def. class Whatever{ public: static const int s_value{ 4 }; static constexpr std::array<int, 3> s_array{ 1, 2, 3 }; }; Static member variables can also be useful when using an internal lookup tables (a list of pre-calculated values) - this will keep that value in memory only once no matter how many isntances of the class. Static member functions In order to access a private static member variable, you need a static member function. Just like the variables, they are not attached to any particular object, but to the class definition itself. You could also instantiate a member of the class and then call a function to access the variable, but that's not very clean. class Something { private : static int s_value ; public : static int getValue () { return s_value ;} }; int Something :: s_value { 1 }; // init the variable int main (){ std :: cout << Something :: getValue () << '\\n' ; // no Something object instance required } Because they are global in scope, static member functions have no *this pointer. This makes sense because static member function do not work on an object. Static member functions can directly access other static member functions or variables, but not non-static members. This is because the non-static members must belong to a class object, and not class object has been instantiated yet. C++ does not support static constructors. If you can, you should directly initialize your static variables. If you need to initialize your static variables with a function (which would run when the program is initialized) you can do it with a lambda function after the class declaration and call it immediately. Friend functions and classes Even though you might seperate code into each of your functions, there are some cases where you might want other closely-knit functions or classes have access to your class' private members. In these situations, there are two options: Have the classes only use the publicly exposed functions. The downside is that this could clutter up the ui of the classes. You should never expose members that you don't think any user should be allowed to use. Use friend classes and friend functions. This lets other classes and functions access a class' private members. class Accumulator { private : int m_value ; public : Accumulator () { m_value = 0 ; } void add ( int value ) { m_value += value ; } // Make the reset() function a friend of this class friend void reset ( Accumulator & accumulator ); }; // now reset can access the private member variable void reset ( Accumulator & accumulatro ){ accumulator . m_value = 0 ; } Of course if the friend function is not part of the class, you won't have a *this pointer and will need to pass a reference to the object. You can also make entire classes friends of each other. If you want to make certain member functions friends of each other, you will have to have them be defined first with forward declaration. This hassle only happens if you are trying to define more than one class in a file, which wouldn't happen that often anyway. Anonymous objects Anonymous objects are objects that are never stored in a variable. Example: int add ( int x , int y ){ int sum { x + y }; return sum ; // sum is a placeholder } int add ( int x , int y ){ return x + x ; // anonymous object is created } All anonymous objects have \"expression scope\" - they are created, evaluated, and destroyed in a single expression. You can manually create anonymous objects by instancing objects and just ommitting the variable name Cents cents { 5 }; Cents { 7 }; //anonymous This is just really useful for ommiting temp variables and making the code more concice. Timing your code C++ comes with chrono, which is a bit of an archic timing functionality. We can wrap it up with a class like this: #include <chrono> class Timer { private : // Type aliases to make accessing nested type easier using clock_t = std :: chrono :: high_resolution_clock ; using second_t = std :: chrono :: duration < double , std :: ratio < 1 > > ; std :: chrono :: time_point < clock_t > m_beg ; public : Timer () : m_beg ( clock_t :: now ()) { } void reset () { m_beg = clock_t :: now (); } double elapsed () const { return std :: chrono :: duration_cast < second_t > ( clock_t :: now () - m_beg ). count (); } }; int main () { Timer t ; // Code to time goes here std :: cout << \"Time elapsed: \" << t . elapsed () << \" seconds \\n \" ; return 0 ; } Note that when benchmarking your code you should be using release builds only. Debug builds can be less performant in different ways than release builds. Always measure things at least 3 times to account for background processes and other things that might be effecting performance. Also note that these results will only be valid for your machines specific architecture.","title":"Basic object-oriented programming"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#basic-object-oriented-programming","text":"Traditional programming, programs are basically a list of instructions with the semantics defined by the user: driveTo ( you , work ); Obects are the conceptual definitions we use to sort reality. Object have major components which defined them as different or similar to other objects. Objects also have behaviours that they can exhibit (being opened, making something hot, etc) you . driveTo ( work ) This reads more clearly and makes it clear what the subject of the instructions is (you).","title":"Basic object-oriented programming"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#classes","text":"Classes are similar to structs in that they hold data, but they can also hold a lot more, like functions. The class keyword defines a new user-defined class. struct DateStruct { int year {}; int month {}; int day {} }; class DateClass { public : int m_year {}; int m_month {}; int m_day {}; }; The only significan difference is the public keyword in the class. Just like struct declarations, class delcarations do not allocate any memory. Class and struct definitions are like blueprints, they describe what the resulting object will look like, but do not actually create the object. The big benefit of classes are that they can hold functions, called member functions or methods . class DateClass { public : int m_year {}; int m_month {}; int m_day {}; void print (){ std :: cout << m_year << '/' << m_month << '/' << m_day ; } }; int main (){ DateClass today { 2020 , 10 , 14 }; today . m_day = 16 ; today . print (); } Note that within the function you do not need to use it's namespace to access the member variables. These are called implicit objects . Note Name your classes starting with a capital letter. You can call your functions out of the order they are defined within the function. The following works class foo { public : void x () { y (); } void y () {}; }; Classes can have member types (including type aliases). You can also nest classes within other classes, though the cases for using this are rare. Structs can also have many of these associated member function in C++, but they do not clean up after themselves. Note Use the struct keyword for data-only structures. Use the class keyword for objects that have both data and functions. all of the elements of the standard library are also classes!","title":"Classes"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#public-vs-private","text":"Public members are members of a struct or class that can e accessed from outisde of the struct or class. If they are not explicitely declared as public and you try to access the variables otuside of the class, the program will not compile. The variables not after the public: keyword are considered Private members . The public keyword with the : is called an access specifier - these dtermine who has access to the members that follow the specifier. There are three access specifier keywords: public private protected You can (and will) use multiple access specifiers to set the access levels of each member. The default member variable is private. Note Make member variables private, and member functions public, unless you have a good reason not to. The group of public member variables are commonly referred to as the public inteface . This interface determines how we interact with the class. One interesting nuance of C++ is that every object instance has the same rights to every instance of that project. This means that if a function inside a class of object A can access variable foo, it can also access variable foo of object B. The big difference between structs vs classes here it is: Note A struct default is members to public but a class to private","title":"Public vs. Private"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#encapsulation","text":"Why have private member variables at all? This can seem strange at first, but having less ways to interact with an object allows it to be simplified in the context of large code. It's abstraction of a concept, so you don't need to remember or know the entire inner workings of objects. This concept is referred to as encapsulation in object oriented programming, or information hiding. This way users can use the object without understanding how it is working.","title":"Encapsulation"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#benefits-of-encapsulation","text":"Easier to use and reduction of program complexity. You can safley forget how a class is working internally, and just use the public interface. This dramatically reduces teh complexity of programs, and reduces mistakes. Protect your data and pervent misuse. This allows you a guarantee over your utility variables, and extends the assumptions that you can make about them. For example a variable m_length should maybe always be the length of a string. If a user sets this variable incorrectly, other parts of the class might not work. This can force users to use the public functions instead of the varialbes themselves, and allows implementation of a validation layer. This is very similar to the at() functions of std::array and std::vector! Encapsulated classes are easier to change. You can keep legacy functions by simply re-directing them to refactored and updated versions. Encapsulated classes are easier to debug. If there are less ways to use a class, it's much easier to find errors in it. Depending on the class, it may or may not be appropriate to set variables directly. Note that if you are setting them directly, it's a commitment to never change that variable name. Because of this, it is common to wrap your variables in access functions , which get/set the functionality of that variable instead. There are two types of access functions: getters and setters . Getters should always return by value or const reference as \"read-only\" access to data. Otherwise the getter would allow the user to change the variable effectively circumventing the setter function. Some general rulse which can help decide wether to implement getter/setter functions: If nobody outside the class needs access to the member, don't provide access functions If access is required for the memeber, think about whether you can expose a behaviour or action instead. Consider providing only a getter.","title":"Benefits of encapsulation"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#constructors","text":"If all members of a class are public, we can use aggregate initialization to initialize the class with a list or uniform initialization. This stops working as soon as some variables become private. Constructors are a special kind of class member function that are called when an object is instantiated. Typically they are used to initialize class variables. The default costructor is what is called when no arguments are used when creating the class. It is called the same as the class. class Fraction { private : int m_numerator ; int m_denominator ; public : Fraction (){ m_numerator = 1 ; m_denominator = 1 ; } }; Of course constructurs can also take inputs. These now allow the classes to be initialized with direct or list initialization: fraction fiveThirds { 5 , 3 }; Fraction threeQuaters ( 3 , 4 ); Consider how you might keep the number of constructors down through smart defaulting of variables when you implement your constructor. If there is no constructor provided, C++ will generate a default one. You can initialize member variables as you define them when you don't have a constructor or there is no special logic in setting them. If you don't need a construct use = default; class Date{ private: int m_year{ 1900 }; int m_month{ 1 }; int m_day{ 1 }; public: Date() = default; Date(int year, int month, int day){ m_year = year; m_month = month; m_day = day; } } This is better because it's more explicit, and it guarantees that there will be an empty constructor wether there are other constructors or not. If classes are nested, the constructors of the internal classes will be called first. Note Always initialize all member variables in your objects One problem with assigning all member variables in your constructor, is that it won't work with const vars. Because of this and style in general, it's reccomended to use a member initializer list - which is different than a regular initializer list. A member initializer list is almost identical to doing direct initialization or unitform initialization. class Something { private : int m_value1 ; double m_value2 ; char m_value3 ; public : Something ( int value1 , double value2 , char value3 = 'c' ) : m_value { value1 }, m_value2 { value2 }, m_value3 { value3 }{ // no need for assignment here } \\\\ Initialize our member variables } Note Use member initializer lists to initialize your class member values instead of assignment. Depending on how many arguments your member initializer list has you can put the whole thing on one line, two lines () and :{}, or one line for each value with commas at the end of each. Don't initialize member variables in such a way that they are dependent upon other member variables being initialized first. Initialize variables in the member initialization list in the same order that they are declared in your class. This isn't required but makes sense. In general for non-static member varialbes you should intialize them when they are defined, and possibly overwrite them with the constructor. Static members are pretty rare anyway, and if you run into them you're probably going to have some extra logic around that anyway. Note Favor use of non-static member initialization to give default values for your member variables. To avoid duplicate code we might try the following: class Foo { public : Foo (){ // code to do A } Foo ( int value ){ Foo (); // code to do B } } Surprisingly this will not work as you expect. What's happening is that the second constructor is creating a new Foo() object, which is immediately discareded. To combat this problem we use constructor chaining , the process of which is called delegating constructors . The above problem would be fixed like this: class Foo { public : Foo (){ // code to do A } Foo ( int value ) : Foo {}{ // code to do B } } Note If you have multiple constructors that have the same functionality, use delegating constructors to avoid duplicate code. This is how it's generally done: class Employee { private : int m_id {}; std :: string m_name {}; public : Employee ( int id = 0 , const std :: string & name = \"\" ) : m_id { id }, m_name { name }{ init ( name ); } Employee ( const std :: string & name ) : Employee { 0 , name } { } init ( const std :: string & name ){ std :: cout << \"Employee \" << m_name << \" created. \\n \" ; } }; The only caveaut with this is that anybody can re-init your object anytime. So you might consider makint init a private member function.","title":"Constructors"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#destructors","text":"Similar to how a constructor is called when creating objects, a destructor is called when the object is destroyed. This is espcially usefull when cleaning up any arrays created by the object. The destructor must have the same name as the class preceded by a ~ The destructor can not take arguments The destructor has no return type You can safely call member functions with the destructor, as it runs just before the object is removed. Interior classes are deconstructed first in the opposite order to how the constructors create them. RAII (Resource Acquisition Is Initialization) is a programming technique that has the constructor allocating \"new\" and then the destructor clearning it up. How do classes know to call their own member varialbes? simple . setId ( 2 ) Is converted by the compiler to setId ( & simple , 2 ); and setId likewise void setID ( intid ) { m_id = id ; } // converted to void setID ( Simple * const this , int id ) { this -> m_id = id ; } The this pointer is a hidden const pointer that holds the address of the object the member function was called on. The compiler add this-> to all class members inside of the classes. \"this\" always points to the object being operated on. Often people will explicitly reference \"this\", but I prefer the m_ prefix to member variables for better readability. If your member functions return a this, you can chain them together similar to std::cout, which does that as well by returning the this pointer. That way if you chain them together they will always resolve to themselves: class Calc { private : int m_value {}; public : Calc & add ( int value ) { m_value += value ; return * this ; } Calc & sub ( int value ) { m_value -= value ; return * this ; } Calc & mult ( int value ) { m_value *= value ; return * this ; } int getValue () { return m_value ; } } Calc calc {}; calc . add ( 5 ). sub ( 3 ). mult ( 3 ); std :: cout << calc . getvalue () << '\\n' ; This allows very readable compression into a single expression.","title":"Destructors"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#class-code-and-header-files","text":"As classes get longer and more complicated, it becomes distracting having the implementation code next to the defenitions. Because of this it's common to defined member functions outside of the class itself. class Date { private : int m_year ; int m_month ; int m_day ; public : Date ( int year , int month , int day ); void SetDate ( int year , int month , int day ); int getYear () { return m_year ; } int getMonth () { return m_month ; } int getDay () { return m_day ; } }; // Date constructor Date :: Date ( int year , int month , int day ) { SetDate ( year , month , day ); } // Date member function void Date :: SetDate ( int year , int month , int day ) { m_month = month ; m_day = day ; } This way of seperating the definitions of the member functions from the class makes it much easier to put the class for forward-declaration into a header file. This doesn't violoate the one-definition rule because if the header file has proper header guards, it shoulnd't be possible to include the class definition more than once in the same file. Defining member functions in the head does not violate the one-definition rule, because they are considered implicitly inline. This means it's no problem defining trivial member functions (such as getters/setters) inside the class definition itself. For classes used in only one file that aren't generally reusable, defien them directly in the single .cpp file they're used int. For classes used in multiple files, or intended for general reuse, define them in a .h file that has the same name as the class Trivial member functions (trivial cnostructors or destructors, acces functions, etc...) can be defined inside the class. Non-trivial member functions should be defined in a .cpp file that has the same name as the class. Default parameters for member function should be declared int he class definitions (.h) where they can be seen by whomever #includes the header. The examples in this course usually have the classes defined in the main .cpp file for ease of illustration, but larger code project should have everything structured into headers etc. A \"header only\" library is a library of .h files for your syntax comletion and illustration of the objects, and a pre-compiled binary. this makes it faster to link and recomiple, and it can be shared with many applications. It also makes it less likely that people will steal the code.","title":"Class code and header files"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#const-class-objects-and-member-functions","text":"The guy who wrote doom says we should basically const all our functions and classes. What does this mean exactly? If you instantiate the class using the const keyword, any modification of the member variables of the object is disallowed. We're familiar with this behaviour and have already been using it. This isn't what mr. doom meant tho, he meant consting member functions. This is because consting a class makes so you can't call any of the class' non const member functions! A const member functions is a member function that guarantees it will not modify the object or call any non-const member functions. To make a function a const member function, just append the const keyword to the function prototype after the parameter list, but before the function body: class Something { public : int m_value ; Something () : m_value { 0 } {} void resetValue () { m_value = 0 ; } void setValue ( int value ) { m_value = value ; } int getValue () const { return m_value ;} }; Note Make any member function that does not modify the state of the class object const, so that it can be called by const objects. The const keyword must be used in both the function prototype in the class defintion and on the function definition. You can overload functions for different behaviour for const and non-const versions of the class.","title":"Const class objects and member functions"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#static-member-variables","text":"When you instnatiate a class, each instance gets its own copy of all normal member variables. When you make a member variables static, it is the same reference across all instances of the object. Static members are not associated with class objects, they are create when the program starts and destroyed when the program ends. They can also be accessed directly without creating an instance of the class class something { public : static int s_value ; }; int Something :: s_value { 1 }; int main (){ Something :: s_value = 2 ; std :: cout << Something :: s_value << '\\n' ; return 0 ; }; This can be useful for something like a unique id counter for the duration of the program... When you declare the static member variable in the function, you are informing the complier of its existence, but you still need to define it outside of the class. If the static member is a const integral type, or const enum, you can initialize it inside the class definitions. constexpr can also be initialized directly inside the class def. class Whatever{ public: static const int s_value{ 4 }; static constexpr std::array<int, 3> s_array{ 1, 2, 3 }; }; Static member variables can also be useful when using an internal lookup tables (a list of pre-calculated values) - this will keep that value in memory only once no matter how many isntances of the class.","title":"Static member variables"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#static-member-functions","text":"In order to access a private static member variable, you need a static member function. Just like the variables, they are not attached to any particular object, but to the class definition itself. You could also instantiate a member of the class and then call a function to access the variable, but that's not very clean. class Something { private : static int s_value ; public : static int getValue () { return s_value ;} }; int Something :: s_value { 1 }; // init the variable int main (){ std :: cout << Something :: getValue () << '\\n' ; // no Something object instance required } Because they are global in scope, static member functions have no *this pointer. This makes sense because static member function do not work on an object. Static member functions can directly access other static member functions or variables, but not non-static members. This is because the non-static members must belong to a class object, and not class object has been instantiated yet. C++ does not support static constructors. If you can, you should directly initialize your static variables. If you need to initialize your static variables with a function (which would run when the program is initialized) you can do it with a lambda function after the class declaration and call it immediately.","title":"Static member functions"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#friend-functions-and-classes","text":"Even though you might seperate code into each of your functions, there are some cases where you might want other closely-knit functions or classes have access to your class' private members. In these situations, there are two options: Have the classes only use the publicly exposed functions. The downside is that this could clutter up the ui of the classes. You should never expose members that you don't think any user should be allowed to use. Use friend classes and friend functions. This lets other classes and functions access a class' private members. class Accumulator { private : int m_value ; public : Accumulator () { m_value = 0 ; } void add ( int value ) { m_value += value ; } // Make the reset() function a friend of this class friend void reset ( Accumulator & accumulator ); }; // now reset can access the private member variable void reset ( Accumulator & accumulatro ){ accumulator . m_value = 0 ; } Of course if the friend function is not part of the class, you won't have a *this pointer and will need to pass a reference to the object. You can also make entire classes friends of each other. If you want to make certain member functions friends of each other, you will have to have them be defined first with forward declaration. This hassle only happens if you are trying to define more than one class in a file, which wouldn't happen that often anyway.","title":"Friend functions and classes"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#anonymous-objects","text":"Anonymous objects are objects that are never stored in a variable. Example: int add ( int x , int y ){ int sum { x + y }; return sum ; // sum is a placeholder } int add ( int x , int y ){ return x + x ; // anonymous object is created } All anonymous objects have \"expression scope\" - they are created, evaluated, and destroyed in a single expression. You can manually create anonymous objects by instancing objects and just ommitting the variable name Cents cents { 5 }; Cents { 7 }; //anonymous This is just really useful for ommiting temp variables and making the code more concice.","title":"Anonymous objects"},{"location":"cpp/LearnCpp.com/011_Basic_object-oriented_programming/#timing-your-code","text":"C++ comes with chrono, which is a bit of an archic timing functionality. We can wrap it up with a class like this: #include <chrono> class Timer { private : // Type aliases to make accessing nested type easier using clock_t = std :: chrono :: high_resolution_clock ; using second_t = std :: chrono :: duration < double , std :: ratio < 1 > > ; std :: chrono :: time_point < clock_t > m_beg ; public : Timer () : m_beg ( clock_t :: now ()) { } void reset () { m_beg = clock_t :: now (); } double elapsed () const { return std :: chrono :: duration_cast < second_t > ( clock_t :: now () - m_beg ). count (); } }; int main () { Timer t ; // Code to time goes here std :: cout << \"Time elapsed: \" << t . elapsed () << \" seconds \\n \" ; return 0 ; } Note that when benchmarking your code you should be using release builds only. Debug builds can be less performant in different ways than release builds. Always measure things at least 3 times to account for background processes and other things that might be effecting performance. Also note that these results will only be valid for your machines specific architecture.","title":"Timing your code"},{"location":"cpp/LearnCpp.com/013_Operator_Overloading/","text":"Operator Overloading In C++, operators are implemented as functions. By using function overloading on the operator functions, you can define your own version of the operators that works with different data types. This is called operator overloading . To visualize how operators are functions consider: x + y ; // the readable format operator + ( x , y ); // what's actually going on. User defined classes have no operators by default, and the compiler will error if you try it. If you want to use operators with your user defined classes, you will need to tell the compiler how the operators should work with two operands of your object type. The following two rules are what the compiler uses when evaluating an expression containing an operator: If all the operands are fundamental data types, the compiler will call a build-int routine if one exists, or produce error. if any of the operands are user data types, the compiler searches for a matching overloaded operator function to call. If it can't find one, if twill try to convert the data types into fundamental data types so it can use a matching built-in operator. If that fails, it will produce a compiler error. Limitations Almost any existing operator in C++ can be overloaded except for conditional(?:), sizeof, scope(::), member selector (.), member pointer selector (.*), typeid, and casting operators. You cannot create new operators or rename existing ones. One of the operators being overloaded must be a user-defined type. It's not possible to change the number of operands an operator supports. All operators keep their default precedence and associativity. Note When overloading operators, it's best to keep the function of the operators as close to the original intent of the operators as possible There are three different ways to overload operators: class Cents { private : int m_cents ; public : Cents ( int cents ) { m_cents = cent ; } int getCents () const { return m_cents ; } } Member function With member function overloading, the object is always on the left hand side of the operand, which becomes the implicit *this object. \\\\ in class Cents Cents operator + ( int value ){ return Cents ( m_cents + value ); } Friend function // in class Cents friend Cents operator + ( const Cents & c1 , const Cents & c2 ); friend Cents operator + ( int value , const Cents & c1 ); Cents operator + ( const Cents & c1 , const Cents & c2 ){ // we can access m_cents because this is a friend function return Cents ( c1 . m_cents + c2 . m_cents ); } // you can overload for each combination of data types you desire Cents operator + ( int value , const Cents & c1 ){ return { c1 . m_cents + value }; } Normal function // in class Cents int getCents () const { return m_cents }; Cents operator + ( const Cents & c1 , const Cents & c2 ){ // without being a friend function we need to use the getter return Cents ( c1 . getCents () + c2 . getCents ()); } So which method is the right method? That depends. Not all operands can be overloaded as a friend/normal function and not all can be member function. Consider the following >> and << operators: these require std::ostream& to be on the left hand side and would not work as member functions because of this. Conversely, the assignment (=), subscript ([]), function call (()), and member selection (->) operators must be overloaded as member functions because the language requires it. If overloading =, [], (), -> operators use member function. If overloading a unary operator, do so as a member function if overloading binary operator that does not modify the left operand, do so as a normal function or friend function if required. If overloading binary operator that modifies its left operand where you can't modify the definition of the left operand do so as normal function or friend function if required. If overloading a binary operator that modifies its left operand (+=), and you can modify the definition of the left operand, do so as a member function. Note Prefer overloading operators as normal functions instead of friends if it's possible to do so without adding additional functions. You can overload the << operator to add automatic prints to your objects. std :: ostream & operator << ( std :: ostream & out , const Point & point ){ out << \"point(\" << point . m_x << \", \" << point . m_y << \", \" << point . m_z << ')' ; // return std::ostream so that we can chain calls to operator return out ; } std :: cout << point << '\\n' ; In a similar way you can overload the >> operator to accept input for your class: std :: istream & operator >> ( std :: istream & in , Point & point ){ in >> point . m_x ; in >> point . m_y ; in >> point . m_z ; return in ; } Some more fun operators to overload: -object (invert the object) MEMBER !object (return true if the object is invalid) MEMBER +object (return the object USELESS) MEMBER object==object (return true objects are equal) NORMAL object!=object (return true if objects are unequal) NORMAL object>object (not only for numerical comparison - useful for list sorting) NORMAL object++ (return the object then increment it) MEMBER ++object (increment and return the object) MEMBER To distinguish between prefix and postfix incrementation cpp uses a dummy variable //prefix returns the object after incrementation Object & Object :: operator ++ () ++ object ; //post fix returns the object before incrementation Object & Object :: operator ++ ( int ) object ++ ; object[0] (return the subobject of index 0) MEMBER This MUST return a reference because otherwise assignment would not work. // given that the second element is 6 and you were to return // a copy of the value instead of a reference the following would // resolve to list [ 2 ] = 3 6 = 3 // compilier error! Of course this won't work on pointers to objects, because those are pointer objects. Those would resolve to the pointer assuming you are calling an array of objects of that type and return the next garbage value. You can also overload [] with non integer inputs. skeleton [ head ] object(var, var, ...) (Allow calling the object as a function) MEMBER Calling an object like this uses the objects as a functor , which is an object that behaves like a function. The advantage over traditional functions is that it can internally store data. static_cast (object) (Determin how the object is cast to a type) MEMBER This is user-defined conversion where you determine how your objects are converted. class Cents { private : int m_cents ; public : operator int () const { return m_cents ;} } Cents cents { 7 }; int c { static_cast < int > ( cents ) }; thig = object (Assignment operator - when a variable gets intput to the object) Note that this operator is very different than the copy constructor which initiliazes variables. The copy constructor is used on new objects when they are created, the assignment operator is used to input a new value into an existing object. When creating/modifying an assignment operator you should add a self-assignment check (especially when allocating/deallocating memory) MyString & MyString :: operator = ( const MyString & str ){ if ( this == & str ) return * this ; if ( m_data ) delete [] m_data ; m_length = str . m_length ; m_data = new char [ str . m_length ]; for ( int i = 0 ; i < str . m_length ; ++ i ) m_data [ i ] = str . m_data [ i ]; return * this ; } The self assignment check can be omitted in objects that aren't allocating memory. You can prevent the use of an operator by making it private or using the delete keyword. Note Don't defined overloaded operators that don't make sense! The Copy constructor If you do not have one, C++ will create a public copy constructor for you. A copy constructor is a special type of constructor used to create a new object as a copy of an existing object. Fraction fiveThirds ( 5 , 3 ); Fraction fCopy ( fiveThirds ); // this words even if there is only an explicit constructor for the above amount of inputs. Be default a copy constructor uses memberwise initialization which means that each member of the copy is initialized directly from the member of the class being copied. Fraction ( const Fraction & fraction ) : m_numerator ( fraction . m_numerator ), m_denominator ( fraction . m_denominator ){ std :: cout << \"copy constructor called \\n \" ; } You can prevent copies of your class by explicitly making the copy constructor private. The copy constructor is not called for anonymous object (temp objects). This is because the compiler optimizes it away in a process called elision . Converting Constructors, explicit, and delete Cpp will try to convert literals by automatically putting them into constructors. class Fraction { Fraction ( int n = 0 , int d = 1 ) : m_n { n }, m_d { d } {} } void printFraction ( const Fraction & f ){ std :: cout << f ; } int main (){ printFraction ( 6 );} This works because it's implicitly converted by the compilier to match the inputs. Constructors eligible for this are called converting constructors . As of Cpp11 this is not just constructors taking a single argument, since that is when uniform initialization was introduced. Sometimes this conversion isn't so desirable. For example when Cpp automatically casts chars to ints for a constructor that would also take a string. One way to avoid this is to use the explicit keyword for the constructor: class MyString { private : std :: string m_string ; public : explicit MyString ( int x ){ m_string . resize ( x ); } MyString ( const char * string ){ m_string = string ; } } printString ( 'x' ) // now this won't compile because x can't be implicitly cast to an int In the above case it's still possible to do an explicit conversion to int using static_cast ('x'). If we really want to completely disallow 'x' from being converted to a MyString (implicitly or explicitly), is to use the delete keyword. class Mystring { private : std :: string m_string public : MyString ( char ) = delete // this can never be converted to an int. this input is strictly fobidden. explicit MyString ( int x ){ m_string . resize ( x ); } MyString ( const char * string ){ m_string . resize ( x ); } } printString ( 'x' ); // compile error. Shallow vs. deep copying By default when copying variables, C++ uses a shallow copy aka memberwise copy. This means it copies each member of the class individually. This works well for simple classes. When dynamically allocating memory this can be a bit dangerous though. The problem is that all pointers are copied, but the data they are pointing towards isn't. MyString hello { \"Hello, world!\" }; { MyString copy { hello }; // use default copy constructor } // copy is a local variable, so it gets destroyed here. The destructor deletes copy's string, which leaves hello with a dangling pointer std :: cout << hello . getString () << '\\n' ; // this will have undefined behavior One answer to this problem is to do a deep copy on any non-null pointers being copied. This allocates memory for the copy and then copies the actual value. This requires that we write our own copy constructors and overloaded assignment operators. void MyString::deepCopy ( const MyString & source ) { // first we need to deallocate any value that this string is holding! delete [] m_data ; // because m_length is not a pointer, we can shallow copy it m_length = source . m_length ; // m_data is a pointer, so we need to deep copy it if it is non-null if ( source . m_data ) { // allocate memory for our copy m_data = new char [ m_length ]; // do the copy for ( int i { 0 }; i < m_length ; ++ i ) m_data [ i ] = source . m_data [ i ]; } else m_data = nullptr ; } // Copy constructor MyString :: MyString ( const MyString & source ) { deepCopy ( source ); } // Assignment operator MyString & MyString :: operator = ( const MyString & source ) { // check for self-assignment if ( this != & source ) { // now do the deep copy deepCopy ( source ); } return * this ; } All of this shouldn't be done for any classes that are already in std!","title":"Operator Overloading"},{"location":"cpp/LearnCpp.com/013_Operator_Overloading/#operator-overloading","text":"In C++, operators are implemented as functions. By using function overloading on the operator functions, you can define your own version of the operators that works with different data types. This is called operator overloading . To visualize how operators are functions consider: x + y ; // the readable format operator + ( x , y ); // what's actually going on. User defined classes have no operators by default, and the compiler will error if you try it. If you want to use operators with your user defined classes, you will need to tell the compiler how the operators should work with two operands of your object type. The following two rules are what the compiler uses when evaluating an expression containing an operator: If all the operands are fundamental data types, the compiler will call a build-int routine if one exists, or produce error. if any of the operands are user data types, the compiler searches for a matching overloaded operator function to call. If it can't find one, if twill try to convert the data types into fundamental data types so it can use a matching built-in operator. If that fails, it will produce a compiler error.","title":"Operator Overloading"},{"location":"cpp/LearnCpp.com/013_Operator_Overloading/#limitations","text":"Almost any existing operator in C++ can be overloaded except for conditional(?:), sizeof, scope(::), member selector (.), member pointer selector (.*), typeid, and casting operators. You cannot create new operators or rename existing ones. One of the operators being overloaded must be a user-defined type. It's not possible to change the number of operands an operator supports. All operators keep their default precedence and associativity. Note When overloading operators, it's best to keep the function of the operators as close to the original intent of the operators as possible There are three different ways to overload operators: class Cents { private : int m_cents ; public : Cents ( int cents ) { m_cents = cent ; } int getCents () const { return m_cents ; } } Member function With member function overloading, the object is always on the left hand side of the operand, which becomes the implicit *this object. \\\\ in class Cents Cents operator + ( int value ){ return Cents ( m_cents + value ); } Friend function // in class Cents friend Cents operator + ( const Cents & c1 , const Cents & c2 ); friend Cents operator + ( int value , const Cents & c1 ); Cents operator + ( const Cents & c1 , const Cents & c2 ){ // we can access m_cents because this is a friend function return Cents ( c1 . m_cents + c2 . m_cents ); } // you can overload for each combination of data types you desire Cents operator + ( int value , const Cents & c1 ){ return { c1 . m_cents + value }; } Normal function // in class Cents int getCents () const { return m_cents }; Cents operator + ( const Cents & c1 , const Cents & c2 ){ // without being a friend function we need to use the getter return Cents ( c1 . getCents () + c2 . getCents ()); } So which method is the right method? That depends. Not all operands can be overloaded as a friend/normal function and not all can be member function. Consider the following >> and << operators: these require std::ostream& to be on the left hand side and would not work as member functions because of this. Conversely, the assignment (=), subscript ([]), function call (()), and member selection (->) operators must be overloaded as member functions because the language requires it. If overloading =, [], (), -> operators use member function. If overloading a unary operator, do so as a member function if overloading binary operator that does not modify the left operand, do so as a normal function or friend function if required. If overloading binary operator that modifies its left operand where you can't modify the definition of the left operand do so as normal function or friend function if required. If overloading a binary operator that modifies its left operand (+=), and you can modify the definition of the left operand, do so as a member function. Note Prefer overloading operators as normal functions instead of friends if it's possible to do so without adding additional functions. You can overload the << operator to add automatic prints to your objects. std :: ostream & operator << ( std :: ostream & out , const Point & point ){ out << \"point(\" << point . m_x << \", \" << point . m_y << \", \" << point . m_z << ')' ; // return std::ostream so that we can chain calls to operator return out ; } std :: cout << point << '\\n' ; In a similar way you can overload the >> operator to accept input for your class: std :: istream & operator >> ( std :: istream & in , Point & point ){ in >> point . m_x ; in >> point . m_y ; in >> point . m_z ; return in ; } Some more fun operators to overload: -object (invert the object) MEMBER !object (return true if the object is invalid) MEMBER +object (return the object USELESS) MEMBER object==object (return true objects are equal) NORMAL object!=object (return true if objects are unequal) NORMAL object>object (not only for numerical comparison - useful for list sorting) NORMAL object++ (return the object then increment it) MEMBER ++object (increment and return the object) MEMBER To distinguish between prefix and postfix incrementation cpp uses a dummy variable //prefix returns the object after incrementation Object & Object :: operator ++ () ++ object ; //post fix returns the object before incrementation Object & Object :: operator ++ ( int ) object ++ ; object[0] (return the subobject of index 0) MEMBER This MUST return a reference because otherwise assignment would not work. // given that the second element is 6 and you were to return // a copy of the value instead of a reference the following would // resolve to list [ 2 ] = 3 6 = 3 // compilier error! Of course this won't work on pointers to objects, because those are pointer objects. Those would resolve to the pointer assuming you are calling an array of objects of that type and return the next garbage value. You can also overload [] with non integer inputs. skeleton [ head ] object(var, var, ...) (Allow calling the object as a function) MEMBER Calling an object like this uses the objects as a functor , which is an object that behaves like a function. The advantage over traditional functions is that it can internally store data. static_cast (object) (Determin how the object is cast to a type) MEMBER This is user-defined conversion where you determine how your objects are converted. class Cents { private : int m_cents ; public : operator int () const { return m_cents ;} } Cents cents { 7 }; int c { static_cast < int > ( cents ) }; thig = object (Assignment operator - when a variable gets intput to the object) Note that this operator is very different than the copy constructor which initiliazes variables. The copy constructor is used on new objects when they are created, the assignment operator is used to input a new value into an existing object. When creating/modifying an assignment operator you should add a self-assignment check (especially when allocating/deallocating memory) MyString & MyString :: operator = ( const MyString & str ){ if ( this == & str ) return * this ; if ( m_data ) delete [] m_data ; m_length = str . m_length ; m_data = new char [ str . m_length ]; for ( int i = 0 ; i < str . m_length ; ++ i ) m_data [ i ] = str . m_data [ i ]; return * this ; } The self assignment check can be omitted in objects that aren't allocating memory. You can prevent the use of an operator by making it private or using the delete keyword. Note Don't defined overloaded operators that don't make sense!","title":"Limitations"},{"location":"cpp/LearnCpp.com/013_Operator_Overloading/#the-copy-constructor","text":"If you do not have one, C++ will create a public copy constructor for you. A copy constructor is a special type of constructor used to create a new object as a copy of an existing object. Fraction fiveThirds ( 5 , 3 ); Fraction fCopy ( fiveThirds ); // this words even if there is only an explicit constructor for the above amount of inputs. Be default a copy constructor uses memberwise initialization which means that each member of the copy is initialized directly from the member of the class being copied. Fraction ( const Fraction & fraction ) : m_numerator ( fraction . m_numerator ), m_denominator ( fraction . m_denominator ){ std :: cout << \"copy constructor called \\n \" ; } You can prevent copies of your class by explicitly making the copy constructor private. The copy constructor is not called for anonymous object (temp objects). This is because the compiler optimizes it away in a process called elision .","title":"The Copy constructor"},{"location":"cpp/LearnCpp.com/013_Operator_Overloading/#converting-constructors-explicit-and-delete","text":"Cpp will try to convert literals by automatically putting them into constructors. class Fraction { Fraction ( int n = 0 , int d = 1 ) : m_n { n }, m_d { d } {} } void printFraction ( const Fraction & f ){ std :: cout << f ; } int main (){ printFraction ( 6 );} This works because it's implicitly converted by the compilier to match the inputs. Constructors eligible for this are called converting constructors . As of Cpp11 this is not just constructors taking a single argument, since that is when uniform initialization was introduced. Sometimes this conversion isn't so desirable. For example when Cpp automatically casts chars to ints for a constructor that would also take a string. One way to avoid this is to use the explicit keyword for the constructor: class MyString { private : std :: string m_string ; public : explicit MyString ( int x ){ m_string . resize ( x ); } MyString ( const char * string ){ m_string = string ; } } printString ( 'x' ) // now this won't compile because x can't be implicitly cast to an int In the above case it's still possible to do an explicit conversion to int using static_cast ('x'). If we really want to completely disallow 'x' from being converted to a MyString (implicitly or explicitly), is to use the delete keyword. class Mystring { private : std :: string m_string public : MyString ( char ) = delete // this can never be converted to an int. this input is strictly fobidden. explicit MyString ( int x ){ m_string . resize ( x ); } MyString ( const char * string ){ m_string . resize ( x ); } } printString ( 'x' ); // compile error.","title":"Converting Constructors, explicit, and delete"},{"location":"cpp/LearnCpp.com/013_Operator_Overloading/#shallow-vs-deep-copying","text":"By default when copying variables, C++ uses a shallow copy aka memberwise copy. This means it copies each member of the class individually. This works well for simple classes. When dynamically allocating memory this can be a bit dangerous though. The problem is that all pointers are copied, but the data they are pointing towards isn't. MyString hello { \"Hello, world!\" }; { MyString copy { hello }; // use default copy constructor } // copy is a local variable, so it gets destroyed here. The destructor deletes copy's string, which leaves hello with a dangling pointer std :: cout << hello . getString () << '\\n' ; // this will have undefined behavior One answer to this problem is to do a deep copy on any non-null pointers being copied. This allocates memory for the copy and then copies the actual value. This requires that we write our own copy constructors and overloaded assignment operators. void MyString::deepCopy ( const MyString & source ) { // first we need to deallocate any value that this string is holding! delete [] m_data ; // because m_length is not a pointer, we can shallow copy it m_length = source . m_length ; // m_data is a pointer, so we need to deep copy it if it is non-null if ( source . m_data ) { // allocate memory for our copy m_data = new char [ m_length ]; // do the copy for ( int i { 0 }; i < m_length ; ++ i ) m_data [ i ] = source . m_data [ i ]; } else m_data = nullptr ; } // Copy constructor MyString :: MyString ( const MyString & source ) { deepCopy ( source ); } // Assignment operator MyString & MyString :: operator = ( const MyString & source ) { // check for self-assignment if ( this != & source ) { // now do the deep copy deepCopy ( source ); } return * this ; } All of this shouldn't be done for any classes that are already in std!","title":"Shallow vs. deep copying"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/","text":"An Introduction to object relationships Objects, as concepts, are connected. A square \"is a\" shape, a flower \"depends-on\" bees for pollination, a student is a \"member-of\" a class. This chapter explores the nuances of the relation types of objects in C++. The idea of building complex objects from simpler ones is called object composition . Because objects in C++ are built from many smaller objects they are often referred to as composite types . Property Composition Aggregation Association Dependency Relationship Type Whole/part Whole/part Otherwise unrelated Otherwise unrelated Members can belong to multiple classes No Yes Yes Yes Members existence managed by class Yes No No No Directionality Unidirectional Unidirectional Unidirectional or bidirectional Unidirectional Relationship verb Part-of Has-a Uses-a Depends-on Composition Typically uses normal member variables Can use pointer members if the class handles object allocation/deallocation itself Responsible for creation/destruction of parts This tutorial redefines some terms to aid in explaining them. It will use the term object composition when referring to both composition and aggregation, and composition when referring to the composition subtype. To qualify as a composition and object must have the following relationship The member is part of the object The member can only belong to one object at a time The member has its existence managed by the object The member does not know about the existence of the object Composition is when the object creates the member and then dies with the member. The user of the object doesn't need to concern themselves with the creation of the member. In addition to this, the member is not aware of the object it is a part of. We are calling this a unidirectional relationship, because the object knows about the member but the member doesn't know about the object. The composition should manage its parts without the user of the composition needing to manage anything. When should one sub-class elements of a composition class? Generally it should be done in a way that keeps everything as simple as possible. Each class should be build to accomplish a single task. That task should be either the storage and manipulation of data, OR the coordination of subclasses: not both. Aggregation Typically use pointer or reference members that point to or reference objects that live outside the score of the aggregate class Not responsible for creating/destroying parts To qualify as an aggregation a whole object and its part must have the following relationship The member is part of the object The member can belong to more than one object at a time The member does not have its existence managed by the object The member does not know about the existence of the object. The difference with composition is that the parts can belong to more than one object at once. In aggregation the members are still variables, but they are usually pointers or references to objects that are managed externally. You should always pick the simplest relationship that meets the needs of your program, not what seems right in real life. std::reference_wrapper If you would like to have lists of references, use this object. std::vector cannot handle references because they have to be initialized and cannot be reassigned. It lives in std :: string tom { \"Tom\" }; std :: string berta { \"Berta\" }; std :: vector < std :: reference_wrapper < std :: string >> names { tom , berta }; std :: string jim { \"Jim\" }; names . push_back ( jim ); for ( auto name : names ) { // Use the get() member function to get the referenced string. name . get () += \" Beam\" ; } std :: cout << jim << '\\n' ; // Jim Beam Association To qualify as an association an object and another object must have the following relationship The associated member is otherwise unrelated to the object The associated member can belong to more than one object at a time The associated member does not have its existence managed by the object The associated member may or may not know about the existence of the object Unlike a composition or aggregation, an associated member can be aware of the object that's interacting with it. This can be compared to \"uses a\", a patient \"uses\" the services of a doctor, but is not tied to them. Most often association are implemented using pointers. When objects have relationships with other objects of the same type, this can be called a reflexive association . Dependency A dependency is a very loose associate where one object requires another object's functionality in order to accomplish a specific task. Whenever you you are introducing a dependency to your code to that library or header. Associations are a relationship between two classes at the class level, whereas dependencies can be on any level. Container classes A container class is designed to hold and organize multiple instances of another type. The most common is the std::vector. One way to sort container classes is by aggregation and composition. Value containers are compositions that store copies of the objects they are holding. Reference containers are aggregations that store pointers or references to other objects. Typically you cannot mix the types of objects in a container class. A great example can be found here std::initializer_list This is what the compiler gets when you do this: int array [] { 1 , 2 , 3 , 4 , 5 , 6 , 6 }; By default this won't work with your constructors though. You need to make a constructor that take in an initializer list: IntArray ( int length ) : m_length { length }, m_data { new int [ length ]{} } { } IntArray ( std :: initializer_list < int > list ) : // allow IntArray to be initialized via list initialization IntArray ( static_cast < int > ( list . size ())) // use delegating constructor to set up initial arrayi { int count { 0 }; for ( auto element : list ){ m_data [ count ] = element ; ++ count ; } } If you provide list construction, it's a good idea to provide list assignment as well.","title":"An Introduction to object relationships"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#an-introduction-to-object-relationships","text":"Objects, as concepts, are connected. A square \"is a\" shape, a flower \"depends-on\" bees for pollination, a student is a \"member-of\" a class. This chapter explores the nuances of the relation types of objects in C++. The idea of building complex objects from simpler ones is called object composition . Because objects in C++ are built from many smaller objects they are often referred to as composite types . Property Composition Aggregation Association Dependency Relationship Type Whole/part Whole/part Otherwise unrelated Otherwise unrelated Members can belong to multiple classes No Yes Yes Yes Members existence managed by class Yes No No No Directionality Unidirectional Unidirectional Unidirectional or bidirectional Unidirectional Relationship verb Part-of Has-a Uses-a Depends-on","title":"An Introduction to object relationships"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#composition","text":"Typically uses normal member variables Can use pointer members if the class handles object allocation/deallocation itself Responsible for creation/destruction of parts This tutorial redefines some terms to aid in explaining them. It will use the term object composition when referring to both composition and aggregation, and composition when referring to the composition subtype. To qualify as a composition and object must have the following relationship The member is part of the object The member can only belong to one object at a time The member has its existence managed by the object The member does not know about the existence of the object Composition is when the object creates the member and then dies with the member. The user of the object doesn't need to concern themselves with the creation of the member. In addition to this, the member is not aware of the object it is a part of. We are calling this a unidirectional relationship, because the object knows about the member but the member doesn't know about the object. The composition should manage its parts without the user of the composition needing to manage anything. When should one sub-class elements of a composition class? Generally it should be done in a way that keeps everything as simple as possible. Each class should be build to accomplish a single task. That task should be either the storage and manipulation of data, OR the coordination of subclasses: not both.","title":"Composition"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#aggregation","text":"Typically use pointer or reference members that point to or reference objects that live outside the score of the aggregate class Not responsible for creating/destroying parts To qualify as an aggregation a whole object and its part must have the following relationship The member is part of the object The member can belong to more than one object at a time The member does not have its existence managed by the object The member does not know about the existence of the object. The difference with composition is that the parts can belong to more than one object at once. In aggregation the members are still variables, but they are usually pointers or references to objects that are managed externally. You should always pick the simplest relationship that meets the needs of your program, not what seems right in real life.","title":"Aggregation"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#stdreference_wrapper","text":"If you would like to have lists of references, use this object. std::vector cannot handle references because they have to be initialized and cannot be reassigned. It lives in std :: string tom { \"Tom\" }; std :: string berta { \"Berta\" }; std :: vector < std :: reference_wrapper < std :: string >> names { tom , berta }; std :: string jim { \"Jim\" }; names . push_back ( jim ); for ( auto name : names ) { // Use the get() member function to get the referenced string. name . get () += \" Beam\" ; } std :: cout << jim << '\\n' ; // Jim Beam","title":"std::reference_wrapper"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#association","text":"To qualify as an association an object and another object must have the following relationship The associated member is otherwise unrelated to the object The associated member can belong to more than one object at a time The associated member does not have its existence managed by the object The associated member may or may not know about the existence of the object Unlike a composition or aggregation, an associated member can be aware of the object that's interacting with it. This can be compared to \"uses a\", a patient \"uses\" the services of a doctor, but is not tied to them. Most often association are implemented using pointers. When objects have relationships with other objects of the same type, this can be called a reflexive association .","title":"Association"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#dependency","text":"A dependency is a very loose associate where one object requires another object's functionality in order to accomplish a specific task. Whenever you you are introducing a dependency to your code to that library or header. Associations are a relationship between two classes at the class level, whereas dependencies can be on any level.","title":"Dependency"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#container-classes","text":"A container class is designed to hold and organize multiple instances of another type. The most common is the std::vector. One way to sort container classes is by aggregation and composition. Value containers are compositions that store copies of the objects they are holding. Reference containers are aggregations that store pointers or references to other objects. Typically you cannot mix the types of objects in a container class. A great example can be found here","title":"Container classes"},{"location":"cpp/LearnCpp.com/016_An_Introduction_to_object_relationships/#stdinitializer_list","text":"This is what the compiler gets when you do this: int array [] { 1 , 2 , 3 , 4 , 5 , 6 , 6 }; By default this won't work with your constructors though. You need to make a constructor that take in an initializer list: IntArray ( int length ) : m_length { length }, m_data { new int [ length ]{} } { } IntArray ( std :: initializer_list < int > list ) : // allow IntArray to be initialized via list initialization IntArray ( static_cast < int > ( list . size ())) // use delegating constructor to set up initial arrayi { int count { 0 }; for ( auto element : list ){ m_data [ count ] = element ; ++ count ; } } If you provide list construction, it's a good idea to provide list assignment as well.","title":"std::initializer_list"},{"location":"cpp/LearnCpp.com/017_Introduction_to_inheritance/","text":"Introduction to inheritance Inheritance is when one object is derived from another and changed some things yea. The class being inherited from is called the parent/base/superclass and the class doing the inheriting is called the child/derived/subclass . Inheritance represents an \"is\" relationship as opposed to \"has-a\" relationship. To inherit a baseball player from a person you do it like this class BaseballPlayer : public Person { public : doubld m_battingAverage {}; int m_homeRuns {}; BaseballPlayer ( double battingAverage = 0.0 , int homeRuns = 0 ) : m_battingAverage { battingAverage }, m_homeRuns { homeRuns }{} } You can chain inheritance as deeply as you like. New derived classes can be considered two part: One part base, and one part derived. Behind the scenes the most-base class at the top is constructed first. Then each child class is constructed in order, until the bottom. With non-derived classes, constructors only have to worry about their own members. Memory for base is set aside The appropriate Base constructor is called The initialization list initializes variables The body of the constructor executes Control is returned to the caller. For a derived class there's one extra step Memory for base is set aside The appropriate Base constructor is called The base object is constructed first using the appropriate base constructor, if none is specified the default constructor will be used . The initialization list initializes variables The body of the constructor executes Control is returned to the caller. C++ prevents classes from initializing inherited member variables. The values can only be set by the initializer of each respective class. This ensures that all variables are initialized only once. To initialize the Base class you do it like a member variable: class Derived : public Base { public : double m_cost ; Derived ( double cost = 0.0 , int id = 0 ){ // base requires id : Base { id }, m_cost { cost } {} } } It treats Base like a member variable of Derived. Memory for derived is allocated. The Derived(double, int) constructor is called, where cost = 1.3, and id = 5 The compiler looks to see if we\u2019ve asked for a particular Base class constructor. We have! So it calls Base(int) with id = 5. The base class constructor initialization list sets m_id to 5 The base class constructor body executes, which does nothing The base class constructor returns The derived class constructor initialization list sets m_cost to 1.3 The derived class constructor body executes, which does nothing The derived class constructor returns Constructors can only call constructors from their immediate parent/base class. Destructors are called in the reverse order like one would expect. Inheritance and access specifiers When you create a subclass, this class will have no access to private member variables. This is where the protected access specifiers comes in: it allows the subclass to access the members, but nothing outside it. Because refactoring would be a huge issue without getters and setters, this is best suited for small teams with a limited scope of derived classes. It saves some effort on interface design. Just like member variables, there are three different access specifiers for inheriting from classes. class Pub : public Base {}; class Pro : protected Base {}; class Pri : private Base {}; class Def : Base {}; // defaults to private inheritance Public inheritance is the most commonly used. It keeps all the variables from the parent class in the same state as in the parent class. Protected makes them all protected, and private makes them all private. You should use public inheritance unless you have a specific reason to do otherwise. You can redefine behaviour in subclasses. Note that the derived functions still have the same access as the subclass. You can extend the behaviour of a function by calling the base class function inside the derived function. class Derived : public Base { public : Derived ( int vluae ) : Base ( value ){} int getValue () { return m_value } // m_value is protected void identify (){ Base :: identify (); std :: cout << \"I am a Derived \\n \" ; } } You can always static_cast your subclasses to their parent classes. This is especially useful for friend functions where you want to call the baseclass. You can hide members of the base class by changing their access specifier. class Base { private : int m_value ; public : Base ( int value ) : m_value ( value ) {} protected : void printValue () { std :: cout << m_value ; } }; class Derived : public Base { public : Derived ( int value ) : Base ( value ) {} using Base :: printValue // printValue is now public in the subclass } Of course you cannot change private members to be public as well. Multiple inheritance What if you want to have many parents?? Multiple inheritance enables a derived class to inherit members from multiple parent classes. Multiple inheritance is maintenance nightmare. There is ambiguity for when both parent classes have a similarly named member. Because of this you need to specify which parent class's member to call during the function call . There is also the diamond of doom problem: what if a subclass inherits from two parent classes that both inherit from the same parent. Most of the issues can be addressed through scoping, but the overall complexity still skyrockets. Note Avoid multiple inheritance unless alternative lead to more complexity","title":"Introduction to inheritance"},{"location":"cpp/LearnCpp.com/017_Introduction_to_inheritance/#introduction-to-inheritance","text":"Inheritance is when one object is derived from another and changed some things yea. The class being inherited from is called the parent/base/superclass and the class doing the inheriting is called the child/derived/subclass . Inheritance represents an \"is\" relationship as opposed to \"has-a\" relationship. To inherit a baseball player from a person you do it like this class BaseballPlayer : public Person { public : doubld m_battingAverage {}; int m_homeRuns {}; BaseballPlayer ( double battingAverage = 0.0 , int homeRuns = 0 ) : m_battingAverage { battingAverage }, m_homeRuns { homeRuns }{} } You can chain inheritance as deeply as you like. New derived classes can be considered two part: One part base, and one part derived. Behind the scenes the most-base class at the top is constructed first. Then each child class is constructed in order, until the bottom. With non-derived classes, constructors only have to worry about their own members. Memory for base is set aside The appropriate Base constructor is called The initialization list initializes variables The body of the constructor executes Control is returned to the caller. For a derived class there's one extra step Memory for base is set aside The appropriate Base constructor is called The base object is constructed first using the appropriate base constructor, if none is specified the default constructor will be used . The initialization list initializes variables The body of the constructor executes Control is returned to the caller. C++ prevents classes from initializing inherited member variables. The values can only be set by the initializer of each respective class. This ensures that all variables are initialized only once. To initialize the Base class you do it like a member variable: class Derived : public Base { public : double m_cost ; Derived ( double cost = 0.0 , int id = 0 ){ // base requires id : Base { id }, m_cost { cost } {} } } It treats Base like a member variable of Derived. Memory for derived is allocated. The Derived(double, int) constructor is called, where cost = 1.3, and id = 5 The compiler looks to see if we\u2019ve asked for a particular Base class constructor. We have! So it calls Base(int) with id = 5. The base class constructor initialization list sets m_id to 5 The base class constructor body executes, which does nothing The base class constructor returns The derived class constructor initialization list sets m_cost to 1.3 The derived class constructor body executes, which does nothing The derived class constructor returns Constructors can only call constructors from their immediate parent/base class. Destructors are called in the reverse order like one would expect.","title":"Introduction to inheritance"},{"location":"cpp/LearnCpp.com/017_Introduction_to_inheritance/#inheritance-and-access-specifiers","text":"When you create a subclass, this class will have no access to private member variables. This is where the protected access specifiers comes in: it allows the subclass to access the members, but nothing outside it. Because refactoring would be a huge issue without getters and setters, this is best suited for small teams with a limited scope of derived classes. It saves some effort on interface design. Just like member variables, there are three different access specifiers for inheriting from classes. class Pub : public Base {}; class Pro : protected Base {}; class Pri : private Base {}; class Def : Base {}; // defaults to private inheritance Public inheritance is the most commonly used. It keeps all the variables from the parent class in the same state as in the parent class. Protected makes them all protected, and private makes them all private. You should use public inheritance unless you have a specific reason to do otherwise. You can redefine behaviour in subclasses. Note that the derived functions still have the same access as the subclass. You can extend the behaviour of a function by calling the base class function inside the derived function. class Derived : public Base { public : Derived ( int vluae ) : Base ( value ){} int getValue () { return m_value } // m_value is protected void identify (){ Base :: identify (); std :: cout << \"I am a Derived \\n \" ; } } You can always static_cast your subclasses to their parent classes. This is especially useful for friend functions where you want to call the baseclass. You can hide members of the base class by changing their access specifier. class Base { private : int m_value ; public : Base ( int value ) : m_value ( value ) {} protected : void printValue () { std :: cout << m_value ; } }; class Derived : public Base { public : Derived ( int value ) : Base ( value ) {} using Base :: printValue // printValue is now public in the subclass } Of course you cannot change private members to be public as well.","title":"Inheritance and access specifiers"},{"location":"cpp/LearnCpp.com/017_Introduction_to_inheritance/#multiple-inheritance","text":"What if you want to have many parents?? Multiple inheritance enables a derived class to inherit members from multiple parent classes. Multiple inheritance is maintenance nightmare. There is ambiguity for when both parent classes have a similarly named member. Because of this you need to specify which parent class's member to call during the function call . There is also the diamond of doom problem: what if a subclass inherits from two parent classes that both inherit from the same parent. Most of the issues can be addressed through scoping, but the overall complexity still skyrockets. Note Avoid multiple inheritance unless alternative lead to more complexity","title":"Multiple inheritance"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/","text":"Virtual Functions We can creat pointers to child classes, and they produce the expected result #include <iostream> int main () { Derived derived { 5 }; std :: cout << \"derived is a \" << derived . getName () << \" and has value \" << derived . getValue () << '\\n' ; Derived & rDerived { derived }; std :: cout << \"rDerived is a \" << rDerived . getName () << \" and has value \" << rDerived . getValue () << '\\n' ; Derived * pDerived { & derived }; std :: cout << \"pDerived is a \" << pDerived -> getName () << \" and has value \" << pDerived -> getValue () << '\\n' ; return 0 ; } Derived is a class inheriting from base. What's interesting, is that we can also create pointers to the base class Derived derived { 5 }; // These are both legal! Base & rBase { derived }; Base * pBase { & derived }; std :: cout << \"derived is a \" << derived . getName () << \" and has value \" << derived . getValue () << '\\n' ; std :: cout << \"rBase is a \" << rBase . getName () << \" and has value \" << rBase . getValue () << '\\n' ; std :: cout << \"pBase is a \" << pBase -> getName () << \" and has value \" << pBase -> getValue () << '\\n' ; These base pointers cannot see any of the functions or members of the Derived class. This is extremely useful for classes where a lot of subclasses can be input to the same functions. If you have a base class Animal with Cat and Dog inheriting from it, you would have to write an overloaded print function that takes each of the animal classes. void print ( const Cat & cat ){ std :: cout << cat . getName () << \" says \" << cat . speak () << '\\n' ; } voic print ( const Dog & dog ) etc .. This would get really annoying with multiple animal types. Instead, we can do something like this: void print ( const Animal & animal ){} The problem now, of course, is that we don't know what the specific animals' sound is. Virtual functions can solve this. A virtual function is a special type of function that, when called resolves to the most-derived version of the function that exists between the base and derived class. This is called polymorphism because it's an adaptive function to the current definition of the class. It respects the override functions of the child classes, and calls those instead if they exist. You create them with the virtual keyword. class Base { public : virutal std :: string_view getName () const { return \"Base\" ; } // the virtual keyword tells the class to always use the most override }; class Derived : public Base { public : virutal std :: string_view getName () const { return \"Derived\" ; } } int main (){ Derived derived ; Base & rBase { derived }; std :: cout << \"rBase is a \" << rBase . getName () << '\\n' ; return 0 ; } This prints rBase is a Derived - even though we cast derived to a reference of it's base class. This is based on the object that is referencing. If you have further derived classes, it won't call them just because they exist. It calls the most overridden one of this particular instance of the base class. Note While the virtual keyword on the derived class is not required for it to work, it's good practice to keep it there to make it more obvious what's going on. Note Do not call virutal functions from constructors or destructors. Because the classes have not all bee initialized yet, they won't be able to call each other as expected. Same goes for destructors. Note Only make the functions virtual that require it. It's more overhead to resolve virtual functions. Because you sometimes want an override function to be slightly different than the function it's overriding (say it's const or a minor difference) there is the override specifier to force it to override. This goes right after where the const specifier would go. class A { public : virtual const char * getName1 ( int x ) { return \"A\" ; } virtual const char * getName2 ( int x ) { return \"A\" ; } virtual const char * getName3 ( int x ) { return \"A\" ; } } class B : public A { public : virutal const char * getName1 ( short int x ) override { return \"B\" ; } // this will now produce a compile error } Note Use the override specifier for every inteded override function you write. This makes it easier to read and catches more errors. If you do not want someone to be able to override a function any further, you can use the final specifier in the same place as the override specifier. class A { public : virtual const char * getName () { return \"A\" ; } }; class B : public A { public : // note use of final specifier on following line -- that makes this function no longer overridable virtual const char * getName () override final { return \"B\" ; } // okay, overrides A::getName() }; class C : public B { public : virtual const char * getName () override { return \"C\" ; } // compile error: overrides B::getName(), which is final }; Here you can see there is a compile error coming up when attempting to override a function that was set to final. Note that without the override keyword this would not produce the error, but getting a ref to A would call B.getName(). There is a way to allow for different return types. If the return type of a virtual function is a pointer or a reference to a class, override functions can return a pointer or a reference to a derived class. These are called covariant return types . In the following because Derived \"is-a\" base it's allowed: class Base { public : // This version of getThis() returns a pointer to a Base class virtual Base * getThis () { std :: cout << \"called Base::getThis() \\n \" ; return this ; } void printType () { std :: cout << \"returned a Base \\n \" ; } }; class Derived : public Base { public : // Normally override functions have to return objects of the same type as the base function // However, because Derived is derived from Base, it's okay to return Derived* instead of Base* Derived * getThis () override { std :: cout << \"called Derived::getThis() \\n \" ; return this ; } void printType () { std :: cout << \"returned a Derived \\n \" ; } }; In the above example, you only get a Derived* if you call getThis() with an object that is typed as a Derived object. Derived d {}; Base * b { & d }; d . getThis () -> printType (); // calls Derived::getThis(), returns a Derived*, calls Derived::printType b -> getThis () -> printType (); // calls Derived::getThis(), returns a Base*, calls Base::printType Virtual destructors, virtual assignment, and overriding virtualisation When creating your own destructors, you should always make them virtual when dealing with inheritance. class Base { public : virtual ~ Base () // note: virtual { std :: cout << \"Calling ~Base() \\n \" ; } }; class Derived : public Base { private : int * m_array ; public : Derived ( int length ) : m_array { new int [ length ] } { } virtual ~ Derived () // note: virtual { std :: cout << \"Calling ~Derived() \\n \" ; delete [] m_array ; } }; Without the virtual keyword, that array would not be cleaned up. * If you intend your class to be inherited from, make sure your destructor is virtual * If you do not intend your class to be inherited from, mark your class as final. What about when you want to ignore virtualisation? Derived derived ; const Base & base { derived }; // Calls Base::GetName() instead of the virtualized Derived::GetName() std :: cout << base . Base :: getName () << '\\n' ; Early binding, late binding (optional) Binding is when variables and function names are bound to addresses in memory. Direct function calls are bound early, because the compiler knows example how much memory they will take. This is the same as static binding. In some programs, you don't know which function will be called until runtime. This is called late binding . The following code is an example: #include <iostream> int add ( int x , int y ) { return x + y ; } int main () { // Create a function pointer and make it point to the add function int ( * pFcn )( int , int ) = add ; std :: cout << pFcn ( 5 , 3 ) << std :: endl ; // add 5 + 3 return 0 ; } The compiler doesn't know which function will be called until the execution of the program. This is slightly less efficient, because it involves an extra level of indirection. Virtual functions use a special form of late binding known as the virtual table : a lookup table of functions used to resolve function calls in a dynamic/late binding manner. Each class has a static array of function pointers defined at compile time, with one entry for each virtual function that can be called by objects of the class. There is also a special hidden pointer to the base class *__vptr . This is setup automatically and is inherited by derived classes. Consider the following example class Base { public : FunctionPointer * __vptr ; // this is created automatically we are just adding it to be explicit virtual void function1 () {}; virtual void function2 () {}; }; class D1 : public Base { public : virtual void function1 () {}; }; class D2 : public Base { public : virtual void function2 () {}; }; In this example each class has a virtual table of 2 function points. *__vptr is set to point to the virtual table for that class. By default each entry to that table is filled with the most derived version for that class. Pure virtual functions, abstract base classes, and interface classes You can also create pure virtual functions to enable expansion of your classes. For example adding hooks inside your functions that you can potentially extend later. You create them by simply assigning them 0. class Base { public : const char * sayHi () const { return \"Hi\" ;} virtual int getValue () const = 0 ; // a pure virutual function } We are basically saying \"it is up to the derived classes to implement this function\" - any class with one or more pure virtual functions becomes an * abstract base class . This means it can not be instantiated! There would be no way to resolve this classes function. Because of this only child subclasses of the class can be instantiated. You can give virtual functions a body by defining it after the class class Animal // This Animal is an abstract base class { protected : std :: string m_name ; public : Animal ( const std :: string & name ) : m_name { name } { } std :: string getName () { return m_name ; } virtual const char * speak () const = 0 ; // The = 0 means this function is pure virtual virtual ~ Animal () = default ; }; const char * Animal::speak () const // even though it has a body { return \"buzz\" ; } This can be useful when we want there to be a defined default implmentation, but want to force an explicit calls to it. Interface class An interface class is a class that has no member variables, and where all of the functions are pure virtual. It's pure definition, with no implmentation. This is useful when you want to define the functionality that derived classes must implmenet, but leave the details to the derived class. They are typically named beginning with an I. class IErrorLog { public : virtual bool openLog ( const char * filename ) = 0 ; virutal bool closeLog () = 0 ; virtual bool writeError ( const char * errorMessage ) = 0 ; virtual ~ IErrorLog () {} // make a virtual destructor in case we delete an IErrorLog pointer, so the proper derived desturctor is called. } This way you can easily refactor the error in case you want to use a different logger. Don't forget to include virtual destructors for your interface classes. If you want to share a base class between multiple child classes, you can create a virutal base class. This means there is only one base object if you choose to use multiple inheritance. class PoweredDevice { public : PoweredDevice ( int power ) { std :: cout << \"PoweredDevice: \" << power << '\\n' ; } }; class Scanner : virtual public PoweredDevice // note: PoweredDevice is now a virtual base class { public : Scanner ( int scanner , int power ) : PoweredDevice { power } // this line is required to create Scanner objects, but ignored in this case { std :: cout << \"Scanner: \" << scanner << '\\n' ; } }; class Printer : virtual public PoweredDevice // note: PoweredDevice is now a virtual base class { public : Printer ( int printer , int power ) : PoweredDevice { power } // this line is required to create Printer objects, but ignored in this case { std :: cout << \"Printer: \" << printer << '\\n' ; } }; class Copier : public Scanner , public Printer { public : Copier ( int scanner , int printer , int power ) : PoweredDevice { power }, // PoweredDevice is constructed here Scanner { scanner , power }, Printer { printer , power } { } }; PoweredDevice : 3 Scanner : 1 Printer : 2 Couple more things to note on this: Virtual Base classes are always created before non-virtuali base classes. The virutal intermediary subclasses still have calls to the constructors of the superclasses. These are in case we create an instance of those classes. The most derived class is responsible for constucting the virtual base class. All classes inheriting a virtual base class will have a virtual table and be larger by a pointer. You can slice objects by initializing their parent class with them. This keeps all the varialbes of the parent class, but effectivly trims out all the elements of the subclass. It's easy to accidentally slice object when not passing them into functions by reference. It's also easy to slice objects when putting them into a vector. std :: vector < Base > v {}; v . push_back ( Base { 5 }); v . push_back ( Derived { 6 }); // Derived gets sliced to base only You can't fix this by passing in a reference to the vector, but you could make it a vector of pointers, or use std::reference_wrapper the Frankenobject Derived d1 { 5 }; Derived d2 { 6 }; Base & b { d2 }; b = d1 ; // this line is problematic This kind of assignment is not virtual. It will slice d1 to a Baseobject. Even more problematic, is if the inheritance chance was longer. The \"top\" of the slice would still exist in memory and couldn't be deleted. Dynamic casting What if you want to access some information in a derived class but you only have a pointer to a base class. The opposite of upcasting , downcasting is when you downcast a pointer to a child class. This is done with an operator called dynamic_case (base). Note Always ensure your dunamic casts actually succeeded by checking for a null pointer result. Base * b { getObject ( true ) }; Derived * d { dynamic_cast < Derived *> ( b ) }; // use dynamic cast to convert Base pointer into Derived pointer if ( d ) // make sure d is non-null std :: cout << \"The name of the Derived is: \" << d -> getName () << '\\n' ; delete b ; This will not work with: Protected or private inheritance For classes that do not declare or inherit any virtual functions (and thus don't have a virtual table) Certain classes involving virtual base classes. You can also downcast with static_cast, but it's not guaranteed to work. dynamic_cast can also work with references in the same way with references. Note Use static_cast unless you're downcasting, or avoid casting alltogether and use virtual functions Times when downcasting is better than using a virtual function When you cannot modify the base class to add a virtual funcctions When you need access to something that is derived-class specific (like a getter that only this one class needs) When adding a virtual function to your base class doesn't make sense. Can we make Operator \"<<\" virtual? Nope. Only member functions can be virtualized, and those can't return a std::out out& The fix is to delegate the printing to a virtualized function! #include <iostream> class Base { public : // Here's our overloaded operator<< friend std :: ostream & operator << ( std :: ostream & out , const Base & b ) { // Delegate printing responsibility for printing to member function print() return b . print ( out ); } // We'll rely on member function print() to do the actual printing // Because print is a normal member function, it can be virtualized virtual std :: ostream & print ( std :: ostream & out ) const { out << \"Base\" ; return out ; } }; class Derived : public Base { public : // Here's our override print function to handle the Derived case virtual std :: ostream & print ( std :: ostream & out ) const override { out << \"Derived\" ; return out ; } }; int main () { Base b {}; std :: cout << b << '\\n' ; Derived d {}; std :: cout << d << '\\n' ; // note that this works even with no operator<< that explicitly handles Derived objects Base & bref { d }; std :: cout << bref << '\\n' ; return 0 ; }","title":"Virtual Functions"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#virtual-functions","text":"We can creat pointers to child classes, and they produce the expected result #include <iostream> int main () { Derived derived { 5 }; std :: cout << \"derived is a \" << derived . getName () << \" and has value \" << derived . getValue () << '\\n' ; Derived & rDerived { derived }; std :: cout << \"rDerived is a \" << rDerived . getName () << \" and has value \" << rDerived . getValue () << '\\n' ; Derived * pDerived { & derived }; std :: cout << \"pDerived is a \" << pDerived -> getName () << \" and has value \" << pDerived -> getValue () << '\\n' ; return 0 ; } Derived is a class inheriting from base. What's interesting, is that we can also create pointers to the base class Derived derived { 5 }; // These are both legal! Base & rBase { derived }; Base * pBase { & derived }; std :: cout << \"derived is a \" << derived . getName () << \" and has value \" << derived . getValue () << '\\n' ; std :: cout << \"rBase is a \" << rBase . getName () << \" and has value \" << rBase . getValue () << '\\n' ; std :: cout << \"pBase is a \" << pBase -> getName () << \" and has value \" << pBase -> getValue () << '\\n' ; These base pointers cannot see any of the functions or members of the Derived class. This is extremely useful for classes where a lot of subclasses can be input to the same functions. If you have a base class Animal with Cat and Dog inheriting from it, you would have to write an overloaded print function that takes each of the animal classes. void print ( const Cat & cat ){ std :: cout << cat . getName () << \" says \" << cat . speak () << '\\n' ; } voic print ( const Dog & dog ) etc .. This would get really annoying with multiple animal types. Instead, we can do something like this: void print ( const Animal & animal ){} The problem now, of course, is that we don't know what the specific animals' sound is. Virtual functions can solve this. A virtual function is a special type of function that, when called resolves to the most-derived version of the function that exists between the base and derived class. This is called polymorphism because it's an adaptive function to the current definition of the class. It respects the override functions of the child classes, and calls those instead if they exist. You create them with the virtual keyword. class Base { public : virutal std :: string_view getName () const { return \"Base\" ; } // the virtual keyword tells the class to always use the most override }; class Derived : public Base { public : virutal std :: string_view getName () const { return \"Derived\" ; } } int main (){ Derived derived ; Base & rBase { derived }; std :: cout << \"rBase is a \" << rBase . getName () << '\\n' ; return 0 ; } This prints rBase is a Derived - even though we cast derived to a reference of it's base class. This is based on the object that is referencing. If you have further derived classes, it won't call them just because they exist. It calls the most overridden one of this particular instance of the base class. Note While the virtual keyword on the derived class is not required for it to work, it's good practice to keep it there to make it more obvious what's going on. Note Do not call virutal functions from constructors or destructors. Because the classes have not all bee initialized yet, they won't be able to call each other as expected. Same goes for destructors. Note Only make the functions virtual that require it. It's more overhead to resolve virtual functions. Because you sometimes want an override function to be slightly different than the function it's overriding (say it's const or a minor difference) there is the override specifier to force it to override. This goes right after where the const specifier would go. class A { public : virtual const char * getName1 ( int x ) { return \"A\" ; } virtual const char * getName2 ( int x ) { return \"A\" ; } virtual const char * getName3 ( int x ) { return \"A\" ; } } class B : public A { public : virutal const char * getName1 ( short int x ) override { return \"B\" ; } // this will now produce a compile error } Note Use the override specifier for every inteded override function you write. This makes it easier to read and catches more errors. If you do not want someone to be able to override a function any further, you can use the final specifier in the same place as the override specifier. class A { public : virtual const char * getName () { return \"A\" ; } }; class B : public A { public : // note use of final specifier on following line -- that makes this function no longer overridable virtual const char * getName () override final { return \"B\" ; } // okay, overrides A::getName() }; class C : public B { public : virtual const char * getName () override { return \"C\" ; } // compile error: overrides B::getName(), which is final }; Here you can see there is a compile error coming up when attempting to override a function that was set to final. Note that without the override keyword this would not produce the error, but getting a ref to A would call B.getName(). There is a way to allow for different return types. If the return type of a virtual function is a pointer or a reference to a class, override functions can return a pointer or a reference to a derived class. These are called covariant return types . In the following because Derived \"is-a\" base it's allowed: class Base { public : // This version of getThis() returns a pointer to a Base class virtual Base * getThis () { std :: cout << \"called Base::getThis() \\n \" ; return this ; } void printType () { std :: cout << \"returned a Base \\n \" ; } }; class Derived : public Base { public : // Normally override functions have to return objects of the same type as the base function // However, because Derived is derived from Base, it's okay to return Derived* instead of Base* Derived * getThis () override { std :: cout << \"called Derived::getThis() \\n \" ; return this ; } void printType () { std :: cout << \"returned a Derived \\n \" ; } }; In the above example, you only get a Derived* if you call getThis() with an object that is typed as a Derived object. Derived d {}; Base * b { & d }; d . getThis () -> printType (); // calls Derived::getThis(), returns a Derived*, calls Derived::printType b -> getThis () -> printType (); // calls Derived::getThis(), returns a Base*, calls Base::printType","title":"Virtual Functions"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#virtual-destructors-virtual-assignment-and-overriding-virtualisation","text":"When creating your own destructors, you should always make them virtual when dealing with inheritance. class Base { public : virtual ~ Base () // note: virtual { std :: cout << \"Calling ~Base() \\n \" ; } }; class Derived : public Base { private : int * m_array ; public : Derived ( int length ) : m_array { new int [ length ] } { } virtual ~ Derived () // note: virtual { std :: cout << \"Calling ~Derived() \\n \" ; delete [] m_array ; } }; Without the virtual keyword, that array would not be cleaned up. * If you intend your class to be inherited from, make sure your destructor is virtual * If you do not intend your class to be inherited from, mark your class as final. What about when you want to ignore virtualisation? Derived derived ; const Base & base { derived }; // Calls Base::GetName() instead of the virtualized Derived::GetName() std :: cout << base . Base :: getName () << '\\n' ;","title":"Virtual destructors, virtual assignment, and overriding virtualisation"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#early-binding-late-binding-optional","text":"Binding is when variables and function names are bound to addresses in memory. Direct function calls are bound early, because the compiler knows example how much memory they will take. This is the same as static binding. In some programs, you don't know which function will be called until runtime. This is called late binding . The following code is an example: #include <iostream> int add ( int x , int y ) { return x + y ; } int main () { // Create a function pointer and make it point to the add function int ( * pFcn )( int , int ) = add ; std :: cout << pFcn ( 5 , 3 ) << std :: endl ; // add 5 + 3 return 0 ; } The compiler doesn't know which function will be called until the execution of the program. This is slightly less efficient, because it involves an extra level of indirection. Virtual functions use a special form of late binding known as the virtual table : a lookup table of functions used to resolve function calls in a dynamic/late binding manner. Each class has a static array of function pointers defined at compile time, with one entry for each virtual function that can be called by objects of the class. There is also a special hidden pointer to the base class *__vptr . This is setup automatically and is inherited by derived classes. Consider the following example class Base { public : FunctionPointer * __vptr ; // this is created automatically we are just adding it to be explicit virtual void function1 () {}; virtual void function2 () {}; }; class D1 : public Base { public : virtual void function1 () {}; }; class D2 : public Base { public : virtual void function2 () {}; }; In this example each class has a virtual table of 2 function points. *__vptr is set to point to the virtual table for that class. By default each entry to that table is filled with the most derived version for that class.","title":"Early binding, late binding (optional)"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#pure-virtual-functions-abstract-base-classes-and-interface-classes","text":"You can also create pure virtual functions to enable expansion of your classes. For example adding hooks inside your functions that you can potentially extend later. You create them by simply assigning them 0. class Base { public : const char * sayHi () const { return \"Hi\" ;} virtual int getValue () const = 0 ; // a pure virutual function } We are basically saying \"it is up to the derived classes to implement this function\" - any class with one or more pure virtual functions becomes an * abstract base class . This means it can not be instantiated! There would be no way to resolve this classes function. Because of this only child subclasses of the class can be instantiated. You can give virtual functions a body by defining it after the class class Animal // This Animal is an abstract base class { protected : std :: string m_name ; public : Animal ( const std :: string & name ) : m_name { name } { } std :: string getName () { return m_name ; } virtual const char * speak () const = 0 ; // The = 0 means this function is pure virtual virtual ~ Animal () = default ; }; const char * Animal::speak () const // even though it has a body { return \"buzz\" ; } This can be useful when we want there to be a defined default implmentation, but want to force an explicit calls to it.","title":"Pure virtual functions, abstract base classes, and interface classes"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#interface-class","text":"An interface class is a class that has no member variables, and where all of the functions are pure virtual. It's pure definition, with no implmentation. This is useful when you want to define the functionality that derived classes must implmenet, but leave the details to the derived class. They are typically named beginning with an I. class IErrorLog { public : virtual bool openLog ( const char * filename ) = 0 ; virutal bool closeLog () = 0 ; virtual bool writeError ( const char * errorMessage ) = 0 ; virtual ~ IErrorLog () {} // make a virtual destructor in case we delete an IErrorLog pointer, so the proper derived desturctor is called. } This way you can easily refactor the error in case you want to use a different logger. Don't forget to include virtual destructors for your interface classes. If you want to share a base class between multiple child classes, you can create a virutal base class. This means there is only one base object if you choose to use multiple inheritance. class PoweredDevice { public : PoweredDevice ( int power ) { std :: cout << \"PoweredDevice: \" << power << '\\n' ; } }; class Scanner : virtual public PoweredDevice // note: PoweredDevice is now a virtual base class { public : Scanner ( int scanner , int power ) : PoweredDevice { power } // this line is required to create Scanner objects, but ignored in this case { std :: cout << \"Scanner: \" << scanner << '\\n' ; } }; class Printer : virtual public PoweredDevice // note: PoweredDevice is now a virtual base class { public : Printer ( int printer , int power ) : PoweredDevice { power } // this line is required to create Printer objects, but ignored in this case { std :: cout << \"Printer: \" << printer << '\\n' ; } }; class Copier : public Scanner , public Printer { public : Copier ( int scanner , int printer , int power ) : PoweredDevice { power }, // PoweredDevice is constructed here Scanner { scanner , power }, Printer { printer , power } { } }; PoweredDevice : 3 Scanner : 1 Printer : 2 Couple more things to note on this: Virtual Base classes are always created before non-virtuali base classes. The virutal intermediary subclasses still have calls to the constructors of the superclasses. These are in case we create an instance of those classes. The most derived class is responsible for constucting the virtual base class. All classes inheriting a virtual base class will have a virtual table and be larger by a pointer. You can slice objects by initializing their parent class with them. This keeps all the varialbes of the parent class, but effectivly trims out all the elements of the subclass. It's easy to accidentally slice object when not passing them into functions by reference. It's also easy to slice objects when putting them into a vector. std :: vector < Base > v {}; v . push_back ( Base { 5 }); v . push_back ( Derived { 6 }); // Derived gets sliced to base only You can't fix this by passing in a reference to the vector, but you could make it a vector of pointers, or use std::reference_wrapper","title":"Interface class"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#the-frankenobject","text":"Derived d1 { 5 }; Derived d2 { 6 }; Base & b { d2 }; b = d1 ; // this line is problematic This kind of assignment is not virtual. It will slice d1 to a Baseobject. Even more problematic, is if the inheritance chance was longer. The \"top\" of the slice would still exist in memory and couldn't be deleted.","title":"the Frankenobject"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#dynamic-casting","text":"What if you want to access some information in a derived class but you only have a pointer to a base class. The opposite of upcasting , downcasting is when you downcast a pointer to a child class. This is done with an operator called dynamic_case (base). Note Always ensure your dunamic casts actually succeeded by checking for a null pointer result. Base * b { getObject ( true ) }; Derived * d { dynamic_cast < Derived *> ( b ) }; // use dynamic cast to convert Base pointer into Derived pointer if ( d ) // make sure d is non-null std :: cout << \"The name of the Derived is: \" << d -> getName () << '\\n' ; delete b ; This will not work with: Protected or private inheritance For classes that do not declare or inherit any virtual functions (and thus don't have a virtual table) Certain classes involving virtual base classes. You can also downcast with static_cast, but it's not guaranteed to work. dynamic_cast can also work with references in the same way with references. Note Use static_cast unless you're downcasting, or avoid casting alltogether and use virtual functions Times when downcasting is better than using a virtual function When you cannot modify the base class to add a virtual funcctions When you need access to something that is derived-class specific (like a getter that only this one class needs) When adding a virtual function to your base class doesn't make sense.","title":"Dynamic casting"},{"location":"cpp/LearnCpp.com/018_VirtualFunctions/#can-we-make-operator-virtual","text":"Nope. Only member functions can be virtualized, and those can't return a std::out out& The fix is to delegate the printing to a virtualized function! #include <iostream> class Base { public : // Here's our overloaded operator<< friend std :: ostream & operator << ( std :: ostream & out , const Base & b ) { // Delegate printing responsibility for printing to member function print() return b . print ( out ); } // We'll rely on member function print() to do the actual printing // Because print is a normal member function, it can be virtualized virtual std :: ostream & print ( std :: ostream & out ) const { out << \"Base\" ; return out ; } }; class Derived : public Base { public : // Here's our override print function to handle the Derived case virtual std :: ostream & print ( std :: ostream & out ) const override { out << \"Derived\" ; return out ; } }; int main () { Base b {}; std :: cout << b << '\\n' ; Derived d {}; std :: cout << d << '\\n' ; // note that this works even with no operator<< that explicitly handles Derived objects Base & bref { d }; std :: cout << bref << '\\n' ; return 0 ; }","title":"Can we make Operator \"&lt;&lt;\" virtual?"},{"location":"cpp/LearnCpp.com/019_Templates/","text":"Templates Intro Because C++ is a heavily typed language, it can be really annoying to write the same function and overload for every data type. Wouldn\u2019t it be nice if we could write one version of max() that was able to work with parameters of ANY type? In C++, function templates are functions that serve as a blueprint for creating other similar functions. Instead of using defined types these functions can use template type parameters that then allow all the functions required to overload for those parameters to be created by compile time. Creating a function template is not really that hard: template < typename T > // this is the tempalte parameter declaration T max ( T x , T y ){ return ( x > y ) ? x : y ; } The template \"type\" declaration is called a template parameter declaration . The keyword template tell the compiler that what follows is going to be a list of template parameters. Then all parameters get places inside the <>. If the function uses multiple template type parameters, they can be separated by commas. template < typenae T1 , typename T2 > It's common to see them name \"T1\" and \"T2\" or other single capital letter names such as \"S\". It's also generally good to make the parameters and return types of templated functions const references since it's not possible to assume they are going to be fundamental data types. template < typename T > const T & max ( const T & x , const T & y ){ return ( x > y ) ? x : y ; } The main drawbacks of templated functions are an increased compile time, and hard to comprehend compiler errors when they are not working. Function template instances Not all templates possible are created at compile time - only the ones needed for your program to run. When the compiler encounters a call to a function templates, it creates a function templates instance . Then in the future it creates more for combinations of input parameters that it doesn't know yet. What if the above template function tries to compare two object that do not have overloaded > operators? This will produce a compile error. Adding an overloaded operator> to the class fixes this. Template classes Templates can be used to generalize things like container classes. That way a container class can contain any type of variables. When creating templated classes you need to declare the template declaration again for each member function defined outside the class #ifndef ARRAY_H #define ARRAY_H #include <cassert> template < class T > class Array { private : int m_length {}; T * m_data {}; public : Array ( int length ) { assert ( length > 0 ); m_data = new T [ length ]{}; m_length = length ; } Array ( const Array & ) = delete ; Array & operator = ( const Array & ) = delete ; ~ Array () { delete [] m_data ; } void Erase () { delete [] m_data ; // We need to make sure we set m_data to 0 here, otherwise it will // be left pointing at deallocated memory! m_data = nullptr ; m_length = 0 ; } T & operator []( int index ) { assert ( index >= 0 && index < m_length ); return m_data [ index ]; } // templated getLength() function defined below int getLength () const ; }; // member functions defined outside the class need their own template declaration template < class T > int Array < T >:: getLength () const // note class name is Array<T>, not Array { return m_length ; } #endif Now when we use this class note how we need to defined the templated variables within the <> int main () { Array < int > intArray ( 12 ); Array < double > doubleArray ( 12 ); for ( int count { 0 }; count < intArray . getLength (); ++ count ) { intArray [ count ] = count ; doubleArray [ count ] = count + 0.5 ; } for ( int count { intArray . getLength () - 1 }; count >= 0 ; -- count ) std :: cout << intArray [ count ] << '\\t' << doubleArray [ count ] << '\\n' ; return 0 ; } Now we finally understand what <> mean next to a class! One thing to note is that separating template classes header from their body doesn't really work. This is because by the time the compiler adds the template function implementation of the body, it has forgotten the template definitions and can't match to the class. If you can put all the code into the header. If that is too messy, you can rename .cpp to .inl (stands for inline) and then include .inl from the bottom of the .h header. This is the same as putting all the code into the header but is neater. You can also use a three file approach, where the third file contains all of the instantiated classes you need. This file is often called templates.cpp Template non-type parameters Basically templates are functions that create classes and functions with the possibility that the inputs allow for polymorphism. You can also have non-type inputs, that are always the same type, but vary in value. Taking the above array class. This pretty much allows you to skip the constructor for a class that has variables that won't change but need to be initialized. #include <iostream> template < class T , int size > // size is the non-type parameter class StaticArray { private : // The non-type parameter controls the size of the array T m_array [ size ]; public : T * getArray (); T & operator []( int index ) { return m_array [ index ]; } }; // Showing how a function for a class with a non-type parameter is defined outside of the class template < class T , int size > T * StaticArray < T , size >:: getArray () { return m_array ; } int main () { // declare an integer array with room for 12 integers StaticArray < int , 12 > intArray ; // Fill it up in order, then print it backwards for ( int count = 0 ; count < 12 ; ++ count ) intArray [ count ] = count ; for ( int count = 11 ; count >= 0 ; -- count ) std :: cout << intArray [ count ] << \" \" ; std :: cout << '\\n' ; // declare a double buffer with room for 4 doubles StaticArray < double , 4 > doubleArray ; for ( int count = 0 ; count < 4 ; ++ count ) doubleArray [ count ] = 4.4 + 0.1 * count ; for ( int count = 0 ; count < 4 ; ++ count ) std :: cout << doubleArray [ count ] << ' ' ; return 0 ; } The basically makes is so that we do not have to dynamically allocate the m_array member variable. For any given instance of the class, size is actually constant. Function template specialization What if you want special behaviour for when a template is created with a specific type? Say we want specifically double values to output in scientific notation. We can do this with function template specialization , which creates a specialized version of the function when called with a specific type. template < class T > class Storage { private : T m_value ; public : Storage ( T value ) { m_value = value ; } ~ Storage () { } void print () { std :: cout << m_value << '\\n' ; } }; // print doubles with scientific notation template <> void Storage < double >:: print () { std :: cout << std :: scientific << m_value << '\\n' ; } In this case you are overriding the print function for one very specific return of the template function. Note how the class name includes the template type. Class template specialization You can also specialize class templates. Let's specialize the following class for a more efficient memory management of bools. template < class T > class Storage8 { private : T m_array [ 8 ]; public : void set ( int index , const T & value ) { m_array [ index ] = value ; } const T & get ( int index ) const { return m_array [ index ]; } }; template <> // the following is a template class with no templated parameters class Storage8 < bool > // we're specializing Storage8 for bool { // What follows is just standard class implementation details private : unsigned char m_data {}; public : void set ( int index , bool value ) { // Figure out which bit we're setting/unsetting // This will put a 1 in the bit we're interested in turning on/off auto mask { 1 << index }; if ( value ) // If we're setting a bit m_data |= mask ; // Use bitwise-or to turn that bit on else // if we're turning a bit off m_data &= ~ mask ; // bitwise-and the inverse mask to turn that bit off } bool get ( int index ) { // Figure out which bit we're getting auto mask { 1 << index }; // bitwise-and to get the value of the bit we're interested in // Then implicit cast to boolean return ( m_data & mask ); } }; You can overwrite any part you like. We should try to keep a consistent interface with this, because the whole point of not writing another class is that things \"just work\". Note that you need to re-write the whole class for this. If you want to specialize a template with only part of the template defined you can do this. Here we are overloading the print function // overload of print() function for partially specialized StaticArray<char, size> template < int size > // size is still a templated expression parameter void print ( StaticArray < char , size > & array ) // we're explicitly defining type char here { for ( int count { 0 }; count < size ; ++ count ) std :: cout << array [ count ]; } As of c++14 partial template specialization can only be used with classes, not template function (which must be fully specialized). If you do not want to re-write the whole class for template specialization, you can inherit from a common base class. #include <iostream> template < class T , int size > // size is the expression parameter class StaticArray_Base { protected : // The expression parameter controls the size of the array T m_array [ size ]{}; public : T * getArray () { return m_array ; } T & operator []( int index ) { return m_array [ index ]; } void print () { for ( int i { 0 }; i < size ; ++ i ) std :: cout << m_array [ i ]; std :: cout << '\\n' ; } virtual ~ StaticArray_Base () = default ; }; template < class T , int size > // size is the expression parameter class StaticArray : public StaticArray_Base < T , size > { public : }; template < int size > // size is the expression parameter class StaticArray < double , size >: public StaticArray_Base < double , size > { public : void print () { for ( int i { 0 }; i < size ; ++ i ) std :: cout << std :: scientific << this -> m_array [ i ] << ' ' ; // note: The this-> prefix in the above line is needed. // See https://stackoverflow.com/a/6592617 or https://isocpp.org/wiki/faq/templates#nondependent-name-lookup-members for more info on why. std :: cout << '\\n' ; } }; int main () { // declare an integer array with room for 6 integers StaticArray < int , 6 > intArray {}; // Fill it up in order, then print it for ( int count { 0 }; count < 6 ; ++ count ) intArray [ count ] = count ; intArray . print (); // declare a double buffer with room for 4 doubles StaticArray < double , 4 > doubleArray {}; for ( int count { 0 }; count < 4 ; ++ count ) doubleArray [ count ] = ( 4.0 + 0.1 * count ); doubleArray . print (); return 0 ; } You can also partially specialize a template for only pointer types like this template < typename T > class Storage < T *> // this is a partial-specialization of Storage that works with pointer types { private : T * m_value ; public : Storage ( T * value ) // for pointer type T { // For pointers, we'll do a deep copy m_value = new T ( * value ); // this copies a single value, not an array } ~ Storage () { delete m_value ; // so we use scalar delete here, not array delete } void print () { std :: cout << * m_value << '\\n' ; } }; This is especially useful to include deletion of all pointers.","title":"Templates"},{"location":"cpp/LearnCpp.com/019_Templates/#templates","text":"","title":"Templates"},{"location":"cpp/LearnCpp.com/019_Templates/#intro","text":"Because C++ is a heavily typed language, it can be really annoying to write the same function and overload for every data type. Wouldn\u2019t it be nice if we could write one version of max() that was able to work with parameters of ANY type? In C++, function templates are functions that serve as a blueprint for creating other similar functions. Instead of using defined types these functions can use template type parameters that then allow all the functions required to overload for those parameters to be created by compile time. Creating a function template is not really that hard: template < typename T > // this is the tempalte parameter declaration T max ( T x , T y ){ return ( x > y ) ? x : y ; } The template \"type\" declaration is called a template parameter declaration . The keyword template tell the compiler that what follows is going to be a list of template parameters. Then all parameters get places inside the <>. If the function uses multiple template type parameters, they can be separated by commas. template < typenae T1 , typename T2 > It's common to see them name \"T1\" and \"T2\" or other single capital letter names such as \"S\". It's also generally good to make the parameters and return types of templated functions const references since it's not possible to assume they are going to be fundamental data types. template < typename T > const T & max ( const T & x , const T & y ){ return ( x > y ) ? x : y ; } The main drawbacks of templated functions are an increased compile time, and hard to comprehend compiler errors when they are not working.","title":"Intro"},{"location":"cpp/LearnCpp.com/019_Templates/#function-template-instances","text":"Not all templates possible are created at compile time - only the ones needed for your program to run. When the compiler encounters a call to a function templates, it creates a function templates instance . Then in the future it creates more for combinations of input parameters that it doesn't know yet. What if the above template function tries to compare two object that do not have overloaded > operators? This will produce a compile error. Adding an overloaded operator> to the class fixes this.","title":"Function template instances"},{"location":"cpp/LearnCpp.com/019_Templates/#template-classes","text":"Templates can be used to generalize things like container classes. That way a container class can contain any type of variables. When creating templated classes you need to declare the template declaration again for each member function defined outside the class #ifndef ARRAY_H #define ARRAY_H #include <cassert> template < class T > class Array { private : int m_length {}; T * m_data {}; public : Array ( int length ) { assert ( length > 0 ); m_data = new T [ length ]{}; m_length = length ; } Array ( const Array & ) = delete ; Array & operator = ( const Array & ) = delete ; ~ Array () { delete [] m_data ; } void Erase () { delete [] m_data ; // We need to make sure we set m_data to 0 here, otherwise it will // be left pointing at deallocated memory! m_data = nullptr ; m_length = 0 ; } T & operator []( int index ) { assert ( index >= 0 && index < m_length ); return m_data [ index ]; } // templated getLength() function defined below int getLength () const ; }; // member functions defined outside the class need their own template declaration template < class T > int Array < T >:: getLength () const // note class name is Array<T>, not Array { return m_length ; } #endif Now when we use this class note how we need to defined the templated variables within the <> int main () { Array < int > intArray ( 12 ); Array < double > doubleArray ( 12 ); for ( int count { 0 }; count < intArray . getLength (); ++ count ) { intArray [ count ] = count ; doubleArray [ count ] = count + 0.5 ; } for ( int count { intArray . getLength () - 1 }; count >= 0 ; -- count ) std :: cout << intArray [ count ] << '\\t' << doubleArray [ count ] << '\\n' ; return 0 ; } Now we finally understand what <> mean next to a class! One thing to note is that separating template classes header from their body doesn't really work. This is because by the time the compiler adds the template function implementation of the body, it has forgotten the template definitions and can't match to the class. If you can put all the code into the header. If that is too messy, you can rename .cpp to .inl (stands for inline) and then include .inl from the bottom of the .h header. This is the same as putting all the code into the header but is neater. You can also use a three file approach, where the third file contains all of the instantiated classes you need. This file is often called templates.cpp","title":"Template classes"},{"location":"cpp/LearnCpp.com/019_Templates/#template-non-type-parameters","text":"Basically templates are functions that create classes and functions with the possibility that the inputs allow for polymorphism. You can also have non-type inputs, that are always the same type, but vary in value. Taking the above array class. This pretty much allows you to skip the constructor for a class that has variables that won't change but need to be initialized. #include <iostream> template < class T , int size > // size is the non-type parameter class StaticArray { private : // The non-type parameter controls the size of the array T m_array [ size ]; public : T * getArray (); T & operator []( int index ) { return m_array [ index ]; } }; // Showing how a function for a class with a non-type parameter is defined outside of the class template < class T , int size > T * StaticArray < T , size >:: getArray () { return m_array ; } int main () { // declare an integer array with room for 12 integers StaticArray < int , 12 > intArray ; // Fill it up in order, then print it backwards for ( int count = 0 ; count < 12 ; ++ count ) intArray [ count ] = count ; for ( int count = 11 ; count >= 0 ; -- count ) std :: cout << intArray [ count ] << \" \" ; std :: cout << '\\n' ; // declare a double buffer with room for 4 doubles StaticArray < double , 4 > doubleArray ; for ( int count = 0 ; count < 4 ; ++ count ) doubleArray [ count ] = 4.4 + 0.1 * count ; for ( int count = 0 ; count < 4 ; ++ count ) std :: cout << doubleArray [ count ] << ' ' ; return 0 ; } The basically makes is so that we do not have to dynamically allocate the m_array member variable. For any given instance of the class, size is actually constant.","title":"Template non-type parameters"},{"location":"cpp/LearnCpp.com/019_Templates/#function-template-specialization","text":"What if you want special behaviour for when a template is created with a specific type? Say we want specifically double values to output in scientific notation. We can do this with function template specialization , which creates a specialized version of the function when called with a specific type. template < class T > class Storage { private : T m_value ; public : Storage ( T value ) { m_value = value ; } ~ Storage () { } void print () { std :: cout << m_value << '\\n' ; } }; // print doubles with scientific notation template <> void Storage < double >:: print () { std :: cout << std :: scientific << m_value << '\\n' ; } In this case you are overriding the print function for one very specific return of the template function. Note how the class name includes the template type.","title":"Function template specialization"},{"location":"cpp/LearnCpp.com/019_Templates/#class-template-specialization","text":"You can also specialize class templates. Let's specialize the following class for a more efficient memory management of bools. template < class T > class Storage8 { private : T m_array [ 8 ]; public : void set ( int index , const T & value ) { m_array [ index ] = value ; } const T & get ( int index ) const { return m_array [ index ]; } }; template <> // the following is a template class with no templated parameters class Storage8 < bool > // we're specializing Storage8 for bool { // What follows is just standard class implementation details private : unsigned char m_data {}; public : void set ( int index , bool value ) { // Figure out which bit we're setting/unsetting // This will put a 1 in the bit we're interested in turning on/off auto mask { 1 << index }; if ( value ) // If we're setting a bit m_data |= mask ; // Use bitwise-or to turn that bit on else // if we're turning a bit off m_data &= ~ mask ; // bitwise-and the inverse mask to turn that bit off } bool get ( int index ) { // Figure out which bit we're getting auto mask { 1 << index }; // bitwise-and to get the value of the bit we're interested in // Then implicit cast to boolean return ( m_data & mask ); } }; You can overwrite any part you like. We should try to keep a consistent interface with this, because the whole point of not writing another class is that things \"just work\". Note that you need to re-write the whole class for this. If you want to specialize a template with only part of the template defined you can do this. Here we are overloading the print function // overload of print() function for partially specialized StaticArray<char, size> template < int size > // size is still a templated expression parameter void print ( StaticArray < char , size > & array ) // we're explicitly defining type char here { for ( int count { 0 }; count < size ; ++ count ) std :: cout << array [ count ]; } As of c++14 partial template specialization can only be used with classes, not template function (which must be fully specialized). If you do not want to re-write the whole class for template specialization, you can inherit from a common base class. #include <iostream> template < class T , int size > // size is the expression parameter class StaticArray_Base { protected : // The expression parameter controls the size of the array T m_array [ size ]{}; public : T * getArray () { return m_array ; } T & operator []( int index ) { return m_array [ index ]; } void print () { for ( int i { 0 }; i < size ; ++ i ) std :: cout << m_array [ i ]; std :: cout << '\\n' ; } virtual ~ StaticArray_Base () = default ; }; template < class T , int size > // size is the expression parameter class StaticArray : public StaticArray_Base < T , size > { public : }; template < int size > // size is the expression parameter class StaticArray < double , size >: public StaticArray_Base < double , size > { public : void print () { for ( int i { 0 }; i < size ; ++ i ) std :: cout << std :: scientific << this -> m_array [ i ] << ' ' ; // note: The this-> prefix in the above line is needed. // See https://stackoverflow.com/a/6592617 or https://isocpp.org/wiki/faq/templates#nondependent-name-lookup-members for more info on why. std :: cout << '\\n' ; } }; int main () { // declare an integer array with room for 6 integers StaticArray < int , 6 > intArray {}; // Fill it up in order, then print it for ( int count { 0 }; count < 6 ; ++ count ) intArray [ count ] = count ; intArray . print (); // declare a double buffer with room for 4 doubles StaticArray < double , 4 > doubleArray {}; for ( int count { 0 }; count < 4 ; ++ count ) doubleArray [ count ] = ( 4.0 + 0.1 * count ); doubleArray . print (); return 0 ; } You can also partially specialize a template for only pointer types like this template < typename T > class Storage < T *> // this is a partial-specialization of Storage that works with pointer types { private : T * m_value ; public : Storage ( T * value ) // for pointer type T { // For pointers, we'll do a deep copy m_value = new T ( * value ); // this copies a single value, not an array } ~ Storage () { delete m_value ; // so we use scalar delete here, not array delete } void print () { std :: cout << * m_value << '\\n' ; } }; This is especially useful to include deletion of all pointers.","title":"Class template specialization"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/","text":"Move semantics and smart pointers It's pretty easy to forget to deallocate pointers. Even if you don't forget, there are many ways that pointers aren't deleted when functions exit early. If we wrap pointers in a class, then the destructor can automatically delete the pointer when the class goes out of scope. This sort of class is called smart pointer : a composition class that is designed to manage dynamically allocated memory and ensure that this memory gets deleted when the smart pointer object goes out of scope. The problem is if the pointer gets copied, then it's destroyed twice and the program will crash. This is because the default copy constructor will do a shallow copy of the value of the pointer. Both pointers are then pointing to the same resource. It will also happen if you are passing in parameters by value. The core idea behind move semantics is having our copy constructor and assignment transver/move ownership of the pointer from the source to the destination object. It means the class will transfer ownership of the object rather than make a copy. #include <iostream> template < class T > class Auto_ptr2 { T * m_ptr ; public : Auto_ptr2 ( T * ptr = nullptr ) : m_ptr ( ptr ) { } ~ Auto_ptr2 () { delete m_ptr ; } // A copy constructor that implements move semantics Auto_ptr2 ( Auto_ptr2 & a ) // note: not const { m_ptr = a . m_ptr ; // transfer our dumb pointer from the source to our local object a . m_ptr = nullptr ; // make sure the source no longer owns the pointer } // An assignment operator that implements move semantics Auto_ptr2 & operator = ( Auto_ptr2 & a ) // note: not const { if ( & a == this ) return * this ; delete m_ptr ; // make sure we deallocate any pointer the destination is already holding first m_ptr = a . m_ptr ; // then transfer our dumb pointer from the source to the local object a . m_ptr = nullptr ; // make sure the source no longer owns the pointer return * this ; } T & operator * () const { return * m_ptr ; } T * operator -> () const { return m_ptr ; } bool isNull () const { return m_ptr == nullptr ; } }; class Resource { public : Resource () { std :: cout << \"Resource acquired \\n \" ; } ~ Resource () { std :: cout << \"Resource destroyed \\n \" ; } }; int main () { Auto_ptr2 < Resource > res1 ( new Resource ()); Auto_ptr2 < Resource > res2 ; // Start as nullptr std :: cout << \"res1 is \" << ( res1 . isNull () ? \"null \\n \" : \"not null \\n \" ); std :: cout << \"res2 is \" << ( res2 . isNull () ? \"null \\n \" : \"not null \\n \" ); res2 = res1 ; // res2 assumes ownership, res1 is set to null std :: cout << \"Ownership transferred \\n \" ; std :: cout << \"res1 is \" << ( res1 . isNull () ? \"null \\n \" : \"not null \\n \" ); std :: cout << \"res2 is \" << ( res2 . isNull () ? \"null \\n \" : \"not null \\n \" ); return 0 ; } Note Avoid std::auto_ptr. This implmenents move semantics through the move and copy constructor. Passing it by value to a function will cause your resource to get moved to the function parameters (and destroyed when the function goes out of scope). It also deletes its contents using non-array delete, which means it won't work with dynamically allocated arays. It also doesn't play nice with a lot of the other classes in the std library. Consider it deprecated and don't use it. Before C++11 there was no mechanism to differentiate \"copy semantics\" from \"move semantics\". Because of this the concept of \"move\" was formally defined and move semantics added to the language to properly differentiate copying from moving. The std::auto_ptr has now been replaces with std::unique_ptr, std::weak_ptr and std::shared_ptr. R-value references To understand move semantics we need to revisit the topic of r-values and l-values. Every expression in C++ has two properties: a type, and a value category . The value category is used for certain kinds of syntax checking. An l-value can be thought of as a function or object (or expression that evaluates to this). All l-values have memory addresses. They were originally defined as \"values that are suitable to be on the left-hand side of an assignment expression\". After the const keyword was added to the language, l-values were split into two sub-categories: modifiable and non-modifiable. An r-value is pretty much anything that is not an l-value. This includes literals, temp values, and anonymous objects. They are typically evaluated for their values, have expression scope, and cannot be assigned to. Because they are expression scope, as soon as assigning a value to them, they would already go out of scope. To support move semantics, C++11 introduced 3 new categories: pr-value, x-values, and gl-values, but we don't need to understand these to understand move semantics. L-value references Before C++11 this was the only type of reference. Now they are called l-value reference. These can only be initialized with modifiable l-values L-value reference Can be initialized with Can modify Modifiable l-values Yes Yes Non-modifiable l-values No No R-values No No L-value references to const object can be initialized with l-values and r-values alike. However, those values can't be modified. L-value reference to const Can be initialized with Can modify Modifiable l-values Yes No Non-modifiable l-values Yes No R-values Yes No These are particularly useful because they allow us to pass any type of argument without making a copy of the argument. R-value references As of C++11 there are now r-value references. These are designed to be initialized with r-values (only). They are created with a double &&. int x { 5 }; int & lref { x }; //l-value reference int && rref { 5 }; // r-value reference (cannot use x) They cannot be initialized with l-values R-value reference Can be initialized with Can modify Modifiable l-values No No Non-modifiable l-values No No R-values Yes Yes R-value reference to const Can be initialized with Can modify Modifiable l-values No No Non-modifiable l-values No No R-values Yes No Just like l-values references to const objects, r-value references extend the lifespan of the object they are initialized with to the lifespan of the r-value reference. They also allow you to modify they r-value! auto & lref { Fraction { 3 , 5 } }; // this won't compile because fraction is temp auto const & lref { Fraction { 3 , 5 } }; // this will compile but you can't change fraction because it only exists as a temp value. Note that this also extends the lifespane of Fraction. auto && rref { Fraction { 3 , 5 } }; // this will compile and you can change the fraction and no copies are created. R-values are almost never used in this way, they are most often used as function parameters for overloads when you want to have different behaviour for l-value and r-value arguments. void fun ( const int & lref ){ std :: cout << \"l-value \\n \" ; } void fun ( int && rref ){ std :: cout << \"r-value \\n \" ; } Move constructors and move assignments Copy Semantics Review Copy assignment is used to copy one class to another existing class. These constructors are provided by default for all classes unless the user specifies one. These copies do shallow copies, which may cause problems for classes that allocate dynamic memory, so classes that deal with dynamic memory should override these functions to do deep copies. Let's go back to our Auto_ptr class to see how this works. template < class T > class Auto_ptr3 { T * m_ptr ; public : Auto_ptr3 ( T * ptr = nullptr ) : m_ptr ( ptr ) { } ~ Auto_ptr3 () { delete m_ptr ; } // Copy constructor // Do deep copy of a.m_ptr to m_ptr Auto_ptr3 ( const Auto_ptr3 & a ) { m_ptr = new T ; * m_ptr = * a . m_ptr ; } // Copy assignment // Do deep copy of a.m_ptr to m_ptr Auto_ptr3 & operator = ( const Auto_ptr3 & a ) { // Self-assignment detection if ( & a == this ) return * this ; // Release any resource we're holding delete m_ptr ; // Copy the resource m_ptr = new T ; * m_ptr = * a . m_ptr ; return * this ; } T & operator * () const { return * m_ptr ; } T * operator -> () const { return m_ptr ; } bool isNull () const { return m_ptr == nullptr ; } }; This still makes for a lot of resource creation and destruction. Every time the pointer is created or returned it does a deep copy of everything. This doesn't crash, but it's quite inefficient! Move semantics fixes this. Here is the same class using r-value references: template < class T > class Auto_ptr4 { T * m_ptr ; public : Auto_ptr4 ( T * ptr = nullptr ) : m_ptr ( ptr ) { } ~ Auto_ptr4 () { delete m_ptr ; } // Move constructor // Transfer ownership of a.m_ptr to m_ptr Auto_ptr4 ( Auto_ptr4 && a ) noexcept : m_ptr ( a . m_ptr ) { a . m_ptr = nullptr ; // we'll talk more about this line below } // Move assignment // Transfer ownership of a.m_ptr to m_ptr Auto_ptr4 & operator = ( Auto_ptr4 && a ) noexcept { // Self-assignment detection if ( & a == this ) return * this ; // Release any resource we're holding delete m_ptr ; // Transfer ownership of a.m_ptr to m_ptr m_ptr = a . m_ptr ; a . m_ptr = nullptr ; // we'll talk more about this line below return * this ; } T & operator * () const { return * m_ptr ; } T * operator -> () const { return m_ptr ; } bool isNull () const { return m_ptr == nullptr ; } }; Now instead of creating and copying and destroying on assignment, the old pointer is set to null and the new pointer is pointed at the value. Moving the value makes it so that the pointer can be copied all over the place without the actual value changing. Note If you want a move constructor and move assignment that do moves, you'll need to write them yourself. Only in rare cases where all other constructors are obstructed will cpp auto-create one. Key Insight If we do assignment or construct with an l-value, the only thing we can do is copy the l-value. We can't assume it's safe to alter the l-value, because it may be used again later in the program. a=b should never change b. If we do assignment or construction with an r-value, then we know that this is just a temp object anyway. Instead of copying this, we can then steal the resources from it to the object we're constructing or assignment. This is because that value will be discarded anyway! Because r-value references have a definition as of c++11, we can overload our constructor to use this more efficient method when r-values are provided to it. Note You should always re-assign your temp object to nullptr otherwise they will become dangling references. Otherwise when they are deconstructed they will delete the data of the pointer! Note Often it's desirable to disable the copy and assignment creator in move-enabled classes. This guides the user to use r-values instead. std::move When you start using move semantics more, you'll often want to move things with l-values. std::move does just this. It assigns an empty value to the variable, and passes the value on as a r-value. template < class T > void myswap ( T & a , T & b ) { T tmp { std :: move ( a ) }; // invokes move constructor // a is now an empty string a = std :: move ( b ); // invokes move assignment b = std :: move ( tmp ); // invokes move assignment } std::move gives a hint to the compiler that the programmer doesn't need this object anymore in it's current state. Move functions should always leave your objects in a well-defined state so they don't crash your program when they go out of scope. This is also very useful when sorting an array of elements. std::move_if_noexcept The noexcept exception specifier and operator is a guarantee to the compiler that a function or class will not raise any exceptions. Consider when we are coping an object, and this copy fails (e.g. the machine is out of memory). This doesn't harm the object being copied, and we move on. When moving, things aren't as simple. If the move operation brakes, then the original object will be empty and we might lose data. To comply with the strong exception guarantee that we want for our functions, we'd need to move the resource back to the source object. But there's no guarantee that move will work either. To counter this we have two options: Use noexcept on the constructor to prevent it from throwing an exception. Ust std::move_if_noexcept instead. Note std::move_if_noexcept will return a movable r-value if the object has a noexcept move constructor, otherwise it will return a copyable l-value. This is great especially for templates where you might not be sure if a class has a noexcept constructor. This noexcept is not a compile-time guarantee, it's still up to the person writing the noexcept functions to wrap things up properly in a try catch block. The standard library uses noexcept a lot along with move_if_noexcept. It's useful, but not a guarantee. std::unique_ptr If a function exits early, or throws an exception, there's a chance that your pointers might now get deleted. A smart pointer can offer other features, but the basic functionality of it is that it manages a dynamically allocated resources on the heap, and ensures destruction of that resource whenever the pointer goes out of scope. Note Never dynamically allocate smart pointers themselves. If the smart pointer is never cleaned up, it will never clean up the object it's pointing to and the whole purpose of it will be invalid. std::unique_ptr is the C++11 replacement for std::auto_ptr. This should be used to manage any dynamically allocated object that is not shared by multiple pointers. It also properly implements move semantics. res2 = res1 ; // Won't compile: copy assignment is disabled res2 = std :: move ( res1 ); // res2 assumes ownership, res1 is set to null Because it's designed with move semantics, copy initialization and copy assignment are disabled. Move semantics are the only way to transfer ownership. std::unique_ptr has overloaded * and -> operators that work just like with regular pointers. Before using them you should check that the resource exists. This is easy because the implicit cast to bool return true if it's managing a resources. std :: unique_ptr < Resource > res { new Resource {} }; if ( res ) // use implicit cast to bool to ensure res contains a Resource std :: cout << * res << '\\n' ; // print the Resource that res is owning std::unique_ptr works well with arrays. Rule Favor std::array, std::vector, or std::string over a smart pointer managing a fixed array, dynamic array, or c-style string. As of C++14 there is also std::make_unique(), which is the preferred way to create smart pointers. It not only is more readable, but it handles some exceptions that can result form C++ leaving the order of evaluation for function arguments unspecified. Rule use std::make_unique() instead of creating std::unique_ptr and using new yourself. auto f1 { std :: make_unique < object > ( arg , arg ) }; Always return std::unique_ptr by value - the internals will apply the correct move semantics. std :: unique_ptr < Resource > createResource () { return std :: make_unique < Resource > (); } Likewise always pass std::unique_ptr by value into functions, and use std::move to put it into the arg. The compiler will force you to use std::move because copy semantics for std::unique_ptr have been disabled. // takeOwnership(ptr); // This doesn't work, need to use move semantics takeOwnership ( std :: move ( ptr )); // ok: use move semantics Even though this is possible, usually you won't want the function to take ownership of the pointer. If it took ownership, then the pointer would be destroyed afterwards. Just pass the resource the pointer is pointing to itself, by pointer or reference. This way the function can remain agnostic as to how the caller is managing resources. You can use get() on a std::unique_ptr to get the resource. In this case you don't want to delete the pointer at the end of the function since the memory will still be in use afterwards. void useResource ( Resource * res ) { if ( res ) std :: cout << * res << '\\n' ; } auto ptr { std :: make_unique < Resource > () }; useResource ( ptr . get ()); // note: get() used here to get a pointer to the Resource You can use std::unique_ptr as part of your classes, but remember that if the class itself is dynamically allocated and not cleaned up using smart pointers won't make a difference. Two things to avoid with mart pointers Don't let multiple classes manage the same resource. Resource * res { new Resource () }; std :: unique_ptr < Resource > res1 { res }; std :: unique_ptr < Resource > res2 { res }; Both res1 and res2 will try to delete the same resource after going out of scope, which will lead to undefined behaviour. Don't manually delete the resource out from underneath the std::unique_ptr Resource * res { new Resource () }; std :: unique_ptr < Resource > res1 { res }; delete res ; std::shared_ptr This is the class for when you want multiple smart pointers pointing at the same resource. // allocate a Resource object and have it owned by std::shared_ptr Resource * res = new Resource ; std :: shared_ptr < Resource > ptr1 ( res ); { std :: shared_ptr < Resource > ptr2 ( ptr1 ); // use copy initialization to make another std::shared_ptr pointing to the same thing // DO NOT DO IT LIKE THIS std :: shared_ptr < Resource > ptr2 ( res ); // this will then kill the resource if going out of scope std :: cout << \"Killing one shared pointer \\n \" ; } // ptr2 goes out of scope here, but nothing happens std :: cout << \"Killing another shared pointer \\n \" ; As you can see above, it's important to create std::shared_ptr that point at the same resources from each other. Rule Always make a copy of an exisiting std::shared_ptr if you need more than one std::shared_ptr pointing to the same resource std::make_shared Like with std::make_unique, it's better to use std:make_shared. int main () { // allocate a Resource object and have it owned by std::shared_ptr auto ptr1 = std :: make_shared < Resource > (); { auto ptr2 = ptr1 ; // create ptr2 using copy initialization of ptr1 std :: cout << \"Killing one shared pointer \\n \" ; } // ptr2 goes out of scope here, but nothing happens std :: cout << \"Killing another shared pointer \\n \" ; return 0 ; } // ptr1 goes out of scope here, and the allocated Resource is destroyed Internally, std::shared_ptr uses two pointers. One poitns at the resource bing managed, the other at a \"control block\" which dynamically allocated and tracks a bunch of stuff like how many instances of the shared_ptr there are. You can convert std::shared_ptr from std::unique_ptr, but you can't convert a std::stared_ptr into a std::unique_ptr. Just like std::unique_ptr you have to worry about the pointer itself being properly disposed of. And not just one, but all instances of the shared_ptr. The resource will be deallocated with the last std::shared_ptr managing the resource is destroyed. Circular dependency issues with std::stared_ptr and std:weak_ptr. Circular references are a series of references where each object references the next, and the last object references back to the first, creating a loop. They do not need to be actual references, they can be pointers, unique ID's or any other means of identifying specific objects. A points at B, B points at C, C points at A. If these go out of scope like this, none of the objects will be deallocated if they are shared pointers, because there's no place to start deallocating. The same thing also happens with a std::shared_ptr referencing the object that contains it. std::weak_ptr is designed to solve this cyclical ownership problem. It is an observer, it can observe and access the same object as a std::shared_ptr, but is not considered an owner. So functionally a std::weak_ptr is the same as a std::shared_ptr, but it doesn't count as a \"user\" of the object. The annoying thing is to use the ptr you need to convert it to a std::shared_ptr first. #include <iostream> #include <memory> // for std::shared_ptr and std::weak_ptr #include <string> class Person { std :: string m_name ; std :: weak_ptr < Person > m_partner ; // note: This is now a std::weak_ptr public : Person ( const std :: string & name ) : m_name ( name ) { std :: cout << m_name << \" created \\n \" ; } ~ Person () { std :: cout << m_name << \" destroyed \\n \" ; } friend bool partnerUp ( std :: shared_ptr < Person > & p1 , std :: shared_ptr < Person > & p2 ) { if ( ! p1 || ! p2 ) return false ; p1 -> m_partner = p2 ; p2 -> m_partner = p1 ; std :: cout << p1 -> m_name << \" is now partnered with \" << p2 -> m_name << \" \\n \" ; return true ; } const std :: shared_ptr < Person > getPartner () const { return m_partner . lock (); } // use lock() to convert weak_ptr to shared_ptr const std :: string & getName () const { return m_name ; } }; int main () { auto lucy = std :: make_shared < Person > ( \"Lucy\" ); auto ricky = std :: make_shared < Person > ( \"Ricky\" ); partnerUp ( lucy , ricky ); auto partner = ricky -> getPartner (); // get shared_ptr to Ricky's partner std :: cout << ricky -> getName () << \"'s partner is: \" << partner -> getName () << '\\n' ; return 0 ; }","title":"Move semantics and smart pointers"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#move-semantics-and-smart-pointers","text":"It's pretty easy to forget to deallocate pointers. Even if you don't forget, there are many ways that pointers aren't deleted when functions exit early. If we wrap pointers in a class, then the destructor can automatically delete the pointer when the class goes out of scope. This sort of class is called smart pointer : a composition class that is designed to manage dynamically allocated memory and ensure that this memory gets deleted when the smart pointer object goes out of scope. The problem is if the pointer gets copied, then it's destroyed twice and the program will crash. This is because the default copy constructor will do a shallow copy of the value of the pointer. Both pointers are then pointing to the same resource. It will also happen if you are passing in parameters by value. The core idea behind move semantics is having our copy constructor and assignment transver/move ownership of the pointer from the source to the destination object. It means the class will transfer ownership of the object rather than make a copy. #include <iostream> template < class T > class Auto_ptr2 { T * m_ptr ; public : Auto_ptr2 ( T * ptr = nullptr ) : m_ptr ( ptr ) { } ~ Auto_ptr2 () { delete m_ptr ; } // A copy constructor that implements move semantics Auto_ptr2 ( Auto_ptr2 & a ) // note: not const { m_ptr = a . m_ptr ; // transfer our dumb pointer from the source to our local object a . m_ptr = nullptr ; // make sure the source no longer owns the pointer } // An assignment operator that implements move semantics Auto_ptr2 & operator = ( Auto_ptr2 & a ) // note: not const { if ( & a == this ) return * this ; delete m_ptr ; // make sure we deallocate any pointer the destination is already holding first m_ptr = a . m_ptr ; // then transfer our dumb pointer from the source to the local object a . m_ptr = nullptr ; // make sure the source no longer owns the pointer return * this ; } T & operator * () const { return * m_ptr ; } T * operator -> () const { return m_ptr ; } bool isNull () const { return m_ptr == nullptr ; } }; class Resource { public : Resource () { std :: cout << \"Resource acquired \\n \" ; } ~ Resource () { std :: cout << \"Resource destroyed \\n \" ; } }; int main () { Auto_ptr2 < Resource > res1 ( new Resource ()); Auto_ptr2 < Resource > res2 ; // Start as nullptr std :: cout << \"res1 is \" << ( res1 . isNull () ? \"null \\n \" : \"not null \\n \" ); std :: cout << \"res2 is \" << ( res2 . isNull () ? \"null \\n \" : \"not null \\n \" ); res2 = res1 ; // res2 assumes ownership, res1 is set to null std :: cout << \"Ownership transferred \\n \" ; std :: cout << \"res1 is \" << ( res1 . isNull () ? \"null \\n \" : \"not null \\n \" ); std :: cout << \"res2 is \" << ( res2 . isNull () ? \"null \\n \" : \"not null \\n \" ); return 0 ; } Note Avoid std::auto_ptr. This implmenents move semantics through the move and copy constructor. Passing it by value to a function will cause your resource to get moved to the function parameters (and destroyed when the function goes out of scope). It also deletes its contents using non-array delete, which means it won't work with dynamically allocated arays. It also doesn't play nice with a lot of the other classes in the std library. Consider it deprecated and don't use it. Before C++11 there was no mechanism to differentiate \"copy semantics\" from \"move semantics\". Because of this the concept of \"move\" was formally defined and move semantics added to the language to properly differentiate copying from moving. The std::auto_ptr has now been replaces with std::unique_ptr, std::weak_ptr and std::shared_ptr.","title":"Move semantics and smart pointers"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#r-value-references","text":"To understand move semantics we need to revisit the topic of r-values and l-values. Every expression in C++ has two properties: a type, and a value category . The value category is used for certain kinds of syntax checking. An l-value can be thought of as a function or object (or expression that evaluates to this). All l-values have memory addresses. They were originally defined as \"values that are suitable to be on the left-hand side of an assignment expression\". After the const keyword was added to the language, l-values were split into two sub-categories: modifiable and non-modifiable. An r-value is pretty much anything that is not an l-value. This includes literals, temp values, and anonymous objects. They are typically evaluated for their values, have expression scope, and cannot be assigned to. Because they are expression scope, as soon as assigning a value to them, they would already go out of scope. To support move semantics, C++11 introduced 3 new categories: pr-value, x-values, and gl-values, but we don't need to understand these to understand move semantics.","title":"R-value references"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#l-value-references","text":"Before C++11 this was the only type of reference. Now they are called l-value reference. These can only be initialized with modifiable l-values L-value reference Can be initialized with Can modify Modifiable l-values Yes Yes Non-modifiable l-values No No R-values No No L-value references to const object can be initialized with l-values and r-values alike. However, those values can't be modified. L-value reference to const Can be initialized with Can modify Modifiable l-values Yes No Non-modifiable l-values Yes No R-values Yes No These are particularly useful because they allow us to pass any type of argument without making a copy of the argument.","title":"L-value references"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#r-value-references_1","text":"As of C++11 there are now r-value references. These are designed to be initialized with r-values (only). They are created with a double &&. int x { 5 }; int & lref { x }; //l-value reference int && rref { 5 }; // r-value reference (cannot use x) They cannot be initialized with l-values R-value reference Can be initialized with Can modify Modifiable l-values No No Non-modifiable l-values No No R-values Yes Yes R-value reference to const Can be initialized with Can modify Modifiable l-values No No Non-modifiable l-values No No R-values Yes No Just like l-values references to const objects, r-value references extend the lifespan of the object they are initialized with to the lifespan of the r-value reference. They also allow you to modify they r-value! auto & lref { Fraction { 3 , 5 } }; // this won't compile because fraction is temp auto const & lref { Fraction { 3 , 5 } }; // this will compile but you can't change fraction because it only exists as a temp value. Note that this also extends the lifespane of Fraction. auto && rref { Fraction { 3 , 5 } }; // this will compile and you can change the fraction and no copies are created. R-values are almost never used in this way, they are most often used as function parameters for overloads when you want to have different behaviour for l-value and r-value arguments. void fun ( const int & lref ){ std :: cout << \"l-value \\n \" ; } void fun ( int && rref ){ std :: cout << \"r-value \\n \" ; }","title":"R-value references"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#move-constructors-and-move-assignments","text":"","title":"Move constructors and move assignments"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#copy-semantics-review","text":"Copy assignment is used to copy one class to another existing class. These constructors are provided by default for all classes unless the user specifies one. These copies do shallow copies, which may cause problems for classes that allocate dynamic memory, so classes that deal with dynamic memory should override these functions to do deep copies. Let's go back to our Auto_ptr class to see how this works. template < class T > class Auto_ptr3 { T * m_ptr ; public : Auto_ptr3 ( T * ptr = nullptr ) : m_ptr ( ptr ) { } ~ Auto_ptr3 () { delete m_ptr ; } // Copy constructor // Do deep copy of a.m_ptr to m_ptr Auto_ptr3 ( const Auto_ptr3 & a ) { m_ptr = new T ; * m_ptr = * a . m_ptr ; } // Copy assignment // Do deep copy of a.m_ptr to m_ptr Auto_ptr3 & operator = ( const Auto_ptr3 & a ) { // Self-assignment detection if ( & a == this ) return * this ; // Release any resource we're holding delete m_ptr ; // Copy the resource m_ptr = new T ; * m_ptr = * a . m_ptr ; return * this ; } T & operator * () const { return * m_ptr ; } T * operator -> () const { return m_ptr ; } bool isNull () const { return m_ptr == nullptr ; } }; This still makes for a lot of resource creation and destruction. Every time the pointer is created or returned it does a deep copy of everything. This doesn't crash, but it's quite inefficient! Move semantics fixes this. Here is the same class using r-value references: template < class T > class Auto_ptr4 { T * m_ptr ; public : Auto_ptr4 ( T * ptr = nullptr ) : m_ptr ( ptr ) { } ~ Auto_ptr4 () { delete m_ptr ; } // Move constructor // Transfer ownership of a.m_ptr to m_ptr Auto_ptr4 ( Auto_ptr4 && a ) noexcept : m_ptr ( a . m_ptr ) { a . m_ptr = nullptr ; // we'll talk more about this line below } // Move assignment // Transfer ownership of a.m_ptr to m_ptr Auto_ptr4 & operator = ( Auto_ptr4 && a ) noexcept { // Self-assignment detection if ( & a == this ) return * this ; // Release any resource we're holding delete m_ptr ; // Transfer ownership of a.m_ptr to m_ptr m_ptr = a . m_ptr ; a . m_ptr = nullptr ; // we'll talk more about this line below return * this ; } T & operator * () const { return * m_ptr ; } T * operator -> () const { return m_ptr ; } bool isNull () const { return m_ptr == nullptr ; } }; Now instead of creating and copying and destroying on assignment, the old pointer is set to null and the new pointer is pointed at the value. Moving the value makes it so that the pointer can be copied all over the place without the actual value changing. Note If you want a move constructor and move assignment that do moves, you'll need to write them yourself. Only in rare cases where all other constructors are obstructed will cpp auto-create one.","title":"Copy Semantics Review"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#key-insight","text":"If we do assignment or construct with an l-value, the only thing we can do is copy the l-value. We can't assume it's safe to alter the l-value, because it may be used again later in the program. a=b should never change b. If we do assignment or construction with an r-value, then we know that this is just a temp object anyway. Instead of copying this, we can then steal the resources from it to the object we're constructing or assignment. This is because that value will be discarded anyway! Because r-value references have a definition as of c++11, we can overload our constructor to use this more efficient method when r-values are provided to it. Note You should always re-assign your temp object to nullptr otherwise they will become dangling references. Otherwise when they are deconstructed they will delete the data of the pointer! Note Often it's desirable to disable the copy and assignment creator in move-enabled classes. This guides the user to use r-values instead.","title":"Key Insight"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#stdmove","text":"When you start using move semantics more, you'll often want to move things with l-values. std::move does just this. It assigns an empty value to the variable, and passes the value on as a r-value. template < class T > void myswap ( T & a , T & b ) { T tmp { std :: move ( a ) }; // invokes move constructor // a is now an empty string a = std :: move ( b ); // invokes move assignment b = std :: move ( tmp ); // invokes move assignment } std::move gives a hint to the compiler that the programmer doesn't need this object anymore in it's current state. Move functions should always leave your objects in a well-defined state so they don't crash your program when they go out of scope. This is also very useful when sorting an array of elements.","title":"std::move"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#stdmove_if_noexcept","text":"The noexcept exception specifier and operator is a guarantee to the compiler that a function or class will not raise any exceptions. Consider when we are coping an object, and this copy fails (e.g. the machine is out of memory). This doesn't harm the object being copied, and we move on. When moving, things aren't as simple. If the move operation brakes, then the original object will be empty and we might lose data. To comply with the strong exception guarantee that we want for our functions, we'd need to move the resource back to the source object. But there's no guarantee that move will work either. To counter this we have two options: Use noexcept on the constructor to prevent it from throwing an exception. Ust std::move_if_noexcept instead. Note std::move_if_noexcept will return a movable r-value if the object has a noexcept move constructor, otherwise it will return a copyable l-value. This is great especially for templates where you might not be sure if a class has a noexcept constructor. This noexcept is not a compile-time guarantee, it's still up to the person writing the noexcept functions to wrap things up properly in a try catch block. The standard library uses noexcept a lot along with move_if_noexcept. It's useful, but not a guarantee.","title":"std::move_if_noexcept"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#stdunique_ptr","text":"If a function exits early, or throws an exception, there's a chance that your pointers might now get deleted. A smart pointer can offer other features, but the basic functionality of it is that it manages a dynamically allocated resources on the heap, and ensures destruction of that resource whenever the pointer goes out of scope. Note Never dynamically allocate smart pointers themselves. If the smart pointer is never cleaned up, it will never clean up the object it's pointing to and the whole purpose of it will be invalid. std::unique_ptr is the C++11 replacement for std::auto_ptr. This should be used to manage any dynamically allocated object that is not shared by multiple pointers. It also properly implements move semantics. res2 = res1 ; // Won't compile: copy assignment is disabled res2 = std :: move ( res1 ); // res2 assumes ownership, res1 is set to null Because it's designed with move semantics, copy initialization and copy assignment are disabled. Move semantics are the only way to transfer ownership. std::unique_ptr has overloaded * and -> operators that work just like with regular pointers. Before using them you should check that the resource exists. This is easy because the implicit cast to bool return true if it's managing a resources. std :: unique_ptr < Resource > res { new Resource {} }; if ( res ) // use implicit cast to bool to ensure res contains a Resource std :: cout << * res << '\\n' ; // print the Resource that res is owning std::unique_ptr works well with arrays. Rule Favor std::array, std::vector, or std::string over a smart pointer managing a fixed array, dynamic array, or c-style string. As of C++14 there is also std::make_unique(), which is the preferred way to create smart pointers. It not only is more readable, but it handles some exceptions that can result form C++ leaving the order of evaluation for function arguments unspecified. Rule use std::make_unique() instead of creating std::unique_ptr and using new yourself. auto f1 { std :: make_unique < object > ( arg , arg ) }; Always return std::unique_ptr by value - the internals will apply the correct move semantics. std :: unique_ptr < Resource > createResource () { return std :: make_unique < Resource > (); } Likewise always pass std::unique_ptr by value into functions, and use std::move to put it into the arg. The compiler will force you to use std::move because copy semantics for std::unique_ptr have been disabled. // takeOwnership(ptr); // This doesn't work, need to use move semantics takeOwnership ( std :: move ( ptr )); // ok: use move semantics Even though this is possible, usually you won't want the function to take ownership of the pointer. If it took ownership, then the pointer would be destroyed afterwards. Just pass the resource the pointer is pointing to itself, by pointer or reference. This way the function can remain agnostic as to how the caller is managing resources. You can use get() on a std::unique_ptr to get the resource. In this case you don't want to delete the pointer at the end of the function since the memory will still be in use afterwards. void useResource ( Resource * res ) { if ( res ) std :: cout << * res << '\\n' ; } auto ptr { std :: make_unique < Resource > () }; useResource ( ptr . get ()); // note: get() used here to get a pointer to the Resource You can use std::unique_ptr as part of your classes, but remember that if the class itself is dynamically allocated and not cleaned up using smart pointers won't make a difference. Two things to avoid with mart pointers Don't let multiple classes manage the same resource. Resource * res { new Resource () }; std :: unique_ptr < Resource > res1 { res }; std :: unique_ptr < Resource > res2 { res }; Both res1 and res2 will try to delete the same resource after going out of scope, which will lead to undefined behaviour. Don't manually delete the resource out from underneath the std::unique_ptr Resource * res { new Resource () }; std :: unique_ptr < Resource > res1 { res }; delete res ;","title":"std::unique_ptr"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#stdshared_ptr","text":"This is the class for when you want multiple smart pointers pointing at the same resource. // allocate a Resource object and have it owned by std::shared_ptr Resource * res = new Resource ; std :: shared_ptr < Resource > ptr1 ( res ); { std :: shared_ptr < Resource > ptr2 ( ptr1 ); // use copy initialization to make another std::shared_ptr pointing to the same thing // DO NOT DO IT LIKE THIS std :: shared_ptr < Resource > ptr2 ( res ); // this will then kill the resource if going out of scope std :: cout << \"Killing one shared pointer \\n \" ; } // ptr2 goes out of scope here, but nothing happens std :: cout << \"Killing another shared pointer \\n \" ; As you can see above, it's important to create std::shared_ptr that point at the same resources from each other. Rule Always make a copy of an exisiting std::shared_ptr if you need more than one std::shared_ptr pointing to the same resource","title":"std::shared_ptr"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#stdmake_shared","text":"Like with std::make_unique, it's better to use std:make_shared. int main () { // allocate a Resource object and have it owned by std::shared_ptr auto ptr1 = std :: make_shared < Resource > (); { auto ptr2 = ptr1 ; // create ptr2 using copy initialization of ptr1 std :: cout << \"Killing one shared pointer \\n \" ; } // ptr2 goes out of scope here, but nothing happens std :: cout << \"Killing another shared pointer \\n \" ; return 0 ; } // ptr1 goes out of scope here, and the allocated Resource is destroyed Internally, std::shared_ptr uses two pointers. One poitns at the resource bing managed, the other at a \"control block\" which dynamically allocated and tracks a bunch of stuff like how many instances of the shared_ptr there are. You can convert std::shared_ptr from std::unique_ptr, but you can't convert a std::stared_ptr into a std::unique_ptr. Just like std::unique_ptr you have to worry about the pointer itself being properly disposed of. And not just one, but all instances of the shared_ptr. The resource will be deallocated with the last std::shared_ptr managing the resource is destroyed.","title":"std::make_shared"},{"location":"cpp/LearnCpp.com/020M_Move_semantics_and_smart_pointers/#circular-dependency-issues-with-stdstared_ptr-and-stdweak_ptr","text":"Circular references are a series of references where each object references the next, and the last object references back to the first, creating a loop. They do not need to be actual references, they can be pointers, unique ID's or any other means of identifying specific objects. A points at B, B points at C, C points at A. If these go out of scope like this, none of the objects will be deallocated if they are shared pointers, because there's no place to start deallocating. The same thing also happens with a std::shared_ptr referencing the object that contains it. std::weak_ptr is designed to solve this cyclical ownership problem. It is an observer, it can observe and access the same object as a std::shared_ptr, but is not considered an owner. So functionally a std::weak_ptr is the same as a std::shared_ptr, but it doesn't count as a \"user\" of the object. The annoying thing is to use the ptr you need to convert it to a std::shared_ptr first. #include <iostream> #include <memory> // for std::shared_ptr and std::weak_ptr #include <string> class Person { std :: string m_name ; std :: weak_ptr < Person > m_partner ; // note: This is now a std::weak_ptr public : Person ( const std :: string & name ) : m_name ( name ) { std :: cout << m_name << \" created \\n \" ; } ~ Person () { std :: cout << m_name << \" destroyed \\n \" ; } friend bool partnerUp ( std :: shared_ptr < Person > & p1 , std :: shared_ptr < Person > & p2 ) { if ( ! p1 || ! p2 ) return false ; p1 -> m_partner = p2 ; p2 -> m_partner = p1 ; std :: cout << p1 -> m_name << \" is now partnered with \" << p2 -> m_name << \" \\n \" ; return true ; } const std :: shared_ptr < Person > getPartner () const { return m_partner . lock (); } // use lock() to convert weak_ptr to shared_ptr const std :: string & getName () const { return m_name ; } }; int main () { auto lucy = std :: make_shared < Person > ( \"Lucy\" ); auto ricky = std :: make_shared < Person > ( \"Ricky\" ); partnerUp ( lucy , ricky ); auto partner = ricky -> getPartner (); // get shared_ptr to Ricky's partner std :: cout << ricky -> getName () << \"'s partner is: \" << partner -> getName () << '\\n' ; return 0 ; }","title":"Circular dependency issues with std::stared_ptr and std:weak_ptr."},{"location":"cpp/LearnCpp.com/020_Exceptions/","text":"Exceptions If a function fails, a common practice is to use the return code to determine if it did so. This could be a bool or commonly -1 if it failed for int return types. This has a few drawbacks - mainly that it's cryptic, and that the return type is not always something that you can set to explicitly false. In some functions -1 is a valid return type, so the user might be unsure if this is an error or expected behaviour. What you can do is to put the result of the function into a reference type like so: double divide ( int x , int y , bool & success ) { if ( y == 0 ) { success = false ; return 0.0 ; } success = true ; return static_cast < double > ( x ) / y ; } This still needs to be checked constantly, and the user of the function needs to remember to check it constantly. This is also not going to work inside of object constructors. What if something goes catastrophically wrong in a cosntructor? Enter: Exceptions. Exception handling provides a mechanism do decuople handling of errors or other exceptional circumstances from the typical control flow of your code. There are three keywords that are used to implement exceptions in cpp. Throw A throw statement is used to signal that an exception has occurred. This is also called raising an exception. You do this with the throw keywoard, followed by a value of any data type you wish to use to signal that an error has occured. throw -1 ; // throw a literal integer value throw ENUM_INVALID_INDEX ; // throw an enum value throw \"Can not take square root of negative number\" ; // throw a literal C-style (const char*) string throw dX ; // throw a double variable that was previously defined throw MyException ( \"Fatal Error\" ); // Throw an object of class MyException Try How do you catch exceptions? Once they are thrown by a function, do you always want your program to stop? The try block runs statements that could potentially generate exceptions and catches them without necessarily stopping the program. Catch After the exceptions have been gathered by the try block, they are handled by the catch block . Try and catch blocks work together. A try block detects the exceptions, and the catch block handles them. Here's an example of them all working together: try { // Statements that may throw exceptions you want to handle go here throw -1 ; // here's a trivial example } catch ( int x ) { // Any exceptions of type int thrown within the above try block get sent here std :: cerr << \"We caught an int exception with value: \" << x << '\\n' ; } catch ( double ) // no variable name since we don't use the exception itself in the catch block below { // Any exceptions of type double thrown within the above try block get sent here std :: cerr << \"We caught an exception of type double\" << '\\n' ; } catch ( const std :: string & str ) // catch classes by const reference { // Any exceptions of type std::string thrown within the above try block get sent here std :: cerr << \"We caught an exception of type std::string\" << '\\n' ; } std :: cout << \"Continuing on our merry way \\n \" ; After an exception is thrown in a try block, the rest of the block is ignored and the program jumps straight to the catch block. Typically if an exception is routed to a catch block, it's considered handled. These are three common things that catch blocks do: print an error (to console or log) return an error code back to caller throw another exception for the next catch block to handle Exceptions with Functions Exceptions thrown within functions get passed up the stack until they are detected in a try block. The process of tracing them up the stack is called unwinding the stack . The interesting part is that you can throw exceptions in a valid way in functions without the code being directly in a try block. This is helpful because different applications my want to handle the exception in different ways. Note that program execution is suspended all the way up the stack until the exception is caught. This is very great for skipping out on code dependant on a certain variable being a certain way. Uncaught exceptions and catch-all handlers If an exception is not caught your program will terminate.... often unexpectedly. This is something you want to avoid. To deal with unknown exceptions completely crashing your program, you can use a catch-all handler . It's done, quit simple, by using ellipsis. catch (...){ // catch all handler std : cout << \"We caught an exception of undetermined type \\n \" ; } Often this is left empty to ignore all uncaught exceptions. It will keep the stack unwinding to the top of your program, but not do any specific error handling. This is a common use of the catch all handler: int main () { try { runGame (); } catch (...) { std :: cerr << \"Abnormal termination \\n \" ; } saveState (); // Save user's game return 1 ; } Exception, classes and inheritance Because the type of exception can be ambiguous, it makes sense to throw exception classes . These are a standardized class that you can assume will be thrown. Any class can be an exception class, but it makes sense to have them store an error string like so : class ArrayException { private : std :: string m_error ; public : ArrayException ( std :: string error ) : m_error { error } { } const char * getError () const { return m_error . c_str (); } }; Note Exception handlers should catch class exception object by reference instead of by value. This prevents the compiler from making a copy of the exception. Exception handler will not only catch classes of a type, but also all classes derived from that type. Remember to catch the exceptions in the reverse order or class inheritance if you do so. try { throw Derived (); } catch ( const Base & base ) { std :: cerr << \"caught Base\" ; } catch ( const Derived & derived ) { std :: cerr << \"caught Derived\" ; } The above will print \"caught Base\". To get it to catch derived properly the derived catch must be before the base catch. Writing your own exception class kind of just adds more exception standards, so usually you will be using or inheriting from std::exception. It's a small class designed to serve as a base to any exception thrown by the standard library. Thanks to std::exception, we can set up an exception handler to catch all exceptions in the standard library! #include <exception> // for std::exception #include <limits> #include <string> // for this example int main () { try { // Your code using standard library goes here // We'll trigger one of these exceptions intentionally for the sake of the example std :: string s ; s . resize ( std :: numeric_limits < std :: size_t >:: max ()); // will trigger a std::length_error or allocation exception } // This handler will catch std::exception and all the derived exceptions too catch ( const std :: exception & exception ) { std :: cerr << \"Standard exception: \" << exception . what () << '\\n' ; } return 0 ; } Interesting to note is that std::exception has a what() function that returns a C-style string description of the exception. If subclassing, this is what you want to overwrite to add the description for your own exception. Using inheritance we can use specific handlers to target specific derived exception classes. Note Nothing throws a std::exception directly, and neighter should you. A list of standard exceptions can be found here Re-throwing exceptions Sometimes you want to pass an exception up the stack. You can do this by throwing another exception in your catch block. int getIntValueFromDatabase ( Database * d , std :: string table , std :: string key ) { assert ( d ); try { return d -> getIntValue ( table , key ); // throws int exception on failure } catch ( int exception ) { // Write an error to some global logfile g_log . logError ( \"doSomethingImportant failed\" ); throw 'q' ; // throw char exception 'q' up the stack to be handled by caller of getIntValueFromDatabase() } } What you should not do is to re-throw the same exception like this. int getIntValueFromDatabase ( Database * d , std :: string table , std :: string key ) { assert ( d ); try { return d -> getIntValue ( table , key ); // throws Derived exception on failure } catch ( Base & exception ) { // Write an error to some global logfile g_log . logError ( \"doSomethingImportant failed\" ); throw exception ; // Danger: this throws a Base object, not a Derived object } } This is slicing the derived object that's being returned! The right way to re-throw the exception is to use the throw keyword again. try { throw Derived {}; } catch ( Base & b ) { std :: cout << \"Caught Base b, which is actually a \" ; b . print (); std :: cout << \" \\n \" ; throw ; // note: We're now rethrowing the object here } Function Try blocks What if you want to catch an expression within a constructor? For this you need a function try block class B : public A { public : B ( int x ) try : A ( x ) // note addition of try keyword here { } catch (...) // note this is at same level of indentation as the function itself { // Exceptions from member initializer list or constructor body are caught here std :: cerr << \"Exception caught \\n \" ; // If an exception isn't explicitly thrown here, the current exception will be implicitly rethrown } }; These try blocks can catch both base and current class exceptions. Don't try to use these to clean up resources, after the constructor has failed the object is considered undefined behaviour. Exception dangers and downsides One of the biggest problems with exceptions is manually allocated data. In this case the catch needs to clean up the data or it will leak. What are some ways to do this for pointers that would otherwise go out of scope? One way is to declare the pointer outside of the try block. Another is to use a std::unique_ptr . This will automatically deallocate the pointer when going out of scope. Note Exceptions should never be thrown in destructors. Write a message to a log file instead. When should you use exceptions? * The error being handles is likely to occur only infrequently (performance consideration) * The error is serious and execution could not continue otherwise * The error cannot be handled at the place where it occurs. * There isn't a good alternative way to return an error code back to the caller Exception specifications and noexcept. How can you tell if a function is going to be throwing an exception or not? All functions in C++ are classified as either non-throwing or potentially throwing . Exception specifications are a language mechanism that was originally designed to document what kind of exceptions a function might throw as a part of a function specification. If you want to specifically defined your function as not throwing exceptions, you use the noexcept specifier void dosomething () noexcept ; // this function is non-throwing The following functions are non-throwing by default default constructors copy constructors move constructors destructors copy assignment operators move assignment operators You should still tag them as noexcept if you want to specify them as non-throwing, because they might be calling other functions which might be throwing. You can know if a function is throwing or not by using noexcept. void foo () { throw -1 ;} void boo () {}; void goo () noexcept {}; struct S {}; constexpr bool b1 { noexcept ( 5 + 3 ) }; // true; ints are non-throwing constexpr bool b2 { noexcept ( foo ()) }; // false; foo() throws an exception constexpr bool b3 { noexcept ( boo ()) }; // false; boo() is implicitly noexcept(false) constexpr bool b4 { noexcept ( goo ()) }; // true; goo() is explicitly noexcept(true) constexpr bool b5 { noexcept ( S {}) }; // true; a struct's default constructor is noexcept by default Exception safety guarantees are contractual guidelines about how functions will behave in the event an exception occurs. There are four levels of safety. No guarantee -- anything could happen Basic guarantee -- if an exception is thrown, no memory will be leaked and the object is still usable, but the program may be left in a modified state. Strong guarantee -- If an exception is thrown, no memory will be leaked and the program state will not be changed. This means the function must either completely succeed or have no side effects if it fails. This is easy if the failure happens before anything is modified in the first place, but can also be achieved by rolling back any changes so the program is return to the pre-failure state. No throw/ No fail -- the function will always succeed or fail without throwing an exception. For example, all destructors should have a no-throw guarantee, as well as all functions that destructors might call. Note Use the noexcep specifier in specific cases where you want to express a no-fail or no-throw guarantee. Better to err on the side of caution and not mark it with noexcept. Why should functions be marked as non-throwing? They can safely be used in destructors and other dangerous contexts They can enable the compiler to perform some optimizations that would not otherwise be available. Some libraries are optimized for noexcept.","title":"Exceptions"},{"location":"cpp/LearnCpp.com/020_Exceptions/#exceptions","text":"If a function fails, a common practice is to use the return code to determine if it did so. This could be a bool or commonly -1 if it failed for int return types. This has a few drawbacks - mainly that it's cryptic, and that the return type is not always something that you can set to explicitly false. In some functions -1 is a valid return type, so the user might be unsure if this is an error or expected behaviour. What you can do is to put the result of the function into a reference type like so: double divide ( int x , int y , bool & success ) { if ( y == 0 ) { success = false ; return 0.0 ; } success = true ; return static_cast < double > ( x ) / y ; } This still needs to be checked constantly, and the user of the function needs to remember to check it constantly. This is also not going to work inside of object constructors. What if something goes catastrophically wrong in a cosntructor? Enter: Exceptions. Exception handling provides a mechanism do decuople handling of errors or other exceptional circumstances from the typical control flow of your code. There are three keywords that are used to implement exceptions in cpp.","title":"Exceptions"},{"location":"cpp/LearnCpp.com/020_Exceptions/#throw","text":"A throw statement is used to signal that an exception has occurred. This is also called raising an exception. You do this with the throw keywoard, followed by a value of any data type you wish to use to signal that an error has occured. throw -1 ; // throw a literal integer value throw ENUM_INVALID_INDEX ; // throw an enum value throw \"Can not take square root of negative number\" ; // throw a literal C-style (const char*) string throw dX ; // throw a double variable that was previously defined throw MyException ( \"Fatal Error\" ); // Throw an object of class MyException","title":"Throw"},{"location":"cpp/LearnCpp.com/020_Exceptions/#try","text":"How do you catch exceptions? Once they are thrown by a function, do you always want your program to stop? The try block runs statements that could potentially generate exceptions and catches them without necessarily stopping the program.","title":"Try"},{"location":"cpp/LearnCpp.com/020_Exceptions/#catch","text":"After the exceptions have been gathered by the try block, they are handled by the catch block . Try and catch blocks work together. A try block detects the exceptions, and the catch block handles them. Here's an example of them all working together: try { // Statements that may throw exceptions you want to handle go here throw -1 ; // here's a trivial example } catch ( int x ) { // Any exceptions of type int thrown within the above try block get sent here std :: cerr << \"We caught an int exception with value: \" << x << '\\n' ; } catch ( double ) // no variable name since we don't use the exception itself in the catch block below { // Any exceptions of type double thrown within the above try block get sent here std :: cerr << \"We caught an exception of type double\" << '\\n' ; } catch ( const std :: string & str ) // catch classes by const reference { // Any exceptions of type std::string thrown within the above try block get sent here std :: cerr << \"We caught an exception of type std::string\" << '\\n' ; } std :: cout << \"Continuing on our merry way \\n \" ; After an exception is thrown in a try block, the rest of the block is ignored and the program jumps straight to the catch block. Typically if an exception is routed to a catch block, it's considered handled. These are three common things that catch blocks do: print an error (to console or log) return an error code back to caller throw another exception for the next catch block to handle","title":"Catch"},{"location":"cpp/LearnCpp.com/020_Exceptions/#exceptions-with-functions","text":"Exceptions thrown within functions get passed up the stack until they are detected in a try block. The process of tracing them up the stack is called unwinding the stack . The interesting part is that you can throw exceptions in a valid way in functions without the code being directly in a try block. This is helpful because different applications my want to handle the exception in different ways. Note that program execution is suspended all the way up the stack until the exception is caught. This is very great for skipping out on code dependant on a certain variable being a certain way.","title":"Exceptions with Functions"},{"location":"cpp/LearnCpp.com/020_Exceptions/#uncaught-exceptions-and-catch-all-handlers","text":"If an exception is not caught your program will terminate.... often unexpectedly. This is something you want to avoid. To deal with unknown exceptions completely crashing your program, you can use a catch-all handler . It's done, quit simple, by using ellipsis. catch (...){ // catch all handler std : cout << \"We caught an exception of undetermined type \\n \" ; } Often this is left empty to ignore all uncaught exceptions. It will keep the stack unwinding to the top of your program, but not do any specific error handling. This is a common use of the catch all handler: int main () { try { runGame (); } catch (...) { std :: cerr << \"Abnormal termination \\n \" ; } saveState (); // Save user's game return 1 ; }","title":"Uncaught exceptions and catch-all handlers"},{"location":"cpp/LearnCpp.com/020_Exceptions/#exception-classes-and-inheritance","text":"Because the type of exception can be ambiguous, it makes sense to throw exception classes . These are a standardized class that you can assume will be thrown. Any class can be an exception class, but it makes sense to have them store an error string like so : class ArrayException { private : std :: string m_error ; public : ArrayException ( std :: string error ) : m_error { error } { } const char * getError () const { return m_error . c_str (); } }; Note Exception handlers should catch class exception object by reference instead of by value. This prevents the compiler from making a copy of the exception. Exception handler will not only catch classes of a type, but also all classes derived from that type. Remember to catch the exceptions in the reverse order or class inheritance if you do so. try { throw Derived (); } catch ( const Base & base ) { std :: cerr << \"caught Base\" ; } catch ( const Derived & derived ) { std :: cerr << \"caught Derived\" ; } The above will print \"caught Base\". To get it to catch derived properly the derived catch must be before the base catch. Writing your own exception class kind of just adds more exception standards, so usually you will be using or inheriting from std::exception. It's a small class designed to serve as a base to any exception thrown by the standard library. Thanks to std::exception, we can set up an exception handler to catch all exceptions in the standard library! #include <exception> // for std::exception #include <limits> #include <string> // for this example int main () { try { // Your code using standard library goes here // We'll trigger one of these exceptions intentionally for the sake of the example std :: string s ; s . resize ( std :: numeric_limits < std :: size_t >:: max ()); // will trigger a std::length_error or allocation exception } // This handler will catch std::exception and all the derived exceptions too catch ( const std :: exception & exception ) { std :: cerr << \"Standard exception: \" << exception . what () << '\\n' ; } return 0 ; } Interesting to note is that std::exception has a what() function that returns a C-style string description of the exception. If subclassing, this is what you want to overwrite to add the description for your own exception. Using inheritance we can use specific handlers to target specific derived exception classes. Note Nothing throws a std::exception directly, and neighter should you. A list of standard exceptions can be found here","title":"Exception, classes and inheritance"},{"location":"cpp/LearnCpp.com/020_Exceptions/#re-throwing-exceptions","text":"Sometimes you want to pass an exception up the stack. You can do this by throwing another exception in your catch block. int getIntValueFromDatabase ( Database * d , std :: string table , std :: string key ) { assert ( d ); try { return d -> getIntValue ( table , key ); // throws int exception on failure } catch ( int exception ) { // Write an error to some global logfile g_log . logError ( \"doSomethingImportant failed\" ); throw 'q' ; // throw char exception 'q' up the stack to be handled by caller of getIntValueFromDatabase() } } What you should not do is to re-throw the same exception like this. int getIntValueFromDatabase ( Database * d , std :: string table , std :: string key ) { assert ( d ); try { return d -> getIntValue ( table , key ); // throws Derived exception on failure } catch ( Base & exception ) { // Write an error to some global logfile g_log . logError ( \"doSomethingImportant failed\" ); throw exception ; // Danger: this throws a Base object, not a Derived object } } This is slicing the derived object that's being returned! The right way to re-throw the exception is to use the throw keyword again. try { throw Derived {}; } catch ( Base & b ) { std :: cout << \"Caught Base b, which is actually a \" ; b . print (); std :: cout << \" \\n \" ; throw ; // note: We're now rethrowing the object here }","title":"Re-throwing exceptions"},{"location":"cpp/LearnCpp.com/020_Exceptions/#function-try-blocks","text":"What if you want to catch an expression within a constructor? For this you need a function try block class B : public A { public : B ( int x ) try : A ( x ) // note addition of try keyword here { } catch (...) // note this is at same level of indentation as the function itself { // Exceptions from member initializer list or constructor body are caught here std :: cerr << \"Exception caught \\n \" ; // If an exception isn't explicitly thrown here, the current exception will be implicitly rethrown } }; These try blocks can catch both base and current class exceptions. Don't try to use these to clean up resources, after the constructor has failed the object is considered undefined behaviour.","title":"Function Try blocks"},{"location":"cpp/LearnCpp.com/020_Exceptions/#exception-dangers-and-downsides","text":"One of the biggest problems with exceptions is manually allocated data. In this case the catch needs to clean up the data or it will leak. What are some ways to do this for pointers that would otherwise go out of scope? One way is to declare the pointer outside of the try block. Another is to use a std::unique_ptr . This will automatically deallocate the pointer when going out of scope. Note Exceptions should never be thrown in destructors. Write a message to a log file instead. When should you use exceptions? * The error being handles is likely to occur only infrequently (performance consideration) * The error is serious and execution could not continue otherwise * The error cannot be handled at the place where it occurs. * There isn't a good alternative way to return an error code back to the caller","title":"Exception dangers and downsides"},{"location":"cpp/LearnCpp.com/020_Exceptions/#exception-specifications-and-noexcept","text":"How can you tell if a function is going to be throwing an exception or not? All functions in C++ are classified as either non-throwing or potentially throwing . Exception specifications are a language mechanism that was originally designed to document what kind of exceptions a function might throw as a part of a function specification. If you want to specifically defined your function as not throwing exceptions, you use the noexcept specifier void dosomething () noexcept ; // this function is non-throwing The following functions are non-throwing by default default constructors copy constructors move constructors destructors copy assignment operators move assignment operators You should still tag them as noexcept if you want to specify them as non-throwing, because they might be calling other functions which might be throwing. You can know if a function is throwing or not by using noexcept. void foo () { throw -1 ;} void boo () {}; void goo () noexcept {}; struct S {}; constexpr bool b1 { noexcept ( 5 + 3 ) }; // true; ints are non-throwing constexpr bool b2 { noexcept ( foo ()) }; // false; foo() throws an exception constexpr bool b3 { noexcept ( boo ()) }; // false; boo() is implicitly noexcept(false) constexpr bool b4 { noexcept ( goo ()) }; // true; goo() is explicitly noexcept(true) constexpr bool b5 { noexcept ( S {}) }; // true; a struct's default constructor is noexcept by default Exception safety guarantees are contractual guidelines about how functions will behave in the event an exception occurs. There are four levels of safety. No guarantee -- anything could happen Basic guarantee -- if an exception is thrown, no memory will be leaked and the object is still usable, but the program may be left in a modified state. Strong guarantee -- If an exception is thrown, no memory will be leaked and the program state will not be changed. This means the function must either completely succeed or have no side effects if it fails. This is easy if the failure happens before anything is modified in the first place, but can also be achieved by rolling back any changes so the program is return to the pre-failure state. No throw/ No fail -- the function will always succeed or fail without throwing an exception. For example, all destructors should have a no-throw guarantee, as well as all functions that destructors might call. Note Use the noexcep specifier in specific cases where you want to express a no-fail or no-throw guarantee. Better to err on the side of caution and not mark it with noexcept. Why should functions be marked as non-throwing? They can safely be used in destructors and other dangerous contexts They can enable the compiler to perform some optimizations that would not otherwise be available. Some libraries are optimized for noexcept.","title":"Exception specifications and noexcept."},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/","text":"The Standard Library The Standark library contains a collection of classes that provide templted containers, algorithms, and iterators. This is a high level look at some of the things in the standard library. STL containers overview The most used things are the container classes. There are six basic containers: std::vector The unfortunately named vector is a dynamic array capable of growing as needed to contain its elements. std :: vector < int > vect ; for ( int count = 0 ; count < 6 ; ++ count ) vect . push_back ( 10 - count ); // insert at end of array std::deque Pronounced \"deck\" this is a double-ended queue class which can grow from both ends. std :: deque < int > deq ; for ( int count = 0 ; count < 3 ; ++ count ) { deq . push_back ( count ); // insert at end of array deq . push_front ( 10 - count ); // insert at front of array } std::list A special type of sequence container called a doubly linked list , wher each element in the container contains pointers that point at the next and previous elements in the list. Only the start and end of the list are provided access to, there is no random access provided. You need to start and one end and \"walk the list\" until you reach the element you want to find. Inserting elements is super fast if you know where you want to insert them. Associative Containers These are containers that automatically sort their inputs when inserted to the container. They usually compare elements using <, so the elements will need an overloaded operator with that. std::set stores unique elements, with duplicates forbidden. The elements are sorted by their values std::multiset is a set where duplicate elements are allowed std::map (aka associative array) is a set where each element is a pair as in a key/value pair. The key is used for sorting and indexing the data. These are like dicts in python std::multimap (aka dictionary) is a map that allows duplicate keys. All the keys are automatically sorted in ascending order. Some words have multiple values, which is why a dictionary is a multimap rather than a map. container Adapters These are special predefined containers that are adapted to specific uses. std::stack is a container where elements operate in a LIFO (Last in, First out) context. As elements are pushed in (inserted), the ones at the end are popped (removed) from the container. std::queue is FIFO (First in, First out). Elements are pushed to the back and popped from the ront. Both of the above default to using deques, stack can also use vector or list, queue can also use list. std::priority_queue is a queue where the elements are kept sorted. The elements that are popped are always the ones of highest priority. STL iterators overview. Iterators are objects that iterate over a container class without the user caring about how the container is implemented. Particularly with lists and similar classes, iterators are the primary way to access their elements. It's good to think of them as pointers to a given element in the container, with overloaded operators to provide as set of common functions Operator * returns the element the iterator is currently pointing at Operator++ moves the iterator tot he next element. (Most also provide operator-- to move to previous element) Operator== and Operator!= compaer if two iterators point to the same element. Operator= Assign iterator to new position. This is different than assigning a value to what the iterator is pointing at. To do that you need to dereference the iterator first. There are also four basic member functions for use with Operator= std::begin() returns iterator pointing at beginning of container's elements std::end() returns iterator pointing to last of containers elements. std::cbegin() return const begin (can't change) std::cend() returns const end to the element after the last element in the container ( not the last ) - this is for more convenient looping. Each container also provides at least two types of iterators container::iterator read/write container::const_iterator read-only iterator Here's a basic example of using an iterator std :: vector < int > vect ; for ( int count = 0 ; count < 6 ; ++ count ) vect . push_back ( count ); std :: vector < int >:: const_iterator it ; // declare a read-only iterator it = vect . cbegin (); // assign it to the start of the vector while ( it != vect . cend ()){ // while it hasn't reach the end std :: cout << * it << \" \" ; // print the value of the element it points to ++ it ; // and iterate to the next element } This iteration code is essentially identical for all containers. STL algorithms overview These are algorithms for working with the elements of container classes. They are implements as functions that operator using iterators. In that way each algorithm only needs to be implemented once, and works with all container classes. Some combinations of algorithm + container won't work though, so you still have to think for yourself. std::min_element and std::max_element std :: list < int > li ( 6 ); // Fill li with numbers starting at 0. // iota produces a contiguous series of values std :: iota ( li . begin (), li . end (), 0 ); std :: cout << * std :: min_element ( li . begin (), li . end ()) << ' ' << * std :: max_element ( li . begin (), li . end ()) << '\\n' ; std::find and list::insert Find a value in the list class and use list::insert() to add a new value at that point std :: list < int > li ( 6 ); std :: iota ( li . begin (), li . end (), 0 ); // Find the value 3 in the list auto it { find ( li . begin (), li . end (), 3 ) }; if ( it == li . end ()){ std :: cout << \"3 was not found \\n \" ; } else { // Insert 8 right before 3. li . insert ( it , 8 ); for ( int i : li ) // for loop with iterators std :: cout << i << ' ' ; } If the search algorithm doesn't find what it's looking for, it will return the end iterator, so you need to check for this. std::sort and std::reverse How to sort a vector and reverse it std :: vector < int > vect { 7 , -3 , 6 , 2 , -5 , 0 , 4 }; // sort the vector std :: sort ( vect . begin (), vect . end ()); for ( int i : vect ) { std :: cout << i << ' ' ; } std :: cout << '\\n' ; // reverse the vector std :: reverse ( vect . begin (), vect . end ()); for ( int i : vect ) { std :: cout << i << ' ' ; } You can also pass a comparison function as the third argument for std::sort (remember lambdas? also in the header) This doesn't work on list container classes, but they provide their own sort() member function.","title":"The Standard Library"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#the-standard-library","text":"The Standark library contains a collection of classes that provide templted containers, algorithms, and iterators. This is a high level look at some of the things in the standard library.","title":"The Standard Library"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stl-containers-overview","text":"The most used things are the container classes. There are six basic containers:","title":"STL containers overview"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stdvector","text":"The unfortunately named vector is a dynamic array capable of growing as needed to contain its elements. std :: vector < int > vect ; for ( int count = 0 ; count < 6 ; ++ count ) vect . push_back ( 10 - count ); // insert at end of array","title":"std::vector"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stddeque","text":"Pronounced \"deck\" this is a double-ended queue class which can grow from both ends. std :: deque < int > deq ; for ( int count = 0 ; count < 3 ; ++ count ) { deq . push_back ( count ); // insert at end of array deq . push_front ( 10 - count ); // insert at front of array }","title":"std::deque"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stdlist","text":"A special type of sequence container called a doubly linked list , wher each element in the container contains pointers that point at the next and previous elements in the list. Only the start and end of the list are provided access to, there is no random access provided. You need to start and one end and \"walk the list\" until you reach the element you want to find. Inserting elements is super fast if you know where you want to insert them.","title":"std::list"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#associative-containers","text":"These are containers that automatically sort their inputs when inserted to the container. They usually compare elements using <, so the elements will need an overloaded operator with that. std::set stores unique elements, with duplicates forbidden. The elements are sorted by their values std::multiset is a set where duplicate elements are allowed std::map (aka associative array) is a set where each element is a pair as in a key/value pair. The key is used for sorting and indexing the data. These are like dicts in python std::multimap (aka dictionary) is a map that allows duplicate keys. All the keys are automatically sorted in ascending order. Some words have multiple values, which is why a dictionary is a multimap rather than a map.","title":"Associative Containers"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#container-adapters","text":"These are special predefined containers that are adapted to specific uses. std::stack is a container where elements operate in a LIFO (Last in, First out) context. As elements are pushed in (inserted), the ones at the end are popped (removed) from the container. std::queue is FIFO (First in, First out). Elements are pushed to the back and popped from the ront. Both of the above default to using deques, stack can also use vector or list, queue can also use list. std::priority_queue is a queue where the elements are kept sorted. The elements that are popped are always the ones of highest priority.","title":"container Adapters"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stl-iterators-overview","text":"Iterators are objects that iterate over a container class without the user caring about how the container is implemented. Particularly with lists and similar classes, iterators are the primary way to access their elements. It's good to think of them as pointers to a given element in the container, with overloaded operators to provide as set of common functions Operator * returns the element the iterator is currently pointing at Operator++ moves the iterator tot he next element. (Most also provide operator-- to move to previous element) Operator== and Operator!= compaer if two iterators point to the same element. Operator= Assign iterator to new position. This is different than assigning a value to what the iterator is pointing at. To do that you need to dereference the iterator first. There are also four basic member functions for use with Operator= std::begin() returns iterator pointing at beginning of container's elements std::end() returns iterator pointing to last of containers elements. std::cbegin() return const begin (can't change) std::cend() returns const end to the element after the last element in the container ( not the last ) - this is for more convenient looping. Each container also provides at least two types of iterators container::iterator read/write container::const_iterator read-only iterator Here's a basic example of using an iterator std :: vector < int > vect ; for ( int count = 0 ; count < 6 ; ++ count ) vect . push_back ( count ); std :: vector < int >:: const_iterator it ; // declare a read-only iterator it = vect . cbegin (); // assign it to the start of the vector while ( it != vect . cend ()){ // while it hasn't reach the end std :: cout << * it << \" \" ; // print the value of the element it points to ++ it ; // and iterate to the next element } This iteration code is essentially identical for all containers.","title":"STL iterators overview."},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stl-algorithms-overview","text":"These are algorithms for working with the elements of container classes. They are implements as functions that operator using iterators. In that way each algorithm only needs to be implemented once, and works with all container classes. Some combinations of algorithm + container won't work though, so you still have to think for yourself.","title":"STL algorithms overview"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stdmin_element-and-stdmax_element","text":"std :: list < int > li ( 6 ); // Fill li with numbers starting at 0. // iota produces a contiguous series of values std :: iota ( li . begin (), li . end (), 0 ); std :: cout << * std :: min_element ( li . begin (), li . end ()) << ' ' << * std :: max_element ( li . begin (), li . end ()) << '\\n' ;","title":"std::min_element and std::max_element"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stdfind-and-listinsert","text":"Find a value in the list class and use list::insert() to add a new value at that point std :: list < int > li ( 6 ); std :: iota ( li . begin (), li . end (), 0 ); // Find the value 3 in the list auto it { find ( li . begin (), li . end (), 3 ) }; if ( it == li . end ()){ std :: cout << \"3 was not found \\n \" ; } else { // Insert 8 right before 3. li . insert ( it , 8 ); for ( int i : li ) // for loop with iterators std :: cout << i << ' ' ; } If the search algorithm doesn't find what it's looking for, it will return the end iterator, so you need to check for this.","title":"std::find and list::insert"},{"location":"cpp/LearnCpp.com/021_The_Standard_Library/#stdsort-and-stdreverse","text":"How to sort a vector and reverse it std :: vector < int > vect { 7 , -3 , 6 , 2 , -5 , 0 , 4 }; // sort the vector std :: sort ( vect . begin (), vect . end ()); for ( int i : vect ) { std :: cout << i << ' ' ; } std :: cout << '\\n' ; // reverse the vector std :: reverse ( vect . begin (), vect . end ()); for ( int i : vect ) { std :: cout << i << ' ' ; } You can also pass a comparison function as the third argument for std::sort (remember lambdas? also in the header) This doesn't work on list container classes, but they provide their own sort() member function.","title":"std::sort and std::reverse"},{"location":"cpp/LearnCpp.com/022_std%3A%3Astring/","text":"std::string C-style strings have many shortcomings, primarily revolving around the fact that you have to do all the memory management yourself. char * stdHello = new char [ 7 ]; // don't forget to account for an extra null terminator! strcopy ( strHello , \"hello!\" ); // then you have to copy the value in char by char // Hopefully you made your buffer large enogh so there's no buffer overflow! // and of course you have to remember to delete it as wel delete [] strHello ; // don't forget to use array deleted There are 3 different string classes in the header. basic_string is the superclass that string and wstring are derived from. std::string is used for standard ascii and utf-8 strings, and std::wstring is used for utf-16 strings. There is no class for utf-32 strings, but it wouldn't be hard to make one. All the functionality is implemented in basic_string, with the only different in string and wstring being their size. There are a couple of things that the std::string does not include: RegEx support Creating strings from numbers Capitalization Case-insensitive comparisons Tokenization / splitting into array Easy function for getting left or right hand portion of string Whitespace trimming Formatting the string in sprintf style Conversion from utf-8 to utf-16 std::strnig construction and destruction std :: string Source { \"myString\" }; //default constructor std :: string sOutput { sSource }; // copy constructor std :: string trimmed { sSource , \"4\" }; const char * szSource { \"my string\" }; std :: string CStyle { szSource }; //cstyle constructor std :: string CStyleTrimemd { szSource , 3 }; //cstyle constructor of only the first 3 characters std :: string sOutput ( 4 , 'Q' ); // create a string of 4 Q chars There is no way to create a string from numbers using . The easiest way to work aroundt his is to use std::ostringstream, which is set up to accept input from a variety of sources. #include <iostream> #include <sstream> #include <string> template < typename T > inline std :: string ToSTring ( T tX ){ std :: ostringstream oStream ; return ! ( oStream << tX ). fail (); //extract value into tX ,return success or not } You can find the length of a string with // these two are identical int len = string . length (); int len = string . size (); int max_size = string . max_size () // the maximum amount of characters allowed in a string Instead of using (s.length() == 0) use s.empty() You can get the capacity of a string to find out how much memory it has allocated for. Strings generally try to allocate more memory than they need because re-allocation is expensive. If you know your string will need a certain amount in the future, you can use string.reserve() to pre-allocate the string to a certain capacity. std :: srand ( std :: time ( nullptr )); // seed random number generator string sString {}; // length 0 sString . reserve ( 64 ); // reserve 64 characters // Fill string up with random lower case characters for ( int nCount { 0 }; nCount < 64 ; ++ nCount ) sString += 'a' + std :: rand () % 26 ; When accessing a string's characters outside of it's range will lead to undefined behaviour. string.at() will provide an out_of_range exception if this is tried, and is therefore safer. You can convert strings into c-style arrays in the different ways std :: string myString { \"mystring\" }; const char * cString { myString . c_str ()}; // cString is owned by std::string and should not be deleted char * cStringData { myString . data ()}; // cStringData is owned by std:string and should not be deleted const char * cStringDataConst { myString . data ()}; // same as above char szBuf [ 20 ] : int nLength { static_cast < int > ( sSource . copy ( szBuf , 5 , 10 )) }; // copy the string to the buffer - it's up to the caller to ensure szBuf is initialized to NULL or terminate the string using the returned length and not overloadin szBuf szBuf [ nLength ] = '\\0' ; // make sure to terminate string in buffer You can assign a value to a string using the overloaded operator= function, or string.assign(). string sString ; sString = string ( \"one\" ); // Assigne a string value sString = \"two\" ; // Assignea c-style string sString = '5' ; // Assign a char sString . assign ( \"Four\" ); // use the assign functions oString = \"Buffallo\" ; sString . assign ( oString , 2 , 4 ); // assign a substring from index 2 to 6 (length 4) sString . swap ( oString ); // swap the values of oString and sString Appending strings has several forms as well string sString { \"My GREATEST string\" }; sString += string ( \" nope\" ); // add two string objects sString . append ( \" nope\" ); // same as above - both also work on c-style strings sString . append ( \" copppiy\" , 4 ); // only append the first four chars sString . pushBack ( \" nope\" ); same as append but with stack terminology Inserting strings string sString { \"Hello there\" }; sString . insert ( 5 , \" my dog\" ); // insert from index 5 of the string sString . insert ( 5 , \" my dog ate christmas\" , 0 , 6 ); // produces same result as above by using the substring chars 0-6 sString . insert ( 5 , \" my dog ate christmas\" , 6 ); // same as above sString . insert ( 5 , 3 , 'i' ); // \"Helloiii there\"","title":"std::string"},{"location":"cpp/LearnCpp.com/022_std%3A%3Astring/#stdstring","text":"C-style strings have many shortcomings, primarily revolving around the fact that you have to do all the memory management yourself. char * stdHello = new char [ 7 ]; // don't forget to account for an extra null terminator! strcopy ( strHello , \"hello!\" ); // then you have to copy the value in char by char // Hopefully you made your buffer large enogh so there's no buffer overflow! // and of course you have to remember to delete it as wel delete [] strHello ; // don't forget to use array deleted There are 3 different string classes in the header. basic_string is the superclass that string and wstring are derived from. std::string is used for standard ascii and utf-8 strings, and std::wstring is used for utf-16 strings. There is no class for utf-32 strings, but it wouldn't be hard to make one. All the functionality is implemented in basic_string, with the only different in string and wstring being their size. There are a couple of things that the std::string does not include: RegEx support Creating strings from numbers Capitalization Case-insensitive comparisons Tokenization / splitting into array Easy function for getting left or right hand portion of string Whitespace trimming Formatting the string in sprintf style Conversion from utf-8 to utf-16","title":"std::string"},{"location":"cpp/LearnCpp.com/022_std%3A%3Astring/#stdstrnig-construction-and-destruction","text":"std :: string Source { \"myString\" }; //default constructor std :: string sOutput { sSource }; // copy constructor std :: string trimmed { sSource , \"4\" }; const char * szSource { \"my string\" }; std :: string CStyle { szSource }; //cstyle constructor std :: string CStyleTrimemd { szSource , 3 }; //cstyle constructor of only the first 3 characters std :: string sOutput ( 4 , 'Q' ); // create a string of 4 Q chars There is no way to create a string from numbers using . The easiest way to work aroundt his is to use std::ostringstream, which is set up to accept input from a variety of sources. #include <iostream> #include <sstream> #include <string> template < typename T > inline std :: string ToSTring ( T tX ){ std :: ostringstream oStream ; return ! ( oStream << tX ). fail (); //extract value into tX ,return success or not } You can find the length of a string with // these two are identical int len = string . length (); int len = string . size (); int max_size = string . max_size () // the maximum amount of characters allowed in a string Instead of using (s.length() == 0) use s.empty() You can get the capacity of a string to find out how much memory it has allocated for. Strings generally try to allocate more memory than they need because re-allocation is expensive. If you know your string will need a certain amount in the future, you can use string.reserve() to pre-allocate the string to a certain capacity. std :: srand ( std :: time ( nullptr )); // seed random number generator string sString {}; // length 0 sString . reserve ( 64 ); // reserve 64 characters // Fill string up with random lower case characters for ( int nCount { 0 }; nCount < 64 ; ++ nCount ) sString += 'a' + std :: rand () % 26 ; When accessing a string's characters outside of it's range will lead to undefined behaviour. string.at() will provide an out_of_range exception if this is tried, and is therefore safer. You can convert strings into c-style arrays in the different ways std :: string myString { \"mystring\" }; const char * cString { myString . c_str ()}; // cString is owned by std::string and should not be deleted char * cStringData { myString . data ()}; // cStringData is owned by std:string and should not be deleted const char * cStringDataConst { myString . data ()}; // same as above char szBuf [ 20 ] : int nLength { static_cast < int > ( sSource . copy ( szBuf , 5 , 10 )) }; // copy the string to the buffer - it's up to the caller to ensure szBuf is initialized to NULL or terminate the string using the returned length and not overloadin szBuf szBuf [ nLength ] = '\\0' ; // make sure to terminate string in buffer You can assign a value to a string using the overloaded operator= function, or string.assign(). string sString ; sString = string ( \"one\" ); // Assigne a string value sString = \"two\" ; // Assignea c-style string sString = '5' ; // Assign a char sString . assign ( \"Four\" ); // use the assign functions oString = \"Buffallo\" ; sString . assign ( oString , 2 , 4 ); // assign a substring from index 2 to 6 (length 4) sString . swap ( oString ); // swap the values of oString and sString Appending strings has several forms as well string sString { \"My GREATEST string\" }; sString += string ( \" nope\" ); // add two string objects sString . append ( \" nope\" ); // same as above - both also work on c-style strings sString . append ( \" copppiy\" , 4 ); // only append the first four chars sString . pushBack ( \" nope\" ); same as append but with stack terminology Inserting strings string sString { \"Hello there\" }; sString . insert ( 5 , \" my dog\" ); // insert from index 5 of the string sString . insert ( 5 , \" my dog ate christmas\" , 0 , 6 ); // produces same result as above by using the substring chars 0-6 sString . insert ( 5 , \" my dog ate christmas\" , 6 ); // same as above sString . insert ( 5 , 3 , 'i' ); // \"Helloiii there\"","title":"std::strnig construction and destruction"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/","text":"Input and output (IO) The iostream library uses multiple inheritance. A stream is a sequence of bytes that can be accessed sequentially. It can produce unlimited amounts of data over time. There are two types of streams Input streams are used to hold input from a data producer, such as a keyboard, file, or network. Output streams hold output for a particular data consumer like a moniror, file, or printer. The data will sit in the output stream until it starts getting consumed. The istream class is used for input streams, and uses the extraction operator>> to remove values from the stream. The ostream class is used fr output streams, and uses the insertion modifier << to put value into the stream. iostream handles both. There are four standard streams in cpp cin an istream class tied to standard input (keyboard) cout an ostream class tied to standard output (keyboard) cerr an ostream class tied to the standard error (monitor) providing unbuffered output clog an ostream class providing buffered output. istream A common problem with cin is buffer overflow char buf [ 10 ]; std :: cin >> buf ; // what happens if more than 18 chars get input? You can use a manipulator object to modify the stream when applied with the extraction or insertion operators. setw can be used to limit the number of character read in from the stream. #include <iomanip.h> char buf [ 10 ]; std :: cin >> std :: setw ( 10 ) >> buf ; Now the program will only read the first 9 character out of the stream (leaving room for th terminator). If you want to get input including whitespace you can use the get() function char ch ; while ( std :: cin . get ( ch )) std :: cout << ch ; You can also limit the amount of characters to get char strBuf [ 11 ]; std :: cin . get ( strBuf , 11 ); std :: cout << strBuf << '\\n' ; Watch out for the fact that get() doesn't read in a newline character. Because of this there is the getline . char strBuf [ 100 ]; std : cin :: getline ( strBuf , 100 ); std :: cout << strBuf << '\\n' ; std :: cout << std :: cin . gcount () << \" characters were read\" << std :: endl ; A couple more useful istream functions ignore() discards the first character in the stream ignore(int nCount) discads the first ncount characters. peek() allows you to read a character from the stream without removing it from the stream unget() returns the last character read back into the stream so it can be read again by the next call putback(char ch) allows you to put a character of your choice back into the stream to be read by the next call. ostream and ios There are two ways to change formatting options: flags an manipulators. Flags are boolean variables that can be on or off. Objects placed in a steram that effect the way things are input and output are manipulators . std :: cout . setf ( std :: ios :: showpos ); // turn on the std::ios::showpos flag std :: cout << 27 << '\\n' ; prints + 27 You can turn on multiple flags using the OR (|) std :: cout . setf ( std :: ios :: showpos | std :: ios :: uppercase ); Format groups are groups of glags that perform similar formatting objections. std :: cout . setf ( std :: ios :: hex ); std :: cout . unsetf ( std :: ios :: dec ); // otherwise the output won't be in hex You could also make the flag the only one of the format group visible like so std :: cout . setf ( std :: ios :: hex , std :: ios :: basefield ); // hex is the only flag on in the basefield group You can chain flags directly into cout std::cout << std::noboolaplpha << true << \" \" << false << '\\n'; std::cout << std::boolalpha << true << \" \" << false < '\\n'; 1 0 true false You can set width with a certain char std :: cout << std :: setw ( 10 ) << left << 12345 << '\\n' ; // print left justified to a width of 10 Stream classes for strings The string stream classes provide buffers that are not connected to keyboard or mouse. One of the primary uses of these is to buffer output for display at a later time, or process input line-by-line. There are two ways to get data into a stringstream std :: stringstream os ; os << \"en garde!\" << '\\n' ; os . str ( \"en garde!\" ); To retrieve values std :: stringstream os ; os << \"123456 23.0\" std :: string strValue ; os >> strValue ; std :: string strValue2 ; os >> strValue2 ; std :: string strValue { os . str ()}; This is very useful for converting strings to numbers and back, since the >> and << operators do this by default. std :: stringstream os ; int nValue { 12345 }; os << nValue ; std :: stringVal { os . str (); } int nValue ; os >> nValue ; // convert back to int You can empty stringstreams by overwriting the string os . str ( \"\" ); os . str (); os . clear (); // generally a good idea to clear the error flags Stream states and input validation There are several state flags in the ios_base class that signal conditions that might occur when using streams. Flat Meaning goodbit Everything is ok badbit Some kind of fatal error occured eofbit the stream has reached the end of a file failbit A non-fatal error occured (e.g wrong input) Generally you access these flags through ios ios::_____ Meaning good() returns true if the goodbit is set bad() returns true if the badbit is set eof() returns true if the eofbit is set fail() returns true if the failbit is set clear() clears all flags and restores goodbit clear(state) clears all flags and sets the state to state rdstate() returns the currently set flags setstate(state) set the state flag to state Input Validation The process of checking whether the user input means some set of criteia is input validation . There are generally two types of input validation: string and numeric. This is usually in the form of prompting the user for input and then rejecting it if it's not in the correct type. Numerical validation is usually to make sure the numbers are in the correct range. Here are some useful validation functions: Function Meaning std::isalnum(int) Is a letter or digit std::isalpha(int) Is a letter std::iscntrl(int) Is a control character std::isdigit(int) Is a digit std::isgraph(int) Is printable char that is not whitespace std::isprint(int) Is printable char including whitespace std::ispunct(int) Is neither alphanumeric or whitespace std::isspace(int) Is whitespace std::isxdigit(int) I hexadecimal digit (0-9, a-f, A-F) Yuo use it like this: bool isValudName ( std :: string_view name ){ return std :: range :: all_of ( name , []( char ch )){ return ( std :: isalpha ( ch ) || std :: isspace ( ch ));} } // Before C++20, without ranges // return std::all_of(name.begin(), name.end(), [](char ch) { // return (std::isalpha(ch) || std::isspace(ch)); // }); }","title":"Input and output (IO)"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/#input-and-output-io","text":"The iostream library uses multiple inheritance. A stream is a sequence of bytes that can be accessed sequentially. It can produce unlimited amounts of data over time. There are two types of streams Input streams are used to hold input from a data producer, such as a keyboard, file, or network. Output streams hold output for a particular data consumer like a moniror, file, or printer. The data will sit in the output stream until it starts getting consumed. The istream class is used for input streams, and uses the extraction operator>> to remove values from the stream. The ostream class is used fr output streams, and uses the insertion modifier << to put value into the stream. iostream handles both. There are four standard streams in cpp cin an istream class tied to standard input (keyboard) cout an ostream class tied to standard output (keyboard) cerr an ostream class tied to the standard error (monitor) providing unbuffered output clog an ostream class providing buffered output.","title":"Input and output (IO)"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/#istream","text":"A common problem with cin is buffer overflow char buf [ 10 ]; std :: cin >> buf ; // what happens if more than 18 chars get input? You can use a manipulator object to modify the stream when applied with the extraction or insertion operators. setw can be used to limit the number of character read in from the stream. #include <iomanip.h> char buf [ 10 ]; std :: cin >> std :: setw ( 10 ) >> buf ; Now the program will only read the first 9 character out of the stream (leaving room for th terminator). If you want to get input including whitespace you can use the get() function char ch ; while ( std :: cin . get ( ch )) std :: cout << ch ; You can also limit the amount of characters to get char strBuf [ 11 ]; std :: cin . get ( strBuf , 11 ); std :: cout << strBuf << '\\n' ; Watch out for the fact that get() doesn't read in a newline character. Because of this there is the getline . char strBuf [ 100 ]; std : cin :: getline ( strBuf , 100 ); std :: cout << strBuf << '\\n' ; std :: cout << std :: cin . gcount () << \" characters were read\" << std :: endl ; A couple more useful istream functions ignore() discards the first character in the stream ignore(int nCount) discads the first ncount characters. peek() allows you to read a character from the stream without removing it from the stream unget() returns the last character read back into the stream so it can be read again by the next call putback(char ch) allows you to put a character of your choice back into the stream to be read by the next call.","title":"istream"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/#ostream-and-ios","text":"There are two ways to change formatting options: flags an manipulators. Flags are boolean variables that can be on or off. Objects placed in a steram that effect the way things are input and output are manipulators . std :: cout . setf ( std :: ios :: showpos ); // turn on the std::ios::showpos flag std :: cout << 27 << '\\n' ; prints + 27 You can turn on multiple flags using the OR (|) std :: cout . setf ( std :: ios :: showpos | std :: ios :: uppercase ); Format groups are groups of glags that perform similar formatting objections. std :: cout . setf ( std :: ios :: hex ); std :: cout . unsetf ( std :: ios :: dec ); // otherwise the output won't be in hex You could also make the flag the only one of the format group visible like so std :: cout . setf ( std :: ios :: hex , std :: ios :: basefield ); // hex is the only flag on in the basefield group You can chain flags directly into cout std::cout << std::noboolaplpha << true << \" \" << false << '\\n'; std::cout << std::boolalpha << true << \" \" << false < '\\n'; 1 0 true false You can set width with a certain char std :: cout << std :: setw ( 10 ) << left << 12345 << '\\n' ; // print left justified to a width of 10","title":"ostream and ios"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/#stream-classes-for-strings","text":"The string stream classes provide buffers that are not connected to keyboard or mouse. One of the primary uses of these is to buffer output for display at a later time, or process input line-by-line. There are two ways to get data into a stringstream std :: stringstream os ; os << \"en garde!\" << '\\n' ; os . str ( \"en garde!\" ); To retrieve values std :: stringstream os ; os << \"123456 23.0\" std :: string strValue ; os >> strValue ; std :: string strValue2 ; os >> strValue2 ; std :: string strValue { os . str ()}; This is very useful for converting strings to numbers and back, since the >> and << operators do this by default. std :: stringstream os ; int nValue { 12345 }; os << nValue ; std :: stringVal { os . str (); } int nValue ; os >> nValue ; // convert back to int You can empty stringstreams by overwriting the string os . str ( \"\" ); os . str (); os . clear (); // generally a good idea to clear the error flags","title":"Stream classes for strings"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/#stream-states-and-input-validation","text":"There are several state flags in the ios_base class that signal conditions that might occur when using streams. Flat Meaning goodbit Everything is ok badbit Some kind of fatal error occured eofbit the stream has reached the end of a file failbit A non-fatal error occured (e.g wrong input) Generally you access these flags through ios ios::_____ Meaning good() returns true if the goodbit is set bad() returns true if the badbit is set eof() returns true if the eofbit is set fail() returns true if the failbit is set clear() clears all flags and restores goodbit clear(state) clears all flags and sets the state to state rdstate() returns the currently set flags setstate(state) set the state flag to state","title":"Stream states and input validation"},{"location":"cpp/LearnCpp.com/023_Input_and_output_IO/#input-validation","text":"The process of checking whether the user input means some set of criteia is input validation . There are generally two types of input validation: string and numeric. This is usually in the form of prompting the user for input and then rejecting it if it's not in the correct type. Numerical validation is usually to make sure the numbers are in the correct range. Here are some useful validation functions: Function Meaning std::isalnum(int) Is a letter or digit std::isalpha(int) Is a letter std::iscntrl(int) Is a control character std::isdigit(int) Is a digit std::isgraph(int) Is printable char that is not whitespace std::isprint(int) Is printable char including whitespace std::ispunct(int) Is neither alphanumeric or whitespace std::isspace(int) Is whitespace std::isxdigit(int) I hexadecimal digit (0-9, a-f, A-F) Yuo use it like this: bool isValudName ( std :: string_view name ){ return std :: range :: all_of ( name , []( char ch )){ return ( std :: isalpha ( ch ) || std :: isspace ( ch ));} } // Before C++20, without ranges // return std::all_of(name.begin(), name.end(), [](char ch) { // return (std::isalpha(ch) || std::isspace(ch)); // }); }","title":"Input Validation"},{"location":"cpp/ModernCmake/","text":"This is an e-book I found here","title":"Index"},{"location":"cpp/ModernCmake/000_Introduction_to_the_basics/","text":"Intorduction to the basics At the beginning of the top CMakeLists.txt file of every project goes a line for the minimum cmake version required. cmake_minimum_required cmake_minimum_required ( VERSION 3.1 ) Syntax wise cmake commands are case insensitive. Because of this it's common practice to use lowercase for them. VERSION is a special keyword for this function, and the value of 3.1 is written into the variable . This line is important! It specifies how your cmake policies are defined. For example if you set minimum_required to VERSION 2.8, you'll get the wrong linking behaviour on macOS, even if the user happens to use a newer cmake version. It tells cmake how to interpret your files. This is to always preserve backwards compatibility. You can read all the policies here . As of cmake 3.12, this also supports a range of versions. cmake_minimum_required ( VERSION 3.7 ) if ( ${ CMAKE_VERSION } VERSION_LESS 3.19 ) cmake_policy ( VERSION ${ CMAKE_MAJOR_VERSION } . ${ CMAKE_MINOR_VERSION } ) else () cmake_policy ( VERSION 3.19 ) endif () New projcts should use the above setup. This supports down through cmake 3.7 for older distributions, and adjusts the cmake policies if it's a lower version accordingly. The next thing every top level cmake file has is this line: project ( MyProject VERSION 1.0 DESCRIPTION \"Very nice project\" LANGUAGES CXX ) Strings are quoted, whitespace doesn't matter. Next you will want to add a target . Targets are used in every build system, and they determined rules for things to build. Targets, can be executables (the program to run), libraries (things for other programs to link to), or as simple as copying files from a-z.","title":"Intorduction to the basics"},{"location":"cpp/ModernCmake/000_Introduction_to_the_basics/#intorduction-to-the-basics","text":"At the beginning of the top CMakeLists.txt file of every project goes a line for the minimum cmake version required. cmake_minimum_required cmake_minimum_required ( VERSION 3.1 ) Syntax wise cmake commands are case insensitive. Because of this it's common practice to use lowercase for them. VERSION is a special keyword for this function, and the value of 3.1 is written into the variable . This line is important! It specifies how your cmake policies are defined. For example if you set minimum_required to VERSION 2.8, you'll get the wrong linking behaviour on macOS, even if the user happens to use a newer cmake version. It tells cmake how to interpret your files. This is to always preserve backwards compatibility. You can read all the policies here . As of cmake 3.12, this also supports a range of versions. cmake_minimum_required ( VERSION 3.7 ) if ( ${ CMAKE_VERSION } VERSION_LESS 3.19 ) cmake_policy ( VERSION ${ CMAKE_MAJOR_VERSION } . ${ CMAKE_MINOR_VERSION } ) else () cmake_policy ( VERSION 3.19 ) endif () New projcts should use the above setup. This supports down through cmake 3.7 for older distributions, and adjusts the cmake policies if it's a lower version accordingly. The next thing every top level cmake file has is this line: project ( MyProject VERSION 1.0 DESCRIPTION \"Very nice project\" LANGUAGES CXX ) Strings are quoted, whitespace doesn't matter. Next you will want to add a target . Targets are used in every build system, and they determined rules for things to build. Targets, can be executables (the program to run), libraries (things for other programs to link to), or as simple as copying files from a-z.","title":"Intorduction to the basics"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/000_Introduction/","text":"Introduction There is a lot more to learn in the C++11 and 14 than \"more cpp\". The advice that this book gives is not a set of water-tight rules, but principles which will help to use cpp more effecitvely. One of the most pervasive new features of C++ 11 is the distinction between expressions that are rvalues from those that are lvalues . Rvalues are distinguished from lvlues from the fact that you can't take their address. They are temporary objects return from functions, while lvalues are stored in variables that are accessed either by pointer, name or reference. Lot of info about notation type.","title":"Introduction"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/000_Introduction/#introduction","text":"There is a lot more to learn in the C++11 and 14 than \"more cpp\". The advice that this book gives is not a set of water-tight rules, but principles which will help to use cpp more effecitvely. One of the most pervasive new features of C++ 11 is the distinction between expressions that are rvalues from those that are lvalues . Rvalues are distinguished from lvlues from the fact that you can't take their address. They are temporary objects return from functions, while lvalues are stored in variables that are accessed either by pointer, name or reference. Lot of info about notation type.","title":"Introduction"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/","text":"Deducing Types Before C++11 there was only one set of rules for type deduction: function templates. C++11 adds two more: auto and decltype . The advantages of type deduction is that it makes code much easier to refactor, but it can also make it harder to understand, as it's less verbose. Item 1: Understand template type deduction Templates type deduction is a tremendous success in C++ because most people don't understand how it works, and can use it anyway. Template type deduction is the basis for auto , so now is the time to learn how it actually works. Given the following pseudocode: template < typename T > void f ( ParamType param ); // a call can look like this: f ( expr ); Compliers will use expr to deduce a type for T and a type for ParamType . Often these are not the same type, as param might be const or reference, while T is the type without adornments. T's type is not just dependent on the type of expr, but also on the form of ParamType . There are three cases where the form of ParamType can change T ParamType is a pointer or reference type, but not universal reference. ParamType is a universal reference. ParamType is neither pointer or reference. Case 1: ParamType is a reference or Pointer, but not Universal Reference This is the simplest case. If expr 's type is a reference, ignore the reference part Pattern-match expr 's type against ParamType to determine T. template < typename T > void f ( T & param ); // param is a reference // take these declarations int x = 27 ; const int cx = x ; const int & rx = x ; f ( x ); // T is int, param's type is int& f ( cx ); // T is const int, param's type is const int& f ( rx ); // T is const int, param's type is const int& Passing a const object to a reference parameter, the caller expects that object to remain unmodifiable. The constness of the object becomes part of the type deduced for T. Interesting is that even when the variable passed in is a reference like in int& rx = x; , T is still deduced to be a non-reference. This works the same for rvalue references. template < typename T > void f ( const T & param ); int x = 27 ; f ( x ); // T is int, param's type is const int& All of this works as expected. Case 2: ParamType is a Universal Reference Universal reference parameters are declared like rvalue references, but they behave differently when lvalue arguments are passed in. If expr is an lvalue, both T and ParamType are deduced to be lvalue refs. This is very odd because it's the only situation where T is deduced to be a reference, and because ParamType is deduced to an lvalue ref instead of an rvalue ref. template < typename T > void f ( T && param ); // param is now universal reference int x = 27 ; const int cx = x ; const int & rx = x ; f ( x ); // x is lvalue T is int& param's type is int& f ( cx ); // cx is lvalue T is const int& param's type is const int& f ( rx ); // rx is lvalue T is const int& param's type is const int& f ( 27 ); // 27 is lvalue T is int, param's type is int&& When universal references are being used, type deduction distinguishes between lvalue and rvalue arguments. Case 3: ParamType is neither a pointer or reference When ParamType is neither pointer or reference, we have a simple pass by value - param will be a copy of whatever is passed in. It doesn't matter if the parameters being passed in are pointers or references, they will be copied into new variables. It also ignores any constness that the arguments might have. template < typename T > void f ( T param ); f ( x ); // T and param are both int f ( cx ); // T and param are both int f ( rx ); // T and param are both int Param isn't const since it is a copy. Because it is a copy this inherently guarantees that the arguments passed in will not be modified. As above, if it's a reference then templates respect that because it would otherwise modify the data being referenced. Array Arguments Array types are different from pointer types for templates just like for C - the array decays into a pointer. When an array is passed into a template parameter, it's treated as a pointer declaration. void myFunc ( int param []) void myFunc ( int * param ); // this is equivalent to the above While arrays cannot be passed in directly without decaying to pointers, they can be passed by reference. tempalte < typename T > void f ( T & param ); char [ 13 ] name = \"adkfksofydnecx\" ; f ( name ) // this is passed in as an array including the size // the type of param becomes const char (&)[13] With this it is possible to decude the size of an array at compiletime using templates Find size of array at compiletime // return size of an array as a compile-time constant. (The // array parameter has no name, because we care only about // the number of elements it contains.) template < typename & , std :: size_t N > constexpr std :: size_t arraySize ( Tb ( & )[ N ]) no except { return N ; } // Now we can, for example, declare an array with the same // number of elements as another one int keyvals [] = { 1 , 2 , 3 , 4 , 67 , 43 , 2 , 13 }; int mappedVals [ arraySize ( keyvals )]; Of course the is useless to a modern cpp developer who would just use std::array Function Arguments Just like arrays, function types can also decay into function pointers. All of the above applies to that just same. void someFunc ( int , double ); // someFunc is a function; // type is void(int, duoble) template < typename T > void f1 ( T param ); // in f1, param passed by value template < typename T > void f2 ( T & param ) // in f2, param passed by ref f1 ( someFunc ); // param decuded as ptr-to-func; // type is void (*)(int, double) f2 ( someFunc ); // param decuded as ref-to-func; // type is void (&)(int, double) Doesn't really make much difference in practice, but interesting to know?? Template type dection is what auto type deduction is built on top of. The special treatment of universal references and the decay to pointers are ones to watch out for. If you are unsure of what types are getting deduced check out TODO add chapter 4 here when I've gotten notes to it Note Templates deduce reference arguments as non-references lvalue arguments for universal reference parameters get special treatment by-value parameters that are const and volatile are treated as non- const and non- volatile Arguments that are array or function names decay to pointers unless they're used to intialize references. Item 2: Understand auto type deduction auto type deduction is template type deduction. It's literally the same algorithm to deduce the types. When a variables is declared usin auto , auto plays the role of T in the template, and the type specifier for the variable acts as ParamType . auto x = 27 ; const auto cx = x ; const auto & rx = s ; // these types are decuded the same as the following tempalte < typename T > void func_for_x ( T para ); funx_for_x ( 27 ); template < typename T > void func_for_cx ( const T param ); func_for_cx ( x ); template < typename T > void func_for_rx ( const T & param ); func_for_rx ( x ); There is only one difference between auto and template type deduction. There are now 4 ways to initialize ints int x1 = 27 ; int x2 ( 27 ); int x3 = { 27 }; int x4 { 27 }; What if we want to declaer these as auto? auto x1 = 27 ; // type is int, value is 27 auto x2 ( 27 ); // same auto x3 = { 27 }; // type is std::initializer_list<int>, value is 27 auto x4 { 27 }; // also std::initializer_list<int> This is because of a specialtype deduction rule for auto if using uniform initialization the type is deduced to be ain initilizer list. If you pass the same thing into a template you get a type deduction error auto x = { 11 , 23 , 9 }; template < typename T > void f ( T param ); f ({ 11 , 23 , 9 }); // error! can't deduce type template < typename T > void f ( std :: initilizer_list < T > initlist ); f ({ 11 , 23 , 9 }); // T deduced as int Basically the difference is that auto assumes that braced initializer represents a std::initilizer_list , but template type deduction doesn't. BUT WHY Scott has not found a convincing explanation for why this is. In C++14 things become even more interesting. Now the return type of a function can be auto , but for this template type deduction is used NOT auto type deduction. auto createInitList (){ return { 1 , 2 , 3 }; // error! can't deduce type } !! NOTE * auto type deduduction is the same as template type deduction except when using uniform initialization where auto assumes it represents a std::initializer_list * auto in a function return type or lambda implies template type deduction not auto type deduction Item 3: Understand decltype decltype tells you the name's or expression's type. Sometimes this returns something you would not expect. The primary use for decltype is declaring function templates where the function's return type depends on its parameter types. One example of this is a template where you are overloading operator[]. Typically in a teamplate of type T this operator returns objects of type T&.","title":"Deducing Types"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#deducing-types","text":"Before C++11 there was only one set of rules for type deduction: function templates. C++11 adds two more: auto and decltype . The advantages of type deduction is that it makes code much easier to refactor, but it can also make it harder to understand, as it's less verbose.","title":"Deducing Types"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#item-1-understand-template-type-deduction","text":"Templates type deduction is a tremendous success in C++ because most people don't understand how it works, and can use it anyway. Template type deduction is the basis for auto , so now is the time to learn how it actually works. Given the following pseudocode: template < typename T > void f ( ParamType param ); // a call can look like this: f ( expr ); Compliers will use expr to deduce a type for T and a type for ParamType . Often these are not the same type, as param might be const or reference, while T is the type without adornments. T's type is not just dependent on the type of expr, but also on the form of ParamType . There are three cases where the form of ParamType can change T ParamType is a pointer or reference type, but not universal reference. ParamType is a universal reference. ParamType is neither pointer or reference.","title":"Item 1: Understand template type deduction"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#case-1-paramtype-is-a-reference-or-pointer-but-not-universal-reference","text":"This is the simplest case. If expr 's type is a reference, ignore the reference part Pattern-match expr 's type against ParamType to determine T. template < typename T > void f ( T & param ); // param is a reference // take these declarations int x = 27 ; const int cx = x ; const int & rx = x ; f ( x ); // T is int, param's type is int& f ( cx ); // T is const int, param's type is const int& f ( rx ); // T is const int, param's type is const int& Passing a const object to a reference parameter, the caller expects that object to remain unmodifiable. The constness of the object becomes part of the type deduced for T. Interesting is that even when the variable passed in is a reference like in int& rx = x; , T is still deduced to be a non-reference. This works the same for rvalue references. template < typename T > void f ( const T & param ); int x = 27 ; f ( x ); // T is int, param's type is const int& All of this works as expected.","title":"Case 1: ParamType is a reference or Pointer, but not Universal Reference"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#case-2-paramtype-is-a-universal-reference","text":"Universal reference parameters are declared like rvalue references, but they behave differently when lvalue arguments are passed in. If expr is an lvalue, both T and ParamType are deduced to be lvalue refs. This is very odd because it's the only situation where T is deduced to be a reference, and because ParamType is deduced to an lvalue ref instead of an rvalue ref. template < typename T > void f ( T && param ); // param is now universal reference int x = 27 ; const int cx = x ; const int & rx = x ; f ( x ); // x is lvalue T is int& param's type is int& f ( cx ); // cx is lvalue T is const int& param's type is const int& f ( rx ); // rx is lvalue T is const int& param's type is const int& f ( 27 ); // 27 is lvalue T is int, param's type is int&& When universal references are being used, type deduction distinguishes between lvalue and rvalue arguments.","title":"Case 2: ParamType is a Universal Reference"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#case-3-paramtype-is-neither-a-pointer-or-reference","text":"When ParamType is neither pointer or reference, we have a simple pass by value - param will be a copy of whatever is passed in. It doesn't matter if the parameters being passed in are pointers or references, they will be copied into new variables. It also ignores any constness that the arguments might have. template < typename T > void f ( T param ); f ( x ); // T and param are both int f ( cx ); // T and param are both int f ( rx ); // T and param are both int Param isn't const since it is a copy. Because it is a copy this inherently guarantees that the arguments passed in will not be modified. As above, if it's a reference then templates respect that because it would otherwise modify the data being referenced.","title":"Case 3: ParamType is neither a pointer or reference"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#array-arguments","text":"Array types are different from pointer types for templates just like for C - the array decays into a pointer. When an array is passed into a template parameter, it's treated as a pointer declaration. void myFunc ( int param []) void myFunc ( int * param ); // this is equivalent to the above While arrays cannot be passed in directly without decaying to pointers, they can be passed by reference. tempalte < typename T > void f ( T & param ); char [ 13 ] name = \"adkfksofydnecx\" ; f ( name ) // this is passed in as an array including the size // the type of param becomes const char (&)[13] With this it is possible to decude the size of an array at compiletime using templates Find size of array at compiletime // return size of an array as a compile-time constant. (The // array parameter has no name, because we care only about // the number of elements it contains.) template < typename & , std :: size_t N > constexpr std :: size_t arraySize ( Tb ( & )[ N ]) no except { return N ; } // Now we can, for example, declare an array with the same // number of elements as another one int keyvals [] = { 1 , 2 , 3 , 4 , 67 , 43 , 2 , 13 }; int mappedVals [ arraySize ( keyvals )]; Of course the is useless to a modern cpp developer who would just use std::array","title":"Array Arguments"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#function-arguments","text":"Just like arrays, function types can also decay into function pointers. All of the above applies to that just same. void someFunc ( int , double ); // someFunc is a function; // type is void(int, duoble) template < typename T > void f1 ( T param ); // in f1, param passed by value template < typename T > void f2 ( T & param ) // in f2, param passed by ref f1 ( someFunc ); // param decuded as ptr-to-func; // type is void (*)(int, double) f2 ( someFunc ); // param decuded as ref-to-func; // type is void (&)(int, double) Doesn't really make much difference in practice, but interesting to know?? Template type dection is what auto type deduction is built on top of. The special treatment of universal references and the decay to pointers are ones to watch out for. If you are unsure of what types are getting deduced check out TODO add chapter 4 here when I've gotten notes to it Note Templates deduce reference arguments as non-references lvalue arguments for universal reference parameters get special treatment by-value parameters that are const and volatile are treated as non- const and non- volatile Arguments that are array or function names decay to pointers unless they're used to intialize references.","title":"Function Arguments"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#item-2-understand-auto-type-deduction","text":"auto type deduction is template type deduction. It's literally the same algorithm to deduce the types. When a variables is declared usin auto , auto plays the role of T in the template, and the type specifier for the variable acts as ParamType . auto x = 27 ; const auto cx = x ; const auto & rx = s ; // these types are decuded the same as the following tempalte < typename T > void func_for_x ( T para ); funx_for_x ( 27 ); template < typename T > void func_for_cx ( const T param ); func_for_cx ( x ); template < typename T > void func_for_rx ( const T & param ); func_for_rx ( x ); There is only one difference between auto and template type deduction. There are now 4 ways to initialize ints int x1 = 27 ; int x2 ( 27 ); int x3 = { 27 }; int x4 { 27 }; What if we want to declaer these as auto? auto x1 = 27 ; // type is int, value is 27 auto x2 ( 27 ); // same auto x3 = { 27 }; // type is std::initializer_list<int>, value is 27 auto x4 { 27 }; // also std::initializer_list<int> This is because of a specialtype deduction rule for auto if using uniform initialization the type is deduced to be ain initilizer list. If you pass the same thing into a template you get a type deduction error auto x = { 11 , 23 , 9 }; template < typename T > void f ( T param ); f ({ 11 , 23 , 9 }); // error! can't deduce type template < typename T > void f ( std :: initilizer_list < T > initlist ); f ({ 11 , 23 , 9 }); // T deduced as int Basically the difference is that auto assumes that braced initializer represents a std::initilizer_list , but template type deduction doesn't. BUT WHY Scott has not found a convincing explanation for why this is. In C++14 things become even more interesting. Now the return type of a function can be auto , but for this template type deduction is used NOT auto type deduction. auto createInitList (){ return { 1 , 2 , 3 }; // error! can't deduce type } !! NOTE * auto type deduduction is the same as template type deduction except when using uniform initialization where auto assumes it represents a std::initializer_list * auto in a function return type or lambda implies template type deduction not auto type deduction","title":"Item 2: Understand auto type deduction"},{"location":"cpp/Scott%20Meyers/Effective%20Modern%20C%2B%2B/001_Deducing_Types/#item-3-understand-decltype","text":"decltype tells you the name's or expression's type. Sometimes this returns something you would not expect. The primary use for decltype is declaring function templates where the function's return type depends on its parameter types. One example of this is a template where you are overloading operator[]. Typically in a teamplate of type T this operator returns objects of type T&.","title":"Item 3: Understand decltype"},{"location":"howto/build_vim_ycm_no_sudo/","text":"How to build vim with ycm completer on centos with no sudo access You will need to grab vim from source vim You will need to grab Ycm from the legacy cpp 11 branch ycm You will need to get python 3.6 from source (official release didn't work for me) pyton First you will need to compile python with shared libs so Ycm can link against it later. # Go to where you cloned python ./configure --prefix = /path/to/usr/.local/python3 --enable-optimizations --enable-shared make -j16 make -j16 install Then you need to compile vim with shared libs. This is a little more complicated export LDFLAGS = \"-rdynamic\" export LD_LIBRARY_PATH = \"/path/to/usr/.local/python3/lib\" export PATH ={ $PATH } :/path/to/usr/.local/python3/bin \" # cd to vim source dir ./configure --with-featuers=huge --enable-multibyte --enable-python3interp=yes --with-python3-command=/path/to/usr/.local/python3/bin/python3 --enable-cscope --prefix=/path/to/usr/.local/vim/ --enable-fail-if-missing # destdir and vimruntime dir must be set make -j16 VIMRUNTIMEDIR=/path/to/usr/.local/share/vim DESTDIR=/path/to/usr/.local/vim make -j16 install VIMRUNTIMEDIR=/path/to/usr/.local/share/vim DESTDIR=/path/to/usr/.local/vim \" Then you need to compile ycm for ycm you will need to download cmake 3 and modify the python path. To modify the python path I just manually overwrote it To download ycm if you are behind a nomachine internet or similar I reccomend cloning it on your home machine to get all the git submodules and then emailing a zip of that to yourself. vim /path/to/usr/.vim/bundle/YouCompleteMe/third_party/ycmd/build.py Search for include_dir = On line 295 change it to this include_dir = '/path/to/usr/.local/python3/include/python3.6' ; Then in the ycm root directory cd /path/to/usr/.vim/bundle/YouCompleteMe/ /path/to/usr/.local/python3/bin/python3 install.py --cmake-path /path/to/usr/.local/cmake/cmake Then everything should wrk!","title":"How to build vim with ycm completer on centos with no sudo access"},{"location":"howto/build_vim_ycm_no_sudo/#how-to-build-vim-with-ycm-completer-on-centos-with-no-sudo-access","text":"You will need to grab vim from source vim You will need to grab Ycm from the legacy cpp 11 branch ycm You will need to get python 3.6 from source (official release didn't work for me) pyton First you will need to compile python with shared libs so Ycm can link against it later. # Go to where you cloned python ./configure --prefix = /path/to/usr/.local/python3 --enable-optimizations --enable-shared make -j16 make -j16 install Then you need to compile vim with shared libs. This is a little more complicated export LDFLAGS = \"-rdynamic\" export LD_LIBRARY_PATH = \"/path/to/usr/.local/python3/lib\" export PATH ={ $PATH } :/path/to/usr/.local/python3/bin \" # cd to vim source dir ./configure --with-featuers=huge --enable-multibyte --enable-python3interp=yes --with-python3-command=/path/to/usr/.local/python3/bin/python3 --enable-cscope --prefix=/path/to/usr/.local/vim/ --enable-fail-if-missing # destdir and vimruntime dir must be set make -j16 VIMRUNTIMEDIR=/path/to/usr/.local/share/vim DESTDIR=/path/to/usr/.local/vim make -j16 install VIMRUNTIMEDIR=/path/to/usr/.local/share/vim DESTDIR=/path/to/usr/.local/vim \" Then you need to compile ycm for ycm you will need to download cmake 3 and modify the python path. To modify the python path I just manually overwrote it To download ycm if you are behind a nomachine internet or similar I reccomend cloning it on your home machine to get all the git submodules and then emailing a zip of that to yourself. vim /path/to/usr/.vim/bundle/YouCompleteMe/third_party/ycmd/build.py Search for include_dir = On line 295 change it to this include_dir = '/path/to/usr/.local/python3/include/python3.6' ; Then in the ycm root directory cd /path/to/usr/.vim/bundle/YouCompleteMe/ /path/to/usr/.local/python3/bin/python3 install.py --cmake-path /path/to/usr/.local/cmake/cmake Then everything should wrk!","title":"How to build vim with ycm completer on centos with no sudo access"},{"location":"math/matrix/","text":"Matrix Fundamentals Basic theory and multiplication You can read about how to transform a vector by a matrix in Linar Transformations and Matrices This goes over th exact process of multiplying matricies Matrix multiplication as composition Multiplying 3d vectors written out Three-dimensional linear transformations The determinant of the matrix is the volume/area that it's basis vectors take up. Read more on how this works here Taking the dot product of two vectors is the same operation as creating a one row matrix out of the first one and treating it as a transform. link Rotating a vector in a different coordiante space What if you want to rotate a joint not in it's parent coordinate space but in that of another joint in a different hierarchy? Change of basis Cramer's rule is not really useful other than a conceptual thought experiement, because you could also just use gaussian elemination with an inverted matrix to get the same resule with better computation efficiancy. It's useful for determining single axes of vectors though, and to prove things geometrically. Cramer's rule, explained geometrically For every transformation of a matrix, the vectors that do not change direction are eigenvectors. They are very useful to know.","title":"Matrix Fundamentals"},{"location":"math/matrix/#matrix-fundamentals","text":"","title":"Matrix Fundamentals"},{"location":"math/matrix/#basic-theory-and-multiplication","text":"You can read about how to transform a vector by a matrix in Linar Transformations and Matrices This goes over th exact process of multiplying matricies Matrix multiplication as composition Multiplying 3d vectors written out Three-dimensional linear transformations The determinant of the matrix is the volume/area that it's basis vectors take up. Read more on how this works here Taking the dot product of two vectors is the same operation as creating a one row matrix out of the first one and treating it as a transform. link","title":"Basic theory and multiplication"},{"location":"math/matrix/#rotating-a-vector-in-a-different-coordiante-space","text":"What if you want to rotate a joint not in it's parent coordinate space but in that of another joint in a different hierarchy? Change of basis Cramer's rule is not really useful other than a conceptual thought experiement, because you could also just use gaussian elemination with an inverted matrix to get the same resule with better computation efficiancy. It's useful for determining single axes of vectors though, and to prove things geometrically. Cramer's rule, explained geometrically For every transformation of a matrix, the vectors that do not change direction are eigenvectors. They are very useful to know.","title":"Rotating a vector in a different coordiante space"},{"location":"math/vector/","text":"Vectors The definition of a vector and how to think about it Abstract vector spaces Basis vectors \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) These are the coordinate vectors by which a vector may be multiplied to be transformed into their coordinate space. The span of two vectors is the entirety of possible vectors in a coordinate space. Linear combinations, span and basis vectors ) Transforming a vector by a matrix This goes over exactly how it happens that a vector is transformed by a matrix (think of matrix as a function) Linear Transformations and Matrices Dot product The dot project projects two vectors onto the number line. If it's positive they are pointing similar directions, 0 if they are perpendicular and negative if they are pointing away from each other. It's the same as making a 1 row matrix out of the first vector and treating it as a transform. Read more here A utilitarian breakdown of the dot product can be found here Cross Product Aka \"vector product\" - this is like the dot product but for each row of the vector without the linear transformation. Read the basics and then why the basis vectors are used in the first columns here Rotating a vector in a different coordiante space What if you want to rotate a joint not in it's parent coordinate space but in that of another joint in a different hierarchy? Change of basis","title":"Vectors"},{"location":"math/vector/#vectors","text":"The definition of a vector and how to think about it Abstract vector spaces","title":"Vectors"},{"location":"math/vector/#basis-vectors-mathbfhatimath-and-mathbfhatjmath","text":"These are the coordinate vectors by which a vector may be multiplied to be transformed into their coordinate space. The span of two vectors is the entirety of possible vectors in a coordinate space. Linear combinations, span and basis vectors )","title":"Basis vectors \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\)"},{"location":"math/vector/#transforming-a-vector-by-a-matrix","text":"This goes over exactly how it happens that a vector is transformed by a matrix (think of matrix as a function) Linear Transformations and Matrices","title":"Transforming a vector by a matrix"},{"location":"math/vector/#dot-product","text":"The dot project projects two vectors onto the number line. If it's positive they are pointing similar directions, 0 if they are perpendicular and negative if they are pointing away from each other. It's the same as making a 1 row matrix out of the first vector and treating it as a transform. Read more here A utilitarian breakdown of the dot product can be found here","title":"Dot product"},{"location":"math/vector/#cross-product","text":"Aka \"vector product\" - this is like the dot product but for each row of the vector without the linear transformation. Read the basics and then why the basis vectors are used in the first columns here","title":"Cross Product"},{"location":"math/vector/#rotating-a-vector-in-a-different-coordiante-space","text":"What if you want to rotate a joint not in it's parent coordinate space but in that of another joint in a different hierarchy? Change of basis","title":"Rotating a vector in a different coordiante space"},{"location":"math/Essence_of_calculus/001_The_Essence_of_Calculus/","text":"The Essence of Caculus This series is designed to illustrate some of the core concepts of calculus in a way that feels like discovering it yourself. We will start with the area of a circle: \\(\\pi R^2\\) . Why is this the case? Pondering this will lead to three of the big ideas in calculus: integrals , derivatives , and the *fact that they're opposites. Start approaching the circle problem by taking a layer of your circle like an onion, and figuring out the circumference of that: \\(2\\pi r\\) . The thickness of this layer is aribitrary, but determines the area of the layer. Sticking to standard calculus notation, let's label that thickness: \\(dr\\) \"difference in radius\". So now the area of this thin ring (approximated to a rectangle) is \\(2\\pi r d r\\) . This approximation gets better and better the thinner the layer slice is. Now let's imagine we do this to every single layer of the circle, from 0 to the full radius (using a full radius of 3 as the example). The spacing of these r values corresponds to the thickness of each ring, again \"difference in radius\" \\(d r\\) . You can imagine each of these layers stacked next to each other \"unwrapped\" flat on top of the number line ever increasing as r increases.Each of the layers is \\(2\\pi r\\) , the circumference of the cooresponding ring that each rectangle approximates. This can be visualized as a graph where each of the rectangles extends upwards to where it just barely touches the line of \\(2 \\pi r\\) - which is not linear. The smaller you make each of the rectangles, the closer they are to the above line. Since this creates a triangles you can get the area of it with: \\[ \\text{Area} = \\frac{ 1 }{ 2 } b h \\] \\[ = \\frac{ 1 }{ 2 } (r)(2 \\pi r) \\] \\[ \\pi r^2 \\] Now if you are thinking of a mathematician, you are not just thinking about finding the answer, but about using the process to generalize problem solving tools and techniques. The way we transitioned from the approximation to the precise result was by going an infinitude smaller. In this case that variables that kept getting smaller was the \"difference in radius\" \\(d r\\) . The sum of the area of the rectancles, with more and more samples, approaches the area of the graph. With these results we can then simplify the problem to being the area under the graph instead of the aggregate sum of all the samples. A lot of other hard problems in math can also be broken down as the \"Sum of many small values\". Like figuring out how far a car has traveled based on it's velicity at each point in time \\(v(t)dt\\) . It's the science of interpolating curves. Let's take the example of the x parabola. How would we find the area at any given value of x? This fucntion to get the area at any value of x is called the Integral of x^2. \\(A(x)\\) . This right now is just a mystery to us. Finding these integral fucntions is genuinely hard. Just like with the circle, let's slice this function up into slivers, with each sliver width being the \"difference in X\" \\(dx\\) and each sliver area being \"difference in Area\", \\(dA\\) . That sliver can be pretty well approximated by a rectancle who's height is \\(x^2\\) and width is \\(dx\\) . This allows us to say that the difference in area is approximate to \\(dA \\approx x^2 dx\\) \\[ \\frac{ dA }{ dx } \\approx x^2 \\] Let's take the points 3.001 and 3 with a d of 0.001 as an example: \\[ \\frac{ A(3.001) = A(3) }{ 0.001 } \\approx 3^2 \\] This provides a very strong clue that we can work with. And the solution is not unique to the graph of \\(x^2\\) . It applies to any graph. This lets us stuble into another big idea of calculus: derivatives . This \"difference in Area\" of the function is called the \"Derivative of A\". But technically, the derivative is whatever the formula approaches as d gets closer and closer to zero. Esseneially the derivative is a measure of how sensitive a function is to small changes in its input. This should give a high level overview of what calculus is about.","title":"The Essence of Caculus"},{"location":"math/Essence_of_calculus/001_The_Essence_of_Calculus/#the-essence-of-caculus","text":"This series is designed to illustrate some of the core concepts of calculus in a way that feels like discovering it yourself. We will start with the area of a circle: \\(\\pi R^2\\) . Why is this the case? Pondering this will lead to three of the big ideas in calculus: integrals , derivatives , and the *fact that they're opposites. Start approaching the circle problem by taking a layer of your circle like an onion, and figuring out the circumference of that: \\(2\\pi r\\) . The thickness of this layer is aribitrary, but determines the area of the layer. Sticking to standard calculus notation, let's label that thickness: \\(dr\\) \"difference in radius\". So now the area of this thin ring (approximated to a rectangle) is \\(2\\pi r d r\\) . This approximation gets better and better the thinner the layer slice is. Now let's imagine we do this to every single layer of the circle, from 0 to the full radius (using a full radius of 3 as the example). The spacing of these r values corresponds to the thickness of each ring, again \"difference in radius\" \\(d r\\) . You can imagine each of these layers stacked next to each other \"unwrapped\" flat on top of the number line ever increasing as r increases.Each of the layers is \\(2\\pi r\\) , the circumference of the cooresponding ring that each rectangle approximates. This can be visualized as a graph where each of the rectangles extends upwards to where it just barely touches the line of \\(2 \\pi r\\) - which is not linear. The smaller you make each of the rectangles, the closer they are to the above line. Since this creates a triangles you can get the area of it with: \\[ \\text{Area} = \\frac{ 1 }{ 2 } b h \\] \\[ = \\frac{ 1 }{ 2 } (r)(2 \\pi r) \\] \\[ \\pi r^2 \\] Now if you are thinking of a mathematician, you are not just thinking about finding the answer, but about using the process to generalize problem solving tools and techniques. The way we transitioned from the approximation to the precise result was by going an infinitude smaller. In this case that variables that kept getting smaller was the \"difference in radius\" \\(d r\\) . The sum of the area of the rectancles, with more and more samples, approaches the area of the graph. With these results we can then simplify the problem to being the area under the graph instead of the aggregate sum of all the samples. A lot of other hard problems in math can also be broken down as the \"Sum of many small values\". Like figuring out how far a car has traveled based on it's velicity at each point in time \\(v(t)dt\\) . It's the science of interpolating curves. Let's take the example of the x parabola. How would we find the area at any given value of x? This fucntion to get the area at any value of x is called the Integral of x^2. \\(A(x)\\) . This right now is just a mystery to us. Finding these integral fucntions is genuinely hard. Just like with the circle, let's slice this function up into slivers, with each sliver width being the \"difference in X\" \\(dx\\) and each sliver area being \"difference in Area\", \\(dA\\) . That sliver can be pretty well approximated by a rectancle who's height is \\(x^2\\) and width is \\(dx\\) . This allows us to say that the difference in area is approximate to \\(dA \\approx x^2 dx\\) \\[ \\frac{ dA }{ dx } \\approx x^2 \\] Let's take the points 3.001 and 3 with a d of 0.001 as an example: \\[ \\frac{ A(3.001) = A(3) }{ 0.001 } \\approx 3^2 \\] This provides a very strong clue that we can work with. And the solution is not unique to the graph of \\(x^2\\) . It applies to any graph. This lets us stuble into another big idea of calculus: derivatives . This \"difference in Area\" of the function is called the \"Derivative of A\". But technically, the derivative is whatever the formula approaches as d gets closer and closer to zero. Esseneially the derivative is a measure of how sensitive a function is to small changes in its input. This should give a high level overview of what calculus is about.","title":"The Essence of Caculus"},{"location":"math/Essence_of_linear_algebra/001_Vectors_what_even_are_they/","text":"Vectors, what even are they? There are three different perspectives on vectors Physics Student Vectors are arrows in space. You can move it all around and it's still the same vector. Vectors in flat planes are 2d, and 3d ones are in space. Mathematician A vector can be anything. Very abstract. Good to ignore for now. CS Student Vectors are lists of numbers. You use them for graph theory. Just a fancy word for list. We are going to thing of vectors as an arrow that always starts at the origin. In linear algebra the vector is always located at the origin. While we are all familiar with this coordinate system. We will go over it again anyway. The origin is the intersection of the axis. The coordinates of a vector is the numbers that determine it in each axis. They are usually resolved in the order of the axes. Ever pair of numbers only gives you one vector. Vector Addition To all 2 vectors, move the second one so that :starts at the tip of the first one. This type of addition is the only case in linear algebra where we concipate vectors away from the origin. This is the same as the sum of each number in each of the vectors. It's like taking all of the steps of each vector manually. 1x+2x+4y+5y Vector Multiplication Multiplying a vector by single number is called scaling vectors. You are multiplying each of the vectors' components by that number. Conclusion No matter which way you use you're always doing the same thing.","title":"001 Vectors what even are they"},{"location":"math/Essence_of_linear_algebra/001_Vectors_what_even_are_they/#vectors-what-even-are-they","text":"","title":"Vectors, what even are they?"},{"location":"math/Essence_of_linear_algebra/001_Vectors_what_even_are_they/#there-are-three-different-perspectives-on-vectors","text":"Physics Student Vectors are arrows in space. You can move it all around and it's still the same vector. Vectors in flat planes are 2d, and 3d ones are in space. Mathematician A vector can be anything. Very abstract. Good to ignore for now. CS Student Vectors are lists of numbers. You use them for graph theory. Just a fancy word for list. We are going to thing of vectors as an arrow that always starts at the origin. In linear algebra the vector is always located at the origin. While we are all familiar with this coordinate system. We will go over it again anyway. The origin is the intersection of the axis. The coordinates of a vector is the numbers that determine it in each axis. They are usually resolved in the order of the axes. Ever pair of numbers only gives you one vector.","title":"There are three different perspectives on vectors"},{"location":"math/Essence_of_linear_algebra/001_Vectors_what_even_are_they/#vector-addition","text":"To all 2 vectors, move the second one so that :starts at the tip of the first one. This type of addition is the only case in linear algebra where we concipate vectors away from the origin. This is the same as the sum of each number in each of the vectors. It's like taking all of the steps of each vector manually. 1x+2x+4y+5y","title":"Vector Addition"},{"location":"math/Essence_of_linear_algebra/001_Vectors_what_even_are_they/#vector-multiplication","text":"Multiplying a vector by single number is called scaling vectors. You are multiplying each of the vectors' components by that number.","title":"Vector Multiplication"},{"location":"math/Essence_of_linear_algebra/001_Vectors_what_even_are_they/#conclusion","text":"No matter which way you use you're always doing the same thing.","title":"Conclusion"},{"location":"math/Essence_of_linear_algebra/002_Linear_combinations_span_and_basis_vectors/","text":"Linear combinations, span, and basis vectors Basis Vectors \\(\\mathbf{\\hat{\\imath}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) There are two vry special vectors in the x, y coordinate system. \\({\\mathbf{\\hat{\\imath}}}\\) is the unit vector of the x axis and \\({\\hat{\\mathbf{\\jmath}}}\\) is the unit vector of the y axis. Unit vector means they both have a magnitude of 1. When given a vector you can imagine that vector scaling \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) \\[ \\begin{bmatrix} a \\\\ c \\\\ \\end{bmatrix} =(a){\\hat{\\imath}} * (c){\\hat{\\mathbf{\\jmath}}} \\] This multiplies the unit vectors so that when you add them together you arrive at the input vector. If we choose different basis vectors we basically use a different coordinate system. By modifying the basis vectors you can translated into any space. Describing vectors numerically depends entirely on the basis vectors (CG \"World space\") The \"span\" of \\(\\overrightarrow{{\\hat{\\mathbf{\\imath}}}}\\) and \\(\\overrightarrow{{\\hat{\\mathbf{\\jmath}}}}\\) is the set of all their linear combinations. No matter how much \\(\\overrightarrow{{\\hat{\\mathbf{\\imath}}}}\\) and \\(\\overrightarrow{{\\hat{\\mathbf{\\jmath}}}}\\) have been transformed. After transformation they would no longer be ( \\(\\overrightarrow{{\\hat{\\mathbf{\\imath}}}}\\) and \\(\\overrightarrow{{\\hat{\\mathbf{\\jmath}}}}\\) ) but something else, in our case \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . \\[ a\\overrightarrow{v}+b\\overrightarrow{w} \\] Let a and b vary over all real numbers. If both basis vectors have the same direction Then any input vector can only scale in that direction.In that case the span of the vectors is 1 dimensional along a single line. Vectors are commonly represented as points. Span in 3d What does it mean to take 2 vectors' span in 3d space? Just like with 2d vectors you scale them and then add them all together. \\[ a\\overrightarrow{v}+b\\overrightarrow{w}+c\\overrightarrow{u} \\] If the third vector is in the same direction as one of the first two, you are stuck in the 2d space of the first two vectors like a flat sheet. When a vector like this is redundant it is called Linearly dependent , since it is already in the span. If each vector is adding something to the span the vectors are considered Linearly Independant . Basis Vectors are always Linearly Independant","title":"Linear combinations, span, and basis vectors"},{"location":"math/Essence_of_linear_algebra/002_Linear_combinations_span_and_basis_vectors/#linear-combinations-span-and-basis-vectors","text":"","title":"Linear combinations, span, and basis vectors"},{"location":"math/Essence_of_linear_algebra/002_Linear_combinations_span_and_basis_vectors/#basis-vectors-mathbfhatimath-and-mathbfhatjmath","text":"There are two vry special vectors in the x, y coordinate system. \\({\\mathbf{\\hat{\\imath}}}\\) is the unit vector of the x axis and \\({\\hat{\\mathbf{\\jmath}}}\\) is the unit vector of the y axis. Unit vector means they both have a magnitude of 1. When given a vector you can imagine that vector scaling \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) \\[ \\begin{bmatrix} a \\\\ c \\\\ \\end{bmatrix} =(a){\\hat{\\imath}} * (c){\\hat{\\mathbf{\\jmath}}} \\] This multiplies the unit vectors so that when you add them together you arrive at the input vector. If we choose different basis vectors we basically use a different coordinate system. By modifying the basis vectors you can translated into any space. Describing vectors numerically depends entirely on the basis vectors (CG \"World space\") The \"span\" of \\(\\overrightarrow{{\\hat{\\mathbf{\\imath}}}}\\) and \\(\\overrightarrow{{\\hat{\\mathbf{\\jmath}}}}\\) is the set of all their linear combinations. No matter how much \\(\\overrightarrow{{\\hat{\\mathbf{\\imath}}}}\\) and \\(\\overrightarrow{{\\hat{\\mathbf{\\jmath}}}}\\) have been transformed. After transformation they would no longer be ( \\(\\overrightarrow{{\\hat{\\mathbf{\\imath}}}}\\) and \\(\\overrightarrow{{\\hat{\\mathbf{\\jmath}}}}\\) ) but something else, in our case \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . \\[ a\\overrightarrow{v}+b\\overrightarrow{w} \\] Let a and b vary over all real numbers.","title":"Basis Vectors \\(\\mathbf{\\hat{\\imath}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\)"},{"location":"math/Essence_of_linear_algebra/002_Linear_combinations_span_and_basis_vectors/#if-both-basis-vectors-have-the-same-direction","text":"Then any input vector can only scale in that direction.In that case the span of the vectors is 1 dimensional along a single line. Vectors are commonly represented as points.","title":"If both basis vectors have the same direction"},{"location":"math/Essence_of_linear_algebra/002_Linear_combinations_span_and_basis_vectors/#span-in-3d","text":"What does it mean to take 2 vectors' span in 3d space? Just like with 2d vectors you scale them and then add them all together. \\[ a\\overrightarrow{v}+b\\overrightarrow{w}+c\\overrightarrow{u} \\] If the third vector is in the same direction as one of the first two, you are stuck in the 2d space of the first two vectors like a flat sheet. When a vector like this is redundant it is called Linearly dependent , since it is already in the span. If each vector is adding something to the span the vectors are considered Linearly Independant . Basis Vectors are always Linearly Independant","title":"Span in 3d"},{"location":"math/Essence_of_linear_algebra/003_Linear_transformations_and_matrices/","text":"Linear transfomration Every transformation is also a function. In linear algebra we most commonly have transformations operating on vectors. Transformation sugguests that you think using movement . You imagine the input vector(s) moving to the output vectors. To imagine the transfomration as a whole, you imagine every single input vector being transformed. Visualizing this with a grid is handy, and gives the feeling of transforming space itself. A transformation is linear if it has 2 properties: Lines remain lines Origin must remain fixed in place In General linear transformations keep grid lines paralell. To plot a vector you use the same math, but with transformed basis vectors \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) . \\[ {\\overrightarrow{V}} = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = -1 {\\mathbf{\\hat{\\imath}}}+ 2 {\\mathbf{\\hat{\\jmath}}} \\] \\[ Transformed {\\overrightarrow{V}} = -1(Transformed {\\mathbf{\\hat{\\imath}}}) + 2(Transformed {\\mathbf{\\hat{\\jmath}}}) \\] Given that \\[ {\\mathbf{\\hat{\\imath}}} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\quad and \\quad {\\mathbf{\\hat{\\jmath}}} = \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix} \\] \\[ \\overrightarrow{V}= -1 \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} + 2 \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix} \\] \\[ \\overrightarrow{V} = \\begin{bmatrix} -1(1) + 2(3) \\\\ -1(-2) + 2(0) \\end{bmatrix}= \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} \\] This means that a 2d transformation can be described by just 4 numbers. This can now be represented as a 2x2 Matrix . \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) are columns 1 and 2 respectively. \\[ \\begin{bmatrix} 3 & 2 \\\\ -2 & 1 \\end{bmatrix} * \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} \\] This is matrix multiplication! Note that matrix can also be \"Shear\" where \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) are not at right angles. Remember that if the basis vectors are Linearly dependent then all of their span is reduced to a single line. To sum up given that \\({\\mathbf{\\hat{\\imath}}}\\) = a, b and \\({\\mathbf{\\hat{\\jmath}}}\\) = c, d: \\[ \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = x \\begin{bmatrix} a \\\\ c \\end{bmatrix} +y \\begin{bmatrix} b \\\\ d \\end{bmatrix} = \\begin{bmatrix} ax+by \\\\ cx+dy \\end{bmatrix} \\]","title":"003 Linear transformations and matrices"},{"location":"math/Essence_of_linear_algebra/003_Linear_transformations_and_matrices/#linear-transfomration","text":"Every transformation is also a function. In linear algebra we most commonly have transformations operating on vectors. Transformation sugguests that you think using movement . You imagine the input vector(s) moving to the output vectors. To imagine the transfomration as a whole, you imagine every single input vector being transformed. Visualizing this with a grid is handy, and gives the feeling of transforming space itself.","title":"Linear transfomration"},{"location":"math/Essence_of_linear_algebra/003_Linear_transformations_and_matrices/#a-transformation-is-linear-if-it-has-2-properties","text":"Lines remain lines Origin must remain fixed in place In General linear transformations keep grid lines paralell. To plot a vector you use the same math, but with transformed basis vectors \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) . \\[ {\\overrightarrow{V}} = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = -1 {\\mathbf{\\hat{\\imath}}}+ 2 {\\mathbf{\\hat{\\jmath}}} \\] \\[ Transformed {\\overrightarrow{V}} = -1(Transformed {\\mathbf{\\hat{\\imath}}}) + 2(Transformed {\\mathbf{\\hat{\\jmath}}}) \\] Given that \\[ {\\mathbf{\\hat{\\imath}}} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\quad and \\quad {\\mathbf{\\hat{\\jmath}}} = \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix} \\] \\[ \\overrightarrow{V}= -1 \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} + 2 \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix} \\] \\[ \\overrightarrow{V} = \\begin{bmatrix} -1(1) + 2(3) \\\\ -1(-2) + 2(0) \\end{bmatrix}= \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} \\] This means that a 2d transformation can be described by just 4 numbers. This can now be represented as a 2x2 Matrix . \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) are columns 1 and 2 respectively. \\[ \\begin{bmatrix} 3 & 2 \\\\ -2 & 1 \\end{bmatrix} * \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} \\] This is matrix multiplication! Note that matrix can also be \"Shear\" where \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) are not at right angles. Remember that if the basis vectors are Linearly dependent then all of their span is reduced to a single line. To sum up given that \\({\\mathbf{\\hat{\\imath}}}\\) = a, b and \\({\\mathbf{\\hat{\\jmath}}}\\) = c, d: \\[ \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = x \\begin{bmatrix} a \\\\ c \\end{bmatrix} +y \\begin{bmatrix} b \\\\ d \\end{bmatrix} = \\begin{bmatrix} ax+by \\\\ cx+dy \\end{bmatrix} \\]","title":"A transformation is linear if it has 2 properties:"},{"location":"math/Essence_of_linear_algebra/004_Matrix_multiplication_as_composition/","text":"Matrix multiplication as composition It is my experience that proofs involving matrices can be shortened by 50% if one throws the matrices out - Emil Artin Reacap: Linear Transformations are functions with vectors as inputs and vectors as outputs. \\(L( \\overrightarrow{v} )\\) . You can think of them visually like when you transform an object in maya, or as squishing the grid of space. The transformation is always done based off the basis vector matrix. Each column in the matrix is one of the basis vectors. Then, if you multiply a vector by that matrix, you are transforming the vector in the space of that matrix. What if you want to apply multiple transformations of space? Say that you want to first apply a matrix that rotates everything by 90 degrees and then applies a shear? This is commonly referred to as a composition of the previous two transformations. It can be described by it's own matrix by following \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) . This is esentialyl a new matrix from multiplying the first two. To make it simple, you can apply things the long way where the vector is first transformed by the rotation matrix and then the shear matrix, but the reslt is identical to the right where the vector is transformed by the composition matrix. \\[ \\overbrace{ \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}}^{\\text{Shear Matrix}} \\bigg( \\overbrace{ \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}}^{\\text{Rotation Matrix}} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\bigg) = \\overbrace{ \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\end{bmatrix}}^{\\text{Composition Matrix}} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\] You can call the matrix on the right the product of the two matrices on the left. Note that the order of first rotation (matrix in parenthesis) and then shear is important. This is based on function notation in mathematics. You read the composition from right to left (and the order is important!). \\[ \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\end{bmatrix} \\] To multiply matrices you multiply each column (base vector) in the first matrix \\(M_1\\) by each row in the matrix it is being transformed into \\(M_2\\) . \\[ \\overbrace{ \\textcolor{magenta}{ \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} } }^{M_2} \\overbrace{ \\textcolor{yellow}{ \\begin{bmatrix} \\textcolor{green}{ 1 } & \\textcolor{red}{ -2 }\\\\ \\textcolor{green}{ 1 } & \\textcolor{red}{ 0 } \\end{bmatrix} } }^{M_1} = \\begin{bmatrix} 2 & 0 \\\\ 1 & -2 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 0 & 2\\\\ 1 & 0 \\end{bmatrix} } \\textcolor{green}{ \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} } = \\textcolor{green}{ 1 } \\textcolor{magenta}{ \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} } + \\textcolor{green}{ 1 } \\textcolor{magenta}{ \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} } = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} } \\textcolor{red}{ \\begin{bmatrix} -2 \\\\ 0 \\end{bmatrix} } = \\textcolor{red}{ -2 } \\textcolor{magenta}{ \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} } + \\textcolor{red}{ 0 } \\textcolor{magenta}{ \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} } = \\begin{bmatrix} 0 \\\\ -2 \\end{bmatrix} \\] This can be simplified to the following \\[ \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} e & f \\\\ g & h \\end{bmatrix} = \\begin{bmatrix} ae+bg & af+bh \\\\ ce+dg & cf+dh \\end{bmatrix} \\] The order of the matricies matters as this shows!","title":"Matrix multiplication as composition"},{"location":"math/Essence_of_linear_algebra/004_Matrix_multiplication_as_composition/#matrix-multiplication-as-composition","text":"It is my experience that proofs involving matrices can be shortened by 50% if one throws the matrices out - Emil Artin Reacap: Linear Transformations are functions with vectors as inputs and vectors as outputs. \\(L( \\overrightarrow{v} )\\) . You can think of them visually like when you transform an object in maya, or as squishing the grid of space. The transformation is always done based off the basis vector matrix. Each column in the matrix is one of the basis vectors. Then, if you multiply a vector by that matrix, you are transforming the vector in the space of that matrix.","title":"Matrix multiplication as composition"},{"location":"math/Essence_of_linear_algebra/004_Matrix_multiplication_as_composition/#what-if-you-want-to-apply-multiple-transformations-of-space","text":"Say that you want to first apply a matrix that rotates everything by 90 degrees and then applies a shear? This is commonly referred to as a composition of the previous two transformations. It can be described by it's own matrix by following \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) . This is esentialyl a new matrix from multiplying the first two. To make it simple, you can apply things the long way where the vector is first transformed by the rotation matrix and then the shear matrix, but the reslt is identical to the right where the vector is transformed by the composition matrix. \\[ \\overbrace{ \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}}^{\\text{Shear Matrix}} \\bigg( \\overbrace{ \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}}^{\\text{Rotation Matrix}} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\bigg) = \\overbrace{ \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\end{bmatrix}}^{\\text{Composition Matrix}} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\] You can call the matrix on the right the product of the two matrices on the left. Note that the order of first rotation (matrix in parenthesis) and then shear is important. This is based on function notation in mathematics. You read the composition from right to left (and the order is important!). \\[ \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\end{bmatrix} \\] To multiply matrices you multiply each column (base vector) in the first matrix \\(M_1\\) by each row in the matrix it is being transformed into \\(M_2\\) . \\[ \\overbrace{ \\textcolor{magenta}{ \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} } }^{M_2} \\overbrace{ \\textcolor{yellow}{ \\begin{bmatrix} \\textcolor{green}{ 1 } & \\textcolor{red}{ -2 }\\\\ \\textcolor{green}{ 1 } & \\textcolor{red}{ 0 } \\end{bmatrix} } }^{M_1} = \\begin{bmatrix} 2 & 0 \\\\ 1 & -2 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 0 & 2\\\\ 1 & 0 \\end{bmatrix} } \\textcolor{green}{ \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} } = \\textcolor{green}{ 1 } \\textcolor{magenta}{ \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} } + \\textcolor{green}{ 1 } \\textcolor{magenta}{ \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} } = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} } \\textcolor{red}{ \\begin{bmatrix} -2 \\\\ 0 \\end{bmatrix} } = \\textcolor{red}{ -2 } \\textcolor{magenta}{ \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} } + \\textcolor{red}{ 0 } \\textcolor{magenta}{ \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} } = \\begin{bmatrix} 0 \\\\ -2 \\end{bmatrix} \\] This can be simplified to the following \\[ \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\begin{bmatrix} e & f \\\\ g & h \\end{bmatrix} = \\begin{bmatrix} ae+bg & af+bh \\\\ ce+dg & cf+dh \\end{bmatrix} \\] The order of the matricies matters as this shows!","title":"What if you want to apply multiple transformations of space?"},{"location":"math/Essence_of_linear_algebra/005_Three-dimensional_linear_transformations/","text":"Three-dimensional linear transformations Most of these examples will be in 2 dimensions, but occasionally it's goot to peer out of flatland to see how things apply in higher demensions. In the third dimension we have one addition basis vector: \\({\\mathbf{\\hat{k}}}\\) , which represents the z axis . The three basis vectors form the columns of a 3x3 matrix, commonly referred to as a rotation matrix . To see where a three dimensional vector lands, the math is almost identical to a 2d vector: \\[ \\overrightarrow{v} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = x {\\mathbf{\\hat{\\imath}}} + y {\\mathbf{\\hat{\\jmath}}} + z {\\mathbf{\\hat{k}}} \\] The important part is that this scaling and adding works before and after the transformations. Let's try to write out the multiplication like the 2d matrix from the previous section. \\[ \\overbrace{ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 & 0 & 9 \\\\ 2 & 1 & 6 \\\\ \\end{bmatrix} } }^{M_1} \\overbrace{ \\begin{bmatrix} \\textcolor{red}{ 9 } & \\textcolor{green}{ 3 } & \\textcolor{blue}{ 5 } \\\\ \\textcolor{red}{ 0 } & \\textcolor{green}{ 1 } & \\textcolor{blue}{ 2 } \\\\ \\textcolor{red}{ 3 } & \\textcolor{green}{ 2 } & \\textcolor{blue}{ 8 } \\end{bmatrix} }^{M_2} = \\begin{bmatrix} 36 + 0 + 18 & 12 + 7 + 16 & 20 + 14 + 36 \\\\ 27 + 0 + 18 & 9 + 0 + 18 & 15 + 0 + 72 \\\\ 18 + 0 + 18 & 6 + 2 + 4 & 10 + 2 + 48 \\end{bmatrix} = \\begin{bmatrix} 54 & 35 & 70 \\\\ 46 & 27 & 87 \\\\ 36 & 12 & 60 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 &0 & 9 \\\\ 2 & 1 & 6 \\end{bmatrix} } \\textcolor{red}{ \\begin{bmatrix} 9 \\\\ 0 \\\\ 3 \\end{bmatrix} } = \\textcolor{red}{ 9 } \\textcolor{magenta}{ \\begin{bmatrix} 4 \\\\ 3 \\\\ 2 \\end{bmatrix} } + \\textcolor{red}{ 0 } \\textcolor{magenta}{ \\begin{bmatrix} 7 \\\\ 0 \\\\ 2 \\end{bmatrix} } + \\textcolor{red}{ 3 } \\textcolor{magenta}{ \\begin{bmatrix} 8 \\\\ 9 \\\\ 6 \\end{bmatrix} } = \\begin{bmatrix} 54 \\\\ 46 \\\\ 36 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 &0 & 9 \\\\ 2 & 1 & 6 \\end{bmatrix} } \\textcolor{green}{ \\begin{bmatrix} 3 \\\\ 1 \\\\ 2 \\end{bmatrix} } = \\textcolor{green}{ 3 } \\textcolor{magenta}{ \\begin{bmatrix} 4 \\\\ 3 \\\\ 2 \\end{bmatrix} } + \\textcolor{green}{ 1 } \\textcolor{magenta}{ \\begin{bmatrix} 7 \\\\ 0 \\\\ 2 \\end{bmatrix} } + \\textcolor{green}{ 2 } \\textcolor{magenta}{ \\begin{bmatrix} 8 \\\\ 9 \\\\ 6 \\end{bmatrix} } = \\begin{bmatrix} 35 \\\\ 27 \\\\ 12 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 &0 & 9 \\\\ 2 & 1 & 6 \\end{bmatrix} } \\textcolor{blue}{ \\begin{bmatrix} 5 \\\\ 2 \\\\ 8 \\end{bmatrix} } = \\textcolor{blue}{ 5 } \\textcolor{magenta}{ \\begin{bmatrix} 4 \\\\ 3 \\\\ 2 \\end{bmatrix} } + \\textcolor{blue}{ 2 } \\textcolor{magenta}{ \\begin{bmatrix} 7 \\\\ 0 \\\\ 2 \\end{bmatrix} } + \\textcolor{blue}{ 8 } \\textcolor{magenta}{ \\begin{bmatrix} 8 \\\\ 9 \\\\ 6 \\end{bmatrix} } = \\begin{bmatrix} 70 \\\\ 87 \\\\ 60 \\end{bmatrix} \\] And all of this can be summarized as: \\[ \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix} \\begin{bmatrix} j & k & l \\\\ m & n & o \\\\ p & q & r \\end{bmatrix} = \\begin{bmatrix} aj + bm + cp & ak + bn + cq & al + ao + ar \\\\ dj + em + fp & dk + en + fq & dl + eo + fr \\\\ gj + hm + ip & gk + hn + iq & gl + ho + if \\end{bmatrix} \\]","title":"Three-dimensional linear transformations"},{"location":"math/Essence_of_linear_algebra/005_Three-dimensional_linear_transformations/#three-dimensional-linear-transformations","text":"Most of these examples will be in 2 dimensions, but occasionally it's goot to peer out of flatland to see how things apply in higher demensions. In the third dimension we have one addition basis vector: \\({\\mathbf{\\hat{k}}}\\) , which represents the z axis . The three basis vectors form the columns of a 3x3 matrix, commonly referred to as a rotation matrix . To see where a three dimensional vector lands, the math is almost identical to a 2d vector: \\[ \\overrightarrow{v} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = x {\\mathbf{\\hat{\\imath}}} + y {\\mathbf{\\hat{\\jmath}}} + z {\\mathbf{\\hat{k}}} \\] The important part is that this scaling and adding works before and after the transformations. Let's try to write out the multiplication like the 2d matrix from the previous section. \\[ \\overbrace{ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 & 0 & 9 \\\\ 2 & 1 & 6 \\\\ \\end{bmatrix} } }^{M_1} \\overbrace{ \\begin{bmatrix} \\textcolor{red}{ 9 } & \\textcolor{green}{ 3 } & \\textcolor{blue}{ 5 } \\\\ \\textcolor{red}{ 0 } & \\textcolor{green}{ 1 } & \\textcolor{blue}{ 2 } \\\\ \\textcolor{red}{ 3 } & \\textcolor{green}{ 2 } & \\textcolor{blue}{ 8 } \\end{bmatrix} }^{M_2} = \\begin{bmatrix} 36 + 0 + 18 & 12 + 7 + 16 & 20 + 14 + 36 \\\\ 27 + 0 + 18 & 9 + 0 + 18 & 15 + 0 + 72 \\\\ 18 + 0 + 18 & 6 + 2 + 4 & 10 + 2 + 48 \\end{bmatrix} = \\begin{bmatrix} 54 & 35 & 70 \\\\ 46 & 27 & 87 \\\\ 36 & 12 & 60 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 &0 & 9 \\\\ 2 & 1 & 6 \\end{bmatrix} } \\textcolor{red}{ \\begin{bmatrix} 9 \\\\ 0 \\\\ 3 \\end{bmatrix} } = \\textcolor{red}{ 9 } \\textcolor{magenta}{ \\begin{bmatrix} 4 \\\\ 3 \\\\ 2 \\end{bmatrix} } + \\textcolor{red}{ 0 } \\textcolor{magenta}{ \\begin{bmatrix} 7 \\\\ 0 \\\\ 2 \\end{bmatrix} } + \\textcolor{red}{ 3 } \\textcolor{magenta}{ \\begin{bmatrix} 8 \\\\ 9 \\\\ 6 \\end{bmatrix} } = \\begin{bmatrix} 54 \\\\ 46 \\\\ 36 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 &0 & 9 \\\\ 2 & 1 & 6 \\end{bmatrix} } \\textcolor{green}{ \\begin{bmatrix} 3 \\\\ 1 \\\\ 2 \\end{bmatrix} } = \\textcolor{green}{ 3 } \\textcolor{magenta}{ \\begin{bmatrix} 4 \\\\ 3 \\\\ 2 \\end{bmatrix} } + \\textcolor{green}{ 1 } \\textcolor{magenta}{ \\begin{bmatrix} 7 \\\\ 0 \\\\ 2 \\end{bmatrix} } + \\textcolor{green}{ 2 } \\textcolor{magenta}{ \\begin{bmatrix} 8 \\\\ 9 \\\\ 6 \\end{bmatrix} } = \\begin{bmatrix} 35 \\\\ 27 \\\\ 12 \\end{bmatrix} \\] \\[ \\textcolor{magenta}{ \\begin{bmatrix} 4 & 7 & 8 \\\\ 3 &0 & 9 \\\\ 2 & 1 & 6 \\end{bmatrix} } \\textcolor{blue}{ \\begin{bmatrix} 5 \\\\ 2 \\\\ 8 \\end{bmatrix} } = \\textcolor{blue}{ 5 } \\textcolor{magenta}{ \\begin{bmatrix} 4 \\\\ 3 \\\\ 2 \\end{bmatrix} } + \\textcolor{blue}{ 2 } \\textcolor{magenta}{ \\begin{bmatrix} 7 \\\\ 0 \\\\ 2 \\end{bmatrix} } + \\textcolor{blue}{ 8 } \\textcolor{magenta}{ \\begin{bmatrix} 8 \\\\ 9 \\\\ 6 \\end{bmatrix} } = \\begin{bmatrix} 70 \\\\ 87 \\\\ 60 \\end{bmatrix} \\] And all of this can be summarized as: \\[ \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix} \\begin{bmatrix} j & k & l \\\\ m & n & o \\\\ p & q & r \\end{bmatrix} = \\begin{bmatrix} aj + bm + cp & ak + bn + cq & al + ao + ar \\\\ dj + em + fp & dk + en + fq & dl + eo + fr \\\\ gj + hm + ip & gk + hn + iq & gl + ho + if \\end{bmatrix} \\]","title":"Three-dimensional linear transformations"},{"location":"math/Essence_of_linear_algebra/006_The_determinant/","text":"The determinant *\"The purpose of computation is insight, not numbers.\" - Richard Hamming How do we measure how much a transformation stretches space? Or squishes. How much is the area of the basis vectors increased or decreased? \\[ \\begin{bmatrix} 3 & 0 \\\\ 0 & 2 \\end{bmatrix}\\\\ \\] \\[ New area = 3 * 2 = 6 \\] Just because a matrix is sheared doesn't mean that it's area necessarily changes. The area is determined by the length of the vectors in the base coordinate space. You can measure the factor of scale through the determinant of a transform. This is the amount that the 1x1 square in each of the basis vectors has changed area. \\[ det \\bigg( \\begin{bmatrix} 3 & 2 \\\\ 0 & 2 \\end{bmatrix} \\bigg) = 6 \\] The determinant of a matrix is zero if it squishes all of space down to a line. (If the vectors are pointing in the same direction or a point) The determinant can be negative This has to do with the concept of orientation. This happens when a transform \"inverts\" the orientation of space. For example of X is now pointing in the y direction. On way that this could happen is that if instead of being to the left of \\({\\mathbf{\\hat{\\imath}}}\\) , \\({\\mathbf{\\hat{\\jmath}}}\\) is now to the right of \\({\\mathbf{\\hat{\\imath}}}\\) . This inverts the orientation of space. This will create a negative determinant. In 3d You are scaling volumes. It helps to visualize the cube resting on the basis vectors. After transformation this cube will get warped, possibly into a parallelepiped if the cube is skewed. \\[ det \\Bigg( \\begin{bmatrix} 1.0 & 0.0 & 0.5 \\\\ 0.5 & 1.0 & 0.0 \\\\ 1.0 & 0.0 & 1.0 \\end{bmatrix} \\Bigg) =\\text{Volume of parallelepiped} \\] How do we actually compute the determinant? \\[ det \\Bigg( \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\Bigg) = ad - bc \\] a and d in this example are the distance that \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) in their primary axes (x and y). Even if only one of their non-primary axes are zero (in the case of a parallelogram) the area is still their base times height. B * C basically tells you how much the parallelograph is squished into either direction. In 3d you subtract the det of the y axis and then add the determinant of the z axis. \\[ det \\Bigg( \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix} \\Bigg) = det_a \\Bigg( \\begin{bmatrix} e & f \\\\ h & i \\end{bmatrix} \\Bigg) - deb_b \\Bigg( \\begin{bmatrix} d & f \\\\ g & i \\end{bmatrix} \\Bigg) + det_c \\Bigg( \\begin{bmatrix} d & e \\\\ g & h \\end{bmatrix} \\Bigg) \\] He doesn't go into exactly why this is because it's not that relevant to linear algebra. A fun quiz (explain why this makes sense): \\[ det(M_1 M_2) = det(M_1)det(M_2) \\] This makes sense because you are multiplying the numbers both ways, and the determinant is also multiplied when multiplying matrices. \\(6 == 3 * 2\\)","title":"The determinant"},{"location":"math/Essence_of_linear_algebra/006_The_determinant/#the-determinant","text":"*\"The purpose of computation is insight, not numbers.\" - Richard Hamming","title":"The determinant"},{"location":"math/Essence_of_linear_algebra/006_The_determinant/#how-do-we-measure-how-much-a-transformation-stretches-space","text":"Or squishes. How much is the area of the basis vectors increased or decreased? \\[ \\begin{bmatrix} 3 & 0 \\\\ 0 & 2 \\end{bmatrix}\\\\ \\] \\[ New area = 3 * 2 = 6 \\] Just because a matrix is sheared doesn't mean that it's area necessarily changes. The area is determined by the length of the vectors in the base coordinate space. You can measure the factor of scale through the determinant of a transform. This is the amount that the 1x1 square in each of the basis vectors has changed area. \\[ det \\bigg( \\begin{bmatrix} 3 & 2 \\\\ 0 & 2 \\end{bmatrix} \\bigg) = 6 \\] The determinant of a matrix is zero if it squishes all of space down to a line. (If the vectors are pointing in the same direction or a point)","title":"How do we measure how much a transformation stretches space?"},{"location":"math/Essence_of_linear_algebra/006_The_determinant/#the-determinant-can-be-negative","text":"This has to do with the concept of orientation. This happens when a transform \"inverts\" the orientation of space. For example of X is now pointing in the y direction. On way that this could happen is that if instead of being to the left of \\({\\mathbf{\\hat{\\imath}}}\\) , \\({\\mathbf{\\hat{\\jmath}}}\\) is now to the right of \\({\\mathbf{\\hat{\\imath}}}\\) . This inverts the orientation of space. This will create a negative determinant.","title":"The determinant can be negative"},{"location":"math/Essence_of_linear_algebra/006_The_determinant/#in-3d","text":"You are scaling volumes. It helps to visualize the cube resting on the basis vectors. After transformation this cube will get warped, possibly into a parallelepiped if the cube is skewed. \\[ det \\Bigg( \\begin{bmatrix} 1.0 & 0.0 & 0.5 \\\\ 0.5 & 1.0 & 0.0 \\\\ 1.0 & 0.0 & 1.0 \\end{bmatrix} \\Bigg) =\\text{Volume of parallelepiped} \\]","title":"In 3d"},{"location":"math/Essence_of_linear_algebra/006_The_determinant/#how-do-we-actually-compute-the-determinant","text":"\\[ det \\Bigg( \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\Bigg) = ad - bc \\] a and d in this example are the distance that \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) in their primary axes (x and y). Even if only one of their non-primary axes are zero (in the case of a parallelogram) the area is still their base times height. B * C basically tells you how much the parallelograph is squished into either direction. In 3d you subtract the det of the y axis and then add the determinant of the z axis. \\[ det \\Bigg( \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix} \\Bigg) = det_a \\Bigg( \\begin{bmatrix} e & f \\\\ h & i \\end{bmatrix} \\Bigg) - deb_b \\Bigg( \\begin{bmatrix} d & f \\\\ g & i \\end{bmatrix} \\Bigg) + det_c \\Bigg( \\begin{bmatrix} d & e \\\\ g & h \\end{bmatrix} \\Bigg) \\] He doesn't go into exactly why this is because it's not that relevant to linear algebra. A fun quiz (explain why this makes sense): \\[ det(M_1 M_2) = det(M_1)det(M_2) \\] This makes sense because you are multiplying the numbers both ways, and the determinant is also multiplied when multiplying matrices. \\(6 == 3 * 2\\)","title":"How do we actually compute the determinant?"},{"location":"math/Essence_of_linear_algebra/007_Inverse_matrices_column_space_and_null_space/","text":"Inverse matrices, column space and null space This goes over how to visualize these concepts, not how to calculate them manually. Google \"Gaussian elemination\" and \"Row echelon form\" if you are interested in this. Linear algebra is useful in computer graphics and robotics, but also for helping us solve equations. These are \"Linear system of equations\" \\[ 2x+5y+3z=-3 \\] \\[ 4x+0y+8z=0 \\] These have the same format as vectors, and we can use linear algebra to help us solve for them in a matrix like this: \\[ \\overbrace{ \\begin{bmatrix} 2 & 5 & 3 \\\\ 4 & 0 & 8 \\\\ 1 & 3 & 0 \\end{bmatrix} }^A \\overbrace{ \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} }^{ \\overrightarrow{x} } = \\overbrace{ \\begin{bmatrix} -3 \\\\ 0 \\\\ 2 \\end{bmatrix} }^{ \\overrightarrow{v} } \\] \\[ A \\overrightarrow{x} = \\overrightarrow{v} \\] There are two ways to use this equation: the most obvious is when \\(det(A) \\not = 0\\) this means space is not squished into a single line or dot. Inverse Matrices In this case you can reverse the transformation of the matrix. \\[ \\overbrace{ A^{-1} }^{\\text {Inverse Transformation}} * A = \\overbrace{ \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} }^{\\text{Identity Transform}} \\] Puts your right back where you started. With this inverse matrix (which you can get from a computer), you can solve the equation for x like so: \\[ A^{-1} A \\overrightarrow{x} = A^{-1} \\overrightarrow{v} \\] \\[ \\overrightarrow{x} = A^{-1}\\overrightarrow{v} \\] But what if the determinant is zero? In this case there is no inverse. But if the vector \\(\\overrightarrow{v}\\) is on the line/plane that the zero determinant matrix transfoms into, you can still solve for it. There is terminology for this: Rank 1: A single line matrix (1d) Rank 2: A plane matrix (2d) Rank 3: A 3d matrix (3d) etc. Column Space The set of all possible outputs of a matrix, the \"span\", is called column space . It's the \"span\" of the columns of the matrix. Rank can be defined as the number of dimensions in the column space. \"Full Rank\" is when the column space has the same dimensions as the matrix rank. The zero vector will always be in ever matrix's column space. Null Space When a matrix that is not full rank collapses vectors to the origin (to zero), the space that those vectors were in is called Null Space . It's the space of all the vectors that become null because they land on the zero Vector.","title":"Inverse matrices, column space and null space"},{"location":"math/Essence_of_linear_algebra/007_Inverse_matrices_column_space_and_null_space/#inverse-matrices-column-space-and-null-space","text":"This goes over how to visualize these concepts, not how to calculate them manually. Google \"Gaussian elemination\" and \"Row echelon form\" if you are interested in this. Linear algebra is useful in computer graphics and robotics, but also for helping us solve equations. These are \"Linear system of equations\" \\[ 2x+5y+3z=-3 \\] \\[ 4x+0y+8z=0 \\] These have the same format as vectors, and we can use linear algebra to help us solve for them in a matrix like this: \\[ \\overbrace{ \\begin{bmatrix} 2 & 5 & 3 \\\\ 4 & 0 & 8 \\\\ 1 & 3 & 0 \\end{bmatrix} }^A \\overbrace{ \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} }^{ \\overrightarrow{x} } = \\overbrace{ \\begin{bmatrix} -3 \\\\ 0 \\\\ 2 \\end{bmatrix} }^{ \\overrightarrow{v} } \\] \\[ A \\overrightarrow{x} = \\overrightarrow{v} \\] There are two ways to use this equation: the most obvious is when \\(det(A) \\not = 0\\) this means space is not squished into a single line or dot.","title":"Inverse matrices, column space and null space"},{"location":"math/Essence_of_linear_algebra/007_Inverse_matrices_column_space_and_null_space/#inverse-matrices","text":"In this case you can reverse the transformation of the matrix. \\[ \\overbrace{ A^{-1} }^{\\text {Inverse Transformation}} * A = \\overbrace{ \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} }^{\\text{Identity Transform}} \\] Puts your right back where you started. With this inverse matrix (which you can get from a computer), you can solve the equation for x like so: \\[ A^{-1} A \\overrightarrow{x} = A^{-1} \\overrightarrow{v} \\] \\[ \\overrightarrow{x} = A^{-1}\\overrightarrow{v} \\] But what if the determinant is zero? In this case there is no inverse. But if the vector \\(\\overrightarrow{v}\\) is on the line/plane that the zero determinant matrix transfoms into, you can still solve for it. There is terminology for this: Rank 1: A single line matrix (1d) Rank 2: A plane matrix (2d) Rank 3: A 3d matrix (3d) etc.","title":"Inverse Matrices"},{"location":"math/Essence_of_linear_algebra/007_Inverse_matrices_column_space_and_null_space/#column-space","text":"The set of all possible outputs of a matrix, the \"span\", is called column space . It's the \"span\" of the columns of the matrix. Rank can be defined as the number of dimensions in the column space. \"Full Rank\" is when the column space has the same dimensions as the matrix rank. The zero vector will always be in ever matrix's column space.","title":"Column Space"},{"location":"math/Essence_of_linear_algebra/007_Inverse_matrices_column_space_and_null_space/#null-space","text":"When a matrix that is not full rank collapses vectors to the origin (to zero), the space that those vectors were in is called Null Space . It's the space of all the vectors that become null because they land on the zero Vector.","title":"Null Space"},{"location":"math/Essence_of_linear_algebra/008_Nonsquare_matrices_as_transformations_between_dimensions/","text":"Nonsquare matrices as transformations between dimensions How do you transform matrices that do not have the same number of rows as columns? It's perfectly reasonable to talk about transoforms between dimensions. \\[ \\overbrace{ \\begin{bmatrix} 2 \\\\ 7 \\end{bmatrix} }^{\\text{2d input}} \\to L( \\overrightarrow{v} ) \\to \\overbrace{ \\begin{bmatrix} 1 \\\\ 8 \\\\ 2 \\end{bmatrix} }^{\\text{3d output}} \\] You can encode 2d information in 3d by just having 2 columns. The span of this matrix will be a plane. Similarly a three column two row matrix has three axees each on two dimensions. The span of this is also a plane. Basically a flattened set of vectors. Squishing vectors to a single line has ties to the dot product","title":"Nonsquare matrices as transformations between dimensions"},{"location":"math/Essence_of_linear_algebra/008_Nonsquare_matrices_as_transformations_between_dimensions/#nonsquare-matrices-as-transformations-between-dimensions","text":"How do you transform matrices that do not have the same number of rows as columns? It's perfectly reasonable to talk about transoforms between dimensions. \\[ \\overbrace{ \\begin{bmatrix} 2 \\\\ 7 \\end{bmatrix} }^{\\text{2d input}} \\to L( \\overrightarrow{v} ) \\to \\overbrace{ \\begin{bmatrix} 1 \\\\ 8 \\\\ 2 \\end{bmatrix} }^{\\text{3d output}} \\] You can encode 2d information in 3d by just having 2 columns. The span of this matrix will be a plane. Similarly a three column two row matrix has three axees each on two dimensions. The span of this is also a plane. Basically a flattened set of vectors. Squishing vectors to a single line has ties to the dot product","title":"Nonsquare matrices as transformations between dimensions"},{"location":"math/Essence_of_linear_algebra/009_Dot_products_and_duality/","text":"Dot products and duality Traditional Dot product explanation You multiply each of the rows in two vectors by each other and then add them together: \\[ \\begin{bmatrix} 6 \\\\ 2 \\\\ 8 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 8 \\\\ 5 \\end{bmatrix} = 6*1 + 2 * 8 + 8 * 5 + 3*3 \\] This has a very nice geometry interpretation though. If two vectors are pointing in generally the same direction, their dot product is positive, perpendicular it's zero, and away it's negative. Order does not matter. This only works for normalized vectors. Think of it as projecting a vector onto another vector. If you scale the vector, the projection will be greater or less than 1 and the result inaccurate. You can divide the dot product by the difference in vector scale though, and interestingly you will get the same result. \\[ (2 \\overrightarrow{v} ) \\cdot \\overrightarrow{w} = 2( \\overrightarrow{v} \\cdot \\overrightarrow{w} ) \\] And how does this work anyway? The answer has to do with duality. It has to do with the projection of higher rank vectors to lower rank vectors. The key here isn't to understand how a linear transformation between dimensions works, but that if you have a line of evenly spaced dots in a higher dimension, a linear conversion to a lower dimension will keep them evenly spaced. Let's transofrm a vector \\[ \\overrightarrow{v} = \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} \\] Let's say you have a linear transformation that takes \\({\\mathbf{\\hat{\\imath}}}\\) to 2 and \\({\\mathbf{\\hat{\\jmath}}}\\) to 1. This will transform the vector as such \\[ \\overrightarrow{v} = \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} = 4(1) * 3(-2) = -2 \\] This is basically matrix vector multiplication \\[ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} = 4 * 1 + 3 * 2 \\] Is the same as \\[ \\overbrace{ \\begin{bmatrix} 1 & 2 \\\\ \\end{bmatrix} }^{\\text{Transform}} \\overbrace{ \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} }^{\\text{Vector}} = 4* 1 + 3*2 \\] This is the same as basically taking the dot product! You are basically taking the matrix of \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) and tilting it on it's side. Given unit vector \\({\\hat{\\u}}\\) , if we \"project\" each of that vectors' coordinates onto \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) then those will be the exact same number. Conversly projecing the other way around gives the same numbers. Projecting \\({\\hat{\\u}}\\) in this way is computationally identical to taking the dot product of \\({\\hat{\\u}}\\) . This is why taknig the dot product of a unit vector is like projecting it onto a line. Now if you scale that unit vector, you are also linearly scaling the result. Any time you have a dot product you are basically taking the first vector, flipping it to a lower dimension and then projecting it down. This is what people in math refer to as duality - a natrual but surprising correspondence. You are creating a 1 row matrix from the first vector and then multiplying the second vector by that matrix.","title":"Dot products and duality"},{"location":"math/Essence_of_linear_algebra/009_Dot_products_and_duality/#dot-products-and-duality","text":"","title":"Dot products and duality"},{"location":"math/Essence_of_linear_algebra/009_Dot_products_and_duality/#traditional-dot-product-explanation","text":"You multiply each of the rows in two vectors by each other and then add them together: \\[ \\begin{bmatrix} 6 \\\\ 2 \\\\ 8 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 8 \\\\ 5 \\end{bmatrix} = 6*1 + 2 * 8 + 8 * 5 + 3*3 \\] This has a very nice geometry interpretation though. If two vectors are pointing in generally the same direction, their dot product is positive, perpendicular it's zero, and away it's negative. Order does not matter. This only works for normalized vectors. Think of it as projecting a vector onto another vector. If you scale the vector, the projection will be greater or less than 1 and the result inaccurate. You can divide the dot product by the difference in vector scale though, and interestingly you will get the same result. \\[ (2 \\overrightarrow{v} ) \\cdot \\overrightarrow{w} = 2( \\overrightarrow{v} \\cdot \\overrightarrow{w} ) \\]","title":"Traditional Dot product explanation"},{"location":"math/Essence_of_linear_algebra/009_Dot_products_and_duality/#and-how-does-this-work-anyway","text":"The answer has to do with duality. It has to do with the projection of higher rank vectors to lower rank vectors. The key here isn't to understand how a linear transformation between dimensions works, but that if you have a line of evenly spaced dots in a higher dimension, a linear conversion to a lower dimension will keep them evenly spaced. Let's transofrm a vector \\[ \\overrightarrow{v} = \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} \\] Let's say you have a linear transformation that takes \\({\\mathbf{\\hat{\\imath}}}\\) to 2 and \\({\\mathbf{\\hat{\\jmath}}}\\) to 1. This will transform the vector as such \\[ \\overrightarrow{v} = \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} = 4(1) * 3(-2) = -2 \\] This is basically matrix vector multiplication \\[ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} = 4 * 1 + 3 * 2 \\] Is the same as \\[ \\overbrace{ \\begin{bmatrix} 1 & 2 \\\\ \\end{bmatrix} }^{\\text{Transform}} \\overbrace{ \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix} }^{\\text{Vector}} = 4* 1 + 3*2 \\] This is the same as basically taking the dot product! You are basically taking the matrix of \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) and tilting it on it's side. Given unit vector \\({\\hat{\\u}}\\) , if we \"project\" each of that vectors' coordinates onto \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) then those will be the exact same number. Conversly projecing the other way around gives the same numbers. Projecting \\({\\hat{\\u}}\\) in this way is computationally identical to taking the dot product of \\({\\hat{\\u}}\\) . This is why taknig the dot product of a unit vector is like projecting it onto a line. Now if you scale that unit vector, you are also linearly scaling the result. Any time you have a dot product you are basically taking the first vector, flipping it to a lower dimension and then projecting it down. This is what people in math refer to as duality - a natrual but surprising correspondence. You are creating a 1 row matrix from the first vector and then multiplying the second vector by that matrix.","title":"And how does this work anyway?"},{"location":"math/Essence_of_linear_algebra/010_Cross_Products/","text":"Cross Products \"Every dimension is special.\" -Jeff Lagarias \"In Russian math school we call dot product a \"scalar product\" and a cross product a \"vector product\". And I think this is very intuitive naming\" -mchlkzmn youtube comment The Cross product is the area of the parallelogram created by two vectors. The parallelogram is created by adding each vector to the other vector. It's written like this \\[ \\overrightarrow{v} \\times \\overrightarrow{w} = \\text{Area of parallelogram} \\] It also depends on the order of teh vectors. If \\(\\overrightarrow{v}\\) is on the right of \\(\\overrightarrow{w}\\) then the cross product is positive, on the left it is negative. Order matters! You can remember the order based on the order of a vector (x, y, z) - if the vectors are in this order the result is positive. \\[ \\overrightarrow{x} \\times \\overrightarrow{y} = \\text{positive} \\] \\[ \\overrightarrow{y} \\times \\overrightarrow{x} = \\text{negative} \\] To calculate the cross product we use a very similar method to calculating the determinant . \\[ \\overrightarrow{v} \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} \\times \\overrightarrow{w} \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} 3 & 2 \\\\ 1 & -1 \\end{bmatrix} \\Bigg) \\] The determinant is all about measuring how areas change due to a transformation. You create the transformation by \"transforming\" to the vectors that are being crossed. If \\(\\overrightarrow{v}\\) is on the left of \\(\\overrightarrow{w}\\) , then it means that orientation was flipped, and you get the negative result. In 3d this becomes a lot more interesting. This area will become the length of the new vector. The direction of that new vector is going to be perpendicular to the two input vectors. Note that this vector always points to the right of the plane of x and y on your right hand ( right hand rule ). The thumb is the cross product. The actual method for determining the cross product is strange. It's like calculating the determinant, but only for each row which then becomes the new vector. \\[ \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\times \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} {\\mathbf{\\hat{\\imath}}} & v_1 & w_1 \\\\ {\\mathbf{\\hat{\\jmath}}} & v_2 & w_2 \\\\ {\\mathbf{\\hat{k}}} & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] \\[ {\\mathbf{\\hat{\\imath}}} ( v_2 w_3 - v_3 w_2) + {\\mathbf{\\hat{\\jmath}}} ( v_3 w_1 - v_1 w_3 ) + {\\mathbf{\\hat{k}}} (v_1 w_2 - v_2 w_1) \\] Why on earch are the basis vectors there? We go over this in the next lesson!","title":"Cross Products"},{"location":"math/Essence_of_linear_algebra/010_Cross_Products/#cross-products","text":"\"Every dimension is special.\" -Jeff Lagarias \"In Russian math school we call dot product a \"scalar product\" and a cross product a \"vector product\". And I think this is very intuitive naming\" -mchlkzmn youtube comment The Cross product is the area of the parallelogram created by two vectors. The parallelogram is created by adding each vector to the other vector. It's written like this \\[ \\overrightarrow{v} \\times \\overrightarrow{w} = \\text{Area of parallelogram} \\] It also depends on the order of teh vectors. If \\(\\overrightarrow{v}\\) is on the right of \\(\\overrightarrow{w}\\) then the cross product is positive, on the left it is negative. Order matters! You can remember the order based on the order of a vector (x, y, z) - if the vectors are in this order the result is positive. \\[ \\overrightarrow{x} \\times \\overrightarrow{y} = \\text{positive} \\] \\[ \\overrightarrow{y} \\times \\overrightarrow{x} = \\text{negative} \\] To calculate the cross product we use a very similar method to calculating the determinant . \\[ \\overrightarrow{v} \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} \\times \\overrightarrow{w} \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} 3 & 2 \\\\ 1 & -1 \\end{bmatrix} \\Bigg) \\] The determinant is all about measuring how areas change due to a transformation. You create the transformation by \"transforming\" to the vectors that are being crossed. If \\(\\overrightarrow{v}\\) is on the left of \\(\\overrightarrow{w}\\) , then it means that orientation was flipped, and you get the negative result. In 3d this becomes a lot more interesting. This area will become the length of the new vector. The direction of that new vector is going to be perpendicular to the two input vectors. Note that this vector always points to the right of the plane of x and y on your right hand ( right hand rule ). The thumb is the cross product. The actual method for determining the cross product is strange. It's like calculating the determinant, but only for each row which then becomes the new vector. \\[ \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\times \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} {\\mathbf{\\hat{\\imath}}} & v_1 & w_1 \\\\ {\\mathbf{\\hat{\\jmath}}} & v_2 & w_2 \\\\ {\\mathbf{\\hat{k}}} & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] \\[ {\\mathbf{\\hat{\\imath}}} ( v_2 w_3 - v_3 w_2) + {\\mathbf{\\hat{\\jmath}}} ( v_3 w_1 - v_1 w_3 ) + {\\mathbf{\\hat{k}}} (v_1 w_2 - v_2 w_1) \\] Why on earch are the basis vectors there? We go over this in the next lesson!","title":"Cross Products"},{"location":"math/Essence_of_linear_algebra/011_Cross_Products_in_the_light_of_linear_transformations/","text":"Cross products in the light of linear transformations Why are the symbols of the first column \\({\\mathbf{\\hat{\\imath}}}\\) \\({\\mathbf{\\hat{\\jmath}}}\\) and \\({\\mathbf{\\hat{k}}}\\) ? \\[ \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\times \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} {\\mathbf{\\hat{\\imath}}} & v_1 & w_1 \\\\ {\\mathbf{\\hat{\\jmath}}} & v_2 & w_2 \\\\ {\\mathbf{\\hat{k}}} & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] This results in three numbers that are then used in a vector... but whyyy. This goes back to te mathemathical concept of duality covered here . When linearly transforming vectors to the numberline, you will be able to match those vectors to dual vectors of those transformations. So that performing the linear transformation is the same as taking a dot product with that vector. The cross product is an example of this process in action. We're going to walk through this: Define a 3d-to-1d linear transformation in germs of \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . Find its dual vector Show that dual vector == cross product Remember that for 2d, the cross product is an ordinary determinant returning a 1d number, which is the area of that parallelogram spanned out by those two vectors which is negative or positive depending on if the vectors are flipped in relation to their basis vectors. Also remember that the determinant of a 3x3 transform gives the volume of that parralelopiped created by those three vectors. This is different than the cross product which takes in three vectors and spits out a vector instead of a scalar. Let's start by defining a function to get the volume of a parralelopiped with vectors \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) given arbitrary input vector made up of x, y, z. \\[ \\large f \\Bigg( \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} \\Bigg) = det \\Bigg( \\begin{bmatrix} x & v_1 & w_1 \\\\ y & v_2 & w_2 \\\\ x & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] An important part to remember is that this function is linear because it's outputting a scalar value. This means we can bring in the idea of a dual vector. It means there is some way to describe this function as matrix multiplications. For any fucntion that goes from three dimensions to one dimensions there will be a 1x3 matrix describing that transformations. Remember that this process is the same as the dot product, so that is what we will use to spell out the formula. In this formula we want to solve for \\(\\overrightarrow{p}\\) . \\[ \\overbrace{ \\begin{bmatrix} p_1 \\\\ p_2 \\\\ p_3 \\end{bmatrix} }^{ \\overrightarrow{p} } \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} x & v_1 & w_1 \\\\ y & v_2 & w_2 \\\\ x & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] \\[ p_1 * x + p_2 * y + p_3 * z = x(v_2 * w_3 - v_3* w_2) + y(v_3 * w_1 - v_1 * w_3) + z(v_1 * w_2 - v_2 * w_1) \\] \\[ p_1 = v_2*w_3-v_3*w_2 \\] \\[ p_2 = v_3*w_1-v_1*w_3 \\] \\[ p_3 = v_1*w_2-v_2*w_1 \\] This is very similar to what we do when we manualy calculate a cross product like in the previous section. Only that \\({\\mathbf{\\hat{\\imath}}},\\) \\({\\mathbf{\\hat{\\jmath}}},\\) and \\({\\mathbf{\\hat{k}}}\\) is a way of signalling that we should interpret those coefficients as the coordinates of a vector. What all of this is saying is that the computation for the cross product can be considered a way to anser the question: What vector \\(\\overrightarrow{p}\\) has the property that when you take a dot product between \\(\\overrightarrow{p}\\) and some \\(\\overrightarrow{xyz}\\) , it gives the same result as plugging in \\(\\overrightarrow{xyz}\\) to the first column of a matrix whose other two columns have the coordinates of \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w},\\) and then computing the determinant. Let's rephrase this question in geometrical terms: What vector \\(\\overrightarrow{p}\\) will return the area of a parralelopiped when you take it's dot product with another \\(\\overrightarrow{xyz}\\) , that returns the same volume as when you take the determinant of a matrix with columns \\(\\overrightarrow{xyz}\\) and \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . \\[ ( \\text{Area of parallelogram} ) * ( \\text{Component of } \\overrightarrow{xyz} \\text{ perpendicular to } \\overrightarrow{v} \\text{ and } \\overrightarrow{w} ) \\] This is the same of taking the dot product of any vector \\(\\overrightarrow{xyz}\\) and \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) then setting that to the length of the parallelogram. If the vector is normalized (like the basis vector) you simply need to multiply it by the determinant of \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . If, like the basis vectors, that vector is in the right order, the right hand rule will multiply it by -1 if the vectors are in the other direction. This is why \\(\\overrightarrow{xyz}\\) must be the basis vectors.","title":"Cross products in the light of linear transformations"},{"location":"math/Essence_of_linear_algebra/011_Cross_Products_in_the_light_of_linear_transformations/#cross-products-in-the-light-of-linear-transformations","text":"Why are the symbols of the first column \\({\\mathbf{\\hat{\\imath}}}\\) \\({\\mathbf{\\hat{\\jmath}}}\\) and \\({\\mathbf{\\hat{k}}}\\) ? \\[ \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\times \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} {\\mathbf{\\hat{\\imath}}} & v_1 & w_1 \\\\ {\\mathbf{\\hat{\\jmath}}} & v_2 & w_2 \\\\ {\\mathbf{\\hat{k}}} & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] This results in three numbers that are then used in a vector... but whyyy. This goes back to te mathemathical concept of duality covered here . When linearly transforming vectors to the numberline, you will be able to match those vectors to dual vectors of those transformations. So that performing the linear transformation is the same as taking a dot product with that vector. The cross product is an example of this process in action. We're going to walk through this: Define a 3d-to-1d linear transformation in germs of \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . Find its dual vector Show that dual vector == cross product Remember that for 2d, the cross product is an ordinary determinant returning a 1d number, which is the area of that parallelogram spanned out by those two vectors which is negative or positive depending on if the vectors are flipped in relation to their basis vectors. Also remember that the determinant of a 3x3 transform gives the volume of that parralelopiped created by those three vectors. This is different than the cross product which takes in three vectors and spits out a vector instead of a scalar. Let's start by defining a function to get the volume of a parralelopiped with vectors \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) given arbitrary input vector made up of x, y, z. \\[ \\large f \\Bigg( \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} \\Bigg) = det \\Bigg( \\begin{bmatrix} x & v_1 & w_1 \\\\ y & v_2 & w_2 \\\\ x & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] An important part to remember is that this function is linear because it's outputting a scalar value. This means we can bring in the idea of a dual vector. It means there is some way to describe this function as matrix multiplications. For any fucntion that goes from three dimensions to one dimensions there will be a 1x3 matrix describing that transformations. Remember that this process is the same as the dot product, so that is what we will use to spell out the formula. In this formula we want to solve for \\(\\overrightarrow{p}\\) . \\[ \\overbrace{ \\begin{bmatrix} p_1 \\\\ p_2 \\\\ p_3 \\end{bmatrix} }^{ \\overrightarrow{p} } \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = det \\Bigg( \\begin{bmatrix} x & v_1 & w_1 \\\\ y & v_2 & w_2 \\\\ x & v_3 & w_3 \\end{bmatrix} \\Bigg) \\] \\[ p_1 * x + p_2 * y + p_3 * z = x(v_2 * w_3 - v_3* w_2) + y(v_3 * w_1 - v_1 * w_3) + z(v_1 * w_2 - v_2 * w_1) \\] \\[ p_1 = v_2*w_3-v_3*w_2 \\] \\[ p_2 = v_3*w_1-v_1*w_3 \\] \\[ p_3 = v_1*w_2-v_2*w_1 \\] This is very similar to what we do when we manualy calculate a cross product like in the previous section. Only that \\({\\mathbf{\\hat{\\imath}}},\\) \\({\\mathbf{\\hat{\\jmath}}},\\) and \\({\\mathbf{\\hat{k}}}\\) is a way of signalling that we should interpret those coefficients as the coordinates of a vector. What all of this is saying is that the computation for the cross product can be considered a way to anser the question: What vector \\(\\overrightarrow{p}\\) has the property that when you take a dot product between \\(\\overrightarrow{p}\\) and some \\(\\overrightarrow{xyz}\\) , it gives the same result as plugging in \\(\\overrightarrow{xyz}\\) to the first column of a matrix whose other two columns have the coordinates of \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w},\\) and then computing the determinant. Let's rephrase this question in geometrical terms: What vector \\(\\overrightarrow{p}\\) will return the area of a parralelopiped when you take it's dot product with another \\(\\overrightarrow{xyz}\\) , that returns the same volume as when you take the determinant of a matrix with columns \\(\\overrightarrow{xyz}\\) and \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . \\[ ( \\text{Area of parallelogram} ) * ( \\text{Component of } \\overrightarrow{xyz} \\text{ perpendicular to } \\overrightarrow{v} \\text{ and } \\overrightarrow{w} ) \\] This is the same of taking the dot product of any vector \\(\\overrightarrow{xyz}\\) and \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) then setting that to the length of the parallelogram. If the vector is normalized (like the basis vector) you simply need to multiply it by the determinant of \\(\\overrightarrow{v}\\) and \\(\\overrightarrow{w}\\) . If, like the basis vectors, that vector is in the right order, the right hand rule will multiply it by -1 if the vectors are in the other direction. This is why \\(\\overrightarrow{xyz}\\) must be the basis vectors.","title":"Cross products in the light of linear transformations"},{"location":"math/Essence_of_linear_algebra/012_Cramers_rule_explained_geometrically/","text":"Cramer's rule, explained geometrically Here we will look at the geometry behind \"Cramer's Rule\" The background for this requires determinants , dot products , and how to balance equations Cramer's rule helps us solve this equation for \\(\\overrightarrow{xyz}\\) : \\[ \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 7 \\\\ -8 \\\\ 3 \\end{bmatrix} \\] By divding the determinants of new matrices created with \\(\\overrightarrow{xyz}\\) and the known transform with the determinant of the known transofrm. But how does this work\u001f \\[ x = \\frac{ det \\Bigg( \\begin{bmatrix} \\textcolor{red}{ 7 } & 2 & 3 \\\\ \\textcolor{red}{ -8 } & 0 & 2 \\\\ \\textcolor{red}{ 3 } & 6 & 9 \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\qquad y = \\frac{ det \\Bigg( \\begin{bmatrix} -4 & \\textcolor{red}{ 7 } & 3 \\\\ -1 & \\textcolor{red}{ -8 } & 2 \\\\ -4 & \\textcolor{red}{ 3 } & -9 \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\qquad z = \\frac{ det \\Bigg( \\begin{bmatrix} -4 & 2 & \\textcolor{red}{ 7 }\\\\ -1 & 0 & \\textcolor{red}{ -8 }\\\\ -4 & 6 & \\textcolor{red}{ 3 } \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\] General disclaimer: Cramer's rule isn't the best way to compute solutions to linear systems of equations. Gaussian Elimination will always be faster. Let's start with the setup. \\[ 3x + 2y = -4 \\] \\[ 1x + 2y = -2 \\] You can think of this setup geometryically as a certain known matrix transforming an unknown vector where you know what the output is going to be. It can be thought of as a puzzle: Which input vector xy is going to land at output vector -4, -2. Note that if te determinant is zero then this changes things, so we are assuming that the \\(det(A) \\not = 0\\) . \\[ \\begin{bmatrix} 3 & 2 \\\\ -1 & 2 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} -4 \\\\ -2 \\end{bmatrix} \\] To solve this you might try to take the dot product of the input and output transformations for each axis, assuming they are equal. In this case it would be easy to get the transformation we need because we know what the output vectors are. This would only work for vectors that are perpendicular to each other. Transformations that do preseve dot products where this would work are called \"Orthonormal\" . These are commonly used for rotation matrices, with no stretching or squishing or flipping. i \\[ \\overbrace{ \\begin{bmatrix} cos(30\u00b0) & -sin(30\u00b0) \\\\ sin(30\u00b0) & cos(30\u00b0) \\end{bmatrix} }^\\text{(Orthonormal)} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\] Can be easily solved like this: \\[ x = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} cos(30\u00b0) \\\\ sin(30\u00b0) \\end{bmatrix} \\] \\[ y = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} -sin(30\u00b0) \\\\ cos(30\u00b0) \\end{bmatrix} \\] For all other types of transforms, might there be a similar alternate geometric understanding for the coordinates of our input vector? Let's start by looking at the area of the parrallelogram of the desired transformation and it's basis vector. This is alwasy exqual to the value of the desired vector. \\(Area = x\\) Thinking of this in terms of area let's us compare it to the area of the vector that we already have. In 3d this would be the parallelopiped that the zaxis creates with the basis vectors \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) . \\[ z = det \\Bigg( \\begin{bmatrix} 1 & 0 & x \\\\ 0 & 1 & y \\\\ 0 & 0 & x \\end{bmatrix} \\Bigg) \\] The volume here is also simply the value of the z axis of the vector. Note that because the volume is dependant on the order of the vectors (right hand rule) because it determines the sign of the volume. Now that we are thinking of these in terms of area, we can observe that these areas change after transformations. Because of how the determinant works, all the areas of all the axes are scaled by the same amount during a transformations. Given A is the transformation matrix \\(det(A)\\) . This allows us to now say that Signed Area = \\(det(A)y\\) - SO with this we can now solve for y like this \\[ y = \\frac{ \\text{Area} }{ det(A) } \\] And we have the area from the point where the input vector lands. And this is how we can use Cramer's rule to figure out which input vector was used to generate an output vector given a matrix. \\[ y = \\frac{ det \\Bigg( \\begin{bmatrix} -4 & \\textcolor{red}{ 7 } & 3 \\\\ -1 & \\textcolor{red}{ -8 } & 2 \\\\ -4 & \\textcolor{red}{ 3 } & -9 \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\]","title":"Cramer's rule, explained geometrically"},{"location":"math/Essence_of_linear_algebra/012_Cramers_rule_explained_geometrically/#cramers-rule-explained-geometrically","text":"Here we will look at the geometry behind \"Cramer's Rule\" The background for this requires determinants , dot products , and how to balance equations Cramer's rule helps us solve this equation for \\(\\overrightarrow{xyz}\\) : \\[ \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 7 \\\\ -8 \\\\ 3 \\end{bmatrix} \\] By divding the determinants of new matrices created with \\(\\overrightarrow{xyz}\\) and the known transform with the determinant of the known transofrm. But how does this work\u001f \\[ x = \\frac{ det \\Bigg( \\begin{bmatrix} \\textcolor{red}{ 7 } & 2 & 3 \\\\ \\textcolor{red}{ -8 } & 0 & 2 \\\\ \\textcolor{red}{ 3 } & 6 & 9 \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\qquad y = \\frac{ det \\Bigg( \\begin{bmatrix} -4 & \\textcolor{red}{ 7 } & 3 \\\\ -1 & \\textcolor{red}{ -8 } & 2 \\\\ -4 & \\textcolor{red}{ 3 } & -9 \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\qquad z = \\frac{ det \\Bigg( \\begin{bmatrix} -4 & 2 & \\textcolor{red}{ 7 }\\\\ -1 & 0 & \\textcolor{red}{ -8 }\\\\ -4 & 6 & \\textcolor{red}{ 3 } \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\] General disclaimer: Cramer's rule isn't the best way to compute solutions to linear systems of equations. Gaussian Elimination will always be faster. Let's start with the setup. \\[ 3x + 2y = -4 \\] \\[ 1x + 2y = -2 \\] You can think of this setup geometryically as a certain known matrix transforming an unknown vector where you know what the output is going to be. It can be thought of as a puzzle: Which input vector xy is going to land at output vector -4, -2. Note that if te determinant is zero then this changes things, so we are assuming that the \\(det(A) \\not = 0\\) . \\[ \\begin{bmatrix} 3 & 2 \\\\ -1 & 2 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} -4 \\\\ -2 \\end{bmatrix} \\] To solve this you might try to take the dot product of the input and output transformations for each axis, assuming they are equal. In this case it would be easy to get the transformation we need because we know what the output vectors are. This would only work for vectors that are perpendicular to each other. Transformations that do preseve dot products where this would work are called \"Orthonormal\" . These are commonly used for rotation matrices, with no stretching or squishing or flipping. i \\[ \\overbrace{ \\begin{bmatrix} cos(30\u00b0) & -sin(30\u00b0) \\\\ sin(30\u00b0) & cos(30\u00b0) \\end{bmatrix} }^\\text{(Orthonormal)} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\] Can be easily solved like this: \\[ x = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} cos(30\u00b0) \\\\ sin(30\u00b0) \\end{bmatrix} \\] \\[ y = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} -sin(30\u00b0) \\\\ cos(30\u00b0) \\end{bmatrix} \\] For all other types of transforms, might there be a similar alternate geometric understanding for the coordinates of our input vector? Let's start by looking at the area of the parrallelogram of the desired transformation and it's basis vector. This is alwasy exqual to the value of the desired vector. \\(Area = x\\) Thinking of this in terms of area let's us compare it to the area of the vector that we already have. In 3d this would be the parallelopiped that the zaxis creates with the basis vectors \\({\\mathbf{\\hat{\\imath}}}\\) and \\({\\mathbf{\\hat{\\jmath}}}\\) . \\[ z = det \\Bigg( \\begin{bmatrix} 1 & 0 & x \\\\ 0 & 1 & y \\\\ 0 & 0 & x \\end{bmatrix} \\Bigg) \\] The volume here is also simply the value of the z axis of the vector. Note that because the volume is dependant on the order of the vectors (right hand rule) because it determines the sign of the volume. Now that we are thinking of these in terms of area, we can observe that these areas change after transformations. Because of how the determinant works, all the areas of all the axes are scaled by the same amount during a transformations. Given A is the transformation matrix \\(det(A)\\) . This allows us to now say that Signed Area = \\(det(A)y\\) - SO with this we can now solve for y like this \\[ y = \\frac{ \\text{Area} }{ det(A) } \\] And we have the area from the point where the input vector lands. And this is how we can use Cramer's rule to figure out which input vector was used to generate an output vector given a matrix. \\[ y = \\frac{ det \\Bigg( \\begin{bmatrix} -4 & \\textcolor{red}{ 7 } & 3 \\\\ -1 & \\textcolor{red}{ -8 } & 2 \\\\ -4 & \\textcolor{red}{ 3 } & -9 \\end{bmatrix} \\Bigg) }{ det \\Bigg( \\begin{bmatrix} -4 & 2 & 3 \\\\ -1 & 0 & 2 \\\\ -4 & 6 & -9 \\end{bmatrix} \\Bigg) } \\]","title":"Cramer's rule, explained geometrically"},{"location":"math/Essence_of_linear_algebra/013_Change_of_basis/","text":"Change of basis As a review in linear algebra wewe often think of each element in a vector scaling it's corresponding basis vectors. A Coordinate system is any way to translate between vectors and sets of numbers. Let's imagine using different basis vectors. The same vectors in different coordinate spaces have different numbers. This is kind of like a transformed object space. Note that the origin will always be 0, 0. The direction of axes and spacing of grid lines can all change. So how do we translate between coordinate systems. So the alternative coordinate system might be represented like this: \\[ \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = -1 \\overrightarrow{b_1} + 2 \\overrightarrow{b_2} \\] From the other perspective \\(b_1\\) = is 2, 1 and \\(b_2\\) is -1, -1. You can translate between a strange coordinate system and the normal one by multiplying the vectors by the strange one's vectors. \\[ -1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + 2 \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} -4 \\\\ 1 \\end{bmatrix} \\] The process of scaling each of the basis vectors by the basis vectors of the other coordinate system and then adding them together is basically matrix multiplication (transformation). Matrix multiplication moves things into different coordinate systems. To get vectors into another coordinate space, you can multiply them by the inverse of the matrix of that coordinate space. So that's how you chagne coordinate spaces for vectors. For matrices it's a bit different. This is very similar to how I solved rotations when I first approached them. Take a vector (possibly one you would like to rotate) Multiply it by the inverse of it's parent (or the Change of basis matrix). Apply the transformation Multiply that by the inverse of the change of basis matrix to put it back into the original space. This is a very useful technique for rotation things in different spaces (like different joints). It can be simplified to this \\(A^{-1}MA\\)","title":"Change of basis"},{"location":"math/Essence_of_linear_algebra/013_Change_of_basis/#change-of-basis","text":"As a review in linear algebra wewe often think of each element in a vector scaling it's corresponding basis vectors. A Coordinate system is any way to translate between vectors and sets of numbers. Let's imagine using different basis vectors. The same vectors in different coordinate spaces have different numbers. This is kind of like a transformed object space. Note that the origin will always be 0, 0. The direction of axes and spacing of grid lines can all change. So how do we translate between coordinate systems. So the alternative coordinate system might be represented like this: \\[ \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = -1 \\overrightarrow{b_1} + 2 \\overrightarrow{b_2} \\] From the other perspective \\(b_1\\) = is 2, 1 and \\(b_2\\) is -1, -1. You can translate between a strange coordinate system and the normal one by multiplying the vectors by the strange one's vectors. \\[ -1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + 2 \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} -4 \\\\ 1 \\end{bmatrix} \\] The process of scaling each of the basis vectors by the basis vectors of the other coordinate system and then adding them together is basically matrix multiplication (transformation). Matrix multiplication moves things into different coordinate systems. To get vectors into another coordinate space, you can multiply them by the inverse of the matrix of that coordinate space. So that's how you chagne coordinate spaces for vectors. For matrices it's a bit different. This is very similar to how I solved rotations when I first approached them. Take a vector (possibly one you would like to rotate) Multiply it by the inverse of it's parent (or the Change of basis matrix). Apply the transformation Multiply that by the inverse of the change of basis matrix to put it back into the original space. This is a very useful technique for rotation things in different spaces (like different joints). It can be simplified to this \\(A^{-1}MA\\)","title":"Change of basis"},{"location":"math/Essence_of_linear_algebra/014_Eigenvectors_and_eigenvalues/","text":"Eigenvectors and eigenvalues This topic requires knowlage of linear transformations , determinants , linear systems , and change of basis vectors . Eigenvectors are the vectors of a transformation that do not change. Consider some linear transformation in 2 dimensions. \\[ \\begin{bmatrix} 3 & 1 \\\\ 0 & 2 \\end{bmatrix} \\] Focus on what this does to a vector and the span of that vector passing through the origin. Most vectors will be knocked off that span during their transformation. It would seem pretty co-incedental if the vector happened to stay on the same line. Two vectors stay on the same line though: \\(\\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}\\) \\(\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\) These vectors are called the eigenvectors. Each one of these has an eigenvalue which expresses how much the vector is scaled by a transformation. Why is this useful? In rotations this is the axis of rotation. It's much easier to think of rotations as rotating around a value. Note that with rotations the eigenvalue will always be 1 since rotation never stretch or squish anything. Eigenvectors are found with this expression, \\(\\overrightarrow{v}\\) is the eigenvector to solve for: \\[ \\overbrace{ A }^{\\text{Transformation Matrix}} \\overrightarrow{v} = \\overbrace{ \\lambda }^{\\text{Eigenvalue}} \\overrightarrow{v} \\] The matrix scalar product of the vector must be the same in all cases as any transformation of that vector. The right side is scalar vector multiplication and the left side is matrix vector multiplication. You can represent \\(\\lambda\\) more intuitively by puttin it into a matrix like so: \\[ \\lambda \\overbrace{ \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} }^{I} \\] \\[ A \\overrightarrow{v} =(\\lambda I) \\overrightarrow{v} \\] We can now factor out \\(\\overrightarrow{v}\\) from both sides and modify the equasion to look like this: \\[ A \\overrightarrow{v} - \\lambda I \\overrightarrow{v} = \\overrightarrow{0} \\] \\[ (A - \\lambda I) \\overrightarrow{v} = \\overrightarrow{0} \\] \\[ det(A - \\lambda I ) = \\overrightarrow{0} \\] So we want this matrix times \\(\\overrightarrow{v}\\) to equal the \\(\\overrightarrow{0}\\) . This can be any matrix. \\[ \\overrightarrow{v} \\begin{bmatrix} 3- \\lambda & 1 & 4 \\\\ 1 & 5-\\lambda & 9 \\\\ 2 & 6 & 5 - \\lambda \\end{bmatrix} \\] A further proof that a vector is an eigenvector is if the determinant of that vector is 0. You can visualize this as the squishification of that vector always becing zero on the number line. \\(\\text{Squishification} \\implies det(A - \\lambda I ) = 0\\) . We can write this out in the following where we solve for cases of \\(\\lambda\\) where the determinant = 0. \\[ det \\Bigg( \\overbrace{ \\begin{bmatrix} 2 - \\lambda & 2 \\\\ 1 & 3 - \\lambda \\end{bmatrix} }^{A - \\lambda I} \\Bigg) =0.00 \\] Setting \\(\\lambda\\) to 1 fulfills those requirements. This means that there is a non-zero vector where \\(A \\overrightarrow{v} = ( \\lambda I ) \\overrightarrow{v}\\) . This means that \\(\\overrightarrow{v}\\) is an eigenvector and the eigenvalue of \\(\\overrightarrow{v}\\) is 1. Note that not every transformation has eigenvalues . For example a rotation matrix will not have any Eigenvectors. \\[ det \\Bigg( \\begin{bmatrix} - \\lambda & -1 \\\\ 1 & - \\lambda \\end{bmatrix} \\Bigg) = (- \\lambda)(- \\lambda)-(-1)(1) = \\lambda^2 + 1 = 0 \\] Another interesting example is a shear like this: \\[ det \\Bigg( \\begin{bmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{bmatrix}i \\Bigg) = (1 - \\lambda)(1 - \\lambda) - \\overbrace{ 1 * 0 }^{\\text{Equals 0, so ignore}} = \\lambda = 1 \\] This lines up with what we know: that all eigenvectors have an eigenvalue of 1. A final interesting example is when our basis vectors just so happen to be eigenvectors, which make up a matrix called an Eigenbasis . If the numbers on the matrix are diagonal it's a diagonal matrix . This also means that all the basis vectors are eigenvectors with the diagonal entries of these matrices being their eigenvalues. If you keep multiplying this matrix by itself it will be simply scaling it's values. This makes it very easy to work with. This is why many rotation are transformed into a diagonal matrix and then transformed back. Also if you needed to calculate the 100th power of a given matrix, it would be much easier to change to an eigenbasis, compute the number, and then change back with the inverse. A great exercise to practice this can be found here","title":"Eigenvectors and eigenvalues"},{"location":"math/Essence_of_linear_algebra/014_Eigenvectors_and_eigenvalues/#eigenvectors-and-eigenvalues","text":"This topic requires knowlage of linear transformations , determinants , linear systems , and change of basis vectors .","title":"Eigenvectors and eigenvalues"},{"location":"math/Essence_of_linear_algebra/014_Eigenvectors_and_eigenvalues/#eigenvectors-are-the-vectors-of-a-transformation-that-do-not-change","text":"Consider some linear transformation in 2 dimensions. \\[ \\begin{bmatrix} 3 & 1 \\\\ 0 & 2 \\end{bmatrix} \\] Focus on what this does to a vector and the span of that vector passing through the origin. Most vectors will be knocked off that span during their transformation. It would seem pretty co-incedental if the vector happened to stay on the same line. Two vectors stay on the same line though: \\(\\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}\\) \\(\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\) These vectors are called the eigenvectors. Each one of these has an eigenvalue which expresses how much the vector is scaled by a transformation.","title":"Eigenvectors are the vectors of a transformation that do not change."},{"location":"math/Essence_of_linear_algebra/014_Eigenvectors_and_eigenvalues/#why-is-this-useful","text":"In rotations this is the axis of rotation. It's much easier to think of rotations as rotating around a value. Note that with rotations the eigenvalue will always be 1 since rotation never stretch or squish anything. Eigenvectors are found with this expression, \\(\\overrightarrow{v}\\) is the eigenvector to solve for: \\[ \\overbrace{ A }^{\\text{Transformation Matrix}} \\overrightarrow{v} = \\overbrace{ \\lambda }^{\\text{Eigenvalue}} \\overrightarrow{v} \\] The matrix scalar product of the vector must be the same in all cases as any transformation of that vector. The right side is scalar vector multiplication and the left side is matrix vector multiplication. You can represent \\(\\lambda\\) more intuitively by puttin it into a matrix like so: \\[ \\lambda \\overbrace{ \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} }^{I} \\] \\[ A \\overrightarrow{v} =(\\lambda I) \\overrightarrow{v} \\] We can now factor out \\(\\overrightarrow{v}\\) from both sides and modify the equasion to look like this: \\[ A \\overrightarrow{v} - \\lambda I \\overrightarrow{v} = \\overrightarrow{0} \\] \\[ (A - \\lambda I) \\overrightarrow{v} = \\overrightarrow{0} \\] \\[ det(A - \\lambda I ) = \\overrightarrow{0} \\] So we want this matrix times \\(\\overrightarrow{v}\\) to equal the \\(\\overrightarrow{0}\\) . This can be any matrix. \\[ \\overrightarrow{v} \\begin{bmatrix} 3- \\lambda & 1 & 4 \\\\ 1 & 5-\\lambda & 9 \\\\ 2 & 6 & 5 - \\lambda \\end{bmatrix} \\] A further proof that a vector is an eigenvector is if the determinant of that vector is 0. You can visualize this as the squishification of that vector always becing zero on the number line. \\(\\text{Squishification} \\implies det(A - \\lambda I ) = 0\\) . We can write this out in the following where we solve for cases of \\(\\lambda\\) where the determinant = 0. \\[ det \\Bigg( \\overbrace{ \\begin{bmatrix} 2 - \\lambda & 2 \\\\ 1 & 3 - \\lambda \\end{bmatrix} }^{A - \\lambda I} \\Bigg) =0.00 \\] Setting \\(\\lambda\\) to 1 fulfills those requirements. This means that there is a non-zero vector where \\(A \\overrightarrow{v} = ( \\lambda I ) \\overrightarrow{v}\\) . This means that \\(\\overrightarrow{v}\\) is an eigenvector and the eigenvalue of \\(\\overrightarrow{v}\\) is 1. Note that not every transformation has eigenvalues . For example a rotation matrix will not have any Eigenvectors. \\[ det \\Bigg( \\begin{bmatrix} - \\lambda & -1 \\\\ 1 & - \\lambda \\end{bmatrix} \\Bigg) = (- \\lambda)(- \\lambda)-(-1)(1) = \\lambda^2 + 1 = 0 \\] Another interesting example is a shear like this: \\[ det \\Bigg( \\begin{bmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{bmatrix}i \\Bigg) = (1 - \\lambda)(1 - \\lambda) - \\overbrace{ 1 * 0 }^{\\text{Equals 0, so ignore}} = \\lambda = 1 \\] This lines up with what we know: that all eigenvectors have an eigenvalue of 1. A final interesting example is when our basis vectors just so happen to be eigenvectors, which make up a matrix called an Eigenbasis . If the numbers on the matrix are diagonal it's a diagonal matrix . This also means that all the basis vectors are eigenvectors with the diagonal entries of these matrices being their eigenvalues. If you keep multiplying this matrix by itself it will be simply scaling it's values. This makes it very easy to work with. This is why many rotation are transformed into a diagonal matrix and then transformed back. Also if you needed to calculate the 100th power of a given matrix, it would be much easier to change to an eigenbasis, compute the number, and then change back with the inverse. A great exercise to practice this can be found here","title":"Why is this useful?"},{"location":"math/Essence_of_linear_algebra/015_Abstract_vector_spaces/","text":"Abstract vector spaces What are vectors? Are they arrows? Are they pairs of numbers? Or is it something deper? If they are not simply lists of numbers, what do mathematicians mean when they use the term \"spacial\". Let's talk about other vectorish things: functions. Really, functions are just another type of vector. Let's talk about adding functions. \\((f + g)\\) as an example. The output of the product of f and g is a new function, that at any given input adds f and g together. \\(f(-4.00) + g(-4.00)\\) or \\(f(x) + g(x)\\) . This is similar to adding vectors coordinate by coordinate, except there are infinitly many coordinates to deal with. It's similar to how to think of scaling functions. Which, once again, is similar to scaling a vector coordinate by coordinate. This goes to figure that we could apply many of the concepts that work on vectors, like linear transformations, null space, dot product, eigen-everything to functions in a similar way. For example you can linearly transform a function, that transformation would take in one function and return another. \\[ L \\Bigg( \\frac{ 1 }{ 9 } x^3 - x \\Bigg) = \\frac{ 1 }{ 3 } x^2 -1 \\] One familar example comes from calculus: the derivative. It transforms one function into another function. When transforming functions instead of vectors the term used is linear operatros insteead of transforms. But what does it mean for a transformation of functions to be linear? The formal definition: Additivity: \\(L( \\overrightarrow{v} + \\overrightarrow{w} ) = L( \\overrightarrow{v} ) + L ( \\overrightarrow{w} )\\) Scaling: \\(L(c \\overrightarrow{v})= c L ( \\overrightarrow{v} )\\) A transformation is linear if it satisfies the above two properties. Additivity means that if you add two vectors and get a sum, then apply a transformation, you get the same result as if you added the transformed versions of the two vectors. Likewise, the scaling property says that if you scale two vectors, then apply a transformation, you get the same result as scaling two vectors by the same amount after the transformation. Linear transformations preserve addition and scalar multiplication. Grid lines remaining parallel and evenly spaced is a visual representation of those two properties. The order of operation does not matter. You can trasnform and add, or add and transform and the result is the same. A good comparison can be made to the derivative function in calculus. The derivative is linear, but since I have no idea what that is the comparision doesn't really work for me (future study!). But the point is that they are both from the same family, and that you can apply linear trasnformations (or operations) to both of them. Many of the concepts of linear algebra have direct correlation to functions. Linear algebra concepts Alternat names when applied to functions Linear Transformations Linear operators Dot products Inner products Eigenvectors Eigenfunctions So how does this help us know what a vector is? The point is that there are many vectorish concepts in math that can have transformations applied. All of these vectorish things are called vector spaces . Vectors are one subset of these spaces, that have a discreet list of rules. They are the axioms of vectors. There are 8 axioms for vector space: \\(\\overrightarrow{u} + ( \\overrightarrow{v} + \\overrightarrow{w} ) = ( \\overrightarrow{u} + \\overrightarrow{w} ) + w\\) \\(\\overrightarrow{v} + \\overrightarrow{w} = \\overrightarrow{w} + \\overrightarrow{v}\\) there is a vector 0 such that \\(0 + \\overrightarrow{v} = \\overrightarrow{v} \\text{for all} \\overrightarrow{v}\\) For every vector \\(\\overrightarrow{v}\\) , there is a vector \\(- \\overrightarrow{v}\\) so that \\(\\overrightarrow{v} + (- \\overrightarrow{v}) = 0\\) \\(a(b \\overrightarrow{v})=(ab) \\overrightarrow{v}\\) \\(1 \\overrightarrow{v} = \\overrightarrow{v}\\) \\(a( \\overrightarrow{v} + \\overrightarrow{w} ) = a \\overrightarrow{v} + a \\overrightarrow{w})\\) \\((a + b) \\overrightarrow{v} = a \\overrightarrow{v} + b \\overrightarrow{v}\\) dfa These axioms are not so much rules of nature as an interface between us and other people. They are a list of things that guarantee that linear algebra will work with a given vector space . This is why most textbooks talk about vectors in terms of additivity and scalability. The form that vectors take doesn't really matter as long as it follows these rules.","title":"Abstract vector spaces"},{"location":"math/Essence_of_linear_algebra/015_Abstract_vector_spaces/#abstract-vector-spaces","text":"What are vectors? Are they arrows? Are they pairs of numbers? Or is it something deper? If they are not simply lists of numbers, what do mathematicians mean when they use the term \"spacial\". Let's talk about other vectorish things: functions. Really, functions are just another type of vector. Let's talk about adding functions. \\((f + g)\\) as an example. The output of the product of f and g is a new function, that at any given input adds f and g together. \\(f(-4.00) + g(-4.00)\\) or \\(f(x) + g(x)\\) . This is similar to adding vectors coordinate by coordinate, except there are infinitly many coordinates to deal with. It's similar to how to think of scaling functions. Which, once again, is similar to scaling a vector coordinate by coordinate. This goes to figure that we could apply many of the concepts that work on vectors, like linear transformations, null space, dot product, eigen-everything to functions in a similar way. For example you can linearly transform a function, that transformation would take in one function and return another. \\[ L \\Bigg( \\frac{ 1 }{ 9 } x^3 - x \\Bigg) = \\frac{ 1 }{ 3 } x^2 -1 \\] One familar example comes from calculus: the derivative. It transforms one function into another function. When transforming functions instead of vectors the term used is linear operatros insteead of transforms. But what does it mean for a transformation of functions to be linear? The formal definition: Additivity: \\(L( \\overrightarrow{v} + \\overrightarrow{w} ) = L( \\overrightarrow{v} ) + L ( \\overrightarrow{w} )\\) Scaling: \\(L(c \\overrightarrow{v})= c L ( \\overrightarrow{v} )\\) A transformation is linear if it satisfies the above two properties. Additivity means that if you add two vectors and get a sum, then apply a transformation, you get the same result as if you added the transformed versions of the two vectors. Likewise, the scaling property says that if you scale two vectors, then apply a transformation, you get the same result as scaling two vectors by the same amount after the transformation. Linear transformations preserve addition and scalar multiplication. Grid lines remaining parallel and evenly spaced is a visual representation of those two properties. The order of operation does not matter. You can trasnform and add, or add and transform and the result is the same. A good comparison can be made to the derivative function in calculus. The derivative is linear, but since I have no idea what that is the comparision doesn't really work for me (future study!). But the point is that they are both from the same family, and that you can apply linear trasnformations (or operations) to both of them. Many of the concepts of linear algebra have direct correlation to functions. Linear algebra concepts Alternat names when applied to functions Linear Transformations Linear operators Dot products Inner products Eigenvectors Eigenfunctions So how does this help us know what a vector is? The point is that there are many vectorish concepts in math that can have transformations applied. All of these vectorish things are called vector spaces . Vectors are one subset of these spaces, that have a discreet list of rules. They are the axioms of vectors. There are 8 axioms for vector space: \\(\\overrightarrow{u} + ( \\overrightarrow{v} + \\overrightarrow{w} ) = ( \\overrightarrow{u} + \\overrightarrow{w} ) + w\\) \\(\\overrightarrow{v} + \\overrightarrow{w} = \\overrightarrow{w} + \\overrightarrow{v}\\) there is a vector 0 such that \\(0 + \\overrightarrow{v} = \\overrightarrow{v} \\text{for all} \\overrightarrow{v}\\) For every vector \\(\\overrightarrow{v}\\) , there is a vector \\(- \\overrightarrow{v}\\) so that \\(\\overrightarrow{v} + (- \\overrightarrow{v}) = 0\\) \\(a(b \\overrightarrow{v})=(ab) \\overrightarrow{v}\\) \\(1 \\overrightarrow{v} = \\overrightarrow{v}\\) \\(a( \\overrightarrow{v} + \\overrightarrow{w} ) = a \\overrightarrow{v} + a \\overrightarrow{w})\\) \\((a + b) \\overrightarrow{v} = a \\overrightarrow{v} + b \\overrightarrow{v}\\) dfa These axioms are not so much rules of nature as an interface between us and other people. They are a list of things that guarantee that linear algebra will work with a given vector space . This is why most textbooks talk about vectors in terms of additivity and scalability. The form that vectors take doesn't really matter as long as it follows these rules.","title":"Abstract vector spaces"},{"location":"math/Math_for_Game_Developers/001_Character_Movement/","text":"Math for Game Developers - Character Movement ( Points and Vectors ) Character movement is done with vectors \\(\\overrightarrow{v}\\) . In video games vectors are used for their angles and their magnitude. \\[ \\overrightarrow{v} = ( \\Theta , L) \\] The magnitude of the vector can be used to determine how far the character goes and in what direction. In games we store vectors as a list of floats. \\[ \\overrightarrow{v} = (x, y); \\] To move the character you use this formula. \\(\\prime\\) means \"new\", so \\(P\\prime\\) means \"new Position\". \\(\\overrightarrow{v}\\) is velocity. \\[ P\\prime = P + \\overrightarrow{v} \\] \\[ P\\prime = (P_x + \\overrightarrow{v}_x, P_y + \\overrightarrow{v}_y) \\] You can see a very simple program that moves a P vector by a V vector here","title":"Math for Game Developers - Character Movement ( Points and Vectors )"},{"location":"math/Math_for_Game_Developers/001_Character_Movement/#math-for-game-developers-character-movement-points-and-vectors","text":"Character movement is done with vectors \\(\\overrightarrow{v}\\) . In video games vectors are used for their angles and their magnitude. \\[ \\overrightarrow{v} = ( \\Theta , L) \\] The magnitude of the vector can be used to determine how far the character goes and in what direction. In games we store vectors as a list of floats. \\[ \\overrightarrow{v} = (x, y); \\] To move the character you use this formula. \\(\\prime\\) means \"new\", so \\(P\\prime\\) means \"new Position\". \\(\\overrightarrow{v}\\) is velocity. \\[ P\\prime = P + \\overrightarrow{v} \\] \\[ P\\prime = (P_x + \\overrightarrow{v}_x, P_y + \\overrightarrow{v}_y) \\] You can see a very simple program that moves a P vector by a V vector here","title":"Math for Game Developers - Character Movement ( Points and Vectors )"},{"location":"math/Math_for_Game_Developers/002_Character_Movement_2/","text":"Character Movement 2 (Subtracting Vectors) We now have two characters that we are thinking about: pacman and pinky the ghost. We want to create a vector between pinky and pacman so that pinkey can eat packman. This will be vector \\(\\overrightarrow{v}\\) . The formula for this is very straightforward: \\[ \\overrightarrow{v} = P - I \\] Notice how the pacman point comes first. This is because otherwise the vector will be pointing the other way. \\[ \\overrightarrow{v} = (P_x - I_x, P_y - I_y); \\] We've Implemented this here","title":"Character Movement 2 (Subtracting Vectors)"},{"location":"math/Math_for_Game_Developers/002_Character_Movement_2/#character-movement-2-subtracting-vectors","text":"We now have two characters that we are thinking about: pacman and pinky the ghost. We want to create a vector between pinky and pacman so that pinkey can eat packman. This will be vector \\(\\overrightarrow{v}\\) . The formula for this is very straightforward: \\[ \\overrightarrow{v} = P - I \\] Notice how the pacman point comes first. This is because otherwise the vector will be pointing the other way. \\[ \\overrightarrow{v} = (P_x - I_x, P_y - I_y); \\] We've Implemented this here","title":"Character Movement 2 (Subtracting Vectors)"},{"location":"math/Math_for_Game_Developers/003_Character_Movement_3/","text":"Math for Game Developers - Character Movement 3 (Vector Length) Now we want to know how far pinkey has to go to find packman. We already have the vector that pinky has to dravel on to get to pacman, and we are not going to find the distance that pinky has to now travel at this angle. o If you remember from the first video, the vector can be expressed in two ways. The angle and length, or (x,y). Because we aren't representing the vector with the length part, we need to deduct the length. This is pretty easy to do by creating a triangle with x and y and using the pythagorean theorem to get the length of the imaginary third side. \\[ a^2 + b^2 = c^2 \\] \\(| \\overrightarrow{v} |\\) stands for the vector's length. So we can say: \\[ | \\overrightarrow{v} |^2 = \\overrightarrow{v}_x^2 + \\overrightarrow{v}_y^2 \\] \\[ | \\overrightarrow{v} | = \\sqrt{x^2 + y^2} \\] This will find us the distance between piny and pacman. You can find the implementation here","title":"Math for Game Developers - Character Movement 3 (Vector Length)"},{"location":"math/Math_for_Game_Developers/003_Character_Movement_3/#math-for-game-developers-character-movement-3-vector-length","text":"Now we want to know how far pinkey has to go to find packman. We already have the vector that pinky has to dravel on to get to pacman, and we are not going to find the distance that pinky has to now travel at this angle. o If you remember from the first video, the vector can be expressed in two ways. The angle and length, or (x,y). Because we aren't representing the vector with the length part, we need to deduct the length. This is pretty easy to do by creating a triangle with x and y and using the pythagorean theorem to get the length of the imaginary third side. \\[ a^2 + b^2 = c^2 \\] \\(| \\overrightarrow{v} |\\) stands for the vector's length. So we can say: \\[ | \\overrightarrow{v} |^2 = \\overrightarrow{v}_x^2 + \\overrightarrow{v}_y^2 \\] \\[ | \\overrightarrow{v} | = \\sqrt{x^2 + y^2} \\] This will find us the distance between piny and pacman. You can find the implementation here","title":"Math for Game Developers - Character Movement 3 (Vector Length)"},{"location":"math/Math_for_Game_Developers/004_Distance_Comparison/","text":"Math for Game Developers - Distance Comparison How should we go about comparing the distance between two points (C and I) to our P (position?) if we want to find out which one is closer? $$ | \\overrightarrow{CP} | ? | \\overrightarrow{IP} $$ \\[ \\sqrt{ \\overrightarrow{CP_x}^2 + \\overrightarrow{CP_y}^2 } ? \\sqrt{ \\overrightarrow{IP_x}^2 + \\overrightarrow{IP_y}^2 } \\] We can unsqure these to make it a simpler equation. \\[ \\overrightarrow{CP_x}^2 + \\overrightarrow{CP_y}^2 ? \\overrightarrow{IP_x}^2 + \\overrightarrow{IP_y}^2 \\] So it's actually quicker to compare the squares of the vectors, than the square roots of the squares of the vectors. We implement this here","title":"Math for Game Developers - Distance Comparison"},{"location":"math/Math_for_Game_Developers/004_Distance_Comparison/#math-for-game-developers-distance-comparison","text":"How should we go about comparing the distance between two points (C and I) to our P (position?) if we want to find out which one is closer? $$ | \\overrightarrow{CP} | ? | \\overrightarrow{IP} $$ \\[ \\sqrt{ \\overrightarrow{CP_x}^2 + \\overrightarrow{CP_y}^2 } ? \\sqrt{ \\overrightarrow{IP_x}^2 + \\overrightarrow{IP_y}^2 } \\] We can unsqure these to make it a simpler equation. \\[ \\overrightarrow{CP_x}^2 + \\overrightarrow{CP_y}^2 ? \\overrightarrow{IP_x}^2 + \\overrightarrow{IP_y}^2 \\] So it's actually quicker to compare the squares of the vectors, than the square roots of the squares of the vectors. We implement this here","title":"Math for Game Developers - Distance Comparison"},{"location":"math/Math_for_Game_Developers/005_Character_Movement_4/","text":"Math for Game Developers - Character Movement 4 Now back to moving our character pacman with a vector \\(\\overrightarrow{v}\\) . Let's say we want to speed up pacman. This is basically going to just require multiplying the vector by a scalar to increase its magnitude. \\[ 2 \\overrightarrow{v} = ( \\overrightarrow{v}_x * 2, \\overrightarrow{v}_y * 2 ) \\] If you want to slow down movement, you can multiply by a fraction, or divide. We have implemented this here","title":"Math for Game Developers - Character Movement 4"},{"location":"math/Math_for_Game_Developers/005_Character_Movement_4/#math-for-game-developers-character-movement-4","text":"Now back to moving our character pacman with a vector \\(\\overrightarrow{v}\\) . Let's say we want to speed up pacman. This is basically going to just require multiplying the vector by a scalar to increase its magnitude. \\[ 2 \\overrightarrow{v} = ( \\overrightarrow{v}_x * 2, \\overrightarrow{v}_y * 2 ) \\] If you want to slow down movement, you can multiply by a fraction, or divide. We have implemented this here","title":"Math for Game Developers - Character Movement 4"},{"location":"math/Math_for_Game_Developers/006_Character_Movement_5/","text":"Math for Game Developers - Character Movement 5 (Unit-Length Vectors) One thing about the original pacman, was that he always looked into the same direction as he was moving. So now let's make him moving while looking at pinky. One difference to the vector that stores the velocity of P, the lookat vector has to be a unit vector , this means that it's magnitude needs to be 1. It can face anywhere it wants to, but it's magnitude or length will be on. So how do we convect a vector into a unit vector? Let's calculate the direction between P and I \\(\\overrightarrow{PI}\\) . A unit vector is represented with ^, so what we're solving for is \\(\\widehat{\\overrightarrow{PI}}\\) . To normalize a vector (the process of making a vector length 1), we divide it by it's length. \\[ \\widehat{\\overrightarrow{PI}} = \\frac{ \\overrightarrow{PI} }{ | \\overrightarrow{PI} | } \\] \\[ \\widehat{ \\overrightarrow{PI} } = \\Bigg( \\frac{ \\overrightarrow{PI}_x }{ | \\overrightarrow{PI} | }, \\frac{ \\overrightarrow{PI}_y }{ | \\overrightarrow{PI} | } \\Bigg) \\] Unit length vectors are extremely useful in game development. Knowing how to create and use them will help you everywhere in game development. We have implemented it here","title":"Math for Game Developers - Character Movement 5 (Unit-Length Vectors)"},{"location":"math/Math_for_Game_Developers/006_Character_Movement_5/#math-for-game-developers-character-movement-5-unit-length-vectors","text":"One thing about the original pacman, was that he always looked into the same direction as he was moving. So now let's make him moving while looking at pinky. One difference to the vector that stores the velocity of P, the lookat vector has to be a unit vector , this means that it's magnitude needs to be 1. It can face anywhere it wants to, but it's magnitude or length will be on. So how do we convect a vector into a unit vector? Let's calculate the direction between P and I \\(\\overrightarrow{PI}\\) . A unit vector is represented with ^, so what we're solving for is \\(\\widehat{\\overrightarrow{PI}}\\) . To normalize a vector (the process of making a vector length 1), we divide it by it's length. \\[ \\widehat{\\overrightarrow{PI}} = \\frac{ \\overrightarrow{PI} }{ | \\overrightarrow{PI} | } \\] \\[ \\widehat{ \\overrightarrow{PI} } = \\Bigg( \\frac{ \\overrightarrow{PI}_x }{ | \\overrightarrow{PI} | }, \\frac{ \\overrightarrow{PI}_y }{ | \\overrightarrow{PI} | } \\Bigg) \\] Unit length vectors are extremely useful in game development. Knowing how to create and use them will help you everywhere in game development. We have implemented it here","title":"Math for Game Developers - Character Movement 5 (Unit-Length Vectors)"},{"location":"math/Math_for_Game_Developers/007_Character_Movement_6/","text":"Math for Game Developers - Character Movement 6 Pacman never moves diagonally, but we can make this happen. How does this work? We can do this by adding vectors. In this case let's use a vector pointing right \\(\\overrightarrow{R}\\) and a vector pointing down \\(\\overrightarrow{D}\\) to create a diagonal vector \\(\\overrightarrow{v}\\) . \\[ \\overrightarrow{D} + \\overrightarrow{R} = \\overrightarrow{V} \\] \\[ \\overrightarrow{V} = (\\overrightarrow{D}_x + \\overrightarrow{R}_x, \\overrightarrow{D}_y + \\overrightarrow{R}_y ) \\] This works the same way for subtractions. You can find the implementation here","title":"Math for Game Developers - Character Movement 6"},{"location":"math/Math_for_Game_Developers/007_Character_Movement_6/#math-for-game-developers-character-movement-6","text":"Pacman never moves diagonally, but we can make this happen. How does this work? We can do this by adding vectors. In this case let's use a vector pointing right \\(\\overrightarrow{R}\\) and a vector pointing down \\(\\overrightarrow{D}\\) to create a diagonal vector \\(\\overrightarrow{v}\\) . \\[ \\overrightarrow{D} + \\overrightarrow{R} = \\overrightarrow{V} \\] \\[ \\overrightarrow{V} = (\\overrightarrow{D}_x + \\overrightarrow{R}_x, \\overrightarrow{D}_y + \\overrightarrow{R}_y ) \\] This works the same way for subtractions. You can find the implementation here","title":"Math for Game Developers - Character Movement 6"},{"location":"math/Math_for_Game_Developers/008_Backstabbing_Dot_Product/","text":"Math for Game Developers - Backstabbing (Dot Product) If you want to calculate whether your player is stabbing another black in the back, you can use dot products. A dot product takes in two unit vectors. In this case \\(\\widehat{\\overrightarrow{v}}\\) is the direction the enemy is facing and \\(\\widehat{ \\overrightarrow{BR} }\\) the direction from the enemy to the player. Just to review, in order to get \\(\\widehat{ \\overrightarrow{BR} }\\) we use the following formula: \\[ \\widehat{ \\overrightarrow{BR} } = \\frac{ R-B }{ |R-B| } \\] So now that we have our vectors, we want to know if they are facing in the same direction, or opposite directions. We want to test whether or not the player is behind the enemy. We can do this with the dot produt. The dot product can be thought of as a relationship between two vectors. Let's start with the formula for it: \\[ | \\overrightarrow{a} | | \\overrightarrow{b} | \\cos \\theta \\] Here's a more code friendly formula: \\[ \\overrightarrow{a}_x \\overrightarrow{b}_x + \\overrightarrow{a}_y \\overrightarrow{b}_y \\] This is how it's used in games/engineering. The important thing to know is that if the vectors are facing the same direction, the dot product is going to be 1, opposite direction -1. Using the dotproduct of two vectors we can safely assume that a backstab is valid if the value is less than a certain value. \\[ \\widehat{ \\overrightarrow{BR} } \\uparrow \\cdot \\widehat{ \\overrightarrow{V} } \\uparrow = 1 \\] \\[ \\widehat{ \\overrightarrow{BR} } \\uparrow \\cdot \\widehat{ \\overrightarrow{V} } \\rightarrow = 0 \\] \\[ \\widehat{ \\overrightarrow{BR} } \\uparrow \\cdot \\widehat{ \\overrightarrow{V} } \\downarrow =1 \\] Read more about the dot product here","title":"Math for Game Developers - Backstabbing (Dot Product)"},{"location":"math/Math_for_Game_Developers/008_Backstabbing_Dot_Product/#math-for-game-developers-backstabbing-dot-product","text":"If you want to calculate whether your player is stabbing another black in the back, you can use dot products. A dot product takes in two unit vectors. In this case \\(\\widehat{\\overrightarrow{v}}\\) is the direction the enemy is facing and \\(\\widehat{ \\overrightarrow{BR} }\\) the direction from the enemy to the player. Just to review, in order to get \\(\\widehat{ \\overrightarrow{BR} }\\) we use the following formula: \\[ \\widehat{ \\overrightarrow{BR} } = \\frac{ R-B }{ |R-B| } \\] So now that we have our vectors, we want to know if they are facing in the same direction, or opposite directions. We want to test whether or not the player is behind the enemy. We can do this with the dot produt. The dot product can be thought of as a relationship between two vectors. Let's start with the formula for it: \\[ | \\overrightarrow{a} | | \\overrightarrow{b} | \\cos \\theta \\] Here's a more code friendly formula: \\[ \\overrightarrow{a}_x \\overrightarrow{b}_x + \\overrightarrow{a}_y \\overrightarrow{b}_y \\] This is how it's used in games/engineering. The important thing to know is that if the vectors are facing the same direction, the dot product is going to be 1, opposite direction -1. Using the dotproduct of two vectors we can safely assume that a backstab is valid if the value is less than a certain value. \\[ \\widehat{ \\overrightarrow{BR} } \\uparrow \\cdot \\widehat{ \\overrightarrow{V} } \\uparrow = 1 \\] \\[ \\widehat{ \\overrightarrow{BR} } \\uparrow \\cdot \\widehat{ \\overrightarrow{V} } \\rightarrow = 0 \\] \\[ \\widehat{ \\overrightarrow{BR} } \\uparrow \\cdot \\widehat{ \\overrightarrow{V} } \\downarrow =1 \\] Read more about the dot product here","title":"Math for Game Developers - Backstabbing (Dot Product)"},{"location":"math/Math_for_Game_Developers/009_Jumping_and_Gravity/","text":"Math for Game Developers - Jumping and Gravity (Time Delta, Game Loop) So we know that mario likes jumping. But how do we create the curved path that mario's jump trajectory makes? We do this by cutting up the curve into a lot of tiny pieces. Each piece moves mario a little bit along the jump vector \\(\\overrightarrow{v}\\) and the gravity vector \\(\\overrightarrow{g}\\) . Every one of these pieces is one iteration of the Game Loop . The game loop is as follows: Update (things) Draw (stuff) Loop So back to the jump - how long should each of these cuts be? To answer that we need \\(\\Delta T\\) . This is the time that passes between each frame. Each game loop is one frame. \\(\\Delta T\\) is the time that passes between each frame. \\[ \\Delta T = t^{\\prime} - t \\] So if we're running at 30 fps, then \\(\\Delta T\\) is 1/30 = 0.33333. At sixty this is even less. So bascially these are very tiny pieces. So how do we update mario's position (m) each frame to craete this arc? \\[ m^{\\prime} = m + \\Delta t \\overrightarrow{v} \\] Now in the same loop we need to update the velocity vector \\[ \\overrightarrow{v}^{\\prime} = \\overrightarrow{v} + \\Delta t \\overrightarrow{G} \\] The code from here on out includes files from Jorge's own games, so it's hard to reproduce. I'll revisit this series after going through opengl and creating a basic game with a game loop.","title":"Math for Game Developers - Jumping and Gravity (Time Delta, Game Loop)"},{"location":"math/Math_for_Game_Developers/009_Jumping_and_Gravity/#math-for-game-developers-jumping-and-gravity-time-delta-game-loop","text":"So we know that mario likes jumping. But how do we create the curved path that mario's jump trajectory makes? We do this by cutting up the curve into a lot of tiny pieces. Each piece moves mario a little bit along the jump vector \\(\\overrightarrow{v}\\) and the gravity vector \\(\\overrightarrow{g}\\) . Every one of these pieces is one iteration of the Game Loop . The game loop is as follows: Update (things) Draw (stuff) Loop So back to the jump - how long should each of these cuts be? To answer that we need \\(\\Delta T\\) . This is the time that passes between each frame. Each game loop is one frame. \\(\\Delta T\\) is the time that passes between each frame. \\[ \\Delta T = t^{\\prime} - t \\] So if we're running at 30 fps, then \\(\\Delta T\\) is 1/30 = 0.33333. At sixty this is even less. So bascially these are very tiny pieces. So how do we update mario's position (m) each frame to craete this arc? \\[ m^{\\prime} = m + \\Delta t \\overrightarrow{v} \\] Now in the same loop we need to update the velocity vector \\[ \\overrightarrow{v}^{\\prime} = \\overrightarrow{v} + \\Delta t \\overrightarrow{G} \\] The code from here on out includes files from Jorge's own games, so it's hard to reproduce. I'll revisit this series after going through opengl and creating a basic game with a game loop.","title":"Math for Game Developers - Jumping and Gravity (Time Delta, Game Loop)"},{"location":"math/Math_for_Game_Developers/010_Mouse_Control_Euler_Angles/","text":"Mouse Control (Euler Angles) Euler angles were developed by Leonhad Euler. They can specify any 3d rotation with just three values. There are three rotations in euler angles: Pitch (up/down) Yaw (left/right) Roll (tilting) When the player moves the mouse up and down that's the pitch, left and right is the yaw. So we want to convert these angles to a vector. This conversion is not hard to do with trigonometry. Take a right triangle with a hypotenuse of 1, and an angle of \\(\\theta\\) . In this case \\(sin\\theta = \\frac{y}{1}\\) as well as this \\(\\cos\\theta = \\frac{y}{1}\\) . So to find each element of the vector \\[ V_x = cos(Y) * cos(P) \\] \\[ V_y = sin(P) \\] \\[ V_z = sin(Y) * cos(P) \\] You need to multiply x and z by the cosign of the pitch so that they become less as you look straight up or straight down.","title":"Mouse Control (Euler Angles)"},{"location":"math/Math_for_Game_Developers/010_Mouse_Control_Euler_Angles/#mouse-control-euler-angles","text":"Euler angles were developed by Leonhad Euler. They can specify any 3d rotation with just three values. There are three rotations in euler angles: Pitch (up/down) Yaw (left/right) Roll (tilting) When the player moves the mouse up and down that's the pitch, left and right is the yaw. So we want to convert these angles to a vector. This conversion is not hard to do with trigonometry. Take a right triangle with a hypotenuse of 1, and an angle of \\(\\theta\\) . In this case \\(sin\\theta = \\frac{y}{1}\\) as well as this \\(\\cos\\theta = \\frac{y}{1}\\) . So to find each element of the vector \\[ V_x = cos(Y) * cos(P) \\] \\[ V_y = sin(P) \\] \\[ V_z = sin(Y) * cos(P) \\] You need to multiply x and z by the cosign of the pitch so that they become less as you look straight up or straight down.","title":"Mouse Control (Euler Angles)"},{"location":"math/Tensors/Kahn_IntroductionToTensors/","text":"Introduction to Tensors If you are calculating the direction and magnitude between two points (i.e. NY Harbor and the Empire State building) you have a vector which a magnitude. So basically where \\(\\overrightarrow{d}\\) is the displacement -19 is the displacement in x, 12 in j and 0.45 in k: \\[ \\overrightarrow{d} = -19 { \\hat{\\mathbf{\\imath}} }+ 12 \\hat{\\mathbf{\\jmath}} + 0.45 \\hat{\\mathbf{k}} \\] These three vectors that give the displacement are the component vectors of the displacement. Each component to the displacement is a vector with a single dimension. 1 Basis vector for each component. Expressing force with tensors If we want to know the forces acting on a specific point in a construction beam, we can slice the beam by three axis planes. For each of these planes we can then calculate a force which is expressed as such \\(P_{xx}\\) , \\(P_{ xy }\\) and \\(P_{xz}\\) , where x is the plane that the force is perpendicular to. We can combine these all into a three by three matrix. \\[ P = \\begin{bmatrix} P_{xx} & P_{xy} & P_{xz} \\\\ P_{yx} & P_{yy} & P_{yz} \\\\ P_{zx} & P_{zy} & P_{zz} \\end{bmatrix} \\] Why can't we just add all of these together into a single vector? \\(P_{xx} + P_{xy} + P_{xz}\\) Even though the forces are al acting in the same direction, the nature of the forces is differnt. We need the whole matrix because \\(P_{xx}\\) might be pulling, but \\(P_{xy}\\) might be exerting a shearing force. These different forces effect the beam in different ways. That's why it's important to specify the surface that the force acts on as well as the force itself. thus, to specify stresses, use P, which has 9 components (2 basic vectors /component: 1 for cross-sectional area + 1 for direction of force). We need to know the direction of the surface area and the direction of the force. This matrix is considered a tensor: Info In an m-dimesional space, a tensor of rank n is a mathemathical object that has n indices, \\(m^n\\) components, and obeys certain transformation rules. Generally, m= 3 Info The rank of the tensor is the amount of components per basis vector. A 3d vector has a rank of 1. The P tensor from the board has a rank of 2 aka. a stress tensor. There is a fairly common misconception that tensors and matrices are the same thing. Even if their data is serialized to the same types, it turns out that tensors obey special transformation rules that matricies don't. You can use a matrix to represent a tensor, but they behave differently. We can also use 3d arrays to represent rank 3 tensors. Each component of the tensor is specified by 3 basisvectors and there are \\(3^3 =27\\) total components. The next video goes over the special transformation rules .","title":"Introduction to Tensors"},{"location":"math/Tensors/Kahn_IntroductionToTensors/#introduction-to-tensors","text":"If you are calculating the direction and magnitude between two points (i.e. NY Harbor and the Empire State building) you have a vector which a magnitude. So basically where \\(\\overrightarrow{d}\\) is the displacement -19 is the displacement in x, 12 in j and 0.45 in k: \\[ \\overrightarrow{d} = -19 { \\hat{\\mathbf{\\imath}} }+ 12 \\hat{\\mathbf{\\jmath}} + 0.45 \\hat{\\mathbf{k}} \\] These three vectors that give the displacement are the component vectors of the displacement. Each component to the displacement is a vector with a single dimension. 1 Basis vector for each component.","title":"Introduction to Tensors"},{"location":"math/Tensors/Kahn_IntroductionToTensors/#expressing-force-with-tensors","text":"If we want to know the forces acting on a specific point in a construction beam, we can slice the beam by three axis planes. For each of these planes we can then calculate a force which is expressed as such \\(P_{xx}\\) , \\(P_{ xy }\\) and \\(P_{xz}\\) , where x is the plane that the force is perpendicular to. We can combine these all into a three by three matrix. \\[ P = \\begin{bmatrix} P_{xx} & P_{xy} & P_{xz} \\\\ P_{yx} & P_{yy} & P_{yz} \\\\ P_{zx} & P_{zy} & P_{zz} \\end{bmatrix} \\] Why can't we just add all of these together into a single vector? \\(P_{xx} + P_{xy} + P_{xz}\\) Even though the forces are al acting in the same direction, the nature of the forces is differnt. We need the whole matrix because \\(P_{xx}\\) might be pulling, but \\(P_{xy}\\) might be exerting a shearing force. These different forces effect the beam in different ways. That's why it's important to specify the surface that the force acts on as well as the force itself. thus, to specify stresses, use P, which has 9 components (2 basic vectors /component: 1 for cross-sectional area + 1 for direction of force). We need to know the direction of the surface area and the direction of the force. This matrix is considered a tensor: Info In an m-dimesional space, a tensor of rank n is a mathemathical object that has n indices, \\(m^n\\) components, and obeys certain transformation rules. Generally, m= 3 Info The rank of the tensor is the amount of components per basis vector. A 3d vector has a rank of 1. The P tensor from the board has a rank of 2 aka. a stress tensor. There is a fairly common misconception that tensors and matrices are the same thing. Even if their data is serialized to the same types, it turns out that tensors obey special transformation rules that matricies don't. You can use a matrix to represent a tensor, but they behave differently. We can also use 3d arrays to represent rank 3 tensors. Each component of the tensor is specified by 3 basisvectors and there are \\(3^3 =27\\) total components. The next video goes over the special transformation rules .","title":"Expressing force with tensors"},{"location":"rendering/OpenGL/05_03_2021_benchmarking/","text":"Benchmarking You can use renderDoc to benchmark your open gl stuff. Before at the top of the python program he did an import and inject. You can just use launch application to benchmark shit. Then you can capture a screen, and inspect everything from that frame. You can go through the whole pipeline. See all the shader buffer objects, all the structs etc. You can step through everything, and see how long everything took. The order of things Gl 4.6 it's simpler. Bind things after using the program in general.","title":"Benchmarking"},{"location":"rendering/OpenGL/05_03_2021_benchmarking/#benchmarking","text":"You can use renderDoc to benchmark your open gl stuff. Before at the top of the python program he did an import and inject. You can just use launch application to benchmark shit. Then you can capture a screen, and inspect everything from that frame. You can go through the whole pipeline. See all the shader buffer objects, all the structs etc. You can step through everything, and see how long everything took.","title":"Benchmarking"},{"location":"rendering/OpenGL/05_03_2021_benchmarking/#the-order-of-things","text":"Gl 4.6 it's simpler. Bind things after using the program in general.","title":"The order of things"},{"location":"rendering/OpenGL/Pipeline_Map/","text":"Check out a map of the entire OpenGL 4.4 pieline here: pipeline map","title":"Pipeline Map"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/000_Creating_a_window/","text":"OpenGL State Machine By itself OpenGL is a large state machine: a collection of variables that define how OpenGL should currently operate. State-changing function change these variables which stat-using functions then query to see how they should execute. Extensions When a graphics company comes up with a new technique or optimizations for rendering, they create an extension in their drivers. If a developer's hardware supports this, they can then use these for more advanced graphics. Right now the hot one is raytracing. This way developers can use these features without having to wait for OpenGL to include the functionality in its future versions. If extensions are popular they usually get added to future OpenGL versions. The developer therefore needs to query if the extension is available if ( GL_ARB_extension_name ) { // Do cool new and modern stuff supported by hardware } else { // Extension not supported: do it the old way } Objects OpenGL libraries are written in C, and at its core remains a C-library. Because this doesn't always translate well to higher-level languages, there are several abstractions that got developed. One of these is objects. These objects get their settings set by the state machines. These objects are exposed as function that get and set the object members. // create object unsigned int objectId = 0 ; glGenObject ( 1 , & objectId ); // bind/assign object to context glBindObject ( GL_WINDOW_TARGET , objectId ); // set options of object currently bound to GL_WINDOW_TARGET glSetObjectOption ( GL_WINDOW_TARGET , GL_OPTION_WINDOW_WIDTH , 800 ); glSetObjectOption ( GL_WINDOW_TARGET , GL_OPTION_WINDOW_HEIGHT , 600 ); // set context target back to default glBindObject ( GL_WINDOW_TARGET , 0 ); The above is a very common workflow. Create an object, store it's reference as an id ( the real data is store behind the scenes ). Then bind the object (using it's id) tot he target location of the context. Then you set the window options after the objects has been bound, and then unbind it. You are always binding objects to operate one, doing your thing, and then unbinding and binding other objects.","title":"OpenGL"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/000_Creating_a_window/#opengl","text":"","title":"OpenGL"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/000_Creating_a_window/#state-machine","text":"By itself OpenGL is a large state machine: a collection of variables that define how OpenGL should currently operate. State-changing function change these variables which stat-using functions then query to see how they should execute.","title":"State Machine"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/000_Creating_a_window/#extensions","text":"When a graphics company comes up with a new technique or optimizations for rendering, they create an extension in their drivers. If a developer's hardware supports this, they can then use these for more advanced graphics. Right now the hot one is raytracing. This way developers can use these features without having to wait for OpenGL to include the functionality in its future versions. If extensions are popular they usually get added to future OpenGL versions. The developer therefore needs to query if the extension is available if ( GL_ARB_extension_name ) { // Do cool new and modern stuff supported by hardware } else { // Extension not supported: do it the old way }","title":"Extensions"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/000_Creating_a_window/#objects","text":"OpenGL libraries are written in C, and at its core remains a C-library. Because this doesn't always translate well to higher-level languages, there are several abstractions that got developed. One of these is objects. These objects get their settings set by the state machines. These objects are exposed as function that get and set the object members. // create object unsigned int objectId = 0 ; glGenObject ( 1 , & objectId ); // bind/assign object to context glBindObject ( GL_WINDOW_TARGET , objectId ); // set options of object currently bound to GL_WINDOW_TARGET glSetObjectOption ( GL_WINDOW_TARGET , GL_OPTION_WINDOW_WIDTH , 800 ); glSetObjectOption ( GL_WINDOW_TARGET , GL_OPTION_WINDOW_HEIGHT , 600 ); // set context target back to default glBindObject ( GL_WINDOW_TARGET , 0 ); The above is a very common workflow. Create an object, store it's reference as an id ( the real data is store behind the scenes ). Then bind the object (using it's id) tot he target location of the context. Then you set the window options after the objects has been bound, and then unbind it. You are always binding objects to operate one, doing your thing, and then unbinding and binding other objects.","title":"Objects"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/001_Hello_Window/","text":"Hello Window Note Make sure to include glad BEFORE GLFW!! We're now going to setup a basic window as described here Applications drawing to a buffer required a double buffer in order to avoid flickering issues. Because not all the pixels are rendered at once, the double buffer method waits for the second buffer to finish drawing before replacing the pixels. Otherwise it may contain artifacts. The front buffer contains the final output image that is shown at the screen, while all the rendering commands draw to the back buffer. When they are finished, we then swap the back buffer to the front buffer so the image can be displayed without still being rendered to. GLFW has callback functions that you can bind to. You pass functions into these by reference, and glfw calls them when the appropriate callback activates. void framebuffer_size_callback ( GLFWwindow * window , int width , int height ) { glViewport ( 0 , 0 , width , height ); } glfwSetFramebufferSizeCallback ( window , framebuffer_size_callback ); A frame is a single iteration of the render loop. Basically every time the buffers have been switched. The render loop looks like this: while ( ! glfwWindowShouldClose ( window )) { processInput ( window ); glfwSwapBuffers ( window ); glfwPollEvents (); }","title":"Hello Window"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/001_Hello_Window/#hello-window","text":"Note Make sure to include glad BEFORE GLFW!! We're now going to setup a basic window as described here Applications drawing to a buffer required a double buffer in order to avoid flickering issues. Because not all the pixels are rendered at once, the double buffer method waits for the second buffer to finish drawing before replacing the pixels. Otherwise it may contain artifacts. The front buffer contains the final output image that is shown at the screen, while all the rendering commands draw to the back buffer. When they are finished, we then swap the back buffer to the front buffer so the image can be displayed without still being rendered to. GLFW has callback functions that you can bind to. You pass functions into these by reference, and glfw calls them when the appropriate callback activates. void framebuffer_size_callback ( GLFWwindow * window , int width , int height ) { glViewport ( 0 , 0 , width , height ); } glfwSetFramebufferSizeCallback ( window , framebuffer_size_callback ); A frame is a single iteration of the render loop. Basically every time the buffers have been switched. The render loop looks like this: while ( ! glfwWindowShouldClose ( window )) { processInput ( window ); glfwSwapBuffers ( window ); glfwPollEvents (); }","title":"Hello Window"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/","text":"Hello Triangle OpenGL is all about 3d rendering, but the final output is a 2d array of pixels. A large part of the work is in transforming all 3d coordinates to 2d pixels that fit on your screen. This process is managed by the graphics pipeline of OpenGL. There are two parts to the graphics pipeline: Transform your 3d coordinates into 2d coordinates Transform 2d coordinates into actual colored pixels GPUs today have thousands of small processing cores to process graphics data in parallel. When doing so, each of these cores is running a small program, called a shader . Some of these shaders are configurable by the developer, which allows us to write our own. They are written in the OpenGL Shading Language (GLSL) . Here's a cool image about the different steps: Each section of the graphics pipeline handles one specific part of converting our vertex data. At the beginning of the pipeline we pass in a list of 3d coordinates that should form a triangle. A vertex is a collection of data per 3d coordinate. This data is represented using vertex attributes that contain any data we'd like. One common data type is a color vector. Note OpenGL doesn't know what our input data is without hints called primitives . These are given to OpenGL while calling any of the drawing commands. Examples are GL_POINTS, GL_TRIANGLES and GL_LINE_STRIP Going over the pipeline in each step: The vertex shader takes as input a single vertex. This allows us to do pre-processing on the vertex attributes. The primitive assemply aka shape assembly takes all the vertices (or vertex if a GL_POINTS primitive) that form a primitive and assembles these points in the primitive shape given. The geometry shader gets an input collection of vertices that form a primitive and can change it by emitting new vetices to form new (or other) primitives. In this case it subdivides the triangle This is then passed to the rasterization stage where the resulting primitives are mapped to pixels on the final screen. Clipping is performed during this stage, which discards all fragments that are outside your view. These pixels are passed to the fragment shader , where colors are assigned to the pixels. This is where most of OpenGl's advanced effects occur. The final object then passes through an alpha test and blending stage, where it's sorted in z space before and behind other objects. This checks the opacity of the object, and blends objects accordingly. We are required to define at least a vertex and fragment shader of our own. Vertex input All vertices are given in 3d (xyz) coordinates. Their coordinates are always between -1.0 and 1.0 on all 3 axes. This is what's called normalized device coordinates and will then be converted to \"screen space\" - not your virtual world's space. The step to convert your 3d geometry into NDC space will be covered in a later chapter. When converting your vertices into screen-space coordinates you will use the viewport transform using the data you provided with glViewport. We would like to send the following triangle (in NDC space) through our pipeline: float vertices [] = { -0.5f , -0.5f , 0.0f , 0.5f , -0.5f , 0.0f , 0.0f , 0.5f , 0.0f }; First it needs to go to the vertex shader. To send this data there we need to create memory on the GPU to store it, and configure how OpenGL should interpret this memory. We manage this memory via vertex buffer objects (VBO) that can store a ton of vertices in GPU memory. This allows us to dump large batches of data onto the GPU in a single operation. Here we encounter our first OpenGL object: // create our vertex buffer object. This will pass the data to the gpu // all objects in openGL are access via an id. unsigned int VBO ; // create vertex buffers for this id glGenBuffers ( 1 , & VBO ); // to edit this object we need to bind the id to openGL // you can bind one object of each type at a time before having to unbind glBindBuffer ( GL_ARRAY_BUFFER , VBO ); // now any buffer calls we make (on the GL_ARRAY_BUFFER target) will // be used to configure the currently bound buffer // now bind our vertices to the array buffer // This function allocates memory and stores the data within the // curerntly bound buffer object // There are three ways that this function can treat the data // GL_STREAM_DRAW: the data is set only once and used by the GPU at most a few times // GL_STATIC_DRAW: the data is set only once and used many times // GL_DYNAMIC_DRAW: the data is changed a lot and used manytimes glBufferData ( GL_ARRAY_BUFFER , sizeof ( vertices ), vertices , GL_STATIC_DRAW ); Vertex Shader This is one of the requierd shaders if we want to set up some rendering. To use it we need to write a shader in GLSL, the OpenGL Shading Language, and then compille this shader so we can use it in our application. // the syntax is very similar to C // usually the input data for a shader is not already in NDC, so // the shader will need to do a bit more work than it's doing here. // Our shader is verrrry simple though, and is just forwarding the position // of our vertices which we are conveniently giving in NDC. # version 330 core // declare all the input vertex attributes with the in keyword. // the default vector datatype has 4 floats, so we are using a vec3 // for the position. layout ( location = 0 ) in vec3 aPos ; // to set the output of the vertex shader we need to assign a vector4 value // to each vertex to a predefined variable called gl_Position. // gl_Position will be used as the output of the vertex shader. void main (){ gl_Position = vec4 ( aPos . x , aPos . y , aPos . z , 1.0 ); } Note Vectors in OpenFL have 4 floats. The fourth number is used for perspective division . This will be discussed more later Fragment shader This is the other required shader for rendering a triangle. Colors are once again an array of 4 values, but the fourth value has nothing to do with perspective division, but alpha. The color values range from 0.0 to 1.0. #version 330 core // The fragment shader only requires one output variable similar // to the gl_Position for the vertx shader. In this case it's named // more nicely as FragColor. out vec4 FragColor ; void main (){ FragColor = vec4 ( 1.0f , 0.5f , 0.2f , 1.0f ); } Shader program The final linked version of multiple shader combined is called a shader program object . To use the shaders we just created we need to link them to a shader ptogram object, and then activate this shader when rendering objects. // To use the compiled shader we have to link them to a shader program object // The ative shader program's shader will be used when we issue render calls. // This is also where you'll get linking errors if your outputs and inputs don't match unsigned int shaderProgram { glCreateProgram ()}; // not attach the compiled shaders to the program glAttachShader ( shaderProgram , vertexShader ); glAttachShader ( shaderProgram , fragmentShader ); // This links all the attached shaders in one final shader program object glLinkProgram ( shaderProgram ); // now let's test if the linking was successful glGetProgramiv ( shaderProgram , GL_LINK_STATUS , & success ); if ( ! success ){ glGetProgramInfoLog ( shaderProgram , 512 , NULL , infoLog ); std :: cout << \"ERROR::SHADERPROGRAM::FRAG::COMPILATIONS_FAILED \\n \" << infoLog << '\\ n } // We can now activate the program object // From now one every shader and rendering call will use this program object glUseProgram ( shaderProgram ); // don't forget to delete the shader objects now that we've linked them glDeleteShader ( vertexShader ); glDeleteShader ( fragmentShader ); Linking Vertex Attributes Now we sent the input vertex data to the GPU and instructed the GPU how it should process the data in the shaders. OpenGL still doesn't know how it should connect the vertex data to the vertex shaders' attributes. We need to specify how OpenGL should interpret the vertex data before rendering. Our vertex buffer data is formatted as follows: !vertex_buffer The position data is stored as a 32-bit (4 byte) floating point values Each position is composed of 3 of those values There is no space (or other values) between each set of 3 values. They are tightly packed in the array The first value in the data is at the beginning of the buffer. // We will now tell OpenGL how it should interpret the vertex data (per attribute) // // // The first param specifies which vertex attribute we want to configure. (location = 0) // The next argument specifies the size of the attribute // The next is the type of the attribute // The next is if we want to force normalize the data. // The next is how large our stride is. This is the space between consecutive vertex a // (we know that the array is githly packed so this could also have been 0) // The last parameter sets the offset of where the data begins in the buffer glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * ) 0 ); // 0 is the intex of the vertex attrib array we want to activate glEnableVertexAttribArray ( 0 ); The above process needs to repeat for every single object we are drawing, so it would be useful to be able to save these configurations. Vertext Array Object A vertex array object (VAO) can be found just like a vertex buffer object. Any subsequent vertex attribute calls will then be stored in the VAO. This way you only need to make those calls once when configuring vertex attribute pointers. Whenever we want to draw the object, we can just bind the corresponding VAO. This way we can switch between different vertex data and attribute configurations as easily as binding different VAOs. Everything we set above is stored inside the VAO. Note Core OpenGL requires that we use a VAO so it knows what to do with our vertex intputs. It will refuse to draw anything without a VAO. // ..:: Initialization code (done once (unless your object frequently changes)) :: .. // 1. bind Vertex Array Object glBindVertexArray ( VAO ); // 2. copy our vertices array in a buffer for OpenGL to use glBindBuffer ( GL_ARRAY_BUFFER , VBO ); glBufferData ( GL_ARRAY_BUFFER , sizeof ( vertices ), vertices , GL_STATIC_DRAW ); // 3. then set our vertex attributes pointers glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * ) 0 ); glEnableVertexAttribArray ( 0 ); [...] // ..:: Drawing code (in render loop) :: .. // 4. draw the object glUseProgram ( shaderProgram ); glBindVertexArray ( VAO ); someOpenGLFunctionThatDrawsOurTriangle (); Element Buffer Objects What if we want to render a rectangle? Should we input twice the amount of vertices? That would be totally inefficient! float vertices [] = { // first triangle 0.5f , 0.5f , 0.0f , // top right 0.5f , -0.5f , 0.0f , // bottom right -0.5f , 0.5f , 0.0f , // top left // second triangle 0.5f , -0.5f , 0.0f , // bottom right -0.5f , -0.5f , 0.0f , // bottom left -0.5f , 0.5f , 0.0f // top left }; This problem will only get worse with more complex objects. It would be better to store only the unique locations, and then indices in that array to determine how the triangles get made. EBO (element buffer objects) are additional object buffers that store indices that OpenGL uses to decide how to make triangles out of the vertices. This process is known as indexed drawing . float vertices[] = { 0.5f, 0.5f, 0.0f, // top right 0.5f, -0.5f, 0.0f, // bottom right -0.5f, -0.5f, 0.0f, // bottom left -0.5f, 0.5f, 0.0f // top left }; unsigned int indices[] = { // note that we start from 0! 0, 1, 3, // first triangle 1, 2, 3 // second triangle }; It's created and bound just like the VBO // ..:: Initialization code :: .. // 1. bind Vertex Array Object glBindVertexArray ( VAO ); // 2. copy our vertices array in a vertex buffer for OpenGL to use glBindBuffer ( GL_ARRAY_BUFFER , VBO ); glBufferData ( GL_ARRAY_BUFFER , sizeof ( vertices ), vertices , GL_STATIC_DRAW ); // 3. copy our index array in a element buffer for OpenGL to use glBindBuffer ( GL_ELEMENT_ARRAY_BUFFER , EBO ); glBufferData ( GL_ELEMENT_ARRAY_BUFFER , sizeof ( indices ), indices , GL_STATIC_DRAW ); // 4. then set the vertex attributes pointers glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * ) 0 ); glEnableVertexAttribArray ( 0 ); [...] // ..:: Drawing code (in render loop) :: .. glUseProgram ( shaderProgram ); glBindVertexArray ( VAO ); glDrawElements ( GL_TRIANGLES , 6 , GL_UNSIGNED_INT , 0 ) glBindVertexArray ( 0 );","title":"Hello Triangle"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#hello-triangle","text":"OpenGL is all about 3d rendering, but the final output is a 2d array of pixels. A large part of the work is in transforming all 3d coordinates to 2d pixels that fit on your screen. This process is managed by the graphics pipeline of OpenGL. There are two parts to the graphics pipeline: Transform your 3d coordinates into 2d coordinates Transform 2d coordinates into actual colored pixels GPUs today have thousands of small processing cores to process graphics data in parallel. When doing so, each of these cores is running a small program, called a shader . Some of these shaders are configurable by the developer, which allows us to write our own. They are written in the OpenGL Shading Language (GLSL) . Here's a cool image about the different steps: Each section of the graphics pipeline handles one specific part of converting our vertex data. At the beginning of the pipeline we pass in a list of 3d coordinates that should form a triangle. A vertex is a collection of data per 3d coordinate. This data is represented using vertex attributes that contain any data we'd like. One common data type is a color vector. Note OpenGL doesn't know what our input data is without hints called primitives . These are given to OpenGL while calling any of the drawing commands. Examples are GL_POINTS, GL_TRIANGLES and GL_LINE_STRIP Going over the pipeline in each step: The vertex shader takes as input a single vertex. This allows us to do pre-processing on the vertex attributes. The primitive assemply aka shape assembly takes all the vertices (or vertex if a GL_POINTS primitive) that form a primitive and assembles these points in the primitive shape given. The geometry shader gets an input collection of vertices that form a primitive and can change it by emitting new vetices to form new (or other) primitives. In this case it subdivides the triangle This is then passed to the rasterization stage where the resulting primitives are mapped to pixels on the final screen. Clipping is performed during this stage, which discards all fragments that are outside your view. These pixels are passed to the fragment shader , where colors are assigned to the pixels. This is where most of OpenGl's advanced effects occur. The final object then passes through an alpha test and blending stage, where it's sorted in z space before and behind other objects. This checks the opacity of the object, and blends objects accordingly. We are required to define at least a vertex and fragment shader of our own.","title":"Hello Triangle"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#vertex-input","text":"All vertices are given in 3d (xyz) coordinates. Their coordinates are always between -1.0 and 1.0 on all 3 axes. This is what's called normalized device coordinates and will then be converted to \"screen space\" - not your virtual world's space. The step to convert your 3d geometry into NDC space will be covered in a later chapter. When converting your vertices into screen-space coordinates you will use the viewport transform using the data you provided with glViewport. We would like to send the following triangle (in NDC space) through our pipeline: float vertices [] = { -0.5f , -0.5f , 0.0f , 0.5f , -0.5f , 0.0f , 0.0f , 0.5f , 0.0f }; First it needs to go to the vertex shader. To send this data there we need to create memory on the GPU to store it, and configure how OpenGL should interpret this memory. We manage this memory via vertex buffer objects (VBO) that can store a ton of vertices in GPU memory. This allows us to dump large batches of data onto the GPU in a single operation. Here we encounter our first OpenGL object: // create our vertex buffer object. This will pass the data to the gpu // all objects in openGL are access via an id. unsigned int VBO ; // create vertex buffers for this id glGenBuffers ( 1 , & VBO ); // to edit this object we need to bind the id to openGL // you can bind one object of each type at a time before having to unbind glBindBuffer ( GL_ARRAY_BUFFER , VBO ); // now any buffer calls we make (on the GL_ARRAY_BUFFER target) will // be used to configure the currently bound buffer // now bind our vertices to the array buffer // This function allocates memory and stores the data within the // curerntly bound buffer object // There are three ways that this function can treat the data // GL_STREAM_DRAW: the data is set only once and used by the GPU at most a few times // GL_STATIC_DRAW: the data is set only once and used many times // GL_DYNAMIC_DRAW: the data is changed a lot and used manytimes glBufferData ( GL_ARRAY_BUFFER , sizeof ( vertices ), vertices , GL_STATIC_DRAW );","title":"Vertex input"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#vertex-shader","text":"This is one of the requierd shaders if we want to set up some rendering. To use it we need to write a shader in GLSL, the OpenGL Shading Language, and then compille this shader so we can use it in our application. // the syntax is very similar to C // usually the input data for a shader is not already in NDC, so // the shader will need to do a bit more work than it's doing here. // Our shader is verrrry simple though, and is just forwarding the position // of our vertices which we are conveniently giving in NDC. # version 330 core // declare all the input vertex attributes with the in keyword. // the default vector datatype has 4 floats, so we are using a vec3 // for the position. layout ( location = 0 ) in vec3 aPos ; // to set the output of the vertex shader we need to assign a vector4 value // to each vertex to a predefined variable called gl_Position. // gl_Position will be used as the output of the vertex shader. void main (){ gl_Position = vec4 ( aPos . x , aPos . y , aPos . z , 1.0 ); } Note Vectors in OpenFL have 4 floats. The fourth number is used for perspective division . This will be discussed more later","title":"Vertex Shader"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#fragment-shader","text":"This is the other required shader for rendering a triangle. Colors are once again an array of 4 values, but the fourth value has nothing to do with perspective division, but alpha. The color values range from 0.0 to 1.0. #version 330 core // The fragment shader only requires one output variable similar // to the gl_Position for the vertx shader. In this case it's named // more nicely as FragColor. out vec4 FragColor ; void main (){ FragColor = vec4 ( 1.0f , 0.5f , 0.2f , 1.0f ); }","title":"Fragment shader"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#shader-program","text":"The final linked version of multiple shader combined is called a shader program object . To use the shaders we just created we need to link them to a shader ptogram object, and then activate this shader when rendering objects. // To use the compiled shader we have to link them to a shader program object // The ative shader program's shader will be used when we issue render calls. // This is also where you'll get linking errors if your outputs and inputs don't match unsigned int shaderProgram { glCreateProgram ()}; // not attach the compiled shaders to the program glAttachShader ( shaderProgram , vertexShader ); glAttachShader ( shaderProgram , fragmentShader ); // This links all the attached shaders in one final shader program object glLinkProgram ( shaderProgram ); // now let's test if the linking was successful glGetProgramiv ( shaderProgram , GL_LINK_STATUS , & success ); if ( ! success ){ glGetProgramInfoLog ( shaderProgram , 512 , NULL , infoLog ); std :: cout << \"ERROR::SHADERPROGRAM::FRAG::COMPILATIONS_FAILED \\n \" << infoLog << '\\ n } // We can now activate the program object // From now one every shader and rendering call will use this program object glUseProgram ( shaderProgram ); // don't forget to delete the shader objects now that we've linked them glDeleteShader ( vertexShader ); glDeleteShader ( fragmentShader );","title":"Shader program"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#linking-vertex-attributes","text":"Now we sent the input vertex data to the GPU and instructed the GPU how it should process the data in the shaders. OpenGL still doesn't know how it should connect the vertex data to the vertex shaders' attributes. We need to specify how OpenGL should interpret the vertex data before rendering. Our vertex buffer data is formatted as follows: !vertex_buffer The position data is stored as a 32-bit (4 byte) floating point values Each position is composed of 3 of those values There is no space (or other values) between each set of 3 values. They are tightly packed in the array The first value in the data is at the beginning of the buffer. // We will now tell OpenGL how it should interpret the vertex data (per attribute) // // // The first param specifies which vertex attribute we want to configure. (location = 0) // The next argument specifies the size of the attribute // The next is the type of the attribute // The next is if we want to force normalize the data. // The next is how large our stride is. This is the space between consecutive vertex a // (we know that the array is githly packed so this could also have been 0) // The last parameter sets the offset of where the data begins in the buffer glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * ) 0 ); // 0 is the intex of the vertex attrib array we want to activate glEnableVertexAttribArray ( 0 ); The above process needs to repeat for every single object we are drawing, so it would be useful to be able to save these configurations.","title":"Linking Vertex Attributes"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#vertext-array-object","text":"A vertex array object (VAO) can be found just like a vertex buffer object. Any subsequent vertex attribute calls will then be stored in the VAO. This way you only need to make those calls once when configuring vertex attribute pointers. Whenever we want to draw the object, we can just bind the corresponding VAO. This way we can switch between different vertex data and attribute configurations as easily as binding different VAOs. Everything we set above is stored inside the VAO. Note Core OpenGL requires that we use a VAO so it knows what to do with our vertex intputs. It will refuse to draw anything without a VAO. // ..:: Initialization code (done once (unless your object frequently changes)) :: .. // 1. bind Vertex Array Object glBindVertexArray ( VAO ); // 2. copy our vertices array in a buffer for OpenGL to use glBindBuffer ( GL_ARRAY_BUFFER , VBO ); glBufferData ( GL_ARRAY_BUFFER , sizeof ( vertices ), vertices , GL_STATIC_DRAW ); // 3. then set our vertex attributes pointers glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * ) 0 ); glEnableVertexAttribArray ( 0 ); [...] // ..:: Drawing code (in render loop) :: .. // 4. draw the object glUseProgram ( shaderProgram ); glBindVertexArray ( VAO ); someOpenGLFunctionThatDrawsOurTriangle ();","title":"Vertext Array Object"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/002_HelloTriangle/#element-buffer-objects","text":"What if we want to render a rectangle? Should we input twice the amount of vertices? That would be totally inefficient! float vertices [] = { // first triangle 0.5f , 0.5f , 0.0f , // top right 0.5f , -0.5f , 0.0f , // bottom right -0.5f , 0.5f , 0.0f , // top left // second triangle 0.5f , -0.5f , 0.0f , // bottom right -0.5f , -0.5f , 0.0f , // bottom left -0.5f , 0.5f , 0.0f // top left }; This problem will only get worse with more complex objects. It would be better to store only the unique locations, and then indices in that array to determine how the triangles get made. EBO (element buffer objects) are additional object buffers that store indices that OpenGL uses to decide how to make triangles out of the vertices. This process is known as indexed drawing . float vertices[] = { 0.5f, 0.5f, 0.0f, // top right 0.5f, -0.5f, 0.0f, // bottom right -0.5f, -0.5f, 0.0f, // bottom left -0.5f, 0.5f, 0.0f // top left }; unsigned int indices[] = { // note that we start from 0! 0, 1, 3, // first triangle 1, 2, 3 // second triangle }; It's created and bound just like the VBO // ..:: Initialization code :: .. // 1. bind Vertex Array Object glBindVertexArray ( VAO ); // 2. copy our vertices array in a vertex buffer for OpenGL to use glBindBuffer ( GL_ARRAY_BUFFER , VBO ); glBufferData ( GL_ARRAY_BUFFER , sizeof ( vertices ), vertices , GL_STATIC_DRAW ); // 3. copy our index array in a element buffer for OpenGL to use glBindBuffer ( GL_ELEMENT_ARRAY_BUFFER , EBO ); glBufferData ( GL_ELEMENT_ARRAY_BUFFER , sizeof ( indices ), indices , GL_STATIC_DRAW ); // 4. then set the vertex attributes pointers glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * ) 0 ); glEnableVertexAttribArray ( 0 ); [...] // ..:: Drawing code (in render loop) :: .. glUseProgram ( shaderProgram ); glBindVertexArray ( VAO ); glDrawElements ( GL_TRIANGLES , 6 , GL_UNSIGNED_INT , 0 ) glBindVertexArray ( 0 );","title":"Element Buffer Objects"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/","text":"Shaders Shaders are little programs that run for each GPU kernal. Each shader runs for a specific section of the graphics pipeline. At their core, they are nothing more than programs transforming inputs to outputs. They are also isloated, as they are running in parallel on a ton of gpu cores. The only communication they have is via their inputs and outputs. GLSL Shaders in OpenGl are written in C-like GLSL. They begin with a version delcaration, followed by inputs and outputs, then uniforms, then a main function. #version version_number in type in_variable_name ; in type in_variable_name ; out type out_variable_name ; uniform type uniform_name ; void main () { // process input(s) and do some weird graphics stuff ... // output processed stuff to output variable out_variable_name = weird_stuff_we_processed ; } In the vertex shader each input is a vertex attribute . On all hardware there are always at least 16 4-component vertex attributes available. int nrAttributes; glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &nrAttributes); std::cout << \"Maximum nr of vertex attributes supported: \" << nrAttributes << std::endl; Mine supports 16. GLSL has fundamental data types (int, float, double, uint, and bool), and two container types : vectors and matrices. Vectors A vector is a 1-4 component container for any of the fundamental data types. These are the types of vectors vecn vector of n float bvecn vector of n booleans ivecn vector of n ints uvecn vector of n unsigned integers dvecn vector of n double components Components can be accessed via vec.x - vec.w for each element. You can also use rgba, or stpq for textures. You can swizzle vectors like so vec2 someVec ; vec4 differentVec = someVec . xyxx ; vec3 anotherVec = differentVec . zyw ; vec4 otherVec = someVec . xxxx + anotherVec . yxzy ; Any combination of up to 4 letters can be used to create a new vector of the same type. You can also pass vectors into constructor for other vectors vec2 vect = vec2 ( 0.5 , 0.7 ); vec4 result = vec4 ( vect , 0.0 , 0.0 ); vec4 otherResult = vec4 ( result . xyz , 1.0 ); Without inputs a vertex shader is pretty ineffective. To determine where the inputs are we use the layout (location = 0), so we can link it with vertex data. Note You can also use glGetAttribLocation( shaderProgram, \"position\" ) to figure out where to start, but for basic examples it's simpler to sue the location and it's faster too The fragment shader needs to output FragColor, otherwise your geometry will be either black or white. If we want to send data from one shader to another, we need to send it through the pipeline. Vertex Shader #version 330 core layout ( location = 0 ) in vec3 aPos ; // the position variable has attribute position 0 out vec4 vertexColor ; // specify a color output to the fragment shader void main () { gl_Position = vec4 ( aPos , 1.0 ); // see how we directly give a vec3 to vec4's constructor vertexColor = vec4 ( 0.5 , 0.0 , 0.0 , 1.0 ); // set the output variable to a dark-red color } Fragment shader #version 330 core out vec4 FragColor ; in vec4 vertexColor ; // the input variable from the vertex shader (same name and same type) void main () { FragColor = vertexColor ; } The attributes are automatically linked based on the name ( vetexColor ). Uniforms Uniforms are also a way to pass data from our application to the GPU. They differ from vertex attributes in that they are global - they are unique pershader program object and can be accessed during any stage in the shader program. Because these can be accessed and set anywhere in the program, we have no need to pass it in through the vertex shader, and can define it right in the fragment shader. uniform vec4 ourColor Warning The compilier will silently remove uniform variables that are not begin used Note Before assigning and using a uniform you will have to have \"used\" the program at least once so that a location is assigned. More Attributes! Let's pump a few more vertex attributes through the pipeline! Because we only have one vertex buffer object we need to plug in the attributes after each other. // The last parameter sets the offset of where the data begins in the buffer // Now we are using every 6th float glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 6 * sizeof ( float ), ( void * ) 0 ); When running the program with this new shader, we see a lot more than three colors This is because of fragment interpolation - the rasterizer does this automatically based on the input positions and colors of vertices. All the input variables of the fragment shader are interpoloated by default.","title":"Shaders"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#shaders","text":"Shaders are little programs that run for each GPU kernal. Each shader runs for a specific section of the graphics pipeline. At their core, they are nothing more than programs transforming inputs to outputs. They are also isloated, as they are running in parallel on a ton of gpu cores. The only communication they have is via their inputs and outputs.","title":"Shaders"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#glsl","text":"Shaders in OpenGl are written in C-like GLSL. They begin with a version delcaration, followed by inputs and outputs, then uniforms, then a main function. #version version_number in type in_variable_name ; in type in_variable_name ; out type out_variable_name ; uniform type uniform_name ; void main () { // process input(s) and do some weird graphics stuff ... // output processed stuff to output variable out_variable_name = weird_stuff_we_processed ; } In the vertex shader each input is a vertex attribute . On all hardware there are always at least 16 4-component vertex attributes available. int nrAttributes; glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &nrAttributes); std::cout << \"Maximum nr of vertex attributes supported: \" << nrAttributes << std::endl; Mine supports 16. GLSL has fundamental data types (int, float, double, uint, and bool), and two container types : vectors and matrices.","title":"GLSL"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#vectors","text":"A vector is a 1-4 component container for any of the fundamental data types. These are the types of vectors vecn vector of n float bvecn vector of n booleans ivecn vector of n ints uvecn vector of n unsigned integers dvecn vector of n double components Components can be accessed via vec.x - vec.w for each element. You can also use rgba, or stpq for textures. You can swizzle vectors like so vec2 someVec ; vec4 differentVec = someVec . xyxx ; vec3 anotherVec = differentVec . zyw ; vec4 otherVec = someVec . xxxx + anotherVec . yxzy ; Any combination of up to 4 letters can be used to create a new vector of the same type. You can also pass vectors into constructor for other vectors vec2 vect = vec2 ( 0.5 , 0.7 ); vec4 result = vec4 ( vect , 0.0 , 0.0 ); vec4 otherResult = vec4 ( result . xyz , 1.0 ); Without inputs a vertex shader is pretty ineffective. To determine where the inputs are we use the layout (location = 0), so we can link it with vertex data. Note You can also use glGetAttribLocation( shaderProgram, \"position\" ) to figure out where to start, but for basic examples it's simpler to sue the location and it's faster too The fragment shader needs to output FragColor, otherwise your geometry will be either black or white. If we want to send data from one shader to another, we need to send it through the pipeline.","title":"Vectors"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#vertex-shader","text":"#version 330 core layout ( location = 0 ) in vec3 aPos ; // the position variable has attribute position 0 out vec4 vertexColor ; // specify a color output to the fragment shader void main () { gl_Position = vec4 ( aPos , 1.0 ); // see how we directly give a vec3 to vec4's constructor vertexColor = vec4 ( 0.5 , 0.0 , 0.0 , 1.0 ); // set the output variable to a dark-red color }","title":"Vertex Shader"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#fragment-shader","text":"#version 330 core out vec4 FragColor ; in vec4 vertexColor ; // the input variable from the vertex shader (same name and same type) void main () { FragColor = vertexColor ; } The attributes are automatically linked based on the name ( vetexColor ).","title":"Fragment shader"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#uniforms","text":"Uniforms are also a way to pass data from our application to the GPU. They differ from vertex attributes in that they are global - they are unique pershader program object and can be accessed during any stage in the shader program. Because these can be accessed and set anywhere in the program, we have no need to pass it in through the vertex shader, and can define it right in the fragment shader. uniform vec4 ourColor Warning The compilier will silently remove uniform variables that are not begin used Note Before assigning and using a uniform you will have to have \"used\" the program at least once so that a location is assigned.","title":"Uniforms"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/003_Shaders/#more-attributes","text":"Let's pump a few more vertex attributes through the pipeline! Because we only have one vertex buffer object we need to plug in the attributes after each other. // The last parameter sets the offset of where the data begins in the buffer // Now we are using every 6th float glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 6 * sizeof ( float ), ( void * ) 0 ); When running the program with this new shader, we see a lot more than three colors This is because of fragment interpolation - the rasterizer does this automatically based on the input positions and colors of vertices. All the input variables of the fragment shader are interpoloated by default.","title":"More Attributes!"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/","text":"Textures Textures require uv coordinates. Each vertex should have a textuer coordinate associated with it that specifies which part of the texuture image to sample from. Textures coordinates range from 0 to 1 in the x and y axis (as long as we use 2d textures). You retrieve the correct color for a pixel by sampling the images at the texture coordinate. Lower left is 0, 0 and upper right is 1, 1. Texture Wrapping What happens if we sample a texture outside of it's range? The default behaviour is so repeat textures images, but there are more options GL_REPEAT Repeat the image: this is the default GL_MIRRORED_REPEAT Repeat the image but mirror each time for simple seamlessness GL_CLAMP_TO_EDGE Clamps the coordinates between 0 and 1. This extends/stretches the textures. GL_CLAMP_TO_BORDER Any samples outside the border are given a user-specified color (in the case of decalse this can have an alpha of 0) These options aer set with glTexParameter ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_S , GL_MIRROR_REPEAT ); glTexParameter ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_T , GL_MIRROR_REPEAT ); Note that you need one argument for each axis. If you are using the border extend color you specify the border color like this float borderColorp [] = { 1.0f , 1.0f , 0.0f , 1.0f }; glTexParameterfv ( GL_TEXTURE_2D , GL_TEXTURE_BORDER_COLOR , borderColor ); Texture Filtering Since texture coordinates can be any floating point value, OpenGL needs to figure out which texture pixel ( textel ) is at the coordinate. There are different ways to subsample textures, known as texture filtering . These are the two most important ones GL_NEAREST aks nearest neighbor or point filtering is the default method. This is a proper pixel sample with no additional interpolations. GL_LINEAR aka (bi)linear filtering blurs the result based on the pixels around the edges the of the pixel the sample is closes to. The below image show the difference on a very low resolution image !textureFiltering You set the texture filtering options of your texture like this glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_NEAREST ); // set the filtering option for minimizing a texture glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_LINEAR ); // set the filtering mode for maximizing a texture Mipmaps When there are thousands of objects that are using a texture, there will be some that take up much less or more space on screen than the texture image covers. Not only does OpenGL have difficulties retrieving the right color value when the texture is much higher resolution than the fragment, it is also not memory efficient to load high resolution textures when you don't need to. To solve this issue mipmaps are created by OpenGL which are basically a collection of texture images where each subsequent texture is twice as small compared to the previous one. These are created by glGenerateMipmaps after creating a textures. The following options are avaliable: GL_NEAREST_MIPMAP_NEAREST : Takes the nearest mipmap to match the pixel size and uses neighbor interpolation for texture sampling GL_LINEAR_MIPMAP_NEAREST : Same as above but using linear interpolation GL_NEAREST_MIPMAP_LINEAR : Linearly interpolates between the two mipmaps that most closely match the size of a pixel, and samples the result with linear interpolation. GL_LINEAR_MIPMAP_LINEAR : Linearly interpolates between the two most close mipmaps and then samples the result with linear interpolation as well. You set these like this glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_LINEAR_MIPMAP_LINEAR ); glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_LINEAR ); Note It's dumb to set the magnification filter to mipmapping, since mipmaps don't go above the scale of the texture image. Fortunately this will generate a GL_INVALID_ENUM error code. Loading and creating textures How do you actually read a texture? One way is to write our own image loader based on a certain file format. Why do this though when we can use an image-loading library that supports several popular formats? A popular one is stb_image.h Texture :: Texture ( const std :: string texturePath ){ // load the texture into a char stream int width { 0 }; int height { 0 }; int nrChannels { 0 }; unsigned char * data = stbi_load ( texturePath . c_str (), & width , & height , & nrChannels , 0 ); // Like any open gl objects, textures are referenced with an id // the first input is how many textures to generate and the second // is an int array with the ids (only a single id in our case) glGenTextures ( 1 , & m_ID ); // now bind the texture (this makes it the current object other things operate on) glBindTexture ( GL_TEXTURE_2D , m_ID ); // now generate the textuer using the previously loaded data // // The first argument sets the target. This means that GL_TEXTURE_1D or GL_TEXTURE_3D // will not be effected by this call // // The second argument specifies the mipmap level to generate // The third argument is what sort of format we want to tsore the textuer in // The next two images set the pixel width and height of the resulting texture. // The next argument should always be 0 (legacy) // The 7th and 8th specify the format and datatype of the source image. We loaded // the textuer as RGB values and stored them as chars (bytes) so we'll pass the // corresponding values. // The last is the actual image data glTexImage2D ( GL_TEXTURE_2D , 0 , GL_RGB , width , height , 0 , GL_RGB , GL_UNSIGNED_BYTE , data ); // Generate the mipmaps to the level previously specified glGenerateMipmap ( GL_TEXTURE_2D ); // stbi comes with it's own wrappers for releasing pointer data stbi_image_free ( data ); } Then you need to bind the texturer before drawing elements glBindTexture(GL_TEXTURE_2D, texture); glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); In the shader we reference the texture with a uniform sampler2D uniform sampler2D ourTexture ; void main () { FragColor = texture ( ourTexture , TexCoord ); } Texture Units What is the uniform in the frag shader doing? It's telling the program which texture to sample. Using glUniform1i we can actually assign a lcoation value to the texture sampler so we can set multiple textures at once in the fragment shader. This location is commonly known as the texture unit , and it defaults to 0, which is the default active texture unit. There are at least 16 texture units glActiveTexture ( GL_TEXTURE0 ); // activate the unit glBindTexture ( GL_TEXTURE_2D , texture ); // bind the texture to the unit","title":"Textures"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/#textures","text":"Textures require uv coordinates. Each vertex should have a textuer coordinate associated with it that specifies which part of the texuture image to sample from. Textures coordinates range from 0 to 1 in the x and y axis (as long as we use 2d textures). You retrieve the correct color for a pixel by sampling the images at the texture coordinate. Lower left is 0, 0 and upper right is 1, 1.","title":"Textures"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/#texture-wrapping","text":"What happens if we sample a texture outside of it's range? The default behaviour is so repeat textures images, but there are more options GL_REPEAT Repeat the image: this is the default GL_MIRRORED_REPEAT Repeat the image but mirror each time for simple seamlessness GL_CLAMP_TO_EDGE Clamps the coordinates between 0 and 1. This extends/stretches the textures. GL_CLAMP_TO_BORDER Any samples outside the border are given a user-specified color (in the case of decalse this can have an alpha of 0) These options aer set with glTexParameter ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_S , GL_MIRROR_REPEAT ); glTexParameter ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_T , GL_MIRROR_REPEAT ); Note that you need one argument for each axis. If you are using the border extend color you specify the border color like this float borderColorp [] = { 1.0f , 1.0f , 0.0f , 1.0f }; glTexParameterfv ( GL_TEXTURE_2D , GL_TEXTURE_BORDER_COLOR , borderColor );","title":"Texture Wrapping"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/#texture-filtering","text":"Since texture coordinates can be any floating point value, OpenGL needs to figure out which texture pixel ( textel ) is at the coordinate. There are different ways to subsample textures, known as texture filtering . These are the two most important ones GL_NEAREST aks nearest neighbor or point filtering is the default method. This is a proper pixel sample with no additional interpolations. GL_LINEAR aka (bi)linear filtering blurs the result based on the pixels around the edges the of the pixel the sample is closes to. The below image show the difference on a very low resolution image !textureFiltering You set the texture filtering options of your texture like this glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_NEAREST ); // set the filtering option for minimizing a texture glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_LINEAR ); // set the filtering mode for maximizing a texture","title":"Texture Filtering"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/#mipmaps","text":"When there are thousands of objects that are using a texture, there will be some that take up much less or more space on screen than the texture image covers. Not only does OpenGL have difficulties retrieving the right color value when the texture is much higher resolution than the fragment, it is also not memory efficient to load high resolution textures when you don't need to. To solve this issue mipmaps are created by OpenGL which are basically a collection of texture images where each subsequent texture is twice as small compared to the previous one. These are created by glGenerateMipmaps after creating a textures. The following options are avaliable: GL_NEAREST_MIPMAP_NEAREST : Takes the nearest mipmap to match the pixel size and uses neighbor interpolation for texture sampling GL_LINEAR_MIPMAP_NEAREST : Same as above but using linear interpolation GL_NEAREST_MIPMAP_LINEAR : Linearly interpolates between the two mipmaps that most closely match the size of a pixel, and samples the result with linear interpolation. GL_LINEAR_MIPMAP_LINEAR : Linearly interpolates between the two most close mipmaps and then samples the result with linear interpolation as well. You set these like this glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_LINEAR_MIPMAP_LINEAR ); glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_LINEAR ); Note It's dumb to set the magnification filter to mipmapping, since mipmaps don't go above the scale of the texture image. Fortunately this will generate a GL_INVALID_ENUM error code.","title":"Mipmaps"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/#loading-and-creating-textures","text":"How do you actually read a texture? One way is to write our own image loader based on a certain file format. Why do this though when we can use an image-loading library that supports several popular formats? A popular one is stb_image.h Texture :: Texture ( const std :: string texturePath ){ // load the texture into a char stream int width { 0 }; int height { 0 }; int nrChannels { 0 }; unsigned char * data = stbi_load ( texturePath . c_str (), & width , & height , & nrChannels , 0 ); // Like any open gl objects, textures are referenced with an id // the first input is how many textures to generate and the second // is an int array with the ids (only a single id in our case) glGenTextures ( 1 , & m_ID ); // now bind the texture (this makes it the current object other things operate on) glBindTexture ( GL_TEXTURE_2D , m_ID ); // now generate the textuer using the previously loaded data // // The first argument sets the target. This means that GL_TEXTURE_1D or GL_TEXTURE_3D // will not be effected by this call // // The second argument specifies the mipmap level to generate // The third argument is what sort of format we want to tsore the textuer in // The next two images set the pixel width and height of the resulting texture. // The next argument should always be 0 (legacy) // The 7th and 8th specify the format and datatype of the source image. We loaded // the textuer as RGB values and stored them as chars (bytes) so we'll pass the // corresponding values. // The last is the actual image data glTexImage2D ( GL_TEXTURE_2D , 0 , GL_RGB , width , height , 0 , GL_RGB , GL_UNSIGNED_BYTE , data ); // Generate the mipmaps to the level previously specified glGenerateMipmap ( GL_TEXTURE_2D ); // stbi comes with it's own wrappers for releasing pointer data stbi_image_free ( data ); } Then you need to bind the texturer before drawing elements glBindTexture(GL_TEXTURE_2D, texture); glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); In the shader we reference the texture with a uniform sampler2D uniform sampler2D ourTexture ; void main () { FragColor = texture ( ourTexture , TexCoord ); }","title":"Loading and creating textures"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/004_Textures/#texture-units","text":"What is the uniform in the frag shader doing? It's telling the program which texture to sample. Using glUniform1i we can actually assign a lcoation value to the texture sampler so we can set multiple textures at once in the fragment shader. This location is commonly known as the texture unit , and it defaults to 0, which is the default active texture unit. There are at least 16 texture units glActiveTexture ( GL_TEXTURE0 ); // activate the unit glBindTexture ( GL_TEXTURE_2D , texture ); // bind the texture to the unit","title":"Texture Units"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/005_Transformations/","text":"This lesson is in general a review of the material I have covered here A couple of highlights Homogeneous The fourth compoenent of a vector is known as the homogeneous coordinate . To solve the 3d vector of a vector like this we divide the x, y and z coordinates by this w coordinate. Usually this is assumed to be 1.0, but it's useful when setting the perpective of a camera. If it's zero the vector cannot be translated and is known as a dicrection vector *. It's also used for creating 3d perspective. Rotation In 2d and 3d rotations are represented with angles or radians. Angles You can easily convert back and forth between them angle in degrees = angle in radians * (180 / PI) angle in radians = angle in degrees * (PI / 180) Where PI equals (rounded) 3.14159265359. In 3d rotation are specified with an angle and a rotation axis . You can do this with math using trigonometry. Here are some common forumulas Rotation around x-axis \\[ \\begin{bmatrix} 1 & 0 & 0 &0 \\\\ 0 & \\cos{\\theta} & -\\sin\\theta & 0 \\\\ 0 & \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} * \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x \\\\ \\cos\\theta * y - \\sin\\theta * z \\\\ \\sin\\theta * y + \\cos\\theta * z \\\\ 1 \\end{pmatrix} \\] It's best not to simple rotate about axes though, as this quickly introduces a problem called Gimbal lock . It's much better to rotate about an arbitrary axis. Ideally you will base your rotations around quaternions. GLM GLM is the Open Gl M athematics library and has a bunch of useful matrix functions. #include <glm/glm.hpp> #include <glm/gtc/matrix_transform.hpp> #include <glm/gtc/type_ptr.hpp>","title":"005 Transformations"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/005_Transformations/#rotation","text":"In 2d and 3d rotations are represented with angles or radians. Angles You can easily convert back and forth between them angle in degrees = angle in radians * (180 / PI) angle in radians = angle in degrees * (PI / 180) Where PI equals (rounded) 3.14159265359. In 3d rotation are specified with an angle and a rotation axis . You can do this with math using trigonometry. Here are some common forumulas Rotation around x-axis \\[ \\begin{bmatrix} 1 & 0 & 0 &0 \\\\ 0 & \\cos{\\theta} & -\\sin\\theta & 0 \\\\ 0 & \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} * \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x \\\\ \\cos\\theta * y - \\sin\\theta * z \\\\ \\sin\\theta * y + \\cos\\theta * z \\\\ 1 \\end{pmatrix} \\] It's best not to simple rotate about axes though, as this quickly introduces a problem called Gimbal lock . It's much better to rotate about an arbitrary axis. Ideally you will base your rotations around quaternions.","title":"Rotation"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/005_Transformations/#glm","text":"GLM is the Open Gl M athematics library and has a bunch of useful matrix functions. #include <glm/glm.hpp> #include <glm/gtc/matrix_transform.hpp> #include <glm/gtc/type_ptr.hpp>","title":"GLM"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/","text":"Coordinate Systems OpenGL expects all vertices that we want to become visible to be in NDC (normalized device coordinates) after each vertex shader run. X, y and z should all be between -1.0 and 1.0. This transformation usually happens in several steps. Because some operations are easier to do in different intermediate coordinate systems, we don't just transform everything directly into NDC. These are Local space This is where the vertices of the object start out in. All the vertices are in local space. All the vertices are relative to the origin of the object. World Space Where are the objects in the scene composition? How do they relate to each other? The world coordinates are the vertices of your object multiplied with the model matrix. This is the transformation matrix that puts your object where it belongs. View Space The orthographic camera direction . This is the result of transforming all the vertices by the view matrix . In open GL you don't move the camera, you move the world. Clip Space All coordinates that do not fall into this space -1.0 to 1.0 get clipped. Before this happens, we create our own coordinate system. Vertex coordinates get transformed from view to clip-space with a projection matrix that goes from a range in each dimension. This then converts all coordinates into NDC. Note OpenGL will reconstruct clipped triangles with one or more triangles that fit inside the clipping range The viewing box that the projection matrix creates is called a frustrum , and all the coordinates inside this frustrum will end up on the user's screen. The entire process to convert coordinates within a range to NDC is called projection . Once all the vertices are transformed to to clip space, perspective division is applied to them where we divide x, y and z by the w. After this the coordinate are mapped to the screen and become fragments. There are two types of projection matrices to use Orthographic projection Like a blueprint, this has an infinitely small angle. This directly maps all the coordinates inside the target range to the frustrum without any perspective. You can do this by setting the w coordinate of all vertices to 1.0 To create this projection matrix we can use glm::ortho // the first two parameters specify the left and right // the second two up and down // the last two the distances between near and far glm :: ortho ( 0.0f , 800.0f , 0.0f , 600.0f , 0.1f , 100.0f ); Perspective projection In real life objects get smaller the farther away from you the get. This is called perspective . The projection matrix mimix this with a perspective projection matrix . This maps a given frustrum range to clip space, but also manipulates the w value of each vertex coordinaet in such a way that verticse farther away go closer to 0 (the vanishing point). To create this you can use glm::mat4 // The first parameter defines the field of view // the second parameter sets the aspect ratio // the third and fourth set the near and far clip plane. glm :: mat4 proj = glm :: perspective ( glm :: radians ( 45.0f ), ( float ) width / ( float ) height , 0.1f , 100.0f ); Putting it all together \\[ V_{ clip }= M_{ projection }* M_{ view }* M_{ model }* V_{local} \\] Moving the camera backwards is the same as moving the entire scene forwards. If you don't want zfighting, you need to enable the zbuffer.","title":"Coordinate Systems"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/#coordinate-systems","text":"OpenGL expects all vertices that we want to become visible to be in NDC (normalized device coordinates) after each vertex shader run. X, y and z should all be between -1.0 and 1.0. This transformation usually happens in several steps. Because some operations are easier to do in different intermediate coordinate systems, we don't just transform everything directly into NDC. These are","title":"Coordinate Systems"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/#local-space","text":"This is where the vertices of the object start out in. All the vertices are in local space. All the vertices are relative to the origin of the object.","title":"Local space"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/#world-space","text":"Where are the objects in the scene composition? How do they relate to each other? The world coordinates are the vertices of your object multiplied with the model matrix. This is the transformation matrix that puts your object where it belongs.","title":"World Space"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/#view-space","text":"The orthographic camera direction . This is the result of transforming all the vertices by the view matrix . In open GL you don't move the camera, you move the world.","title":"View Space"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/#clip-space","text":"All coordinates that do not fall into this space -1.0 to 1.0 get clipped. Before this happens, we create our own coordinate system. Vertex coordinates get transformed from view to clip-space with a projection matrix that goes from a range in each dimension. This then converts all coordinates into NDC. Note OpenGL will reconstruct clipped triangles with one or more triangles that fit inside the clipping range The viewing box that the projection matrix creates is called a frustrum , and all the coordinates inside this frustrum will end up on the user's screen. The entire process to convert coordinates within a range to NDC is called projection . Once all the vertices are transformed to to clip space, perspective division is applied to them where we divide x, y and z by the w. After this the coordinate are mapped to the screen and become fragments. There are two types of projection matrices to use Orthographic projection Like a blueprint, this has an infinitely small angle. This directly maps all the coordinates inside the target range to the frustrum without any perspective. You can do this by setting the w coordinate of all vertices to 1.0 To create this projection matrix we can use glm::ortho // the first two parameters specify the left and right // the second two up and down // the last two the distances between near and far glm :: ortho ( 0.0f , 800.0f , 0.0f , 600.0f , 0.1f , 100.0f ); Perspective projection In real life objects get smaller the farther away from you the get. This is called perspective . The projection matrix mimix this with a perspective projection matrix . This maps a given frustrum range to clip space, but also manipulates the w value of each vertex coordinaet in such a way that verticse farther away go closer to 0 (the vanishing point). To create this you can use glm::mat4 // The first parameter defines the field of view // the second parameter sets the aspect ratio // the third and fourth set the near and far clip plane. glm :: mat4 proj = glm :: perspective ( glm :: radians ( 45.0f ), ( float ) width / ( float ) height , 0.1f , 100.0f );","title":"Clip Space"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/006_Coordinate_Systems/#putting-it-all-together","text":"\\[ V_{ clip }= M_{ projection }* M_{ view }* M_{ model }* V_{local} \\] Moving the camera backwards is the same as moving the entire scene forwards. If you don't want zfighting, you need to enable the zbuffer.","title":"Putting it all together"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/007_Camera/","text":"Camera In openGL we move the world, not the camera. For the user, this transformation is more easily thought of as a camera. When we talk about camera space we're talking about all the vertex coordinates within camera object space. This becomes the final space the vertices are transformed into. Note The positive z-axis is the direction that the camera is looking towards. Getting the camera position in easy, we already moved the camera backwards (along the negative z) in the previous chapter. The direction is a bit more tricky. We can get the vector we want by normalizing the camera position - the camera target. // the position of our camera glm :: vec3 cameraPos { 0.0f , 0.0f , 3.0f }; // the direction fo our camera // tecnically this is pointing in the reverse direction of what it is targeting glm :: vec3 cameraTarget { 0.0f , 0.0f , 0.0f }; glm :: vec3 camZ { glm :: normalize ( cameraPos - cameraTarget ) }; // get the right access by crossing up with the direction glm :: vec3 up = glm :: vec3 ( 0.0f , 1.0f , 0.0f ); glm :: vec3 camX = glm :: normalize ( glm :: cross ( up , camZ )); // now get the up vector by crossing the x and z glm :: vec3 camY = glm :: normalize ( glm :: cross ( camZ , camX )); You can create matricies from their axies and a position vector directly \\[ LookAt = \\begin{bmatrix} R_x & R_y & R_z & 0 \\\\ U_x & U_y & U_z & 0 \\\\ D_x & D_y & D_z & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} * \\begin{bmatrix} 1 & 0 & 0 & -P_x \\\\ 0 & 1 & 0 & -P_y \\\\ 0 & 0 & 1 & -P_z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} \\] In this case R is right (X), U is up (y) and D is direction (z). You move everything by multiplying all the vertices by a view matrix in the vertex shader. Time It's not good using a const value to increment the movement speed. Depending on the system the program is used on, the will vary based on how many redraws there are ber second. Because of this, Graphics applications usually keep track of a deltatime variable that stores the tim it took to render the last frame. Look around To look around we're changing the cameraFront vector based on the input of the mouse. The three euler angles we're changing will be the pitch, yaw and roll . Right now we only care about the yaw and pitch values. Given an angle for yaw, we know that the new vector for it will be \\[ x = cos(yaw)* cos(pitch) y = sin(yaw) z = sin(yaw) * cos(pitch) \\] This will make a lot more sense after learning about more trigonometry. We use mouse input to get pitch and yaw.","title":"007 Camera"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/007_Camera/#camera","text":"In openGL we move the world, not the camera. For the user, this transformation is more easily thought of as a camera. When we talk about camera space we're talking about all the vertex coordinates within camera object space. This becomes the final space the vertices are transformed into. Note The positive z-axis is the direction that the camera is looking towards. Getting the camera position in easy, we already moved the camera backwards (along the negative z) in the previous chapter. The direction is a bit more tricky. We can get the vector we want by normalizing the camera position - the camera target. // the position of our camera glm :: vec3 cameraPos { 0.0f , 0.0f , 3.0f }; // the direction fo our camera // tecnically this is pointing in the reverse direction of what it is targeting glm :: vec3 cameraTarget { 0.0f , 0.0f , 0.0f }; glm :: vec3 camZ { glm :: normalize ( cameraPos - cameraTarget ) }; // get the right access by crossing up with the direction glm :: vec3 up = glm :: vec3 ( 0.0f , 1.0f , 0.0f ); glm :: vec3 camX = glm :: normalize ( glm :: cross ( up , camZ )); // now get the up vector by crossing the x and z glm :: vec3 camY = glm :: normalize ( glm :: cross ( camZ , camX )); You can create matricies from their axies and a position vector directly \\[ LookAt = \\begin{bmatrix} R_x & R_y & R_z & 0 \\\\ U_x & U_y & U_z & 0 \\\\ D_x & D_y & D_z & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} * \\begin{bmatrix} 1 & 0 & 0 & -P_x \\\\ 0 & 1 & 0 & -P_y \\\\ 0 & 0 & 1 & -P_z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} \\] In this case R is right (X), U is up (y) and D is direction (z). You move everything by multiplying all the vertices by a view matrix in the vertex shader.","title":"Camera"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/007_Camera/#time","text":"It's not good using a const value to increment the movement speed. Depending on the system the program is used on, the will vary based on how many redraws there are ber second. Because of this, Graphics applications usually keep track of a deltatime variable that stores the tim it took to render the last frame.","title":"Time"},{"location":"rendering/OpenGL/LearnOpenGL.com/001_Getting_Started/007_Camera/#look-around","text":"To look around we're changing the cameraFront vector based on the input of the mouse. The three euler angles we're changing will be the pitch, yaw and roll . Right now we only care about the yaw and pitch values. Given an angle for yaw, we know that the new vector for it will be \\[ x = cos(yaw)* cos(pitch) y = sin(yaw) z = sin(yaw) * cos(pitch) \\] This will make a lot more sense after learning about more trigonometry. We use mouse input to get pitch and yaw.","title":"Look around"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/001_Colors/","text":"Colors We need to map real colors to digital valuse - therefore not all real-world colors can be represented. We can get almost any color in the real world by mixing rgb. The colors we see in real life are reflected from the objects that light is hitting. The colors we see are the wavelengths of the object that are not absorved. In graphics land we define a light source and give it a color. If we multiply this color with an object's color, the resulting color would be the reflected color of the object. We are now creating a second set of shaders for the light and the cube objects","title":"Colors"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/001_Colors/#colors","text":"We need to map real colors to digital valuse - therefore not all real-world colors can be represented. We can get almost any color in the real world by mixing rgb. The colors we see in real life are reflected from the objects that light is hitting. The colors we see are the wavelengths of the object that are not absorved. In graphics land we define a light source and give it a color. If we multiply this color with an object's color, the resulting color would be the reflected color of the object. We are now creating a second set of shaders for the light and the cube objects","title":"Colors"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/","text":"Basic Lighting Lighting in OpenGL is based on approximations of reality using simplified models. One of these models is the Phone lighting model . There are three components: Ambient lighting is the base light. Diffuse lighting multiplies the object color. This calculates the sides that face the light and makes them brighter. Specular lightin simulates the highlight. This takes the light color of the light source. To create good looking scenes we need to simulate at least these 3 lighting components. Ambient Lighting Nowadays this is often replacewd by a global illumination algorithm, but we are going to start with super basic ambient lighting. This is done by adding a small constant (light) color to the final resulting color of the object's fragments. Diffuse lighting This will start giving significant visual impact to the object. To calculate diffuse lighting, we will need a normal vector for the surface of the fragment. Diffuse lighting This will start giving significant visual impact to the object. To calculate diffuse lighting, we will need a normal vector for the surface of the fragment. Remember that we need to update the normal vector by the transformation of the shader. We will need to compare the transformed normal with the angel to the light, and the dot product of the two will tell us the intensity. Normal vectors A normal needs to be added to the vertices in order to get the normal vector (remember that OpenGL interpolates all the attributes to the fragments). To calculate the normal we need to add it to our pipeline. Then we also need to add the position of the fragment in world coordinates. In the vertex shader FragPos = vec3 ( model * vec4 ( aPos , 1.0 )); You need this to calculate the vector to the light position in the fragment shader. This will be interpolated to a per-fragment world position. First we generate the vectors to compare and normalize them just to be safe vec3 normalizedN = normalize ( N ); vec3 lightDir = normalize ( lightPos - FragPos ); // then calculate the diffuse through the dot product // note we don't care about values more then 180 degeres away from the light so we are using max to discard results of the dot product under 0 float diffuse = max ( dot ( normalizedN , lightDit ), 0.0 ); vec3 diffuse = diff * lightColor ; The result looks good, but the normals don't seem right. This is because you can't just transform the normal vector by the model matrix. Normal vectors don't have a position attribute, they are only direction. So first off we should remove the translation part of the matrix. The model matrix could perform a non-uniform scale, which changes the vertices in such a way that the normal vector is no longer perpendicular with the surface anymore. Whenever there is a non-uniform scale applied to a vector, even if it gets normalized afterwards, it will end up scewed and not perpendicular to the surface anymore. The solution is using a model matrix specifically tailored to for normal vector, a normal matrix . This uses the steps in this article to generate a matrix to transform the normals. Basically the normal matrix is the transpose of the inverse of the upper-left 3x3 part of the model matrix . Usually you would derive the normal from the model and view matrix, but because we are working in world space we will derive it from the model matrix alone. N = mat3 ( transpose ( inverse ( model ))) * aN ; Now the normals are fixed Note Inversing matrices is an expensive operation for a shader, so whenever possible try to avoid doing inverse operations. They need to be done for eac hvertex in the scene. In a real application you would want to pre-calculate this matrix and then pass it in as a uniform. glm :: mat3 normalMatrix { glm :: mat3 ( glm :: transpose ( glm :: inverse ( model )))}; geometryShader . setMatrix3 ( \"normalMatrix\" , normalMatrix ); Specular Lighting Specular is similar the diffuse, but based on the player direction. Basically you figure out the reflection vector by mirroring the light direction around the norm axis and seeing if it's in the range of the light. This means we need to get the view vector. For this tutorial we will need to input the world space as another uniform, but many people like to calculate the spec and diffuse in view space. This is convenient, because view space always has (0,0,0) as the view position so you safe a uniform. //specular vec3 viewDir = normalize ( viewPos - FragPos ); // negate the light dir to match the reflect function. vec3 reflectDir = reflect ( - lightDir , normalizedN ); // calculate the dot produce between view direction and reflect direction // raise it to the pow of 32 (higher is sharper spec) float spec = pow ( max ( dot ( viewDir , reflectDir ), 0.0 ), 32 ); vec3 result = ( ambient + diffuse + specular ) * objectColor ; The shinyness of the shader is created by raising the dot product to a pow. Note Back when frag shaders were super expensive, ppl would calculate the same lighting model (called Gouraud) on the vertex shader and let OpenGl handle the interpolation. This looks kinda shit though because it's not accounting for all the highlights between the vertices.","title":"Basic Lighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/#basic-lighting","text":"Lighting in OpenGL is based on approximations of reality using simplified models. One of these models is the Phone lighting model . There are three components: Ambient lighting is the base light. Diffuse lighting multiplies the object color. This calculates the sides that face the light and makes them brighter. Specular lightin simulates the highlight. This takes the light color of the light source. To create good looking scenes we need to simulate at least these 3 lighting components.","title":"Basic Lighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/#ambient-lighting","text":"Nowadays this is often replacewd by a global illumination algorithm, but we are going to start with super basic ambient lighting. This is done by adding a small constant (light) color to the final resulting color of the object's fragments.","title":"Ambient Lighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/#diffuse-lighting","text":"This will start giving significant visual impact to the object. To calculate diffuse lighting, we will need a normal vector for the surface of the fragment.","title":"Diffuse lighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/#diffuse-lighting_1","text":"This will start giving significant visual impact to the object. To calculate diffuse lighting, we will need a normal vector for the surface of the fragment. Remember that we need to update the normal vector by the transformation of the shader. We will need to compare the transformed normal with the angel to the light, and the dot product of the two will tell us the intensity.","title":"Diffuse lighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/#normal-vectors","text":"A normal needs to be added to the vertices in order to get the normal vector (remember that OpenGL interpolates all the attributes to the fragments). To calculate the normal we need to add it to our pipeline. Then we also need to add the position of the fragment in world coordinates. In the vertex shader FragPos = vec3 ( model * vec4 ( aPos , 1.0 )); You need this to calculate the vector to the light position in the fragment shader. This will be interpolated to a per-fragment world position. First we generate the vectors to compare and normalize them just to be safe vec3 normalizedN = normalize ( N ); vec3 lightDir = normalize ( lightPos - FragPos ); // then calculate the diffuse through the dot product // note we don't care about values more then 180 degeres away from the light so we are using max to discard results of the dot product under 0 float diffuse = max ( dot ( normalizedN , lightDit ), 0.0 ); vec3 diffuse = diff * lightColor ; The result looks good, but the normals don't seem right. This is because you can't just transform the normal vector by the model matrix. Normal vectors don't have a position attribute, they are only direction. So first off we should remove the translation part of the matrix. The model matrix could perform a non-uniform scale, which changes the vertices in such a way that the normal vector is no longer perpendicular with the surface anymore. Whenever there is a non-uniform scale applied to a vector, even if it gets normalized afterwards, it will end up scewed and not perpendicular to the surface anymore. The solution is using a model matrix specifically tailored to for normal vector, a normal matrix . This uses the steps in this article to generate a matrix to transform the normals. Basically the normal matrix is the transpose of the inverse of the upper-left 3x3 part of the model matrix . Usually you would derive the normal from the model and view matrix, but because we are working in world space we will derive it from the model matrix alone. N = mat3 ( transpose ( inverse ( model ))) * aN ; Now the normals are fixed Note Inversing matrices is an expensive operation for a shader, so whenever possible try to avoid doing inverse operations. They need to be done for eac hvertex in the scene. In a real application you would want to pre-calculate this matrix and then pass it in as a uniform. glm :: mat3 normalMatrix { glm :: mat3 ( glm :: transpose ( glm :: inverse ( model )))}; geometryShader . setMatrix3 ( \"normalMatrix\" , normalMatrix );","title":"Normal vectors"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/009_Basic_Lighting/#specular-lighting","text":"Specular is similar the diffuse, but based on the player direction. Basically you figure out the reflection vector by mirroring the light direction around the norm axis and seeing if it's in the range of the light. This means we need to get the view vector. For this tutorial we will need to input the world space as another uniform, but many people like to calculate the spec and diffuse in view space. This is convenient, because view space always has (0,0,0) as the view position so you safe a uniform. //specular vec3 viewDir = normalize ( viewPos - FragPos ); // negate the light dir to match the reflect function. vec3 reflectDir = reflect ( - lightDir , normalizedN ); // calculate the dot produce between view direction and reflect direction // raise it to the pow of 32 (higher is sharper spec) float spec = pow ( max ( dot ( viewDir , reflectDir ), 0.0 ), 32 ); vec3 result = ( ambient + diffuse + specular ) * objectColor ; The shinyness of the shader is created by raising the dot product to a pow. Note Back when frag shaders were super expensive, ppl would calculate the same lighting model (called Gouraud) on the vertex shader and let OpenGl handle the interpolation. This looks kinda shit though because it's not accounting for all the highlights between the vertices.","title":"Specular Lighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/010_Materials/","text":"Materials Different surfaces can have common properties abstracted into material properties . You can define a struct of material properties in your material like so: #version 330 core struct Materia { vec3 ambient ; vec3 diffuse ; vec3 specular ; float shininess ; }; uniform Material material ; There is no big different to storing all these as individual unforms, but a struct is more organized. Here we have defined a color for each of the phong lighting's components. If we plug this into our object, it looks a bit too bright. The lights need the same struct, and they multiply those parts of the material in the shader.","title":"Materials"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/010_Materials/#materials","text":"Different surfaces can have common properties abstracted into material properties . You can define a struct of material properties in your material like so: #version 330 core struct Materia { vec3 ambient ; vec3 diffuse ; vec3 specular ; float shininess ; }; uniform Material material ; There is no big different to storing all these as individual unforms, but a struct is more organized. Here we have defined a color for each of the phong lighting's components. If we plug this into our object, it looks a bit too bright. The lights need the same struct, and they multiply those parts of the material in the shader.","title":"Materials"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/011_LightingMaps/","text":"Lightin Maps Just like different object having unique materials, different lights can have unique properties. This chapter goes over how to set up a material struct in the shader and multiply the phong elements by it.","title":"Lightin Maps"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/011_LightingMaps/#lightin-maps","text":"Just like different object having unique materials, different lights can have unique properties. This chapter goes over how to set up a material struct in the shader and multiply the phong elements by it.","title":"Lightin Maps"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/","text":"Light Casters There are many different types of light casters in the real world. Directional Light When a light source is modeled to be infinitely far away it is a directional light . The sun (from our perspective) is a great model for a directional light. Relative to the earth all the light rays are nearly parallel. This is a very simple implementation. Passing You can also pass position data (like the lights direction or position) as a vec4 to better match openGl's structure. Just make sure you always set the 4th element to 1.0, unless it's a direction vector in which case it's 0.0. This will make it easy to check if the light's vector is position or direction. This is how old scool OpenGl (fixed pipe) used to do things. Point Light A point light has a given position in the world and illimunates in all directions with rays fading out over distance. Attenuation is the process of recuding the intensity of the light over the distance a light ray travels. The most basic way to implement this is using a linear equation. These tend to look a bit fake. The brightness of a light in the real world tends to fall off very quickly, leaving a fraction that then diminishes over a larger distance. To get the attenuation we use the following formula \\[ F_{ att }= \\frac{ 1.0 }{ K_x + K_l * d + K_q * d^2 } \\] d = distance from fragment to light source \\(K_c\\) is a constant term kept at 1.0, which is there to make sure the denominator never gets smaller than 1. If it was smaller than one that would boost the intensity with certain distances. \\(K_l\\) is a linear term multiplied with the distance value that creates a linear reduction \\(K_q\\) is a quadratic term multiplied with the quadrang of the distance and it sets a quadratic decrease of intensity from the light source. This is less significant when the distance is small, but makes a larger difference as the distance increases. You can get good default values for lights from Ogre 3d's wiki Distance Constant Linear Quadratic 7 1.0 0.7 1.8 50 1.0 0.09 0.032 100 1.0 0.045 0.0075 200 1.0 0.022 0.0019 To implement a point light I'm going to subclass my light class and add additional position, constant, linear, and quadratic properties. Point light is a light source with a configurable location and attenuation applied to it's lighting calculations. Spotlight The spotlight is like a pointlight, but it has a limited direction towards which is shoots rays. The direction is limited by a cutoff andle that specifies the radius of the spotlight. Lightdir: the vector pointing from the fragment to the light source Spotdir: the direction the spotlight is aiming at Phi \\(\\phi\\) the cutoff angle of the spotlight's radius. Everything outside this is not lit Theta \\(\\theta\\) the angle between the Light Dir and the Spotdir vector. This should be smaller then \\(\\phi\\) to be considered lit and in the spotlight. So once again we need the dot product for the cosine of the angle between the lightDir and the SpotDir. Then compare that with the cutoff angle \\(\\phi\\) to get the strength of the light's effect. Flashlight A flashlight is a spotlight located at the viewer's position and usually aimed straight ahead in the direction the player is facing. Smooth/Soft Edges For smoothing around the edges of the spotlight, we want to simulate the spotlight having an inner and outer cone. The inner cone can be the cutoff value, with the outer cone being a smoothstep to that value. Then if the fragment is between the inner and the outer cone it should calculate an intensity value between 0.0 and 1.0. If the fragment is inside the inner cone its intensit yis equal to 1.0 and 0.0 if the fragment is outsid the outer cone. To get the value we can use the following equation: \\[ I = \\frac{ \\theta - \\gamma }{ \\epsilon } \\] \\(\\epsilon\\) is the cosine difference between the inner ( \\(\\phi\\) ) and outer ( \\(\\gamma\\) ) cone. \\(\\epsilon = \\phi - \\gamma\\) . \"I\" is the intensity of the spotlight at the current fragment. This translates into glsl like the following float theta = dot ( lightDir , normalize ( - light . direction )); float epsilon = light . cutOff - light . outerCutOff ; // the clamping is for convenience so we don't need an if in the frag shader float intensity = clamp (( theta - light . outerCutOff ) / epsilon , 0.0 , 1.0 );","title":"Light Casters"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/#light-casters","text":"There are many different types of light casters in the real world.","title":"Light Casters"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/#directional-light","text":"When a light source is modeled to be infinitely far away it is a directional light . The sun (from our perspective) is a great model for a directional light. Relative to the earth all the light rays are nearly parallel. This is a very simple implementation. Passing You can also pass position data (like the lights direction or position) as a vec4 to better match openGl's structure. Just make sure you always set the 4th element to 1.0, unless it's a direction vector in which case it's 0.0. This will make it easy to check if the light's vector is position or direction. This is how old scool OpenGl (fixed pipe) used to do things.","title":"Directional Light"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/#point-light","text":"A point light has a given position in the world and illimunates in all directions with rays fading out over distance. Attenuation is the process of recuding the intensity of the light over the distance a light ray travels. The most basic way to implement this is using a linear equation. These tend to look a bit fake. The brightness of a light in the real world tends to fall off very quickly, leaving a fraction that then diminishes over a larger distance. To get the attenuation we use the following formula \\[ F_{ att }= \\frac{ 1.0 }{ K_x + K_l * d + K_q * d^2 } \\] d = distance from fragment to light source \\(K_c\\) is a constant term kept at 1.0, which is there to make sure the denominator never gets smaller than 1. If it was smaller than one that would boost the intensity with certain distances. \\(K_l\\) is a linear term multiplied with the distance value that creates a linear reduction \\(K_q\\) is a quadratic term multiplied with the quadrang of the distance and it sets a quadratic decrease of intensity from the light source. This is less significant when the distance is small, but makes a larger difference as the distance increases. You can get good default values for lights from Ogre 3d's wiki Distance Constant Linear Quadratic 7 1.0 0.7 1.8 50 1.0 0.09 0.032 100 1.0 0.045 0.0075 200 1.0 0.022 0.0019 To implement a point light I'm going to subclass my light class and add additional position, constant, linear, and quadratic properties. Point light is a light source with a configurable location and attenuation applied to it's lighting calculations.","title":"Point Light"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/#spotlight","text":"The spotlight is like a pointlight, but it has a limited direction towards which is shoots rays. The direction is limited by a cutoff andle that specifies the radius of the spotlight. Lightdir: the vector pointing from the fragment to the light source Spotdir: the direction the spotlight is aiming at Phi \\(\\phi\\) the cutoff angle of the spotlight's radius. Everything outside this is not lit Theta \\(\\theta\\) the angle between the Light Dir and the Spotdir vector. This should be smaller then \\(\\phi\\) to be considered lit and in the spotlight. So once again we need the dot product for the cosine of the angle between the lightDir and the SpotDir. Then compare that with the cutoff angle \\(\\phi\\) to get the strength of the light's effect.","title":"Spotlight"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/#flashlight","text":"A flashlight is a spotlight located at the viewer's position and usually aimed straight ahead in the direction the player is facing.","title":"Flashlight"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/012_Light_Casters/#smoothsoft-edges","text":"For smoothing around the edges of the spotlight, we want to simulate the spotlight having an inner and outer cone. The inner cone can be the cutoff value, with the outer cone being a smoothstep to that value. Then if the fragment is between the inner and the outer cone it should calculate an intensity value between 0.0 and 1.0. If the fragment is inside the inner cone its intensit yis equal to 1.0 and 0.0 if the fragment is outsid the outer cone. To get the value we can use the following equation: \\[ I = \\frac{ \\theta - \\gamma }{ \\epsilon } \\] \\(\\epsilon\\) is the cosine difference between the inner ( \\(\\phi\\) ) and outer ( \\(\\gamma\\) ) cone. \\(\\epsilon = \\phi - \\gamma\\) . \"I\" is the intensity of the spotlight at the current fragment. This translates into glsl like the following float theta = dot ( lightDir , normalize ( - light . direction )); float epsilon = light . cutOff - light . outerCutOff ; // the clamping is for convenience so we don't need an if in the frag shader float intensity = clamp (( theta - light . outerCutOff ) / epsilon , 0.0 , 1.0 );","title":"Smooth/Soft Edges"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/013_Multiple_lights/","text":"Multiple Lights You can define each light as a function in GLSL, and you can bind multiple lights into struct arrays. For arrays you set the properties of each struct in the array like so glUnfirom3f ( glGetUniformLocation ( m_ID , \"pointLights[0].diffuse\" , vx , vy , vz )); It's a bit annoying, and I worked around it by wrapping it into a function that sets all the elemnts based on a string name of the object. I set the name to \"pointLights[0]\". This will break really easily though, so I'm looking forward to seeing how a more complex render pipeline is structures.","title":"Multiple Lights"},{"location":"rendering/OpenGL/LearnOpenGL.com/002_Lighting/013_Multiple_lights/#multiple-lights","text":"You can define each light as a function in GLSL, and you can bind multiple lights into struct arrays. For arrays you set the properties of each struct in the array like so glUnfirom3f ( glGetUniformLocation ( m_ID , \"pointLights[0].diffuse\" , vx , vy , vz )); It's a bit annoying, and I worked around it by wrapping it into a function that sets all the elemnts based on a string name of the object. I set the name to \"pointLights[0]\". This will break really easily though, so I'm looking forward to seeing how a more complex render pipeline is structures.","title":"Multiple Lights"},{"location":"rendering/OpenGL/LearnOpenGL.com/003_Model_Loading/Assimp/","text":"Assimp Usually geometry is created by 3d artists in DCCs. The render programmer's job is to parse these exported model files and extract all the relevant information to store in a format that OpenGL understands. A common issue is that there are many file formats and each exports the model data in a different way. Wavefront objs are one of the most common but also limited 3d interchange formats. Of course we are also going to be long term interested in things like USD and Alembic. A very popular model import library is Assimp aka Open Asset Import Library . It has support for a ton of different model file formats. Once Assimp has loaded the model, we can retrieve the data from it in a common format. Assimp loads the entire model into a scene object that contains all the data of the imported model/scene. All the data is in a central root scene node This node may contain children nodes, and could have a set of indices that point to mesh data. All meshes are stored in the scene(root) mMeshes array. Mesh objects themselves contain all the relevant data for rendering: vertex positions, normal vectors, texture coordinates, faces, and materials. Each mesh contains one or more faces. A Face is a render primitive of the object (triangles, squares, points). The face holds references to the indices of the vertices for that primitive. This makes it easier for us to render via an index buffer. The material on a mesh hosts severl function to retrieve the properties of an object's material. Colors, texture maps, etc. Even though artists format data in a variety of different meshes, the rendering pipeline doesn't care about this. We take all the meshes and combine them into a single Model object. I'm on arch so I just built assimp using the AUR. :P","title":"Assimp"},{"location":"rendering/OpenGL/LearnOpenGL.com/003_Model_Loading/Assimp/#assimp","text":"Usually geometry is created by 3d artists in DCCs. The render programmer's job is to parse these exported model files and extract all the relevant information to store in a format that OpenGL understands. A common issue is that there are many file formats and each exports the model data in a different way. Wavefront objs are one of the most common but also limited 3d interchange formats. Of course we are also going to be long term interested in things like USD and Alembic. A very popular model import library is Assimp aka Open Asset Import Library . It has support for a ton of different model file formats. Once Assimp has loaded the model, we can retrieve the data from it in a common format. Assimp loads the entire model into a scene object that contains all the data of the imported model/scene. All the data is in a central root scene node This node may contain children nodes, and could have a set of indices that point to mesh data. All meshes are stored in the scene(root) mMeshes array. Mesh objects themselves contain all the relevant data for rendering: vertex positions, normal vectors, texture coordinates, faces, and materials. Each mesh contains one or more faces. A Face is a render primitive of the object (triangles, squares, points). The face holds references to the indices of the vertices for that primitive. This makes it easier for us to render via an index buffer. The material on a mesh hosts severl function to retrieve the properties of an object's material. Colors, texture maps, etc. Even though artists format data in a variety of different meshes, the rendering pipeline doesn't care about this. We take all the meshes and combine them into a single Model object. I'm on arch so I just built assimp using the AUR. :P","title":"Assimp"},{"location":"rendering/OpenGL/LearnOpenGL.com/003_Model_Loading/Mesh/","text":"Mesh Before loading our models it's helpful to create a mesh class. This will help to transform the data into a format that OpenGl understands so that we can render the objects. A mesh should at minimum have a vertex array, where each vertex contains a position vector, normal vector, and texture coordinate vector. It should also contain indices for drawing, and material data in the form of textures. Instead of making a vertex class, we have made a vertex struct. The advantage of this is that the data is sequenctial, and we can use offsetof to get the position of each variable in the struct. glVertexAttribPointer ( 1 , 3 , GL_FLOAT , GL_FALSE , sizeof ( Vertex ), ( void * ) offsetof ( Vertex , Normal )); Model Assimp gives you a pointer to a scene object. Assimp :: Importer importer ; const aiScene * scene = importer . ReadFile ( path , aiProcess_Triangulate | aiProcess_FlipUVs ); Here we are first declaring an importer object and then calling it's ReadFile function. To that function we are adding some post-processing flags to specify how we want to load it. Triangulate tells Assimp to convert the model to triangles, and FlipUvs tells it to flip the texture coordinates. There are some other interesting ones aiProcess_GenNormals : creates normal vectors for each vertex if the model doesn't have any aiProcess_SplitLargeMeshes: auto-splits large meshes into smaller sub-meshes which is great if your rendering has a limited amount of vertices aiProcess_OptimizeMeshes: does the reverse by joining meshes together We now load all the data from Assimp void Model::Draw ( ShaderProgram & shader ) const { for ( Mesh mesh : m_meshes ){ mesh . draw ( shader ); } } void Model::loadModel ( std :: string_view path ){ Assimp :: Importer importer ; const aiScene * scene = importer . ReadFile ( path . data (), aiProcess_Triangulate | aiProcess_FlipUVs ); // check to see if scene data might be incomplete if ( ! scene || scene -> mFlags & AI_SCENE_FLAGS_INCOMPLETE || ! scene -> mRootNode ){ std :: cout << \"ERROR::ASSIMP::\" << importer . GetErrorString () << '\\n' ; return ; }; m_directory = path . substr ( 0 , path . find_last_of ( '/' )); // this will recursively build a mesh out of all the scene node's meshes processNode ( scene -> mRootNode , scene ); } void Model::processNode ( aiNode * node , const aiScene * scene ){ // process all of the nodes meshes for ( unsigned int i { 0 }; i < node -> mNumMeshes ; ++ i ){ aiMesh * mesh = scene -> mMeshes [ node -> mMeshes [ i ]]; m_meshes . push_back ( processMesh ( mesh , scene )); } // recursvly iterate over all child nodes for ( unsigned int i { 0 }; i < node -> mNumChildren ; ++ i ){ processNode ( node -> mChildren [ i ], scene ); } } You could also loop over only the scene's meshes, but that would forgo parent-child relationships. This will make it easier to keep the transformations correct. We aren't doing that right now, but it's a good habit to loop over things this way. Now we just have to convert the aiMesh to our own mesh. Processing a mesh is a three part process: Retrieve vertex data Retrieve mesh indices Retrieve material data","title":"Mesh"},{"location":"rendering/OpenGL/LearnOpenGL.com/003_Model_Loading/Mesh/#mesh","text":"Before loading our models it's helpful to create a mesh class. This will help to transform the data into a format that OpenGl understands so that we can render the objects. A mesh should at minimum have a vertex array, where each vertex contains a position vector, normal vector, and texture coordinate vector. It should also contain indices for drawing, and material data in the form of textures. Instead of making a vertex class, we have made a vertex struct. The advantage of this is that the data is sequenctial, and we can use offsetof to get the position of each variable in the struct. glVertexAttribPointer ( 1 , 3 , GL_FLOAT , GL_FALSE , sizeof ( Vertex ), ( void * ) offsetof ( Vertex , Normal ));","title":"Mesh"},{"location":"rendering/OpenGL/LearnOpenGL.com/003_Model_Loading/Mesh/#model","text":"Assimp gives you a pointer to a scene object. Assimp :: Importer importer ; const aiScene * scene = importer . ReadFile ( path , aiProcess_Triangulate | aiProcess_FlipUVs ); Here we are first declaring an importer object and then calling it's ReadFile function. To that function we are adding some post-processing flags to specify how we want to load it. Triangulate tells Assimp to convert the model to triangles, and FlipUvs tells it to flip the texture coordinates. There are some other interesting ones aiProcess_GenNormals : creates normal vectors for each vertex if the model doesn't have any aiProcess_SplitLargeMeshes: auto-splits large meshes into smaller sub-meshes which is great if your rendering has a limited amount of vertices aiProcess_OptimizeMeshes: does the reverse by joining meshes together We now load all the data from Assimp void Model::Draw ( ShaderProgram & shader ) const { for ( Mesh mesh : m_meshes ){ mesh . draw ( shader ); } } void Model::loadModel ( std :: string_view path ){ Assimp :: Importer importer ; const aiScene * scene = importer . ReadFile ( path . data (), aiProcess_Triangulate | aiProcess_FlipUVs ); // check to see if scene data might be incomplete if ( ! scene || scene -> mFlags & AI_SCENE_FLAGS_INCOMPLETE || ! scene -> mRootNode ){ std :: cout << \"ERROR::ASSIMP::\" << importer . GetErrorString () << '\\n' ; return ; }; m_directory = path . substr ( 0 , path . find_last_of ( '/' )); // this will recursively build a mesh out of all the scene node's meshes processNode ( scene -> mRootNode , scene ); } void Model::processNode ( aiNode * node , const aiScene * scene ){ // process all of the nodes meshes for ( unsigned int i { 0 }; i < node -> mNumMeshes ; ++ i ){ aiMesh * mesh = scene -> mMeshes [ node -> mMeshes [ i ]]; m_meshes . push_back ( processMesh ( mesh , scene )); } // recursvly iterate over all child nodes for ( unsigned int i { 0 }; i < node -> mNumChildren ; ++ i ){ processNode ( node -> mChildren [ i ], scene ); } } You could also loop over only the scene's meshes, but that would forgo parent-child relationships. This will make it easier to keep the transformations correct. We aren't doing that right now, but it's a good habit to loop over things this way. Now we just have to convert the aiMesh to our own mesh. Processing a mesh is a three part process: Retrieve vertex data Retrieve mesh indices Retrieve material data","title":"Model"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/001_Depth_testing/","text":"Depth testing We've already made use of the depth buffer (or zbuffer) to prevent triangles rendering in front of each other. This is made possible because it stores depth values to determine where in zspace particles are. Just like the color buffer which stores all the fragment colors, the depth buffer sotores information per fragment (pixel). It's automatically created by the windowing systems and stores depth values as 16, 24, or 32 bit floats (usually 24). Depth testing is performed in screen spacer after the fragement shader has run. The coordinates relate directly to the viewport defined by OpenGl's glViewport function and can be accessed with gl_FragCoord variables in the fragement shader. The x and y represent the fagement's screen-space (0, 0 at bottom left corner), and the z represents the depth value of the fragment. Note Modern Gpus have early depth testing . This allows the depth test to run before the fragment shader runs. This allows deth culling for fragments behind other fragments. The restriction of using early depth testing is that you can no longer write to the fragment's depth value. Depth testing is enabled like so: glEnable ( GL_DEPTH_TEST ); Once this is enabled, fragments automatically store their z-values in the depth buffer, and are discarded if they fail accordingly. If you have depth testing enabled you should clear the buffer each frame: glClear ( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT ); Sometimes you might want to perform the depth test on all fragments and discard them accordingly but not update the depth buffer. Basically useing a read-only depth buffer. You can disable writing to the depth buffer with glDepthMask ( GL_FALSE ); Depth test function glDepthFunc ( GL_LESS ); The above function works with the folowing operators: Function Description GL_ALWAYS The depth test always passes GL_NEVER The depth test never passes GL_LESS (default) The depth test passes if the value is less than stored depth GL_EQUAL The depth test passes if the value is equal than stored depth GL_LEQUAL The depth test passes if the value is less than or equal than stored depth GL_GREATER The depth test passes if the value is greater than stored depth GL_GEQAUL The depth test passes if the value is greater than stored depth or equal GL_NOTGREATER The depth test passes if the value not equal to the stored depth value GL_ALWAYS is pretty much the same as not enabling GL_DEPTH_TEST at all. Depth value precision Depth values are stored in the depth buffer between 0.0 and 1.0. These map to the near and far plane of the projection matrix. They are transformed with a following linear equation: \\[ F_{depth} = \\frac{ z - {near} }{ {far} - {near } \\] In practice this linear depth buffer is almost never used. Because of projection properties a non-linear equation is used that is porportional to 1/z \\[ F_{depth} = \\frac{ 1/z - 1/{near} }{ 1/{far} - 1/{near} } \\] The nonlinearity of the depth buffer quickly become apparent when we visualize it. We can visualize the depth buffer by outputting it from the frag shader like so: FragColor = vec4 ( vec3 ( gl_FragCoord . z ), 1.0 ); Running this will make everything look close to white. Because it is nonlinear, everything is nearly white. If you get really close to an object then you notice it getting a little darker. To transform the depth buffer back to linear space we can do the following in the shader: #version 330 core out vec4 FragColor ; float near = 0.1 ; float far = 100.0 ; float LinearizeDepth ( float depth ) { float z = depth * 2.0 - 1.0 ; // back to NDC return ( 2.0 * near * far ) / ( far + near - z * ( far - near )); } void main () { float depth = LinearizeDepth ( gl_FragCoord . z ) / far ; // divide by far for demonstration FragColor = vec4 ( vec3 ( depth ), 1.0 ); } Z-fighting If two planes or triangles are so closely aligned that the depth buffer does not have enough precision to figure out which ones to draw on top. Really the best way to prevent this is to never place objects too close to each other. Another trick is to set the near plane as far as possible. This can add to the precision that is available. Otherwise you can use a hight precision depth buffer.","title":"Depth testing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/001_Depth_testing/#depth-testing","text":"We've already made use of the depth buffer (or zbuffer) to prevent triangles rendering in front of each other. This is made possible because it stores depth values to determine where in zspace particles are. Just like the color buffer which stores all the fragment colors, the depth buffer sotores information per fragment (pixel). It's automatically created by the windowing systems and stores depth values as 16, 24, or 32 bit floats (usually 24). Depth testing is performed in screen spacer after the fragement shader has run. The coordinates relate directly to the viewport defined by OpenGl's glViewport function and can be accessed with gl_FragCoord variables in the fragement shader. The x and y represent the fagement's screen-space (0, 0 at bottom left corner), and the z represents the depth value of the fragment. Note Modern Gpus have early depth testing . This allows the depth test to run before the fragment shader runs. This allows deth culling for fragments behind other fragments. The restriction of using early depth testing is that you can no longer write to the fragment's depth value. Depth testing is enabled like so: glEnable ( GL_DEPTH_TEST ); Once this is enabled, fragments automatically store their z-values in the depth buffer, and are discarded if they fail accordingly. If you have depth testing enabled you should clear the buffer each frame: glClear ( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT ); Sometimes you might want to perform the depth test on all fragments and discard them accordingly but not update the depth buffer. Basically useing a read-only depth buffer. You can disable writing to the depth buffer with glDepthMask ( GL_FALSE );","title":"Depth testing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/001_Depth_testing/#depth-test-function","text":"glDepthFunc ( GL_LESS ); The above function works with the folowing operators: Function Description GL_ALWAYS The depth test always passes GL_NEVER The depth test never passes GL_LESS (default) The depth test passes if the value is less than stored depth GL_EQUAL The depth test passes if the value is equal than stored depth GL_LEQUAL The depth test passes if the value is less than or equal than stored depth GL_GREATER The depth test passes if the value is greater than stored depth GL_GEQAUL The depth test passes if the value is greater than stored depth or equal GL_NOTGREATER The depth test passes if the value not equal to the stored depth value GL_ALWAYS is pretty much the same as not enabling GL_DEPTH_TEST at all.","title":"Depth test function"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/001_Depth_testing/#depth-value-precision","text":"Depth values are stored in the depth buffer between 0.0 and 1.0. These map to the near and far plane of the projection matrix. They are transformed with a following linear equation: \\[ F_{depth} = \\frac{ z - {near} }{ {far} - {near } \\] In practice this linear depth buffer is almost never used. Because of projection properties a non-linear equation is used that is porportional to 1/z \\[ F_{depth} = \\frac{ 1/z - 1/{near} }{ 1/{far} - 1/{near} } \\] The nonlinearity of the depth buffer quickly become apparent when we visualize it. We can visualize the depth buffer by outputting it from the frag shader like so: FragColor = vec4 ( vec3 ( gl_FragCoord . z ), 1.0 ); Running this will make everything look close to white. Because it is nonlinear, everything is nearly white. If you get really close to an object then you notice it getting a little darker. To transform the depth buffer back to linear space we can do the following in the shader: #version 330 core out vec4 FragColor ; float near = 0.1 ; float far = 100.0 ; float LinearizeDepth ( float depth ) { float z = depth * 2.0 - 1.0 ; // back to NDC return ( 2.0 * near * far ) / ( far + near - z * ( far - near )); } void main () { float depth = LinearizeDepth ( gl_FragCoord . z ) / far ; // divide by far for demonstration FragColor = vec4 ( vec3 ( depth ), 1.0 ); }","title":"Depth value precision"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/001_Depth_testing/#z-fighting","text":"If two planes or triangles are so closely aligned that the depth buffer does not have enough precision to figure out which ones to draw on top. Really the best way to prevent this is to never place objects too close to each other. Another trick is to set the near plane as far as possible. This can add to the precision that is available. Otherwise you can use a hight precision depth buffer.","title":"Z-fighting"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/002_Stencil_testing/","text":"Stencil testing Once a fragement is processed, a stencil test is executed that has the option to discard fragments. This is based on the contents of the stencil buffer , which we can update during rendering to achieve cool effects. Each stencil value is an 8 bit value, and there are a total of 256 possible stencil valuse per pixel. We can set these values, and then filter for each one discarding other values. Note Each windowing library needs to set up the stencil buffer - this does not always happen automatically like with the depth buffer. GLFW does this automatically though. The stencil buffer is first cleared which sets every fragment to 0. Then an open rectangle of 1s is stored, and only these fragements are rendered. The others are discareded. These stencil buffer operations allow us to set specific values while rendering fragements. This way we can discard certain fragments based on the fragments of other drawn objects in the scene. Enable writing to the stencil buffer. Render objects, updating the content Disable writing to the stencil buffer Render (other) objects, but only the parts that we want to as determined by the stencil buffer. To enable the stencil buffer you use GL_STENCIL_TEST glEnable ( GL_STENCIL_TEST ); // don't forget to add the stencil buffer to the clear call glClear ( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BTI ); To enable/disable writing you set custom bitmasks. Usually you will only need two glStencilMask ( 0xFF ); // each bit is written to the stencil buffer as is glStencilMask ( 0x00 ); // each bit ends up as 0 in the stencil buffer (disabling writes) Similar to depth testing, there are several options about how to pass or fail the fragments for the stencil buffer. These are set with the following two functions glStencilFunc (GLenum func, GLint ref, GLuint mask) func set the test function of whether a frag passes or is disables. It has the same flags as mentioned in the depth chapter. ref specifies the value a bit should hold for the test. mask specifies the target bit So for the example in the image at the top it would be glStencilFunc ( GL_EQUAL , 1 , 0xFF ); This only tell open gl if it should pass or discard frags based on the content, not how to actually update the buffer. glStencilOp (GLenum sfail, GLenum dpfail, GLenumdppass) sfail action to take if test fails dpfail action to take if test passes, but depth test fails dppass action to take if both pass These are the possible action enums Action Description GL_KEEP The currently stored stencil value is kept GL_ZERO The stencil value is set to 0 GL_REPLACE The stencil value is replaced with the value set with glStencilFunc GL_INCR The stencil value is increased by 1 if it is lower than the maximum value of 256 GL_INCR_WRAP The stencil value is increased but is reset to 0 if at the limit GL_DECR The stencil value is decreased unless it's 0 GL_DECR_WRAP The stencil value is decreased and if it is 0 it become 256 GL_INVERT Bitwise inverts the current stencil buffer value The defaults of glStencilOp are (GL_KEEP, GL_KEEP, GL_KEEP) so whatever the outcome, the stencil buffer is uneffected. If you want to write to the stencil buffer it needs to be an active decision. Object outlining One common practical application for the stencil buffer is object outlining. The steps are as follows: Enable stencil writing Set the stencil op to GL_ALWAYS before drawing the objects to be outlined, updating the buffer with 1s wherever the object's fragments are rendered. Render the objects. Disable stencil writing and depth testing Scale each of the objects by a small amount. Use a different fragment shader that outputs a solid color Draw the objects again, but only if the fragments' stencil values are not equal to 1 Enable depth testing again and restore stencil to GL_KEEP","title":"Stencil testing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/002_Stencil_testing/#stencil-testing","text":"Once a fragement is processed, a stencil test is executed that has the option to discard fragments. This is based on the contents of the stencil buffer , which we can update during rendering to achieve cool effects. Each stencil value is an 8 bit value, and there are a total of 256 possible stencil valuse per pixel. We can set these values, and then filter for each one discarding other values. Note Each windowing library needs to set up the stencil buffer - this does not always happen automatically like with the depth buffer. GLFW does this automatically though. The stencil buffer is first cleared which sets every fragment to 0. Then an open rectangle of 1s is stored, and only these fragements are rendered. The others are discareded. These stencil buffer operations allow us to set specific values while rendering fragements. This way we can discard certain fragments based on the fragments of other drawn objects in the scene. Enable writing to the stencil buffer. Render objects, updating the content Disable writing to the stencil buffer Render (other) objects, but only the parts that we want to as determined by the stencil buffer. To enable the stencil buffer you use GL_STENCIL_TEST glEnable ( GL_STENCIL_TEST ); // don't forget to add the stencil buffer to the clear call glClear ( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BTI ); To enable/disable writing you set custom bitmasks. Usually you will only need two glStencilMask ( 0xFF ); // each bit is written to the stencil buffer as is glStencilMask ( 0x00 ); // each bit ends up as 0 in the stencil buffer (disabling writes) Similar to depth testing, there are several options about how to pass or fail the fragments for the stencil buffer. These are set with the following two functions glStencilFunc (GLenum func, GLint ref, GLuint mask) func set the test function of whether a frag passes or is disables. It has the same flags as mentioned in the depth chapter. ref specifies the value a bit should hold for the test. mask specifies the target bit So for the example in the image at the top it would be glStencilFunc ( GL_EQUAL , 1 , 0xFF ); This only tell open gl if it should pass or discard frags based on the content, not how to actually update the buffer. glStencilOp (GLenum sfail, GLenum dpfail, GLenumdppass) sfail action to take if test fails dpfail action to take if test passes, but depth test fails dppass action to take if both pass These are the possible action enums Action Description GL_KEEP The currently stored stencil value is kept GL_ZERO The stencil value is set to 0 GL_REPLACE The stencil value is replaced with the value set with glStencilFunc GL_INCR The stencil value is increased by 1 if it is lower than the maximum value of 256 GL_INCR_WRAP The stencil value is increased but is reset to 0 if at the limit GL_DECR The stencil value is decreased unless it's 0 GL_DECR_WRAP The stencil value is decreased and if it is 0 it become 256 GL_INVERT Bitwise inverts the current stencil buffer value The defaults of glStencilOp are (GL_KEEP, GL_KEEP, GL_KEEP) so whatever the outcome, the stencil buffer is uneffected. If you want to write to the stencil buffer it needs to be an active decision.","title":"Stencil testing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/002_Stencil_testing/#object-outlining","text":"One common practical application for the stencil buffer is object outlining. The steps are as follows: Enable stencil writing Set the stencil op to GL_ALWAYS before drawing the objects to be outlined, updating the buffer with 1s wherever the object's fragments are rendered. Render the objects. Disable stencil writing and depth testing Scale each of the objects by a small amount. Use a different fragment shader that outputs a solid color Draw the objects again, but only if the fragments' stencil values are not equal to 1 Enable depth testing again and restore stencil to GL_KEEP","title":"Object outlining"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/003_Blending/","text":"Blending Blending in OpenGL is most well known for being used to implement transparency within objects. Transparency blends object with object behind them, and you blend the fragments together. The amount of transparency is defined by its color's alpha value. This is the fourth component of the color vector that we've seen quite a bit so far. Discarding Fragments A very cheap and easy way to add transparency is to simply discard fragments that are not a certain alpha. This is commonly known as \"cutout\" transparency. Grass is a good example for this. When adding vegetation to a scene, we don't want to see a square image of grass, but the actual grass. What we want is to discard the fragments that show the transparent parts of the texture, and to not store those in the color buffer. You do this in the shader with a special keyword: vec4 texColor = texture ( texture1 , TexCoords ); if ( texColor . a < 0.1 ) discard ; FragColor = texColor ; Note Because textures wrap by default if you have any mipmapping the top of the textuer could wrap to the bottom which looks bad when repeating. Remember you can turn off repeating with glTexParameteri Blending To enable rendering images with different levels of transparency, we need to enable blending glEnable ( GL_BLEND ); Blending in OpenGL happens with the following equation: \\[ C_{screen} = C_{source} * F_{source} + C_{destination} * F_{destination} \\] After the fragment shader has run and all the tests have passed, this blend equation operates on the final color. The way the colors are blended is determined by the glBlendFunc. This function takes two parameters that set the source factor and destination factor respectively. These are some of the most common options: // The first factor is how the source is alpha-ed // the second is how the color in the buffer is alphad. glBlendFunc ( GLenum sfactor , GLenum dfactor ) Option Value GL_ZERO Factor is 0 GL_ONE Factor is 1 GL_SRC_COLOR Factor is equal to the source color vector \\(C_{source}\\) GL_ONE_MINUS_SRC_COLOR Factor is equal to 1 - source color \\(1 - C_{source}\\) GL_DST_COLOR Factor is equal to the destination color \\(C_{destination}\\) GL_ONE_MINUS_DST_COLOR \\(1 - C_{destination}.rgb\\) GL_SRC_ALPHA Factor is equal to the source alpha value GL_ONE_MINUS_SRC_ALPHA \\(1 - C_{source}.a\\) GL_DST_ALPHA Factor is equal to the destination alpha value GL_ONE_MINUS_DST_ALPHA \\(1 - C_{destination}.a\\) For our two square example, we want the alpha of the source color for the source factor and 1 - alpha for the destination color. glBlendFunc ( GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA ); // this does the same as above glBlendFuncSeperate ( GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA , GL_ONE , GL_ZERO ); You can go further and also set the operator for how the color should be factored together: Option Value GL_FUNC_ADD (default) add both colors to each other GL_FUNC_SUBTRACT subtract both colors from each other SRC - DST GL_FUNC_REVERSE_SUBTRACT subtracts the other way DST - SRC GL_MIN takes the component-wise minimum of both colors GL_MAX takes the component-wise maximum of both colors Usually we can skip setting this because we will be using GL_FUNC_ADD in most situations. Adding transparency to our scene works, but the depth buffer is messing stuff up. This is because even though the transparent part should show the windows behind it, the depth test discards that. This is where the depth buffer will not magically fix everything. To fix this we need to draw object in order from farthest to closest. A simple way to do this is to measure the distance of objects from the viewer's perspective. We can store this in a map data structure from the std lib. I sorted the position vector like this: std :: sort ( vegetation . begin (), vegetation . end (), [ & ]( glm :: vec3 p1 , glm :: vec3 p2 ){ return glm :: distance ( cam . getPos (), p1 ) > glm :: distance ( cam . getPos () , p2 ); }); Not foolproof by any means, sorting is also expensive. There are more advance transparency techniques that tackle this like order indpendent transparency .","title":"Blending"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/003_Blending/#blending","text":"Blending in OpenGL is most well known for being used to implement transparency within objects. Transparency blends object with object behind them, and you blend the fragments together. The amount of transparency is defined by its color's alpha value. This is the fourth component of the color vector that we've seen quite a bit so far.","title":"Blending"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/003_Blending/#discarding-fragments","text":"A very cheap and easy way to add transparency is to simply discard fragments that are not a certain alpha. This is commonly known as \"cutout\" transparency. Grass is a good example for this. When adding vegetation to a scene, we don't want to see a square image of grass, but the actual grass. What we want is to discard the fragments that show the transparent parts of the texture, and to not store those in the color buffer. You do this in the shader with a special keyword: vec4 texColor = texture ( texture1 , TexCoords ); if ( texColor . a < 0.1 ) discard ; FragColor = texColor ; Note Because textures wrap by default if you have any mipmapping the top of the textuer could wrap to the bottom which looks bad when repeating. Remember you can turn off repeating with glTexParameteri","title":"Discarding Fragments"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/003_Blending/#blending_1","text":"To enable rendering images with different levels of transparency, we need to enable blending glEnable ( GL_BLEND ); Blending in OpenGL happens with the following equation: \\[ C_{screen} = C_{source} * F_{source} + C_{destination} * F_{destination} \\] After the fragment shader has run and all the tests have passed, this blend equation operates on the final color. The way the colors are blended is determined by the glBlendFunc. This function takes two parameters that set the source factor and destination factor respectively. These are some of the most common options: // The first factor is how the source is alpha-ed // the second is how the color in the buffer is alphad. glBlendFunc ( GLenum sfactor , GLenum dfactor ) Option Value GL_ZERO Factor is 0 GL_ONE Factor is 1 GL_SRC_COLOR Factor is equal to the source color vector \\(C_{source}\\) GL_ONE_MINUS_SRC_COLOR Factor is equal to 1 - source color \\(1 - C_{source}\\) GL_DST_COLOR Factor is equal to the destination color \\(C_{destination}\\) GL_ONE_MINUS_DST_COLOR \\(1 - C_{destination}.rgb\\) GL_SRC_ALPHA Factor is equal to the source alpha value GL_ONE_MINUS_SRC_ALPHA \\(1 - C_{source}.a\\) GL_DST_ALPHA Factor is equal to the destination alpha value GL_ONE_MINUS_DST_ALPHA \\(1 - C_{destination}.a\\) For our two square example, we want the alpha of the source color for the source factor and 1 - alpha for the destination color. glBlendFunc ( GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA ); // this does the same as above glBlendFuncSeperate ( GL_SRC_ALPHA , GL_ONE_MINUS_SRC_ALPHA , GL_ONE , GL_ZERO ); You can go further and also set the operator for how the color should be factored together: Option Value GL_FUNC_ADD (default) add both colors to each other GL_FUNC_SUBTRACT subtract both colors from each other SRC - DST GL_FUNC_REVERSE_SUBTRACT subtracts the other way DST - SRC GL_MIN takes the component-wise minimum of both colors GL_MAX takes the component-wise maximum of both colors Usually we can skip setting this because we will be using GL_FUNC_ADD in most situations. Adding transparency to our scene works, but the depth buffer is messing stuff up. This is because even though the transparent part should show the windows behind it, the depth test discards that. This is where the depth buffer will not magically fix everything. To fix this we need to draw object in order from farthest to closest. A simple way to do this is to measure the distance of objects from the viewer's perspective. We can store this in a map data structure from the std lib. I sorted the position vector like this: std :: sort ( vegetation . begin (), vegetation . end (), [ & ]( glm :: vec3 p1 , glm :: vec3 p2 ){ return glm :: distance ( cam . getPos (), p1 ) > glm :: distance ( cam . getPos () , p2 ); }); Not foolproof by any means, sorting is also expensive. There are more advance transparency techniques that tackle this like order indpendent transparency .","title":"Blending"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/","text":"Framebuffers So far we've used several types of screen buffers: color, depth, and stencil. The combination of these buffers is stored in GPU memory in a framebuffer . In OpenGL we can define our own framebuffers. unsigned int FBO ; glGenFramebuffers ( 1 , & FBO ); glBindFramebuffer ( GL_FRAMEBUFFER , FBO ); glDeleteFramebuffers ( 1 , & FB0 ); By binding to GL_FRAMEBUFFER all upcoming read and write framebuffer operations will be performed on the newly bound framebuffer. You can also just bind a read/write framebuffer with GL_READ_FRAMEBUFFER or GL_DRAW_FRAMEBUFFER respectively. The read framebuffer will be used for all read operations like glReadPixels and all rendering is done to the draw framebuffer. We cannot yet use the above framebuffer because it is not yet complete. The following list is the requirements for a complete framebuffer. We have to attach at least one buffer there should be at least one color attachment All attachments should be complete with memory reserved Each buffer should have the same number of samples To check if the framebuffer is complete: if ( glCheckFramebufferStatus ( GL_FRAMEBUFFER ) == GL_FRAMEBUFFER_COMPLETE ) // execute victory dance So we need to create some sort of attachments to the buffer. Texture attachments If you attach a texture to a framebuffer, all rendering commands will write out to the texture as if it was a normal color/depth/stencil buffer. This way we can then easily re-use that color information in our shaders. // create a texture for the framebuffer to write to unsigned int tex; glGenTextures(1, &tex); glBindTexture(GL_TEXTURE_2D, tex); // allocate memory for the texture to be written to // the main difference to a regular texture is that we assign null values // we also don't care about wrapping or mipmapping methods in this case glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); // attach the texture to the framebuffer // args: // target: the target we are writing to (draw, read or both) // attachemtn: the type of attachment // textarget: the type of textuer to attach // texture: the texture to attach // level: the level of mipmapping glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, tex, 0); Note If you want to render the whole screen to a textuer of a different size you need to call glViewport each time before rendering to your framebuffer with the new dimensions of your texture. Now we also need to create a depth and stencil texture to the framebuffer object. You can make individual attachments for each, or you can combine them into a single 32 bit texture // now we need to create textures for the depth and stencil as well // we can combine them into a single texture // the first 24 bits will be depth, the last 8 stencil glTexture2D( ) glTexImage2D ( GL_TEXTURE_2D , 0 , GL_DEPTH24_STENCIL8 , 800 , 600 , 0 , GL_DEPTH_STENCIL , GL_UNSIGNED_INT_24_8 , NULL ); glFramebufferTexture2D ( GL_FRAMEBUFFER , GL_DEPTH_STENCIL_ATTACHMENT , GL_TEXTURE_2D , tex , 0 ); Renderbuffer object attachments Just like you can attach textures, you can also attach renderbuffer objects . This is an actual buffer (an array of bytes, integers, pixels etc), but you can't read from this one directly. This makes them faster than textures, because there are some optimizations that OpenGL can make. You can only read from them with the slow glReadPixels. Use render buffers if you never need to sample data from a specific buffer, otherwise use textures. It's constructed very similarly to the texture unsigned int rbo ; glGenRenderbuffers ( 1 , & rbo ); glBindRenderbuffer ( GL_RENDERBUFFER , rbo ); glRenderbufferStorage ( GL_RENDERBUFFER , GL_DEPTH24_STENCIL8 , 800 , 600 ); glBindRenderbuffer ( GL_RENDERBUFFER , 0 ); // attach the renderbuffer to the depth and stencil glFramebufferRenderbuffer ( GL_FRAMEBUFFER , GL_DEPTH_STENCIL_ATTACHMENT , GL_RENDERBUFFER , rbo ); Rendering to a texture Render the scene as usual with the new framebuffer bound as active Bind to default framebuffer Draw a quad that spans the entire screen with the new framebuffers' color buffer as its texture. Note You can put this texture on any object. For example you can render reflections like this. Post-processing Now that we have all pixels on a texture we can start implementing a compositing pipeline. The effects of this pipeline are called post-processing since they are happening after the 3d objects have been rasterized. A quick trick is to invert all the colors: FragColor = vec4 ( vec3 ( 1.0 - texture ( screenTexture , TexCoords )), 1.0 ); (There are more examples in the source shader) Kernel effects A kernel is a small matrix-like array of values centered on the current pixel that multiplies surrounding pixel values by the kernel values and add them all together to form a single value. Comp kernels usually sum up to 1 if you add all the weights together. If not they will change the luminocity of the image. Because everything is now a texture we are simply sampling the image at different uv coordinates. const float offset = 1.0 / 300.0 ; void main () { vec2 offsets [ 9 ] = vec2 []( vec2 ( - offset , offset ), // top-left vec2 ( 0.0 f , offset ), // top-center vec2 ( offset , offset ), // top-right vec2 ( - offset , 0.0 f ), // center-left vec2 ( 0.0 f , 0.0 f ), // center-center vec2 ( offset , 0.0 f ), // center-right vec2 ( - offset , - offset ), // bottom-left vec2 ( 0.0 f , - offset ), // bottom-center vec2 ( offset , - offset ) // bottom-right ); float kernel [ 9 ] = float []( - 1 , - 1 , - 1 , - 1 , 9 , - 1 , - 1 , - 1 , - 1 ); vec3 sampleTex [ 9 ]; for ( int i = 0 ; i < 9 ; i ++ ) { sampleTex [ i ] = vec3 ( texture ( screenTexture , TexCoords . st + offsets [ i ])); } vec3 col = vec3 ( 0.0 ); for ( int i = 0 ; i < 9 ; i ++ ) col += sampleTex [ i ] * kernel [ i ]; FragColor = vec4 ( col , 1.0 ); } There are many interesting kernals out there!","title":"Framebuffers"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/#framebuffers","text":"So far we've used several types of screen buffers: color, depth, and stencil. The combination of these buffers is stored in GPU memory in a framebuffer . In OpenGL we can define our own framebuffers. unsigned int FBO ; glGenFramebuffers ( 1 , & FBO ); glBindFramebuffer ( GL_FRAMEBUFFER , FBO ); glDeleteFramebuffers ( 1 , & FB0 ); By binding to GL_FRAMEBUFFER all upcoming read and write framebuffer operations will be performed on the newly bound framebuffer. You can also just bind a read/write framebuffer with GL_READ_FRAMEBUFFER or GL_DRAW_FRAMEBUFFER respectively. The read framebuffer will be used for all read operations like glReadPixels and all rendering is done to the draw framebuffer. We cannot yet use the above framebuffer because it is not yet complete. The following list is the requirements for a complete framebuffer. We have to attach at least one buffer there should be at least one color attachment All attachments should be complete with memory reserved Each buffer should have the same number of samples To check if the framebuffer is complete: if ( glCheckFramebufferStatus ( GL_FRAMEBUFFER ) == GL_FRAMEBUFFER_COMPLETE ) // execute victory dance So we need to create some sort of attachments to the buffer.","title":"Framebuffers"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/#texture-attachments","text":"If you attach a texture to a framebuffer, all rendering commands will write out to the texture as if it was a normal color/depth/stencil buffer. This way we can then easily re-use that color information in our shaders. // create a texture for the framebuffer to write to unsigned int tex; glGenTextures(1, &tex); glBindTexture(GL_TEXTURE_2D, tex); // allocate memory for the texture to be written to // the main difference to a regular texture is that we assign null values // we also don't care about wrapping or mipmapping methods in this case glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); // attach the texture to the framebuffer // args: // target: the target we are writing to (draw, read or both) // attachemtn: the type of attachment // textarget: the type of textuer to attach // texture: the texture to attach // level: the level of mipmapping glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, tex, 0); Note If you want to render the whole screen to a textuer of a different size you need to call glViewport each time before rendering to your framebuffer with the new dimensions of your texture. Now we also need to create a depth and stencil texture to the framebuffer object. You can make individual attachments for each, or you can combine them into a single 32 bit texture // now we need to create textures for the depth and stencil as well // we can combine them into a single texture // the first 24 bits will be depth, the last 8 stencil glTexture2D( ) glTexImage2D ( GL_TEXTURE_2D , 0 , GL_DEPTH24_STENCIL8 , 800 , 600 , 0 , GL_DEPTH_STENCIL , GL_UNSIGNED_INT_24_8 , NULL ); glFramebufferTexture2D ( GL_FRAMEBUFFER , GL_DEPTH_STENCIL_ATTACHMENT , GL_TEXTURE_2D , tex , 0 );","title":"Texture attachments"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/#renderbuffer-object-attachments","text":"Just like you can attach textures, you can also attach renderbuffer objects . This is an actual buffer (an array of bytes, integers, pixels etc), but you can't read from this one directly. This makes them faster than textures, because there are some optimizations that OpenGL can make. You can only read from them with the slow glReadPixels. Use render buffers if you never need to sample data from a specific buffer, otherwise use textures. It's constructed very similarly to the texture unsigned int rbo ; glGenRenderbuffers ( 1 , & rbo ); glBindRenderbuffer ( GL_RENDERBUFFER , rbo ); glRenderbufferStorage ( GL_RENDERBUFFER , GL_DEPTH24_STENCIL8 , 800 , 600 ); glBindRenderbuffer ( GL_RENDERBUFFER , 0 ); // attach the renderbuffer to the depth and stencil glFramebufferRenderbuffer ( GL_FRAMEBUFFER , GL_DEPTH_STENCIL_ATTACHMENT , GL_RENDERBUFFER , rbo );","title":"Renderbuffer object attachments"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/#rendering-to-a-texture","text":"Render the scene as usual with the new framebuffer bound as active Bind to default framebuffer Draw a quad that spans the entire screen with the new framebuffers' color buffer as its texture. Note You can put this texture on any object. For example you can render reflections like this.","title":"Rendering to a texture"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/#post-processing","text":"Now that we have all pixels on a texture we can start implementing a compositing pipeline. The effects of this pipeline are called post-processing since they are happening after the 3d objects have been rasterized. A quick trick is to invert all the colors: FragColor = vec4 ( vec3 ( 1.0 - texture ( screenTexture , TexCoords )), 1.0 ); (There are more examples in the source shader)","title":"Post-processing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/004_Framebuffers/#kernel-effects","text":"A kernel is a small matrix-like array of values centered on the current pixel that multiplies surrounding pixel values by the kernel values and add them all together to form a single value. Comp kernels usually sum up to 1 if you add all the weights together. If not they will change the luminocity of the image. Because everything is now a texture we are simply sampling the image at different uv coordinates. const float offset = 1.0 / 300.0 ; void main () { vec2 offsets [ 9 ] = vec2 []( vec2 ( - offset , offset ), // top-left vec2 ( 0.0 f , offset ), // top-center vec2 ( offset , offset ), // top-right vec2 ( - offset , 0.0 f ), // center-left vec2 ( 0.0 f , 0.0 f ), // center-center vec2 ( offset , 0.0 f ), // center-right vec2 ( - offset , - offset ), // bottom-left vec2 ( 0.0 f , - offset ), // bottom-center vec2 ( offset , - offset ) // bottom-right ); float kernel [ 9 ] = float []( - 1 , - 1 , - 1 , - 1 , 9 , - 1 , - 1 , - 1 , - 1 ); vec3 sampleTex [ 9 ]; for ( int i = 0 ; i < 9 ; i ++ ) { sampleTex [ i ] = vec3 ( texture ( screenTexture , TexCoords . st + offsets [ i ])); } vec3 col = vec3 ( 0.0 ); for ( int i = 0 ; i < 9 ; i ++ ) col += sampleTex [ i ] * kernel [ i ]; FragColor = vec4 ( col , 1.0 ); } There are many interesting kernals out there!","title":"Kernel effects"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/005_Face_culling/","text":"Face culling If you are rendering a cube from any angle, the maximum amount of faces you will see is never going to be more than 3. Why are we wasting the effort of drawing those other 3 faces when we can't even see them? You can save more than 50% of fragment shader runs because sometimes you see even less than 3 sides. This is what face culling does. OpenGL checks all the faces that are front facing and renders those while discarding all faces that are back facing . It figures out which faces are front facing based on the winding order of the vertex data. The above triangle would translate like this into vertex data float vertices [] = { // clockwise vertices [ 0 ], // vertex 1 vertices [ 1 ], // vertex 2 vertices [ 2 ], // vertex 3 // counter-clockwise vertices [ 0 ], // vertex 1 vertices [ 2 ], // vertex 3 vertices [ 1 ] // vertex 2 }; Ever set of vertices that form a triangle implicitly contain a winding order. If the triangle is facing you, by default, the order is assumed to be counter-clockwise. Implementation Note that this only makes sense for closed shapes like cubes. glEnable ( GL_CULL_FACE ); // decide which frace to cull // options are GL_FRONT, GL_FRONT_AND_BACK glCullFace ( GL_FRONT ); // you can change the rotation // the other way is GL_CCW glFrontFace ( GL_CW );","title":"Face culling"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/005_Face_culling/#face-culling","text":"If you are rendering a cube from any angle, the maximum amount of faces you will see is never going to be more than 3. Why are we wasting the effort of drawing those other 3 faces when we can't even see them? You can save more than 50% of fragment shader runs because sometimes you see even less than 3 sides. This is what face culling does. OpenGL checks all the faces that are front facing and renders those while discarding all faces that are back facing . It figures out which faces are front facing based on the winding order of the vertex data. The above triangle would translate like this into vertex data float vertices [] = { // clockwise vertices [ 0 ], // vertex 1 vertices [ 1 ], // vertex 2 vertices [ 2 ], // vertex 3 // counter-clockwise vertices [ 0 ], // vertex 1 vertices [ 2 ], // vertex 3 vertices [ 1 ] // vertex 2 }; Ever set of vertices that form a triangle implicitly contain a winding order. If the triangle is facing you, by default, the order is assumed to be counter-clockwise.","title":"Face culling"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/005_Face_culling/#implementation","text":"Note that this only makes sense for closed shapes like cubes. glEnable ( GL_CULL_FACE ); // decide which frace to cull // options are GL_FRONT, GL_FRONT_AND_BACK glCullFace ( GL_FRONT ); // you can change the rotation // the other way is GL_CCW glFrontFace ( GL_CW );","title":"Implementation"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/","text":"Cubemaps One multi-texture texture is a cube map . this is an attempt at a 360 degree texture. It contains 6 individual 2d textures that each form one side of a textured cube. The advantage of a cubemap is that it can be indexed/sampled using a direction vector. The direction vector can be imagined as similar to the interpolated local vertex position of the cube. Creating a cube map The cubemap is created like any other texture, but instead of GL_TEXTURE_2D we use GL_TEXTURE_CUBE_MAP. The order of images is important: right left top bottom front back std :: vector < std :: string > SKYBOX_TEXTURES {{ \"textures/skybox/right.jpg\" , \"textures/skybox/left.jpg\" , \"textures/skybox/top.jpg\" , \"textures/skybox/bottom.jpg\" , \"textures/skybox/front.jpg\" , \"textures/skybox/back.jpg\" }}; // load cubemap // -------------- // cubemaps are loaded just like other textures unsigned int skyboxID ; glGenTextures ( 1 , & skyboxID ); glBindTexture ( GL_TEXTURE_CUBE_MAP , skyboxID ); // you need to load each image manually though int width , height , nrChannels ; unsigned char * data ; unsigned int count { 0 }; // load each side of the cube map for ( std :: string skyboxTexture : SKYBOX_TEXTURES ){ std :: string skyboxTexturePath = CWD + skyboxTexture ; data = stbi_load ( skyboxTexturePath . c_str (), & width , & height , & nrChannels , 0 ); glTexImage2D ( GL_TEXTURE_CUBE_MAP_POSITIVE_X + count , 0 , GL_RGB , width , height , 0 , GL_RGB , GL_UNSIGNED_BYTE , data ); ++ count ; } // specify wrapping and fitering methods glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_MAG_FILTER , GL_LINEAR ); glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_MIN_FILTER , GL_LINEAR ); glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_WRAP_S , GL_CLAMP_TO_EDGE ); glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_WRAP_T , GL_CLAMP_TO_EDGE ); // this is the textures wrapping method in the r coordinate (like z for positions) glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_WRAP_R , GL_CLAMP_TO_EDGE ); Unlike regular textures, you need to load an image into each channel. A skybox is a way to make the environment seem much bigger than it is. Cubemaps are usually used for skyboxes and reflections. Displaying the skybox You need to create a cube to sample from. The cube is get the view matrix of the camera, but always with the position at 0. What's interesting is that when you sample the color for the cube, it's from a 3d vector. GLSL converts the 3d vector into texture coordinates for the skybox. Note that if you render the whole skybox first, you are running the fragment shader for fragments that you don't need to. It's better render the skybox last, after the depth buffer has been filled, and only render it on the parts of the depth buffer that are 0.0. The problem is that because the skybox is not large, it will be drawn over all the other objects. We need to trick the depth buffer into thinking the skybox is drawn at 1.0 depth (the maximum). This is done in the vertex shader by setting the z value to it's w value, because the depth is derived by dividing the z by the w. That way we know it's maximum depth, and if we draw the skybox after everything else it will only draw where there is nothing else. Environment Mapping Now that we have a skybox, we can use this in our shaders using environment mapping for reflection and refractions *. Reflection In vfx Reflection samples from the currently loaded scene, but in GL it has to sample from something prebaked (or draw the entire scene again). With a cubemap you can get pretty good looking static reflections. Basically you get the reflection vector based on the interpolated normal and position, and then sample the cube map with it. #version 330 core out vec4 FragColor ; in vec3 Normal ; in vec3 Position ; uniform vec3 cameraPos ; uniform samplerCube skybox ; void main () { vec3 I = normalize ( Position - cameraPos ); vec3 R = reflect ( I , normalize ( Normal )); FragColor = vec4 ( texture ( skybox , R ). rgb , 1.0 ); } Refraction is similar, but like reflection of course it won't render the things behind it. You basically slightly bend the vector of the camera position. void main () { float ratio = 1.00 / 1.52 ; vec3 I = normalize ( Position - cameraPos ); vec3 R = refract ( I , normalize ( Normal ), ratio ); FragColor = vec4 ( texture ( skybox , R ). rgb , 1.0 ); } Dynamic Envinronment Maps While a static maps looks great, you can also generate these maps live based on a sample position and writing things to the frambuffer. This looks great but is very expensive, so the amount of samples is kept as low as possible.","title":"Cubemaps"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/#cubemaps","text":"One multi-texture texture is a cube map . this is an attempt at a 360 degree texture. It contains 6 individual 2d textures that each form one side of a textured cube. The advantage of a cubemap is that it can be indexed/sampled using a direction vector. The direction vector can be imagined as similar to the interpolated local vertex position of the cube.","title":"Cubemaps"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/#creating-a-cube-map","text":"The cubemap is created like any other texture, but instead of GL_TEXTURE_2D we use GL_TEXTURE_CUBE_MAP. The order of images is important: right left top bottom front back std :: vector < std :: string > SKYBOX_TEXTURES {{ \"textures/skybox/right.jpg\" , \"textures/skybox/left.jpg\" , \"textures/skybox/top.jpg\" , \"textures/skybox/bottom.jpg\" , \"textures/skybox/front.jpg\" , \"textures/skybox/back.jpg\" }}; // load cubemap // -------------- // cubemaps are loaded just like other textures unsigned int skyboxID ; glGenTextures ( 1 , & skyboxID ); glBindTexture ( GL_TEXTURE_CUBE_MAP , skyboxID ); // you need to load each image manually though int width , height , nrChannels ; unsigned char * data ; unsigned int count { 0 }; // load each side of the cube map for ( std :: string skyboxTexture : SKYBOX_TEXTURES ){ std :: string skyboxTexturePath = CWD + skyboxTexture ; data = stbi_load ( skyboxTexturePath . c_str (), & width , & height , & nrChannels , 0 ); glTexImage2D ( GL_TEXTURE_CUBE_MAP_POSITIVE_X + count , 0 , GL_RGB , width , height , 0 , GL_RGB , GL_UNSIGNED_BYTE , data ); ++ count ; } // specify wrapping and fitering methods glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_MAG_FILTER , GL_LINEAR ); glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_MIN_FILTER , GL_LINEAR ); glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_WRAP_S , GL_CLAMP_TO_EDGE ); glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_WRAP_T , GL_CLAMP_TO_EDGE ); // this is the textures wrapping method in the r coordinate (like z for positions) glTexParameteri ( GL_TEXTURE_CUBE_MAP , GL_TEXTURE_WRAP_R , GL_CLAMP_TO_EDGE ); Unlike regular textures, you need to load an image into each channel. A skybox is a way to make the environment seem much bigger than it is. Cubemaps are usually used for skyboxes and reflections.","title":"Creating a cube map"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/#displaying-the-skybox","text":"You need to create a cube to sample from. The cube is get the view matrix of the camera, but always with the position at 0. What's interesting is that when you sample the color for the cube, it's from a 3d vector. GLSL converts the 3d vector into texture coordinates for the skybox. Note that if you render the whole skybox first, you are running the fragment shader for fragments that you don't need to. It's better render the skybox last, after the depth buffer has been filled, and only render it on the parts of the depth buffer that are 0.0. The problem is that because the skybox is not large, it will be drawn over all the other objects. We need to trick the depth buffer into thinking the skybox is drawn at 1.0 depth (the maximum). This is done in the vertex shader by setting the z value to it's w value, because the depth is derived by dividing the z by the w. That way we know it's maximum depth, and if we draw the skybox after everything else it will only draw where there is nothing else.","title":"Displaying the skybox"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/#environment-mapping","text":"Now that we have a skybox, we can use this in our shaders using environment mapping for reflection and refractions *.","title":"Environment Mapping"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/#reflection","text":"In vfx Reflection samples from the currently loaded scene, but in GL it has to sample from something prebaked (or draw the entire scene again). With a cubemap you can get pretty good looking static reflections. Basically you get the reflection vector based on the interpolated normal and position, and then sample the cube map with it. #version 330 core out vec4 FragColor ; in vec3 Normal ; in vec3 Position ; uniform vec3 cameraPos ; uniform samplerCube skybox ; void main () { vec3 I = normalize ( Position - cameraPos ); vec3 R = reflect ( I , normalize ( Normal )); FragColor = vec4 ( texture ( skybox , R ). rgb , 1.0 ); } Refraction is similar, but like reflection of course it won't render the things behind it. You basically slightly bend the vector of the camera position. void main () { float ratio = 1.00 / 1.52 ; vec3 I = normalize ( Position - cameraPos ); vec3 R = refract ( I , normalize ( Normal ), ratio ); FragColor = vec4 ( texture ( skybox , R ). rgb , 1.0 ); }","title":"Reflection"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/006_Cubemaps/#dynamic-envinronment-maps","text":"While a static maps looks great, you can also generate these maps live based on a sample position and writing things to the frambuffer. This looks great but is very expensive, so the amount of samples is kept as low as possible.","title":"Dynamic Envinronment Maps"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/007_Advanced_Data/","text":"Advanced Data There are some alternative approaches to managing buffer. Essentially a buffer is just an object that manages a certain portion of GPU memory. We give meaning to the buffer by defining a specific buffer target . We can also bind NULL as the argument for a buffer, if we want to reserve a specific amount of memory and come back to it later. We can also fill specific regions of a buffer with glBufferSubData . This allows us to only updace certain regions of the buffer's memory. Note that you need enough memory allocated for this to fill. glBufferSubData ( GL_ARRAY_BUFFER , 24 , sizeof ( data ), & data ); You can also get a pointer to the buffer's memory directly and copy the data in yourself. float data [] = ... glBindBuffer ( GL_ARRAY_BUFFER , buffer ); // get pointer void * ptr = glMapBuffer ( GL_ARRAY_BUFFER , GL_WRITE_ONLY ); // copy the data into memory memcpy ( ptr , data , sizeof ( data )); // tell opengl that we are done with the buffer glUnmapBuffer ( GL_ARRAY_BUFFER ); This way we can directly map data to a buffer, without first allocating temporary memory. Batching vertex attributes We can specify the attribute layout of the vertex array buffer's content with glVertexAttribPointer . Instead of interleaving the data, 123123123123 we can also use a batched approach 111222333. The batching approach makes individual elements of data easier to update with glBufferSubData . float positions [] { ... }; float normals [] { ... }; float uvs [] { ... }; // fill the buffer glBufferSubData ( GL_ARRAY_BUFFER , 0 , sizeof ( positions ), & positions ); glBufferSubData ( GL_ARRAY_BUFFER , sizeof ( positions ), sizeof ( normals ), & normals ); glBufferSubData ( GL_ARRAY_BUFFER , sizeof ( positions ) + sizeof ( normals ), sizeof ( uvs ), & uvs ); // update the vertex attrib pointers to reflect thsoe changes glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), 0 ); glVertexAttribPointer ( 1 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * )( sizeof ( positions ))); glVertexAttribPointer ( 2 , 2 , GL_FLOAT , GL_FALSE , 2 * sizeof ( float ), ( void * ) sizeof ( positions ) + sizeof ( normals ))); Now the stride parameter is the same for all the vertx attributes, and only the offset is really different. This shouldn't be used if you are not updating the buffer though, the interleaved approach is faster for the GPU to read. Copying buffers You can copy data from one buffer into another one directly. To do this you need to define a from and to target. This could be VERTEX_ARRAY_BUFFER and VERTEX_ELEMENT_ARRAY_BUFFER, but if you want to copy from and to vertex buffers you can use GL_COPY_READ_BUFFER and GL_COPY_WRITE_BUFFER. // this glBindBuffer ( GL_COPY_READ_BUFFER , vbo1 ); glBindBuffer ( GL_COPY_WRITE_BUFFER , vbo2 ); glCopyBufferSubData ( GL_COPY_READ_BUFFER , GL_COPY_WRITE_BUFFER , 0 , 0 , 8 * sizeof ( float )); // could also be done like this glBindBuffer ( GL_ARRAY_BUFFER , vbo1 ); glBindBuffer ( GL_COPY_WRITE_BUFFER , 0 , 0 , 8 * sizeof ( float ));","title":"Advanced Data"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/007_Advanced_Data/#advanced-data","text":"There are some alternative approaches to managing buffer. Essentially a buffer is just an object that manages a certain portion of GPU memory. We give meaning to the buffer by defining a specific buffer target . We can also bind NULL as the argument for a buffer, if we want to reserve a specific amount of memory and come back to it later. We can also fill specific regions of a buffer with glBufferSubData . This allows us to only updace certain regions of the buffer's memory. Note that you need enough memory allocated for this to fill. glBufferSubData ( GL_ARRAY_BUFFER , 24 , sizeof ( data ), & data ); You can also get a pointer to the buffer's memory directly and copy the data in yourself. float data [] = ... glBindBuffer ( GL_ARRAY_BUFFER , buffer ); // get pointer void * ptr = glMapBuffer ( GL_ARRAY_BUFFER , GL_WRITE_ONLY ); // copy the data into memory memcpy ( ptr , data , sizeof ( data )); // tell opengl that we are done with the buffer glUnmapBuffer ( GL_ARRAY_BUFFER ); This way we can directly map data to a buffer, without first allocating temporary memory.","title":"Advanced Data"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/007_Advanced_Data/#batching-vertex-attributes","text":"We can specify the attribute layout of the vertex array buffer's content with glVertexAttribPointer . Instead of interleaving the data, 123123123123 we can also use a batched approach 111222333. The batching approach makes individual elements of data easier to update with glBufferSubData . float positions [] { ... }; float normals [] { ... }; float uvs [] { ... }; // fill the buffer glBufferSubData ( GL_ARRAY_BUFFER , 0 , sizeof ( positions ), & positions ); glBufferSubData ( GL_ARRAY_BUFFER , sizeof ( positions ), sizeof ( normals ), & normals ); glBufferSubData ( GL_ARRAY_BUFFER , sizeof ( positions ) + sizeof ( normals ), sizeof ( uvs ), & uvs ); // update the vertex attrib pointers to reflect thsoe changes glVertexAttribPointer ( 0 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), 0 ); glVertexAttribPointer ( 1 , 3 , GL_FLOAT , GL_FALSE , 3 * sizeof ( float ), ( void * )( sizeof ( positions ))); glVertexAttribPointer ( 2 , 2 , GL_FLOAT , GL_FALSE , 2 * sizeof ( float ), ( void * ) sizeof ( positions ) + sizeof ( normals ))); Now the stride parameter is the same for all the vertx attributes, and only the offset is really different. This shouldn't be used if you are not updating the buffer though, the interleaved approach is faster for the GPU to read.","title":"Batching vertex attributes"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/007_Advanced_Data/#copying-buffers","text":"You can copy data from one buffer into another one directly. To do this you need to define a from and to target. This could be VERTEX_ARRAY_BUFFER and VERTEX_ELEMENT_ARRAY_BUFFER, but if you want to copy from and to vertex buffers you can use GL_COPY_READ_BUFFER and GL_COPY_WRITE_BUFFER. // this glBindBuffer ( GL_COPY_READ_BUFFER , vbo1 ); glBindBuffer ( GL_COPY_WRITE_BUFFER , vbo2 ); glCopyBufferSubData ( GL_COPY_READ_BUFFER , GL_COPY_WRITE_BUFFER , 0 , 0 , 8 * sizeof ( float )); // could also be done like this glBindBuffer ( GL_ARRAY_BUFFER , vbo1 ); glBindBuffer ( GL_COPY_WRITE_BUFFER , 0 , 0 , 8 * sizeof ( float ));","title":"Copying buffers"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/","text":"Advanced GLSL This chapter has good to knows and features that may make your life easier GLSL'S build-in variables Because shaders are so pipelined, if you wan data from any source outside the current shader, that data needs to be passed through that pipeline. The built in variables makes it easier to gather and/or write data. This does not cover all the variables, so check the wiki for all of them. Vertex shader variables gl_Positions is the clip-space output position vector of the vertex shader. Without is you can't render anything. gl_PointSize is a variables you can set when rendering geometry of type GL_POINTS where each vertex is rendered as a primitive. It sets the size of this primitive from the shader. You can also set it with glPointSize function, but that can't be influenced by the shader. You need to enable the shader exporting the point size with glEnable(GL_PROGRAM_POINT_SIZE). This is great for things like particle generation. gl_VertexID is a read-only shader variable that holds the current ID of the vertex we're drawing. If drawing with glDrawElements, this holds the curernt index, while if rendering with glDrawArrays it holds the current vertex. Fragment shader variables gl_FragCoord is the window or screen-space coordinate of the fragment. You could use this to calculate a different color value based on the screen coordinate of a fragment. gl_FrontFacing is a read-only boolean that returns if a fragment is front facing based on it's vertex winding order. You could use this to draw a different material on the insice of an object to the outside. gl_FragDepth is a read/write variable that you can use to set the depth of your fragment. This is helpful to control in which order objects are drawn on top of each other. It's major disadvantage is that setting this in the fragment shader then disables early depth testing . Interface blocks If you want to send large collections of data between shaders, you can define interface blocks that work a lot like structs. The only difference is that they are declared with the in/out keyword insteat of struct. out VS_OUT { vec2 TexCoords ; } vs out ; void main (){ ... vs_out . TexCoords = aTexCoords ; } ------- frag -------- in VS_OUT { vec2 TexCoords ; } fs_in ; ... You just need to make sure that all of the parameters are the same, and that the types are named the same. Uniform buffer objects One annoying thing is setting the same variables on all the shaders of our rendering pipeline. Uniform buffer objects allow us to declare a set of global uniform variables that are the same for all shader programs. Because they are buffers, we create them with glGenBuffers as GL_UNIFORM_BUFFER. In the shader you access them like this: layout ( std140 ) uniform Matrices { mat4 projection ; mat4 view ; }; // you can access these variables directly without a prefix void main (){ gl_Position = projection * view * model * vec4 ( aPos , 1.0 ); } But what does layout std140 mean?? This states that the uniform block uses a specific layout called a uniform block layout . Uniform block layout Because a uniform buffer is a buffer we need an attrib pointer to it. Consider the following buffer: layout ( std140 ) uniform ExampleBlock { float value ; vec3 vector ; mat4 matrix ; float values [ 3 ];; bool boolean ; int integer ; }; How do we know the size of this struct so that we can bind it to the GPU memory appropriately. GLSL uses a uniform memory layout called a shaded layout by default. Shared because it's shared between multiple programs. Getting the offsets in a shared layout is a lot of work though, so the general practice is to not use a shared layout but a std140 layout. This standardizes all of the offsets. In a std140 layout, each variable has a base alignment equal to the space it takes up (including padding) within a uniform block. An aligned offset (the byte offset of a varialbe from the start of the block) is calculated for each variable. This offset must be equal to a multiple of its base alignment. You can find the exact layout rules for each type here layout ( std140 ) uniform ExampleBlock { // base alignment // aligned offset float value ; // 4 // 0 vec3 vector ; // 16 // 16 (offset must be multiple of 16 so 4->16) mat4 matrix ; // 16 // 32 (column 0) // 16 // 48 (column 1) // 16 // 64 (column 2) // 16 // 80 (column 3) float values [ 3 ]; // 16 // 96 (values[0]) // 16 // 112 (values[1]) // 16 // 128 (values[2]) bool boolean ; // 4 // 144 int integer ; // 4 // 148 }; It's not the most efficient layout, but it guarantees us that the layout remains the same in each program. There is also the shared layout, as mentioned above, as well as the packed layout. The packed layout optimizes for each program individually, and you have no guarantees as to the address of the variables. Using uniform buffers unsigned int uboExampleBlock ; glGenBuffers ( 1 , & uboExampleBlock ); glBindBuffer ( GL_UNIFORM_BUFFER , uboExampleBlock ); glBufferData ( GL_UNIFORM_BUFFER , 152 , NULL , GL_STATIC_DRAW ); // allocate 152 butes of memory glBindBuffer ( GL_UNIFORM_BUFFER , 0 ); After this, whenever we want to update or insert data into the buffer, we bind it and then update it with glBufferSubData (as discussed in the previous chapter). The uniform will only need to get updated once, and all shaders will get it. When you bind multiple uniforms to programs, they attach at different binding points. By attaching the programs at the same binding points, they are sharing the same data in gpu memory. In the above you can see that both shaders are bount to the 0 binding point which is where the matrices are stored. To specify a specific binding point, you use glUniformBlockBinding and give it an index. This is how the shaders are able to shader the data. Note that you have to do this for every shader that uses the buffer unsigned int lights_index = glGetUniformBlockIndex ( shaderA . ID , \" Lights \" ); glUniformBlockBinding ( shaderA . ID , lights_index , 2 ); Note In OpenGL version 4.2, you can specify this in the shader itself effectively skipping the above step layout ( std140 , binding = 2 ) uniform Lights { ... }; After his we just need to bind the buffer object to that same binding point // The function expects a target, a binding point index, and a uniform buffer object. glBindBufferBase ( GL_UNIFORM_BUFFER , 2 , uboExampleBlock ); // or // You can also just bind a specific range with glBindBufferRange ( GL_UNIFORM_BUFFER , 2 , uboExampleBlock , 0 , 152 ); // now we can start adding data. We can add all the data at once // or just update parts of the buffer with glBufferSubData glBindBuffer ( GL_UNIFORM_BUFFER , uboExampleBlock ); int b = true ; // update only the boolean value glBufferSubData ( GL_UNIFORM_BUFFER , 144 , 4 , & b ); glBindBuffer ( GL_UNIFORM_BUFFER , 0 ); Uniform buffer objects have severl advantages: Setting lots of uniforms at once is faster than setting multiple uniforms one at a time. Changing the same uniform over multiple shaders only need to be done once There is a much higher limit to the amount of uniforms in a buffer object than free uniforms that OpenGL can store. This come into play with skeletal animation for example.","title":"Advanced GLSL"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#advanced-glsl","text":"This chapter has good to knows and features that may make your life easier","title":"Advanced GLSL"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#glsls-build-in-variables","text":"Because shaders are so pipelined, if you wan data from any source outside the current shader, that data needs to be passed through that pipeline. The built in variables makes it easier to gather and/or write data. This does not cover all the variables, so check the wiki for all of them.","title":"GLSL'S build-in variables"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#vertex-shader-variables","text":"gl_Positions is the clip-space output position vector of the vertex shader. Without is you can't render anything. gl_PointSize is a variables you can set when rendering geometry of type GL_POINTS where each vertex is rendered as a primitive. It sets the size of this primitive from the shader. You can also set it with glPointSize function, but that can't be influenced by the shader. You need to enable the shader exporting the point size with glEnable(GL_PROGRAM_POINT_SIZE). This is great for things like particle generation. gl_VertexID is a read-only shader variable that holds the current ID of the vertex we're drawing. If drawing with glDrawElements, this holds the curernt index, while if rendering with glDrawArrays it holds the current vertex.","title":"Vertex shader variables"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#fragment-shader-variables","text":"gl_FragCoord is the window or screen-space coordinate of the fragment. You could use this to calculate a different color value based on the screen coordinate of a fragment. gl_FrontFacing is a read-only boolean that returns if a fragment is front facing based on it's vertex winding order. You could use this to draw a different material on the insice of an object to the outside. gl_FragDepth is a read/write variable that you can use to set the depth of your fragment. This is helpful to control in which order objects are drawn on top of each other. It's major disadvantage is that setting this in the fragment shader then disables early depth testing .","title":"Fragment shader variables"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#interface-blocks","text":"If you want to send large collections of data between shaders, you can define interface blocks that work a lot like structs. The only difference is that they are declared with the in/out keyword insteat of struct. out VS_OUT { vec2 TexCoords ; } vs out ; void main (){ ... vs_out . TexCoords = aTexCoords ; } ------- frag -------- in VS_OUT { vec2 TexCoords ; } fs_in ; ... You just need to make sure that all of the parameters are the same, and that the types are named the same.","title":"Interface blocks"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#uniform-buffer-objects","text":"One annoying thing is setting the same variables on all the shaders of our rendering pipeline. Uniform buffer objects allow us to declare a set of global uniform variables that are the same for all shader programs. Because they are buffers, we create them with glGenBuffers as GL_UNIFORM_BUFFER. In the shader you access them like this: layout ( std140 ) uniform Matrices { mat4 projection ; mat4 view ; }; // you can access these variables directly without a prefix void main (){ gl_Position = projection * view * model * vec4 ( aPos , 1.0 ); } But what does layout std140 mean?? This states that the uniform block uses a specific layout called a uniform block layout .","title":"Uniform buffer objects"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#uniform-block-layout","text":"Because a uniform buffer is a buffer we need an attrib pointer to it. Consider the following buffer: layout ( std140 ) uniform ExampleBlock { float value ; vec3 vector ; mat4 matrix ; float values [ 3 ];; bool boolean ; int integer ; }; How do we know the size of this struct so that we can bind it to the GPU memory appropriately. GLSL uses a uniform memory layout called a shaded layout by default. Shared because it's shared between multiple programs. Getting the offsets in a shared layout is a lot of work though, so the general practice is to not use a shared layout but a std140 layout. This standardizes all of the offsets. In a std140 layout, each variable has a base alignment equal to the space it takes up (including padding) within a uniform block. An aligned offset (the byte offset of a varialbe from the start of the block) is calculated for each variable. This offset must be equal to a multiple of its base alignment. You can find the exact layout rules for each type here layout ( std140 ) uniform ExampleBlock { // base alignment // aligned offset float value ; // 4 // 0 vec3 vector ; // 16 // 16 (offset must be multiple of 16 so 4->16) mat4 matrix ; // 16 // 32 (column 0) // 16 // 48 (column 1) // 16 // 64 (column 2) // 16 // 80 (column 3) float values [ 3 ]; // 16 // 96 (values[0]) // 16 // 112 (values[1]) // 16 // 128 (values[2]) bool boolean ; // 4 // 144 int integer ; // 4 // 148 }; It's not the most efficient layout, but it guarantees us that the layout remains the same in each program. There is also the shared layout, as mentioned above, as well as the packed layout. The packed layout optimizes for each program individually, and you have no guarantees as to the address of the variables.","title":"Uniform block layout"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/008_Advanced_GLSL/#using-uniform-buffers","text":"unsigned int uboExampleBlock ; glGenBuffers ( 1 , & uboExampleBlock ); glBindBuffer ( GL_UNIFORM_BUFFER , uboExampleBlock ); glBufferData ( GL_UNIFORM_BUFFER , 152 , NULL , GL_STATIC_DRAW ); // allocate 152 butes of memory glBindBuffer ( GL_UNIFORM_BUFFER , 0 ); After this, whenever we want to update or insert data into the buffer, we bind it and then update it with glBufferSubData (as discussed in the previous chapter). The uniform will only need to get updated once, and all shaders will get it. When you bind multiple uniforms to programs, they attach at different binding points. By attaching the programs at the same binding points, they are sharing the same data in gpu memory. In the above you can see that both shaders are bount to the 0 binding point which is where the matrices are stored. To specify a specific binding point, you use glUniformBlockBinding and give it an index. This is how the shaders are able to shader the data. Note that you have to do this for every shader that uses the buffer unsigned int lights_index = glGetUniformBlockIndex ( shaderA . ID , \" Lights \" ); glUniformBlockBinding ( shaderA . ID , lights_index , 2 ); Note In OpenGL version 4.2, you can specify this in the shader itself effectively skipping the above step layout ( std140 , binding = 2 ) uniform Lights { ... }; After his we just need to bind the buffer object to that same binding point // The function expects a target, a binding point index, and a uniform buffer object. glBindBufferBase ( GL_UNIFORM_BUFFER , 2 , uboExampleBlock ); // or // You can also just bind a specific range with glBindBufferRange ( GL_UNIFORM_BUFFER , 2 , uboExampleBlock , 0 , 152 ); // now we can start adding data. We can add all the data at once // or just update parts of the buffer with glBufferSubData glBindBuffer ( GL_UNIFORM_BUFFER , uboExampleBlock ); int b = true ; // update only the boolean value glBufferSubData ( GL_UNIFORM_BUFFER , 144 , 4 , & b ); glBindBuffer ( GL_UNIFORM_BUFFER , 0 ); Uniform buffer objects have severl advantages: Setting lots of uniforms at once is faster than setting multiple uniforms one at a time. Changing the same uniform over multiple shaders only need to be done once There is a much higher limit to the amount of uniforms in a buffer object than free uniforms that OpenGL can store. This come into play with skeletal animation for example.","title":"Using uniform buffers"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/009_Geometry_Shader/","text":"Geometry Shader There is another optional shader which executes between the vertex and fragment shader called the geometry shader . This takes as input a set of vertices that form a primitive, and can then transform and add geometry. This is a geometry shader #version 330 core layout ( points ) in ; layout ( line_strip , max_vertices = 2 ) out ; void main () { gl_Position = gl_in [ 0 ]. gl_Position + vec4 ( - 0.1 , 0.0 , 0.0 , 0.0 ); EmitVertex (); gl_Position = gl_in [ 0 ]. gl_Position + vec4 ( 0.1 , 0.0 , 0.0 , 0.0 ); EmitVertex (); EndPrimitive (); } The in keyword is required to determine what kind of geometry is coming into the shader. Almost all geometry types are supported. We also need to specify a primitive type that the geometry shader will output. This is done by the second layout specifier in the example above. Unlike the input specifier that can take in almost any geometry supported by gl, the output layout qualifier only support three primitive values. points line_strip triangle_strip Triangles would take the triangle_strip, lines the line_strip, and points the points. This shader also expects us to set a maximum number of vertices it outputs. To get data into the geometry shader, you use the gl_in struct which OpenGL provides. Note gl_in is declared as an array struct. It has all of the vertices in the primitive. You create new vertices with EmitVertex(), and end your new primitives with EndPrimitive(). A triangle strip in OpenGL is a more efficient way to draw triangles with fewer vertices. After the first triangle, each subsequent vertex will add a new triangle. With this in mind we can create house shapes out of our points with the following geometry shader #version 330 core layout ( points ) in ; layout ( triangle_strip , max_vertices = 5 ) out ; void build_house ( vec4 position ) { gl_Position = position + vec4 ( - 0.2 , - 0.2 , 0.0 , 0.0 ); // 1:bottom-left EmitVertex (); gl_Position = position + vec4 ( 0.2 , - 0.2 , 0.0 , 0.0 ); // 2:bottom-right EmitVertex (); gl_Position = position + vec4 ( - 0.2 , 0.2 , 0.0 , 0.0 ); // 3:top-left EmitVertex (); gl_Position = position + vec4 ( 0.2 , 0.2 , 0.0 , 0.0 ); // 4:top-right EmitVertex (); gl_Position = position + vec4 ( 0.0 , 0.4 , 0.0 , 0.0 ); // 5:top EmitVertex (); EndPrimitive (); } void main () { build_house ( gl_in [ 0 ]. gl_Position ); } If you want to assign more vertex attributes to the newly created vertices, simply bind the output variables before creating the vertices. fColor = gs_in [ 0 ]. color ; gl_Position = position + vec4 (); EmitVertex (); // this takes te currently bound position and color Exploding objects You can explode all the faces of an object you want to draw by transforming them in the object shader. This is similar to inflating an object in the vertex shader, but the render primitives aren't connected. Note that you only have access to three vertices in the geometry shader that make up the render primitive (line, triangle etc) This is the exploded artwork I came up with Normals","title":"Geometry Shader"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/009_Geometry_Shader/#geometry-shader","text":"There is another optional shader which executes between the vertex and fragment shader called the geometry shader . This takes as input a set of vertices that form a primitive, and can then transform and add geometry. This is a geometry shader #version 330 core layout ( points ) in ; layout ( line_strip , max_vertices = 2 ) out ; void main () { gl_Position = gl_in [ 0 ]. gl_Position + vec4 ( - 0.1 , 0.0 , 0.0 , 0.0 ); EmitVertex (); gl_Position = gl_in [ 0 ]. gl_Position + vec4 ( 0.1 , 0.0 , 0.0 , 0.0 ); EmitVertex (); EndPrimitive (); } The in keyword is required to determine what kind of geometry is coming into the shader. Almost all geometry types are supported. We also need to specify a primitive type that the geometry shader will output. This is done by the second layout specifier in the example above. Unlike the input specifier that can take in almost any geometry supported by gl, the output layout qualifier only support three primitive values. points line_strip triangle_strip Triangles would take the triangle_strip, lines the line_strip, and points the points. This shader also expects us to set a maximum number of vertices it outputs. To get data into the geometry shader, you use the gl_in struct which OpenGL provides. Note gl_in is declared as an array struct. It has all of the vertices in the primitive. You create new vertices with EmitVertex(), and end your new primitives with EndPrimitive(). A triangle strip in OpenGL is a more efficient way to draw triangles with fewer vertices. After the first triangle, each subsequent vertex will add a new triangle. With this in mind we can create house shapes out of our points with the following geometry shader #version 330 core layout ( points ) in ; layout ( triangle_strip , max_vertices = 5 ) out ; void build_house ( vec4 position ) { gl_Position = position + vec4 ( - 0.2 , - 0.2 , 0.0 , 0.0 ); // 1:bottom-left EmitVertex (); gl_Position = position + vec4 ( 0.2 , - 0.2 , 0.0 , 0.0 ); // 2:bottom-right EmitVertex (); gl_Position = position + vec4 ( - 0.2 , 0.2 , 0.0 , 0.0 ); // 3:top-left EmitVertex (); gl_Position = position + vec4 ( 0.2 , 0.2 , 0.0 , 0.0 ); // 4:top-right EmitVertex (); gl_Position = position + vec4 ( 0.0 , 0.4 , 0.0 , 0.0 ); // 5:top EmitVertex (); EndPrimitive (); } void main () { build_house ( gl_in [ 0 ]. gl_Position ); } If you want to assign more vertex attributes to the newly created vertices, simply bind the output variables before creating the vertices. fColor = gs_in [ 0 ]. color ; gl_Position = position + vec4 (); EmitVertex (); // this takes te currently bound position and color","title":"Geometry Shader"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/009_Geometry_Shader/#exploding-objects","text":"You can explode all the faces of an object you want to draw by transforming them in the object shader. This is similar to inflating an object in the vertex shader, but the render primitives aren't connected. Note that you only have access to three vertices in the geometry shader that make up the render primitive (line, triangle etc) This is the exploded artwork I came up with","title":"Exploding objects"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/009_Geometry_Shader/#normals","text":"","title":"Normals"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/010_Instancing/","text":"Instancing If you are drawing literally thousands of the same object every frame, that many render calls will drastically reduce performance. Compared to rendering the actual vertices, the glDrawArrays and glDrawElements are pretty expensive because of the preperations they need to make. Instancing allows the same object multiple times using a single draw call. This saves us all the CPU -> GPU communications needed each time we need to render an object. To use this we just need to change our draw call from glDrawArrays and glDrawElements to glDrawArraysInstance and glDrawElementsInstanced. These functions take one extra parameter, which is the instnace count . When using shaders with these functions there is one new build-in variable in the vertex shader called gl_InstanceID . You change the position in the vertex shader by indexing a bound position based on the gl_InstanceID #version 330 core layout ( location = 0 ) in vec2 aPos ; layout ( location = 1 ) in vec3 aColor ; out vec3 fColor ; uniform vec2 offsets [ 100 ]; void main () { vec2 offset = offsets [ gl_InstanceID ]; gl_Position = vec4 ( aPos + offset , 0.0 , 1.0 ); fColor = aColor ; } Usigne a uniform array isn't very optimial though, not only because of the fixed amount of object hardcoded into the shader, but also just because of the fairly low memory limit for uniforms. It's much better to intput the data through another buffer which is known as an instanced array . #version 330 core layout ( location = 0 ) in vec2 aPos ; layout ( location = 1 ) in vec3 aColor ; layout ( location = 2 ) in vec2 aOffset ; out vec3 fColor ; void main () { gl_Position = vec4 ( aPos + aOffset , 0.0 , 1.0 ); fColor = aColor ; } For this instance buffer it's going to have a different size to our object buffer. So we create a new VBO, but tell it to update on every second instance call. This is done with a funky function called glVertexAttribDivisor, which tells openGL when to step through the array. At 0 open gl will step by every vertex, but at 1 or above it will step through ever x instance. glEnableVertexAttribArray ( 2 ); glBindBuffer ( GL_ARRAY_BUFFER , instanceVBO ); glVertexAttribPointer ( 2 , 2 , GL_FLOAT , GL_FALSE , 2 * sizeof ( float ), ( void * ) 0 ); glBindBuffer ( GL_ARRAY_BUFFER , 0 ); glVertexAttribDivisor ( 2 , 1 ); In the vertex shader we bind it like any other buffer layout ( location = 0 ) in vec2 aPos ; layout ( location = 1 ) in vec3 aColor ; layout ( location = 2 ) in vec2 aOffset ; Now we will try instancing on a more complex scene. This scene has a bunch of asteroids. I start getting a low fps after increasing the amount to about 6000 We will rewrite the code so that there is not a draw call per asteroid. This time it's a bit more complicated, because we want to bring over the whole mat4 thruogh the buffer. The maximum amount of data in a buffer attrib is equal to a vec4. A mat4 is 4 vec4s so we need to reserve 4 vertex attributes for this matrix. With instancing we can draw 80000 before running into framerate issues (probably because of other unoptimzied stuff)","title":"Instancing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/010_Instancing/#instancing","text":"If you are drawing literally thousands of the same object every frame, that many render calls will drastically reduce performance. Compared to rendering the actual vertices, the glDrawArrays and glDrawElements are pretty expensive because of the preperations they need to make. Instancing allows the same object multiple times using a single draw call. This saves us all the CPU -> GPU communications needed each time we need to render an object. To use this we just need to change our draw call from glDrawArrays and glDrawElements to glDrawArraysInstance and glDrawElementsInstanced. These functions take one extra parameter, which is the instnace count . When using shaders with these functions there is one new build-in variable in the vertex shader called gl_InstanceID . You change the position in the vertex shader by indexing a bound position based on the gl_InstanceID #version 330 core layout ( location = 0 ) in vec2 aPos ; layout ( location = 1 ) in vec3 aColor ; out vec3 fColor ; uniform vec2 offsets [ 100 ]; void main () { vec2 offset = offsets [ gl_InstanceID ]; gl_Position = vec4 ( aPos + offset , 0.0 , 1.0 ); fColor = aColor ; } Usigne a uniform array isn't very optimial though, not only because of the fixed amount of object hardcoded into the shader, but also just because of the fairly low memory limit for uniforms. It's much better to intput the data through another buffer which is known as an instanced array . #version 330 core layout ( location = 0 ) in vec2 aPos ; layout ( location = 1 ) in vec3 aColor ; layout ( location = 2 ) in vec2 aOffset ; out vec3 fColor ; void main () { gl_Position = vec4 ( aPos + aOffset , 0.0 , 1.0 ); fColor = aColor ; } For this instance buffer it's going to have a different size to our object buffer. So we create a new VBO, but tell it to update on every second instance call. This is done with a funky function called glVertexAttribDivisor, which tells openGL when to step through the array. At 0 open gl will step by every vertex, but at 1 or above it will step through ever x instance. glEnableVertexAttribArray ( 2 ); glBindBuffer ( GL_ARRAY_BUFFER , instanceVBO ); glVertexAttribPointer ( 2 , 2 , GL_FLOAT , GL_FALSE , 2 * sizeof ( float ), ( void * ) 0 ); glBindBuffer ( GL_ARRAY_BUFFER , 0 ); glVertexAttribDivisor ( 2 , 1 ); In the vertex shader we bind it like any other buffer layout ( location = 0 ) in vec2 aPos ; layout ( location = 1 ) in vec3 aColor ; layout ( location = 2 ) in vec2 aOffset ; Now we will try instancing on a more complex scene. This scene has a bunch of asteroids. I start getting a low fps after increasing the amount to about 6000 We will rewrite the code so that there is not a draw call per asteroid. This time it's a bit more complicated, because we want to bring over the whole mat4 thruogh the buffer. The maximum amount of data in a buffer attrib is equal to a vec4. A mat4 is 4 vec4s so we need to reserve 4 vertex attributes for this matrix. With instancing we can draw 80000 before running into framerate issues (probably because of other unoptimzied stuff)","title":"Instancing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/011_AntiAliasing/","text":"Anti Aliasing The jagged edges around objects are known as aliasing . There are several anti-aliasing techniques to fight this. The first technique used to be super sample anti-aliasing (SSAA) that temporarily rendered to twice the resolution and then downsampled. This also created a major performance drawback, since it renders a lot more fragments. A more modern technique that grew out of this is called multisample anti-aliasing (MSAA) that brrows from the concepts of SSAA while implementing a much more efficient approach. Multisampling The rasterizer is the part of the pipeline that converts the vertices into fragments for the fragment shader to work on. For more detail on that check out the pipeline map . The rasterzer is what sets the pixels red in the following two images.","title":"Anti Aliasing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/011_AntiAliasing/#anti-aliasing","text":"The jagged edges around objects are known as aliasing . There are several anti-aliasing techniques to fight this. The first technique used to be super sample anti-aliasing (SSAA) that temporarily rendered to twice the resolution and then downsampled. This also created a major performance drawback, since it renders a lot more fragments. A more modern technique that grew out of this is called multisample anti-aliasing (MSAA) that brrows from the concepts of SSAA while implementing a much more efficient approach.","title":"Anti Aliasing"},{"location":"rendering/OpenGL/LearnOpenGL.com/004_Advanced_OpenGl/011_AntiAliasing/#multisampling","text":"The rasterizer is the part of the pipeline that converts the vertices into fragments for the fragment shader to work on. For more detail on that check out the pipeline map . The rasterzer is what sets the pixels red in the following two images.","title":"Multisampling"},{"location":"rendering/shaders/TheArtOfCode/ShaderToy_Tutorial_Part_2-Building_stuff_with_circles/","text":"Building Stuff with Circles We can abstract the logic for creating a circle into it's own function: float Circle ( vec2 uv , vec2 p , float r , float blur ){ float d = length ( uv - p ); float c = smoothstep ( r , r - blur , d ); return c ; } Now how to offset the potiion of the circle? We do this by modifying the uv value and puttin it into a new circle. If we want to add another circle, we need to add or subtract it from the existing circle float c = Circle ( uv , vec2 ( 0 , 0 ), .4 , .01 ); c -= Circle ( uv , vec2 ( .2 , .1 ), .1 , .01 ); c -= Circle ( uv , vec2 ( -.2 , .1 ), .1 , .01 ); You can change the color by casting the c mask to col vec3 col = c * vec3 ( 1. , 0. , 1. ); Now that we're making a smiley we might as well make a mouth. One way to do this is to have two circles, one subtracted from another. // Normalized pixel coordinates (from 0 to 1) vec2 uv = fragCoord / iResolution . xy ; uv -= .5 ; // -0.5 <> 0.5 uv . x *= iResolution . x / iResolution . y ; // the head float c = Circle ( uv , vec2 ( 0 , 0 ), .4 , .01 ); // the mouth float mouth_y = -.1 ; float mouth_height = 0.2 ; float mouth_r = .25 ; float mouth = Circle ( uv , vec2 ( 0 , mouth_y ), mouth_r , .01 ); mouth -= Circle ( uv , vec2 ( 0 , mouth_y + mouth_height ), mouth_r + .05 , 0.01 ); if ( mouth < 0. ){ mouth = 0. ;} c -= mouth ; // the eyes c -= Circle ( uv , vec2 ( .2 , .1 ), .1 , .01 ); c -= Circle ( uv , vec2 ( -.2 , .1 ), .1 , .01 ); vec3 col = c * vec3 ( 1. , 0. , 1. ); // Output to screen fragColor = vec4 ( col , 1.0 );","title":"Building Stuff with Circles"},{"location":"rendering/shaders/TheArtOfCode/ShaderToy_Tutorial_Part_2-Building_stuff_with_circles/#building-stuff-with-circles","text":"We can abstract the logic for creating a circle into it's own function: float Circle ( vec2 uv , vec2 p , float r , float blur ){ float d = length ( uv - p ); float c = smoothstep ( r , r - blur , d ); return c ; } Now how to offset the potiion of the circle? We do this by modifying the uv value and puttin it into a new circle. If we want to add another circle, we need to add or subtract it from the existing circle float c = Circle ( uv , vec2 ( 0 , 0 ), .4 , .01 ); c -= Circle ( uv , vec2 ( .2 , .1 ), .1 , .01 ); c -= Circle ( uv , vec2 ( -.2 , .1 ), .1 , .01 ); You can change the color by casting the c mask to col vec3 col = c * vec3 ( 1. , 0. , 1. ); Now that we're making a smiley we might as well make a mouth. One way to do this is to have two circles, one subtracted from another. // Normalized pixel coordinates (from 0 to 1) vec2 uv = fragCoord / iResolution . xy ; uv -= .5 ; // -0.5 <> 0.5 uv . x *= iResolution . x / iResolution . y ; // the head float c = Circle ( uv , vec2 ( 0 , 0 ), .4 , .01 ); // the mouth float mouth_y = -.1 ; float mouth_height = 0.2 ; float mouth_r = .25 ; float mouth = Circle ( uv , vec2 ( 0 , mouth_y ), mouth_r , .01 ); mouth -= Circle ( uv , vec2 ( 0 , mouth_y + mouth_height ), mouth_r + .05 , 0.01 ); if ( mouth < 0. ){ mouth = 0. ;} c -= mouth ; // the eyes c -= Circle ( uv , vec2 ( .2 , .1 ), .1 , .01 ); c -= Circle ( uv , vec2 ( -.2 , .1 ), .1 , .01 ); vec3 col = c * vec3 ( 1. , 0. , 1. ); // Output to screen fragColor = vec4 ( col , 1.0 );","title":"Building Stuff with Circles"},{"location":"rendering/shaders/TheArtOfCode/Shadertoy_for_absolute_beginners/","text":"Shadertoy for absolute beginners In this tutorial we will make a circle. A shader is a little program that takes some input and output just a pixel color. A pixel color consists of three float ( between 0 and 1 ). Then there is also the alpha channel, but shadertoy doesn't really use for anything. Shadertoy takes the output variables fragColor and assigns a vec4 (rgba) to it. The uv is an input for the shader to figure out what color to output. For example you can create a gradient from left to right from black to red by assigning the uv.x to the r component of the fragColor. You calculate the uv based on the pixel coordinate, which depends on the size of the screen. The Uv is the normalized pixel coordinate. vec2 uv = fragCoord / iResolution . xy ; Let's figure out how to draw a circle. We can do this by picking a point on the screen, and compare the distance to that point to figure out if the pixels are in or out of the circle. We then use a smoothstep to soften the edges of the circle. uv -= .5 ; // -0.5 <> 0.5 uv . x *= iResolution . x / iResolution . y ; float d = length ( uv ); float r = 0.3 ; float c = smoothstep ( r , r -0.01 , d ); // Output to screen fragColor = vec4 ( vec3 ( c ), 1.0 );","title":"Shadertoy for absolute beginners"},{"location":"rendering/shaders/TheArtOfCode/Shadertoy_for_absolute_beginners/#shadertoy-for-absolute-beginners","text":"In this tutorial we will make a circle. A shader is a little program that takes some input and output just a pixel color. A pixel color consists of three float ( between 0 and 1 ). Then there is also the alpha channel, but shadertoy doesn't really use for anything. Shadertoy takes the output variables fragColor and assigns a vec4 (rgba) to it. The uv is an input for the shader to figure out what color to output. For example you can create a gradient from left to right from black to red by assigning the uv.x to the r component of the fragColor. You calculate the uv based on the pixel coordinate, which depends on the size of the screen. The Uv is the normalized pixel coordinate. vec2 uv = fragCoord / iResolution . xy ; Let's figure out how to draw a circle. We can do this by picking a point on the screen, and compare the distance to that point to figure out if the pixels are in or out of the circle. We then use a smoothstep to soften the edges of the circle. uv -= .5 ; // -0.5 <> 0.5 uv . x *= iResolution . x / iResolution . y ; float d = length ( uv ); float r = 0.3 ; float c = smoothstep ( r , r -0.01 , d ); // Output to screen fragColor = vec4 ( vec3 ( c ), 1.0 );","title":"Shadertoy for absolute beginners"}]}